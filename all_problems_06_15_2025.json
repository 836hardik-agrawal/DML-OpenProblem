[
    {
        "description": "Write a Python function that computes the dot product of a matrix and a vector. The function should return a list representing the resulting vector if the operation is valid, or -1 if the matrix and vector dimensions are incompatible. A matrix (a list of lists) can be dotted with a vector (a list) only if the number of columns in the matrix equals the length of the vector. For example, an n x m matrix requires a vector of length m.",
        "mdx_file": "2416a2a2-3b84-4a4f-9706-27ec64420715.mdx",
        "tinygrad_difficulty": "easy",
        "id": "1",
        "test_cases": [
            {
                "test": "print(matrix_dot_vector([[1, 2, 3], [2, 4, 5], [6, 8, 9]], [1, 2, 3]))",
                "expected_output": "[14, 25, 49]"
            },
            {
                "test": "print(matrix_dot_vector([[1, 2], [2, 4], [6, 8], [12, 4]], [1, 2, 3]))",
                "expected_output": "-1"
            },
            {
                "test": "print(matrix_dot_vector([[1.5, 2.5], [3.0, 4.0]], [2, 1]))",
                "expected_output": "[5.5, 10.0]"
            }
        ],
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIG1hdHJpeF9kb3RfdmVjdG9yX3RnKGEsIGIpIC0+IFRlbnNvcjoKICAgICIiIgogICAgQ29tcHV0ZSB0aGUgcHJvZHVjdCBvZiBtYXRyaXggYGFgIGFuZCB2ZWN0b3IgYGJgIHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdGlueWdyYWQgVGVuc29ycy4KICAgIFJldHVybnMgYSAxLUQgVGVuc29yIG9mIGxlbmd0aCBtLCBvciBUZW5zb3IoLTEpIGlmIGRpbWVuc2lvbnMgbWlzbWF0Y2guCiAgICAiIiIKICAgICMgRGltZW5zaW9uIG1pc21hdGNoIGNoZWNrCiAgICBpZiBsZW4oYVswXSkgIT0gbGVuKGIpOgogICAgICAgIHJldHVybiBUZW5zb3IoLTEpCiAgICAjIENvbnZlcnQgdG8gVGVuc29yCiAgICBhX3QgPSBUZW5zb3IoYSkKICAgIGJfdCA9IFRlbnNvcihiKQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "difficulty": "easy",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIG1hdHJpeF9kb3RfdmVjdG9yX3RnKGEsIGIpIC0+IFRlbnNvcjoKICAgICIiIgogICAgQ29tcHV0ZSB0aGUgcHJvZHVjdCBvZiBtYXRyaXggYGFgIGFuZCB2ZWN0b3IgYGJgIHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdGlueWdyYWQgVGVuc29ycy4KICAgIFJldHVybnMgYSAxLUQgVGVuc29yIG9mIGxlbmd0aCBtLCBvciBUZW5zb3IoLTEpIGlmIGRpbWVuc2lvbnMgbWlzbWF0Y2guCiAgICAiIiIKICAgIGlmIGxlbihhWzBdKSAhPSBsZW4oYik6CiAgICAgICAgcmV0dXJuIFRlbnNvcigtMSkKICAgIGFfdCA9IFRlbnNvcihhKQogICAgYl90ID0gVGVuc29yKGIpCiAgICByZXR1cm4gYV90Lm1hdG11bChiX3QpCg==",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/DNoLs5tTGAw?si=vpkPobZMA8YY10WY",
        "solution": "def matrix_dot_vector(a: list[list[int|float]], b: list[int|float]) -> list[int|float]:\n    if len(a[0]) != len(b):\n        return -1\n    result = []\n    for row in a:\n        total = 0\n        for i in range(len(row)):\n            total += row[i] * b[i]\n        result.append(total)\n    return result",
        "dislikes": "0",
        "example": {
            "input": "a = [[1, 2], [2, 4]], b = [1, 2]",
            "output": "[5, 10]",
            "reasoning": "Row 1: (1 * 1) + (2 * 2) = 1 + 4 = 5; Row 2: (1 * 2) + (2 * 4) = 2 + 8 = 10"
        },
        "category": "Linear Algebra",
        "starter_code": "def matrix_dot_vector(a: list[list[int|float]], b: list[int|float]) -> list[int|float]:\n\t# Return a list where each element is the dot product of a row of 'a' with 'b'.\n\t# If the number of columns in 'a' does not match the length of 'b', return -1.\n\tpass",
        "learn_section": "\n## Matrix-Vector Dot Product\n\nConsider a matrix $A$ and a vector $v$:\n\n**Matrix $A$ (n x m):**\n$$\nA = \\begin{pmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{pmatrix}\n$$\n\n**Vector $v$ (length m):**\n$$\nv = \\begin{pmatrix}\nv_1 \\\\\nv_2 \\\\\n\\vdots \\\\\nv_m\n\\end{pmatrix}\n$$\n\nThe dot product $A \\cdot v$ produces a new vector of length $n$:\n$$\nA \\cdot v = \\begin{pmatrix}\na_{11}v_1 + a_{12}v_2 + \\cdots + a_{1m}v_m \\\\\na_{21}v_1 + a_{22}v_2 + \\cdots + a_{2m}v_m \\\\\n\\vdots \\\\\na_{n1}v_1 + a_{n2}v_2 + \\cdots + a_{nm}v_m\n\\end{pmatrix}\n$$\n\n### Key Requirement:\nThe number of columns in the matrix ($m$) must equal the length of the vector ($m$). If not, the operation is undefined, and the function should return -1.",
        "title": "Matrix-Vector Dot Product",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = matrix_dot_vector(\n    torch.tensor([[1,2,3],[2,4,5],[6,8,9]], dtype=torch.float),\n    torch.tensor([1,2,3], dtype=torch.float)\n)\nprint(res.numpy().tolist())",
                "expected_output": "[14.0, 25.0, 49.0]"
            },
            {
                "test": "import torch\nres = matrix_dot_vector(\n    torch.tensor([[1,2,3],[2,4,5]], dtype=torch.float),\n    torch.tensor([1,2], dtype=torch.float)\n)\nprint(res.numpy().tolist())",
                "expected_output": "-1"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = matrix_dot_vector_tg(\n    [[1,2,3],[2,4,5],[6,8,9]],\n    [1,2,3]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[14.0, 25.0, 49.0]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = matrix_dot_vector_tg(\n    [[1,2,3],[2,4,5]],\n    [1,2]\n)\nprint(res.numpy().tolist())",
                "expected_output": "-1"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgbWF0cml4X2RvdF92ZWN0b3IoYSwgYikgLT4gdG9yY2guVGVuc29yOgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBwcm9kdWN0IG9mIG1hdHJpeCBgYWAgYW5kIHZlY3RvciBgYmAgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRvcmNoIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMS1EIHRlbnNvciBvZiBsZW5ndGggbSwgb3IgdGVuc29yKC0xKSBpZiBkaW1lbnNpb25zIG1pc21hdGNoLgogICAgIiIiCiAgICBhX3QgPSB0b3JjaC5hc190ZW5zb3IoYSwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBiX3QgPSB0b3JjaC5hc190ZW5zb3IoYiwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBpZiBhX3Quc2l6ZSgxKSAhPSBiX3Quc2l6ZSgwKToKICAgICAgICByZXR1cm4gdG9yY2gudGVuc29yKC0xKQogICAgcmV0dXJuIHRvcmNoLm1hdG11bChhX3QsIGJfdCkK",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgbWF0cml4X2RvdF92ZWN0b3IoYSwgYikgLT4gdG9yY2guVGVuc29yOgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBwcm9kdWN0IG9mIG1hdHJpeCBgYWAgYW5kIHZlY3RvciBgYmAgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRvcmNoIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMS1EIHRlbnNvciBvZiBsZW5ndGggbSwgb3IgdGVuc29yKC0xKSBpZiBkaW1lbnNpb25zIG1pc21hdGNoLgogICAgIiIiCiAgICBhX3QgPSB0b3JjaC5hc190ZW5zb3IoYSwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBiX3QgPSB0b3JjaC5hc190ZW5zb3IoYiwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICAjIERpbWVuc2lvbiBtaXNtYXRjaCBjaGVjawogICAgaWYgYV90LnNpemUoMSkgIT0gYl90LnNpemUoMCk6CiAgICAgICAgcmV0dXJuIHRvcmNoLnRlbnNvcigtMSkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg=="
    },
    {
        "description": "Write a Python function to calculate the covariance matrix for a given set of vectors. The function should take a list of lists, where each inner list represents a feature with its observations, and return a covariance matrix as a list of lists. Additionally, provide test cases to verify the correctness of your implementation.",
        "mdx_file": "96bf8f65-c61a-4c45-b85f-26a01610cb1b.mdx",
        "tinygrad_difficulty": "medium",
        "id": "10",
        "test_cases": [
            {
                "test": "print(calculate_covariance_matrix([[1, 2, 3], [4, 5, 6]]))",
                "expected_output": "[[1.0, 1.0], [1.0, 1.0]]"
            },
            {
                "test": "print(calculate_covariance_matrix([[1, 5, 6], [2, 3, 4], [7, 8, 9]]))",
                "expected_output": "[[7.0, 2.5, 2.5], [2.5, 1.0, 1.0], [2.5, 1.0, 1.0]]"
            }
        ],
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGNhbGN1bGF0ZV9jb3ZhcmlhbmNlX21hdHJpeF90Zyh2ZWN0b3JzKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIENhbGN1bGF0ZSB0aGUgY292YXJpYW5jZSBtYXRyaXggZm9yIGdpdmVuIGZlYXR1cmUgdmVjdG9ycyB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0OiAyRCBhcnJheS1saWtlIG9mIHNoYXBlIChuX2ZlYXR1cmVzLCBuX29ic2VydmF0aW9ucykuCiAgICBSZXR1cm5zIGEgVGVuc29yIG9mIHNoYXBlIChuX2ZlYXR1cmVzLCBuX2ZlYXR1cmVzKS4KICAgICIiIgogICAgdl90ID0gVGVuc29yKHZlY3RvcnMpLmZsb2F0KCkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "difficulty": "easy",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGNhbGN1bGF0ZV9jb3ZhcmlhbmNlX21hdHJpeF90Zyh2ZWN0b3JzKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIENhbGN1bGF0ZSB0aGUgY292YXJpYW5jZSBtYXRyaXggZm9yIGdpdmVuIGZlYXR1cmUgdmVjdG9ycyB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0OiAyRCBhcnJheS1saWtlIG9mIHNoYXBlIChuX2ZlYXR1cmVzLCBuX29ic2VydmF0aW9ucykuCiAgICBSZXR1cm5zIGEgVGVuc29yIG9mIHNoYXBlIChuX2ZlYXR1cmVzLCBuX2ZlYXR1cmVzKS4KICAgICIiIgogICAgdl90ID0gVGVuc29yKHZlY3RvcnMpLmZsb2F0KCkKICAgIG5fZmVhdHVyZXMsIG5fb2JzID0gdl90LnNoYXBlCiAgICAjIGNvbXB1dGUgZmVhdHVyZSBtZWFucwogICAgbWVhbnMgPSB2X3Quc3VtKGF4aXM9MSkucmVzaGFwZShuX2ZlYXR1cmVzLDEpIC8gbl9vYnMKICAgIGNlbnRlcmVkID0gdl90IC0gbWVhbnMKICAgIGNvdiA9IGNlbnRlcmVkLm1hdG11bChjZW50ZXJlZC50cmFuc3Bvc2UoMCwxKSkgLyAobl9vYnMgLSAxKQogICAgcmV0dXJuIGNvdgo=",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/Mmuz3a4idg4",
        "solution": "import numpy as np\n\ndef calculate_covariance_matrix(vectors: list[list[float]]) -> list[list[float]]:\n    n_features = len(vectors)\n    n_observations = len(vectors[0])\n    covariance_matrix = [[0 for _ in range(n_features)] for _ in range(n_features)]\n\n    means = [sum(feature) / n_observations for feature in vectors]\n\n    for i in range(n_features):\n        for j in range(i, n_features):\n            covariance = sum((vectors[i][k] - means[i]) * (vectors[j][k] - means[j]) for k in range(n_observations)) / (n_observations - 1)\n            covariance_matrix[i][j] = covariance_matrix[j][i] = covariance\n\n    return covariance_matrix",
        "dislikes": "0",
        "example": {
            "input": "[[1, 2, 3], [4, 5, 6]]",
            "output": "[[1.0, 1.0], [1.0, 1.0]]",
            "reasoning": "The covariance between the two features is calculated based on their deviations from the mean. For the given vectors, both covariances are 1.0, resulting in a symmetric covariance matrix."
        },
        "category": "Statistics",
        "starter_code": "def calculate_covariance_matrix(vectors: list[list[float]]) -> list[list[float]]:\n\t# Your code here\n\treturn []",
        "learn_section": "## Understanding Covariance Matrix\n\nThe covariance matrix is a fundamental concept in statistics and machine learning, used to understand the relationship between multiple variables (features) in a dataset. It quantifies the degree to which two variables change together.\n\n### Key Concepts\n\n- **Covariance**: Measures the directional relationship between two random variables. A positive covariance indicates that the variables increase together, while a negative covariance indicates that one variable increases as the other decreases.\n- **Covariance Matrix**: For a dataset with $n$ features, the covariance matrix is an $n \\times n$ matrix where each element $(i, j)$ represents the covariance between the $i^{th}$ and $j^{th}$ features.\n\n### Covariance Formula\n\nThe covariance between two variables $X$ and $Y$ is calculated as:\n\n$$\n\\text{cov}(X, Y) = \\frac{\\sum_{k=1}^{m} (X_k - \\bar{X})(Y_k - \\bar{Y})}{m - 1}\n$$\n\nWhere:\n\n- $X_k$ and $Y_k$ are the individual observations of variables $X$ and $Y$.\n- $\\bar{X}$ and $\\bar{Y}$ are the means of $X$ and $Y$.\n- $m$ is the number of observations.\n\n### Constructing the Covariance Matrix\n\nGiven a dataset with $n$ features, the covariance matrix is constructed as follows:\n\n1. **Calculate the Mean**: Compute the mean of each feature.\n2. **Compute Covariance**: For each pair of features, calculate the covariance using the formula above.\n3. **Populate the Matrix**: Place the computed covariance values in the corresponding positions in the matrix. The diagonal elements represent the variance of each feature.\n\n$$\n\\text{Covariance Matrix} =\n\\begin{bmatrix}\n\\text{cov}(X_1, X_1) & \\text{cov}(X_1, X_2) & \\cdots & \\text{cov}(X_1, X_n) \\\\\n\\text{cov}(X_2, X_1) & \\text{cov}(X_2, X_2) & \\cdots & \\text{cov}(X_2, X_n) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\text{cov}(X_n, X_1) & \\text{cov}(X_n, X_2) & \\cdots & \\text{cov}(X_n, X_n) \\\\\n\\end{bmatrix}\n$$\n\n### Example Calculation\n\nConsider the following dataset with two features:\n\n$$\n\\begin{align*}\n\\text{Feature 1} &: [1, 2, 3] \\\\\n\\text{Feature 2} &: [4, 5, 6]\n\\end{align*}\n$$\n\n1. **Calculate Means**:\n   $$\n   \\bar{X}_1 = \\frac{1 + 2 + 3}{3} = 2.0 \\\\\n   \\bar{X}_2 = \\frac{4 + 5 + 6}{3} = 5.0\n   $$\n\n2. **Compute Covariances**:\n   $$\n   \\text{cov}(X_1, X_1) = \\frac{(1-2)^2 + (2-2)^2 + (3-2)^2}{3-1} = 1.0 \\\\\n   \\text{cov}(X_1, X_2) = \\frac{(1-2)(4-5) + (2-2)(5-5) + (3-2)(6-5)}{3-1} = 1.0 \\\\\n   \\text{cov}(X_2, X_2) = \\frac{(4-5)^2 + (5-5)^2 + (6-5)^2}{3-1} = 1.0\n   $$\n\n3. **Covariance Matrix**:\n   $$\n   \\begin{bmatrix}\n   1.0 & 1.0 \\\\\n   1.0 & 1.0 \n   \\end{bmatrix}\n   $$\n\n### Applications\n\nCovariance matrices are widely used in various fields, including:\n\n- **Principal Component Analysis (PCA)**: Reducing the dimensionality of datasets while preserving variance.\n- **Portfolio Optimization**: Understanding the variance and covariance between different financial assets.\n- **Multivariate Statistics**: Analyzing the relationships between multiple variables simultaneously.\n\nUnderstanding the covariance matrix is crucial for interpreting the relationships in multivariate data and for performing advanced statistical analyses.\n",
        "title": "Calculate Covariance Matrix",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nv = [[1.0,2.0,3.0],[4.0,5.0,6.0]]\ncov = calculate_covariance_matrix(v)\nprint(cov.detach().numpy().tolist())",
                "expected_output": "[[1.0, 1.0], [1.0, 1.0]]"
            },
            {
                "test": "import torch\nv = [[1.0,2.0,3.0],[3.0,3.0,3.0]]\ncov = calculate_covariance_matrix(v)\nprint(cov.detach().numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 0.0]]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = calculate_covariance_matrix_tg([[1.0,2.0,3.0],[4.0,5.0,6.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 1.0], [1.0, 1.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = calculate_covariance_matrix_tg([[1.0,2.0,3.0],[3.0,3.0,3.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 0.0]]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgY2FsY3VsYXRlX2NvdmFyaWFuY2VfbWF0cml4KHZlY3RvcnMpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgQ2FsY3VsYXRlIHRoZSBjb3ZhcmlhbmNlIG1hdHJpeCBmb3IgZ2l2ZW4gZmVhdHVyZSB2ZWN0b3JzIHVzaW5nIFB5VG9yY2guCiAgICBJbnB1dDogMkQgYXJyYXktbGlrZSBvZiBzaGFwZSAobl9mZWF0dXJlcywgbl9vYnNlcnZhdGlvbnMpLgogICAgUmV0dXJucyBhIHRlbnNvciBvZiBzaGFwZSAobl9mZWF0dXJlcywgbl9mZWF0dXJlcykuCiAgICAiIiIKICAgIHZfdCA9IHRvcmNoLmFzX3RlbnNvcih2ZWN0b3JzLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgICMgdXNlIGJ1aWx0LWluIGNvdmFyaWFuY2UKICAgIHJldHVybiB0b3JjaC5jb3Yodl90KQo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgY2FsY3VsYXRlX2NvdmFyaWFuY2VfbWF0cml4KHZlY3RvcnMpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgQ2FsY3VsYXRlIHRoZSBjb3ZhcmlhbmNlIG1hdHJpeCBmb3IgZ2l2ZW4gZmVhdHVyZSB2ZWN0b3JzIHVzaW5nIFB5VG9yY2guCiAgICBJbnB1dDogMkQgYXJyYXktbGlrZSBvZiBzaGFwZSAobl9mZWF0dXJlcywgbl9vYnNlcnZhdGlvbnMpLgogICAgUmV0dXJucyBhIHRlbnNvciBvZiBzaGFwZSAobl9mZWF0dXJlcywgbl9mZWF0dXJlcykuCiAgICAiIiIKICAgIHZfdCA9IHRvcmNoLmFzX3RlbnNvcih2ZWN0b3JzLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg=="
    },
    {
        "description": "Implement the Softsign activation function, a smooth activation function used in neural networks. Your task is to compute the Softsign value for a given input, ensuring the output is bounded between -1 and 1.",
        "id": "100",
        "test_cases": [
            {
                "test": "print(softsign(0))",
                "expected_output": "0.0"
            },
            {
                "test": "print(softsign(1))",
                "expected_output": "0.5"
            },
            {
                "test": "print(softsign(-1))",
                "expected_output": "-0.5"
            },
            {
                "test": "print(softsign(100))",
                "expected_output": "0.9901"
            },
            {
                "test": "print(softsign(-100))",
                "expected_output": "-0.9901"
            }
        ],
        "difficulty": "easy",
        "solution": "def softsign(x: float) -> float:\n    \"\"\"\n    Implements the Softsign activation function.\n\n    Args:\n        x (float): Input value\n\n    Returns:\n        float: The Softsign of the input, calculated as x/(1 + |x|)\n    \"\"\"\n    return round(x / (1 + abs(x)), 4)",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-softsign",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "softsign(1)",
            "output": "0.5",
            "reasoning": "For x = 1, the Softsign activation is calculated as $\\frac{x}{1 + |x|}$."
        },
        "category": "Deep Learning",
        "starter_code": "def softsign(x: float) -> float:\n\t\"\"\"\n\tImplements the Softsign activation function.\n\n\tArgs:\n\t\tx (float): Input value\n\n\tReturns:\n\t\tfloat: The Softsign of the input\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,4)",
        "title": "Implement the Softsign Activation Function",
        "learn_section": "## Understanding the Softsign Activation Function\n\nThe Softsign activation function is a smooth, non-linear activation function used in neural networks. It’s similar to the hyperbolic tangent (tanh) function but with different properties, particularly in its tails which approach their limits more slowly.\n\n### Mathematical Definition\n\nThe Softsign function is mathematically defined as:\n\n$$\nSoftsign(x) = \\frac{x}{1 + |x|}\n$$\n\nWhere:\n- $x$ is the input to the function\n- $|x|$ represents the absolute value of $x$\n\n### Characteristics\n\n- **Output Range:** The output is bounded between -1 and 1, approaching these values asymptotically as $x$ approaches $\\pm \\infty$.\n- **Shape:** The function has an S-shaped curve, similar to tanh but with a smoother approach to its asymptotes.\n- **Gradient:** The gradient is smoother and more gradual compared to tanh, which can help prevent vanishing gradient problems in deep networks.\n- **Symmetry:** The function is symmetric around the origin $(0,0)$.\n\n### Key Properties\n\n- **Bounded Output:** Unlike ReLU, Softsign naturally bounds its output between -1 and 1.\n- **Smoothness:** The function is continuous and differentiable everywhere.\n- **No Saturation:** The gradients approach zero more slowly than in tanh or sigmoid functions.\n- **Zero-Centered:** The function crosses through the origin, making it naturally zero-centered.\n\nThis activation function can be particularly useful in scenarios where you need bounded outputs with more gradual saturation compared to tanh or sigmoid functions.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    },
    {
        "description": "Implement the GRPO (Generalized Relative Policy Optimization) objective function used to optimize policy parameters in reinforcement learning. Your task is to compute the GRPO objective given the likelihood ratios, advantage estimates, old policy probabilities, reference policy probabilities, and apply the clipping mechanism and KL divergence penalty correctly to maintain training stability.",
        "id": "101",
        "test_cases": [
            {
                "test": "print(round(grpo_objective([1.2, 0.8, 1.1], [1.0, 1.0, 1.0], [0.9, 1.1, 1.0], [1.0, 0.5, 1.5], epsilon=0.2, beta=0.01),6))",
                "expected_output": "1.032749"
            },
            {
                "test": "print(round(grpo_objective([0.9, 1.1], [1.0, 1.0], [1.0, 1.0], [0.8, 1.2], epsilon=0.1, beta=0.05),6))",
                "expected_output": "0.999743"
            },
            {
                "test": "print(round(grpo_objective([1.5, 0.5, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.2, 0.7, 1.3], epsilon=0.15, beta=0.02),6))",
                "expected_output": "0.882682"
            },
            {
                "test": "print(round(grpo_objective([1.0], [1.0], [1.0], [1.0], epsilon=0.1, beta=0.01),6))",
                "expected_output": "1.0"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef grpo_objective(rhos, A, pi_theta_old, pi_theta_ref, epsilon=0.2, beta=0.01) -> float:\n    \"\"\"\n    Compute the GRPO objective function.\n\n    Args:\n        rhos: List of likelihood ratios (ρ_i) = π_theta(o_i | q) / π_theta_old(o_i | q).\n        A: List of advantage estimates (A_i).\n        pi_theta_old: List representing the old policy probabilities π_theta_old(o_i | q).\n        pi_theta_ref: List representing the reference policy probabilities π_ref(o_i | q).\n        epsilon: Clipping parameter (ϵ).\n        beta: KL divergence penalty coefficient (β).\n\n    Returns:\n        The computed GRPO objective value.\n    \"\"\"\n    G = len(rhos)\n    if not (len(A) == len(pi_theta_old) == len(pi_theta_ref) == G):\n        raise ValueError(\"All input lists must have the same length.\")\n    \n    # Compute clipped likelihood ratios\n    clipped_rhos = np.clip(rhos, 1 - epsilon, 1 + epsilon)\n    \n    # Compute the minimum terms for the objective\n    unclipped = np.array(rhos) * np.array(A)\n    clipped = clipped_rhos * np.array(A)\n    min_terms = np.minimum(unclipped, clipped)\n    average_min = np.mean(min_terms)\n    \n    # Compute pi_theta from rhos and pi_theta_old\n    pi_theta = np.array(rhos) * np.array(pi_theta_old)\n    \n    # Normalize pi_theta and pi_theta_ref to ensure they are valid probability distributions\n    pi_theta /= np.sum(pi_theta)\n    pi_theta_ref /= np.sum(pi_theta_ref)\n    \n    # Compute KL divergence D_KL(pi_theta || pi_theta_ref)\n    kl_divergence = np.sum(pi_theta * np.log(pi_theta / pi_theta_ref + 1e-10))  # Added epsilon to avoid log(0)\n    \n    # Compute the final objective\n    objective = average_min - beta * kl_divergence\n    \n    return objective",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "grpo_objective([1.2, 0.8, 1.1], [1.0, 1.0, 1.0], [0.9, 1.1, 1.0], [1.0, 0.5, 1.5], epsilon=0.2, beta=0.01)",
            "output": "1.032749",
            "reasoning": "The function calculates the GRPO objective by first clipping the likelihood ratios, computing the minimum terms, averaging them, and then subtracting the KL divergence penalty scaled by beta."
        },
        "category": "Reinforcement Learning",
        "starter_code": "import numpy as np\n\ndef grpo_objective(rhos, A, pi_theta_old, pi_theta_ref, epsilon=0.2, beta=0.01) -> float:\n\t\"\"\"\n\tCompute the GRPO objective function.\n\n\tArgs:\n\t\trhos: List of likelihood ratios (p_i) = pi_theta(o_i | q) / pi_theta_old(o_i | q).\n\t\tA: List of advantage estimates (A_i).\n\t\tpi_theta_old: List representing the old policy probabilities pi_theta_old(o_i | q).\n\t\tpi_theta_ref: List representing the reference policy probabilities pi_ref(o_i | q).\n\t\tepsilon: Clipping parameter (eps).\n\t\tbeta: KL divergence penalty coefficient (beta).\n\n\tReturns:\n\t\tThe computed GRPO objective value.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Implement the GRPO Objective Function",
        "learn_section": "### Understanding GRPO (Generalized Relative Policy Optimization)\n\nGRPO is an advanced policy optimization algorithm in reinforcement learning that updates policy parameters while ensuring training stability. It builds upon Proximal Policy Optimization (PPO) by incorporating a KL divergence penalty to keep the new policy close to a reference policy.\n\n### Mathematical Definition\n\nThe GRPO objective function is defined as:\n\n$$\nJ_{GRPO}(\\theta) = \\mathbb{E}_{q \\sim P(Q), \\{o_i\\}_{i=1}^G \\sim \\pi_{\\theta_{old}}(O|q)} \\left[ \\frac{1}{G} \\sum_{i=1}^G \\min\\left( \\rho_i A_i, \\text{clip}(\\rho_i, 1-\\epsilon, 1+\\epsilon) A_i \\right) - \\beta D_{KL}(\\pi_{\\theta} \\| \\pi_{ref}) \\right]\n$$\n\nWhere:\n\n- $\\rho_i = \\frac{\\pi_{\\theta}(o_i | q)}{\\pi_{\\theta_{old}}(o_i | q)}$ is the likelihood ratio.\n- $A_i$ is the advantage estimate for the $i$-th action.\n- $\\epsilon$ is the clipping parameter.\n- $\\beta$ controls the influence of the KL divergence penalty.\n- $D_{KL}$ is the Kullback-Leibler divergence between the new policy $\\pi_{\\theta}$ and the reference policy $\\pi_{ref}$.\n\n### Key Components\n\n#### Likelihood Ratio $\\rho_i$\n- Measures how much more likely the new policy $\\pi_{\\theta}$ is to produce an output $o_i$ compared to the old policy $\\pi_{\\theta_{old}}$.\n- $$\\rho_i = \\frac{\\pi_{\\theta}(o_i | q)}{\\pi_{\\theta_{old}}(o_i | q)}$$\n\n#### Advantage Function $A_i$\n- Evaluates the benefit of taking action $o_i$ compared to the average action.\n- $$A_i = \\frac{r_i - \\text{mean}(r_1, \\ldots, r_G)}{\\text{std}(r_1, \\ldots, r_G)}$$\n- Where $r_i$ is the reward for the $i$-th action.\n\n#### Clipping Mechanism\n- Restricts the likelihood ratio to the range $[1 - \\epsilon, 1 + \\epsilon]$ to prevent large updates.\n- $$\\text{clip}(\\rho_i, 1 - \\epsilon, 1 + \\epsilon)$$\n\n#### KL Divergence Penalty\n- Ensures the new policy $\\pi_{\\theta}$ does not deviate significantly from the reference policy $\\pi_{ref}$.\n- $$-\\beta D_{KL}(\\pi_{\\theta} \\| \\pi_{ref})$$\n\n### Benefits of GRPO\n\n#### Stability\n- The clipping mechanism prevents drastic policy updates, ensuring stable training.\n\n#### Controlled Exploration\n- The KL divergence penalty maintains a balance between exploring new policies and sticking close to a reliable reference policy.\n\n#### Improved Performance\n- By carefully managing policy updates, GRPO can lead to more effective learning and better policy performance.\n\n### Use Cases\n\n#### Reinforcement Learning Tasks\n- Suitable for environments requiring stable and efficient policy updates.\n- also a key component used for the DeepSeek-R1 model\n\n#### Complex Decision-Making Problems\n- Effective in scenarios with high-dimensional action spaces where maintaining policy stability is crucial.\n\n### Conclusion\n\nGRPO enhances policy optimization in reinforcement learning by combining the benefits of PPO with an additional KL divergence penalty. This ensures that policy updates are both effective and stable, leading to more reliable and performant learning agents.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement the Swish activation function, a self-gated activation function that has shown superior performance in deep neural networks compared to ReLU. Your task is to compute the Swish value for a given input.",
        "id": "102",
        "test_cases": [
            {
                "test": "print(round(swish(0),4))",
                "expected_output": "0.0"
            },
            {
                "test": "print(round(swish(1),4))",
                "expected_output": "0.7311"
            },
            {
                "test": "print(round(swish(-1),4))",
                "expected_output": "-0.2689"
            },
            {
                "test": "print(round(swish(10),4))",
                "expected_output": "9.9995"
            },
            {
                "test": "print(round(swish(-10),4))",
                "expected_output": "-0.0005"
            }
        ],
        "difficulty": "easy",
        "solution": "import math\n\ndef swish(x: float) -> float:\n    \"\"\"\n    Implements the Swish activation function.\n\n    Args:\n        x: Input value\n\n    Returns:\n        The Swish activation value\n    \"\"\"\n    return x * (1 / (1 + math.exp(-x)))",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "swish(1)",
            "output": "0.7311",
            "reasoning": "For x = 1, the Swish activation is calculated as $Swish(x) = x \\times \\sigma(x)$, where $\\sigma(x) = \\frac{1}{1 + e^{-x}}$. Substituting the value, $Swish(1) = 1 \\times \\frac{1}{1 + e^{-1}} = 0.7311$."
        },
        "category": "Deep Learning",
        "starter_code": "def swish(x: float) -> float:\n\t\"\"\"\n\tImplements the Swish activation function.\n\n\tArgs:\n\t\tx: Input value\n\n\tReturns:\n\t\tThe Swish activation value\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Implement the Swish Activation Function",
        "learn_section": "## Understanding the Swish Activation Function\n\nThe Swish activation function is a modern self-gated activation function introduced by researchers at Google Brain. It has been shown to perform better than ReLU in many deep networks, particularly in deeper architectures.\n\n### Mathematical Definition\n\nThe Swish function is defined as:\n\n$$Swish(x) = x \\times \\sigma(x)$$\n\nwhere $\\sigma(x)$ is the sigmoid function defined as:\n\n$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n\n### Characteristics\n\n- **Output Range**: Unlike ReLU which has a range of $[0, \\infty)$, Swish has a range of $(-\\infty, \\infty)$\n- **Smoothness**: Swish is smooth and non-monotonic, making it differentiable everywhere\n- **Shape**: The function has a slight dip below 0 for negative values, then curves up smoothly for positive values\n- **Properties**:\n  - For large positive x: Swish(x) ~ x (similar to linear function)\n  - For large negative x: Swish(x) ~ 0 (similar to ReLU)\n  - Has a minimal value around x ~ -1.28\n\n### Advantages\n\n- Smooth function with no hard zero threshold like ReLU\n- Self-gated nature allows for more complex relationships\n- Often provides better performance in deep neural networks\n- Reduces the vanishing gradient problem compared to sigmoid",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    },
    {
        "description": "Implement the SELU (Scaled Exponential Linear Unit) activation function, a self-normalizing variant of ELU. Your task is to compute the SELU value for a given input while ensuring numerical stability.",
        "id": "103",
        "test_cases": [
            {
                "test": "print(round(selu(1.0), 4))",
                "expected_output": "1.0507"
            },
            {
                "test": "print(round(selu(0.0), 4))",
                "expected_output": "0.0"
            },
            {
                "test": "print(round(selu(-1.0), 4))",
                "expected_output": "-1.1113"
            },
            {
                "test": "print(round(selu(5.0), 4))",
                "expected_output": "5.2535"
            },
            {
                "test": "print(round(selu(-5.0), 4))",
                "expected_output": "-1.7463"
            }
        ],
        "difficulty": "easy",
        "solution": "import math\n\ndef selu(x: float) -> float:\n    \"\"\"\n    Implements the SELU (Scaled Exponential Linear Unit) activation function.\n\n    Args:\n        x: Input value\n\n    Returns:\n        SELU activation value\n    \"\"\"\n    alpha = 1.6732632423543772\n    scale = 1.0507009873554804\n    return round(scale * x if x > 0 else scale * alpha * (math.exp(x) - 1), 4)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "selu(-1.0)",
            "output": "-1.1113",
            "reasoning": "For x = -1.0, the SELU activation is calculated using the formula $SELU(x) = \\lambda \\alpha (e^x - 1)$. Substituting the values of $\\lambda$ and $\\alpha$, we get $SELU(-1.0) = 1.0507 \\times 1.6733 \\times (e^{-1.0} - 1) = -1.1113$."
        },
        "category": "Deep Learning",
        "starter_code": "def selu(x: float) -> float:\n\t\"\"\"\n\tImplements the SELU (Scaled Exponential Linear Unit) activation function.\n\n\tArgs:\n\t\tx: Input value\n\n\tReturns:\n\t\tSELU activation value\n\t\"\"\"\n\talpha = 1.6732632423543772\n\tscale = 1.0507009873554804\n\t# Your code here\n\tpass",
        "title": "Implement the SELU Activation Function",
        "learn_section": "## Understanding the SELU Activation Function\n\nThe SELU (Scaled Exponential Linear Unit) activation function is a self-normalizing variant of the ELU activation function, introduced in 2017. It's particularly useful in deep neural networks as it automatically ensures normalized outputs with zero mean and unit variance.\n\n### Mathematical Definition\n\nThe SELU function is defined as:\n\n$$\nSELU(x) = \\lambda \\begin{cases} \nx & \\text{if } x > 0 \\\\\n\\alpha(e^x - 1) & \\text{if } x \\leq 0\n\\end{cases}\n$$\n\nWhere:\n- $\\lambda \\approx 1.0507$ is the scale parameter\n- $\\alpha \\approx 1.6733$ is the alpha parameter\n\n### Characteristics\n\n- **Output Range:** The function maps inputs to $(-\\lambda\\alpha, \\infty)$\n- **Self-Normalizing:** Automatically maintains mean close to 0 and variance close to 1\n- **Continuous:** The function is continuous and differentiable everywhere\n- **Non-Linear:** Provides non-linearity while preserving gradients for negative values\n- **Parameters:** Uses carefully chosen values for $\\lambda$ and $\\alpha$ to ensure self-normalization\n\n### Advantages\n\n1. **Self-Normalization:** Eliminates the need for batch normalization in many cases\n2. **Robust Learning:** Helps prevent vanishing and exploding gradients\n3. **Better Performance:** Often leads to faster training in deep neural networks\n4. **Internal Normalization:** Maintains normalized activations throughout the network\n\n### Use Cases\n\nSELU is particularly effective in:\n- Deep neural networks where maintaining normalized activations is crucial\n- Networks that require self-normalizing properties\n- Scenarios where batch normalization might be problematic or expensive",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    },
    {
        "description": "Implement the prediction function for binary classification using Logistic Regression. Your task is to compute class probabilities using the sigmoid function and return binary predictions based on a threshold of 0.5.",
        "id": "104",
        "test_cases": [
            {
                "test": "print(predict_logistic(np.array([[1, 1], [2, 2], [-1, -1], [-2, -2]]), np.array([1, 1]), 0))",
                "expected_output": "[1 1 0 0]"
            },
            {
                "test": "print(predict_logistic(np.array([[0, 0], [0.1, 0.1], [-0.1, -0.1]]), np.array([1, 1]), 0))",
                "expected_output": "[1 1 0]"
            },
            {
                "test": "print(predict_logistic(np.array([[1, 2, 3], [-1, -2, -3], [0.5, 1, 1.5]]), np.array([0.1, 0.2, 0.3]), -1))",
                "expected_output": "[1 0 0]"
            },
            {
                "test": "print(predict_logistic(np.array([[1], [2], [-1], [-2]]), np.array([2]), 0))",
                "expected_output": "[1 1 0 0]"
            },
            {
                "test": "print(predict_logistic(np.array([[1000, 2000], [-1000, -2000]]), np.array([0.1, 0.1]), 0))",
                "expected_output": "[1 0]"
            }
        ],
        "solution": "import numpy as np\n\ndef predict_logistic(X: np.ndarray, weights: np.ndarray, bias: float) -> np.ndarray:\n    \"\"\"\n    Implements binary classification prediction using Logistic Regression.\n\n    Args:\n        X: Input feature matrix (shape: N × D)\n        weights: Model weights (shape: D)\n        bias: Model bias\n\n    Returns:\n        Binary predictions (0 or 1)\n    \"\"\"\n    z = np.dot(X, weights) + bias\n    z = np.clip(z, -500, 500)  # Prevent overflow in exp\n    probabilities = 1 / (1 + np.exp(-z))\n    return (probabilities >= 0.5).astype(int)",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "predict_logistic(np.array([[1, 1], [2, 2], [-1, -1], [-2, -2]]), np.array([1, 1]), 0)",
            "output": "[1 1 0 0]",
            "reasoning": "Each sample's linear combination is computed using $z = Xw + b$. The sigmoid function is applied, and the output is thresholded at 0.5, resulting in binary predictions."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef predict_logistic(X: np.ndarray, weights: np.ndarray, bias: float) -> np.ndarray:\n\t\"\"\"\n\tImplements binary classification prediction using Logistic Regression.\n\n\tArgs:\n\t\tX: Input feature matrix (shape: N x D)\n\t\tweights: Model weights (shape: D)\n\t\tbias: Model bias\n\n\tReturns:\n\t\tBinary predictions (0 or 1)\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Binary Classification with Logistic Regression",
        "learn_section": "## Binary Classification with Logistic Regression\n\nLogistic Regression is a fundamental algorithm for binary classification. Given input features and learned model parameters (weights and bias), your task is to implement the prediction function that computes class probabilities.\n\n### Mathematical Background\n\nThe logistic regression model makes predictions using the sigmoid function:\n\n$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n\nwhere z is the linear combination of features and weights plus bias:\n\n$$z = \\mathbf{w}^T\\mathbf{x} + b = \\sum_{i=1}^{n} w_ix_i + b$$\n\n### Implementation Requirements\n\nYour task is to implement a function that:\n\n- Takes a batch of samples $\\mathbf{X}$ (shape: N x D), weights $\\mathbf{w}$ (shape: D), and bias b\n- Computes $z = \\mathbf{X}\\mathbf{w} + b$ for all samples\n- Applies the sigmoid function to get probabilities\n- Returns binary predictions i.e., 0 or 1 using a threshold of 0.5\n\n### Important Considerations\n\n- Handle numerical stability in sigmoid computation\n- Ensure efficient vectorized operations using numpy\n- Return binary predictions (0 or 1)\n\n### Hint\n\nTo prevent overflow in the exponential calculation of the sigmoid function, use `np.clip` to limit z values:\n\n```python\nz = np.clip(z, -500, 500)\n```\nThis ensures numerical stability when dealing with large input values.",
        "contributor": [
            {
                "profile_link": "https://github.com/emharsha1812",
                "name": "emharsha1812"
            }
        ]
    },
    {
        "description": "Implement a gradient descent-based training algorithm for Softmax regression. Your task is to compute model parameters using Cross Entropy loss and return the optimized coefficients along with collected loss values over iterations. Make sure to round your solution to 4 decimal places",
        "id": "105",
        "test_cases": [
            {
                "test": "print(train_softmaxreg(np.array([[2.5257, 2.3333, 1.7730, 0.4106, -1.6648], [1.5101, 1.3023, 1.3198, 1.3608, 0.4638], [-2.0969, -1.3596, -1.0403, -2.2548, -0.3235], [-0.9666, -0.6068, -0.7201, -1.7325, -1.1281], [-0.3809, -0.2485, 0.1878, 0.5235, 1.3072], [0.5482, 0.3315, 0.1067, 0.3069, -0.3755], [-3.0339, -2.0196, -0.6546, -0.9033, 2.8918], [0.2860, -0.1265, -0.5220, 0.2830, -0.5865], [-0.2626, 0.7601, 1.8409, -0.2324, 1.8071], [0.3028, -0.4023, -1.2955, -0.1422, -1.7812]]), np.array([2, 3, 0, 0, 1, 3, 0, 1, 2, 1]), 0.03, 10))",
                "expected_output": "([[-0.0841, -0.5693, -0.3651, -0.2423, -0.5344, 0.0339], [0.2566, 0.0535, -0.2103, -0.4004, 0.2709, -0.1461], [-0.1318, 0.211, 0.3998, 0.523, -0.1001, 0.0545], [-0.0407, 0.3049, 0.1757, 0.1197, 0.3637, 0.0576]], [13.8629, 10.7201, 9.3163, 8.4942, 7.9132, 7.4598, 7.0854, 6.7653, 6.4851, 6.2358])"
            },
            {
                "test": "print(train_softmaxreg(np.array([[0.5, -1.2], [-0.3, 1.1], [0.8, -0.6]]), np.array([0, 1, 2]), 0.01, 10))",
                "expected_output": "([[-0.0011, 0.0145, -0.0921], [0.002, -0.0598, 0.1263], [-0.0009, 0.0453, -0.0342]], [3.2958, 3.2611, 3.2272, 3.1941, 3.1618, 3.1302, 3.0993, 3.0692, 3.0398, 3.011])"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\n\ndef train_softmaxreg(X: np.ndarray, y: np.ndarray, \n                 learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n    '''        \n    Gradient-descent training algorithm for softmax regression, that collects mean-reduced\n    CE losses, accuracies.\n    Returns\n    -------\n    B : list[float]\n        CxM updated parameter vector rounded to 4 floating points\n    losses : list[float]\n        collected values of a Cross Entropy rounded to 4 floating points\n    '''\n\n    def softmax(z):\n        return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n\n    def accuracy(y_pred, y_true):\n        return (np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1)).sum() / len(y_true)\n\n    def ce_loss(y_pred, y_true):\n        true_labels_idx = np.argmax(y_true, axis=1)\n        return -np.sum(np.log(y_pred)[list(range(len(y_pred))),true_labels_idx])\n\n    y = y.astype(int)\n    C = y.max()+1 # we assume that classes start from 0\n    y = np.eye(C)[y]\n    X = np.hstack((np.ones((X.shape[0], 1)), X))\n    B = np.zeros((X.shape[1], C))\n    accuracies, losses = [], []\n\n    for epoch in range(iterations):\n        y_pred = softmax(X @ B)\n        B -= learning_rate * X.T @ (y_pred - y)\n        losses.append(round(ce_loss(y_pred, y), 4))\n        accuracies.append(round(accuracy(y_pred, y), 4))\n\n    return B.T.round(4).tolist(), losses",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "train_softmaxreg(np.array([[0.5, -1.2], [-0.3, 1.1], [0.8, -0.6]]), np.array([0, 1, 2]), 0.01, 10)",
            "reasoning": "The function iteratively updates the Softmax regression parameters using gradient descent and collects loss values over iterations.",
            "output": "([[-0.0011, 0.0145, -0.0921], [0.002, -0.0598, 0.1263], [-0.0009, 0.0453, -0.0342]], [3.2958, 3.2611, 3.2272, 3.1941, 3.1618, 3.1302, 3.0993, 3.0692, 3.0398, 3.011])"
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef train_softmaxreg(X: np.ndarray, y: np.ndarray, learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n\t\"\"\"\n\tGradient-descent training algorithm for Softmax regression, optimizing parameters with Cross Entropy loss.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Train Softmax Regression with Gradient Descent",
        "learn_section": "## Overview\nSoftmax regression is a type of logistic regression that extends it to a multiclass problem by outputting a vector $P$ of probabilities for each distinct class and taking $argmax(P)$.\n\n## Connection to a regular logistic regression\nRecall that a standard logistic regression is aimed at approximating\n$$\np = \\frac{1}{e^{-X\\beta}+1} = \\\\\n= \\frac{e^{X\\beta}}{1+e^{X\\beta}},\n$$\n\nwhich actually alignes with the definition of the softmax function:\n$$\nsoftmax(z_i)=\\sigma(z_i)=\\frac{e^{z_i}}{\\sum_j^Ce^{z_j}},\n$$\n\nwhere $C$ is the number of classes and values of which sum up to $1$. Hence it simply extends the functionality of sigmoid to more than 2 classes and could be used for assigning probability values in a categorical distribution, i.e. softmax regression searches for the following vector-approximation:\n$$\np^{(i)}=\\frac{e^{x^{(i)}\\beta}}{\\sum_j^Ce^{x^{(i)}\\beta_j}_j}\n$$\n\n## Loss in softmax regression\n**tl;dr** key differences in the loss from logistic regression include replacing sigmoid with softmax and calculating several gradients for vectors $\\beta_j$ corresponding to a particular class $j\\in\\{1,...,C\\}$.\n\nRecall that we use MLE in logistic regression. It is the same case with softmax regression, although instead of Bernoulli-distributed random variable we have categorical distribution, which is an extension of Bernoulli to more than 2 labels. Its PMF is defined as:\n$$\nf(y|p)=\\prod_{i=1}^Kp_i^{[i=y]},\n$$\n\nHence, our log-likelihood looks like:\n$$\n\\sum_X \\sum_j^C [y_i=j] \\log \\left[p\\left(x_i\\right)\\right]\n$$\n\nWhere we replace our probability function with softmax:\n$$\n\\sum_X \\sum_j^C [y_i=j] \\log \\frac{e^{x_i\\beta_j}}{\\sum_j^Ce^{x_i\\beta_j}}\n$$\n\nwhere $[i=y]$ is a function, that returns $0$, if $i\\neq y$, and $1$ otherwise and $C$ - number of distinct classes (labels). You can see that since we are expecting a $1\\times C$ output of $y$, just like in the neuron backprop problem, we will be having separate vector $\\beta_j$ for every $j$ class out of $C$. \n\n## Optimization objective\nThe optimization objective is the same as with logistic regression. The function, which we are optimizing, is also commonly refered as **Cross Entropy** (CE):\n\n$$\nargmin_\\beta -[\\sum_X \\sum_j^C [y_i=j] \\log \\frac{e^{x_i\\beta_j}}{\\sum_j^Ce^{x_i\\beta_j}}] \\\\\n$$\n\nThen we are yet again using a chain rule for calculating partial derivative of $CE$ with respect to $\\beta$:\n\n\n$$\n\\frac{\\partial CE}{\\partial\\beta^{(j)}_i}=\\frac{\\partial CE}{\\partial\\sigma}\\frac{\\partial\\sigma}{\\partial[X\\beta^{(j)}]}\\frac{\\partial[X\\beta^{(j)}]}{\\beta^{(j)}_i}\n$$\n\nWhich is eventually reduced to a similar to logistic regression gradient matrix form:\n$$\nX^T(\\sigma(X\\beta^{(j)})-Y)\n$$\n\nThen we can finally use gradient descent in order to iteratively update our parameters with respect to a particular class:\n$$\n\\beta^{(j)}_{t+1}=\\beta^{(j)}_t - \\eta [X^T(\\sigma(X\\beta^{(j)}_t)-Y)]\n$$",
        "contributor": [
            {
                "profile_link": "https://github.com/turkunov",
                "name": "turkunov"
            }
        ]
    },
    {
        "description": "Implement a gradient descent-based training algorithm for logistic regression. Your task is to compute model parameters using Binary Cross Entropy loss and return the optimized coefficients along with collected loss values over iterations(round to the 4th decimal).",
        "id": "106",
        "test_cases": [
            {
                "test": "print(train_logreg(np.array([[0.7674, -0.2341, -0.2341, 1.5792], [-1.4123, 0.3142, -1.0128, -0.9080], [-0.4657, 0.5425, -0.4694, -0.4634], [-0.5622, -1.9132, 0.2419, -1.7249], [-1.4247, -0.2257, 1.4656, 0.0675], [1.8522, -0.2916, -0.6006, -0.6017], [0.3756, 0.1109, -0.5443, -1.1509], [0.1968, -1.9596, 0.2088, -1.3281], [1.5230, -0.1382, 0.4967, 0.6476], [-1.2208, -1.0577, -0.0134, 0.8225]]), np.array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]), 0.001, 10))",
                "expected_output": "([-0.0097, 0.0286, 0.015, 0.0135, 0.0316], [6.9315, 6.9075, 6.8837, 6.8601, 6.8367, 6.8134, 6.7904, 6.7675, 6.7448, 6.7223])"
            },
            {
                "test": "print(train_logreg(np.array([[ 0.76743473,  1.57921282, -0.46947439],[-0.23415337,  1.52302986, -0.23413696],[ 0.11092259, -0.54438272, -1.15099358],[-0.60063869,  0.37569802, -0.29169375],[-1.91328024,  0.24196227, -1.72491783],[-1.01283112, -0.56228753,  0.31424733],[-0.1382643 ,  0.49671415,  0.64768854],[-0.46341769,  0.54256004, -0.46572975],[-1.4123037 , -0.90802408,  1.46564877],[ 0.0675282 , -0.2257763 , -1.42474819]]), np.array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0]), 0.1, 10))",
                "expected_output": "([-0.2509, 0.9325, 1.6218, 0.6336], [6.9315, 5.5073, 4.6382, 4.0609, 3.6503, 3.3432, 3.1045, 2.9134, 2.7567, 2.6258])"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef train_logreg(X: np.ndarray, y: np.ndarray, learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n    \"\"\"\n    Gradient-descent training algorithm for logistic regression, optimizing parameters with Binary Cross Entropy loss.\n    \"\"\"\n    def sigmoid(x):\n        return 1 / (1 + np.exp(-x))\n\n    y = y.reshape(-1, 1)\n    X = np.hstack((np.ones((X.shape[0], 1)), X))\n    B = np.zeros((X.shape[1], 1))\n    losses = []\n\n    for _ in range(iterations):\n        y_pred = sigmoid(X @ B)\n        B -= learning_rate * X.T @ (y_pred - y)\n        loss = -np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n        losses.append(round(loss, 4))\n\n    return B.flatten().round(4).tolist(), losses",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "train_logreg(np.array([[1.0, 0.5], [-0.5, -1.5], [2.0, 1.5], [-2.0, -1.0]]), np.array([1, 0, 1, 0]), 0.01, 20)",
            "output": "([0.0037, 0.0246, 0.0202], [2.7726, 2.7373, 2.7024, 2.6678, 2.6335, 2.5995, 2.5659, 2.5327, 2.4997, 2.4671, 2.4348, 2.4029, 2.3712, 2.3399, 2.3089, 2.2783, 2.2480, 2.2180, 2.1882, 2.1588])",
            "reasoning": "The function iteratively updates the logistic regression parameters using gradient descent and collects loss values over iterations."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef train_logreg(X: np.ndarray, y: np.ndarray, learning_rate: float, iterations: int) -> tuple[list[float], ...]:\n\t\"\"\"\n\tGradient-descent training algorithm for logistic regression, optimizing parameters with Binary Cross Entropy loss.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Train Logistic Regression with Gradient Descent",
        "learn_section": "## Overview\nLogistic regression is a model used for a binary classification poblem.\n\n## Prerequisites for a regular logistic regression\nLogistic regression is based on the concept of \"logits of odds\". **Odds** is measure of how frequent we encounter success. It also allows us to shift our probabilities domain of $[0, 1]$ to $[0,\\infty]$ Consider a probability of scoring a goal $p=0.8$, then our $odds=\\frac{0.8}{0.2}=4$. This means that every $4$ matches we could be expecting a goal followed by a miss. So the higher the odds, the more consistent is our streak of goals. **Logit** is an inverse of the standard logistic function, i.e. sigmoid: $logit(p)=\\sigma^{-1}(p)=ln\\frac{p}{1-p}$. In our case $p$ is a probability, therefore we call $\\frac{p}{1-p}$ the \"odds\". The logit allows us to further expand our domain from $[0,\\infty]$ to $[-\\infty,\\infty]$.\n\nWith this domain expansion we can treat our problem as a linear regression and try to approximate our logit function: $X\\beta=logit(p)$. However what we really want for this approximation is to yield predictions for probabilities:\n$$\nX\\beta=ln\\frac{p}{1-p} \\\\\ne^{-X\\beta}=\\frac{1-p}{p} \\\\ \ne^{-X\\beta}+1 = \\frac{1}{p} \\\\\np = \\frac{1}{e^{-X\\beta}+1}\n$$\n\nWhat we practically just did is taking an inverse of a logit function w.r.t. our approximation and go back to sigmoid. This is also the backbone of the regular logistic regression, which is commonly defined as:\n$$\n\\pi=\\frac{e^{\\alpha+X\\beta}}{1+e^{\\alpha+X\\beta}}=\\frac{1}{1+e^{-(\\alpha+X\\beta)}}.\n$$\n\n## Loss in logistic regression\nThe loss function used for solving the logistic regression for $\\beta$ is derived from MLE (Maximum Likelihood Estimation). This method allows us to search for $\\beta$ that maximize our **likelihood function** $L(\\beta)$. This function tells us how likely it is that $X$ has come from the distribution generated by $\\beta$: $L(\\beta)=L(\\beta|X)=P(X|\\beta)=\\prod_{\\{x\\in X\\}}f^{univar}_X(x;\\beta)$, where $f$ is a PMF and $univar$ means univariate, i.e. applied to a single variable.\n\nIn the case of a regular logistic regression we expect our output to belong to a single Bernoulli-distributed random variable (hence the univariance), since our true label is either $y_i=0$ or $y_i=1$. The Bernoulli's PMF is defined as $P(Y=y)=p^y(1-p)^{(1-y)}$, where $y\\in\\{0, 1\\}$. Also let's denote $\\{x\\in X\\}$ simply as $X$ and refer to a single pair of vectors from the training set as $(x_i, y_i)$. Thus, our likelihood function would look like this:\n$$\n\\prod_X p\\left(x_i\\right)^{y_i} \\times\\left[1-p\\left(x_i\\right)\\right]^{1-y_i}\n$$\n\nThen we convert our function from likelihood to log-likelihood by taking $ln$ (or $log$) of it:\n$$\n\\sum_X y_i \\log \\left[p\\left(x_i\\right)\\right]+\\left(1-y_i\\right) \\log \\left[1-p\\left(x_i\\right)\\right]\n$$\n\nAnd then we replace $p(x_i)$ with the sigmoid from previously defined equality to get a final version of our **loss function**:\n$$\n\\sum_X y_i \\log \\left(\\frac{1}{1+e^{-x_i\\beta}}\\right)+\\left(1-y_i\\right)\\log \\left(1-\\frac{1}{1+e^{-x_i\\beta}}\\right)\n$$\n\n## Optimization objective\nRecall that originally we wanted to search for $\\beta$ that maximize the likelihood function. Since $log$ is a monotonic transformation, our maximization objective does not change and we can confindently say that now we can equally search for $\\beta$ that maximize our log-likelihood. Hence we can finally write our actual objective as:\n\n$$\nargmax_\\beta [\\sum_X y_i \\log\\sigma(x_i\\beta)+\\left(1-y_i\\right)\\log (1-\\sigma(x_i\\beta))] = \\\\\n= argmin_\\beta -[\\sum_X y_i \\log\\sigma(x_i\\beta)+\\left(1-y_i\\right)\\log (1-\\sigma(x_i\\beta))]\n$$\n\nwhere $\\sigma$ is the sigmoid. This function we're trying to minimize is also called **Binary Cross Entropy** loss function (BCE). To find the minimum we would need to take the gradient of this LLF (Log-Likelihood Function), or find a vector of derivatives with respect to every individual $\\beta_j$.\n\n### Step 1\nTo do that we're going to use a chain rule, that describes relational change in variables that our original function is made of. In our case the log-likeligood function depends on sigmoid $\\sigma$, $\\sigma$ depends on $X\\beta$ and $X\\beta$ finally depends on $\\beta_j$, hence:\n\n$$\n\\frac{\\partial LLF}{\\partial\\beta_j}=\\frac{\\partial LLF}{\\partial\\sigma}\\frac{\\partial\\sigma}{\\partial[X\\beta]}\\frac{\\partial[X\\beta]}{\\beta_j}\\\\\n=-\\sum_{i=1}^n\\left(y^{(i)} \\frac{1}{\\sigma\\left(x^{(i)}\\beta\\right)}-(1-y^{(i)} ) \\frac{1}{1-\\sigma\\left(x^{(i)}\\beta\\right)}\\right) \\frac{\\partial\\sigma}{\\partial[x^{(i)}\\beta]}\n$$\n\n### Step 2\nThen we use a derivative of the sigmoid function, that is $\\frac{\\partial\\sigma(x)}{\\partial x}=\\sigma(x)(1-\\sigma(x))$: \n$$\n-\\sum_{i=1}^n\\left(y^{(i)} \\frac{1}{\\sigma\\left(x^{(i)}\\beta\\right)}-(1-y^{(i)} ) \\frac{1}{1-\\sigma\\left(x^{(i)}\\beta\\right)}\\right)\\\\\n     \\sigma\\left(x^{(i)}\\beta\\right)\\left(1-\\sigma\\left(x^{(i)}\\beta\\right)\\right)^{(*)} \\frac{\\partial[x^{(i)}\\beta]}{\\partial\\beta_j} \\\\\n=-\\sum_{i=1}^n\\left(y^{(i)}\\left(1-\\sigma\\left(x^{(i)}\\beta\\right)\\right)-(1-y^{(i)} ) \\sigma\\left(x^{(i)}\\beta\\right)\\right) x_j^{(i)} \\\\\n=-\\sum_{i=1}^n\\left(y^{(i)}-\\sigma\\left(x^{(i)}\\beta\\right)\\right) x_j^{(i)} \\\\\n=\\sum_{i=1}^n\\left(\\sigma\\left(x^{(i)}\\beta\\right)-y^{(i)}\\right) x_j^{(i)}.\n$$\n\nThe result sum can be then rewritten in a more convenient gradient matrix form as:\n$$\nX^T(\\sigma(X\\beta)-Y)\n$$\n\nThen we can finally use gradient descent in order to iteratively update our parameters:\n$$\n\\beta_{t+1}=\\beta_t - \\eta [X^T(\\sigma(X\\beta_t)-Y)]\n$$\n",
        "contributor": [
            {
                "profile_link": "https://github.com/turkunov",
                "name": "turkunov"
            }
        ]
    },
    {
        "description": "Implement masked self-attention, a variation of the attention mechanism used in sequence modeling tasks such as text generation. Your task is to compute masked self-attention using query (Q), key (K), value (V) matrices and an attention mask.",
        "id": "107",
        "test_cases": [
            {
                "test": "np.random.seed(42)\nX = np.arange(48).reshape(6,8)\nX = np.random.permutation(X.flatten()).reshape(6, 8)\nmask = np.triu(np.ones((6, 6))*(-np.inf), k=1)\nW_q = np.random.randint(0,4,size=(8,8))\nW_k = np.random.randint(0,5,size=(8,8))\nW_v = np.random.randint(0,6,size=(8,8))\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\nprint(masked_attention(Q, K, V, mask))",
                "expected_output": "[[547. 490. 399. 495. 485. 439. 645. 393.]\n [547. 490. 399. 495. 485. 439. 645. 393.]\n [471. 472. 429. 538. 377. 450. 531. 362.]\n [471. 472. 429. 538. 377. 450. 531. 362.]\n [471. 472. 429. 538. 377. 450. 531. 362.]\n [471. 472. 429. 538. 377. 450. 531. 362.]]"
            },
            {
                "test": "np.random.seed(42)\nX = np.arange(16).reshape(4,4)\nX = np.random.permutation(X.flatten()).reshape(4, 4)\nmask = np.triu(np.ones((4, 4))*(-np.inf), k=1)\nW_q = np.random.randint(0,4,size=(4,4))\nW_k = np.random.randint(0,5,size=(4,4))\nW_v = np.random.randint(0,6,size=(4,4))\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\nprint(masked_attention(Q, K, V, mask))",
                "expected_output": "[[ 52.  63.  48.  71.]\n [103. 109.  46.  99.]\n [103. 109.  46.  99.]\n [103. 109.  46.  99.]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef compute_qkv(X: np.ndarray, W_q: np.ndarray, W_k: np.ndarray, W_v: np.ndarray):\n    Q = np.dot(X, W_q)\n    K = np.dot(X, W_k)\n    V = np.dot(X, W_v)\n    return Q, K, V\n\ndef masked_attention(Q: np.ndarray, K: np.ndarray, V: np.ndarray, mask: np.ndarray) -> np.ndarray:\n    d_k = Q.shape[1]\n    scores = np.matmul(Q, K.T) / np.sqrt(d_k)\n    scores = scores + mask  # Apply mask\n    attention_weights = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n    attention_weights = attention_weights / np.sum(attention_weights, axis=1, keepdims=True)\n    return np.matmul(attention_weights, V)",
        "likes": "0",
        "video": "https://youtu.be/R_OISH-JWPA?si=DP5hKJHoe2uKdjON",
        "dislikes": "0",
        "example": {
            "input": "masked_attention(Q, K, V, mask)",
            "output": "[[547. 490. 399. 495. 485. 439. 645. 393.]\n [547. 490. 399. 495. 485. 439. 645. 393.]\n [471. 472. 429. 538. 377. 450. 531. 362.]\n [471. 472. 429. 538. 377. 450. 531. 362.]\n [471. 472. 429. 538. 377. 450. 531. 362.]\n [471. 472. 429. 538. 377. 450. 531. 362.]]",
            "reasoning": "The function computes self-attention by applying a mask to restrict information flow, ensuring causal dependencies are maintained."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef compute_qkv(X: np.ndarray, W_q: np.ndarray, W_k: np.ndarray, W_v: np.ndarray):\n\t\"\"\"\n\tCompute Query (Q), Key (K), and Value (V) matrices.\n\t\"\"\"\n\treturn np.dot(X, W_q), np.dot(X, W_k), np.dot(X, W_v)\n\ndef masked_attention(Q: np.ndarray, K: np.ndarray, V: np.ndarray, mask: np.ndarray) -> np.ndarray:\n\t\"\"\"\n\tCompute masked self-attention.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Implement Masked Self-Attention",
        "learn_section": "## Understanding Masked Attention\n\nMasked attention is a variation of the attention mechanism used primarily in sequence modeling tasks, such as language modeling and text generation. The key idea behind masked attention is to control the flow of information by selectively masking certain elements in the input sequence. This ensures that the model attends only to valid positions when computing attention scores.\n\nMasked attention is particularly useful in autoregressive tasks where future information should not influence the current prediction. By masking out future tokens, the model is constrained to attend only to preceding tokens or the current token, preserving causality during training and inference.\n\n### Concepts\n\nThe attention mechanism enables the model to weigh the importance of different elements in the input sequence based on their relevance to a specific task. Masked attention modifies this process by incorporating a mask, which defines which elements the model is allowed to attend to. This ensures that the attention mechanism respects temporal or structural constraints, such as the directionality of time in sequence data.\n\nThe process of masked attention involves the following steps:\n\n1. **Computing Attention Scores:** The model calculates how much focus each element in the sequence should receive based on its relationship with other elements.\n2. **Applying the Mask:** A mask is applied to restrict attention to specific positions in the sequence. Elements outside the allowed range are effectively ignored.\n3. **Normalizing Scores:** The masked scores are transformed into probabilities using the softmax function.\n4. **Computing the Output:** The final output is computed as a weighted sum of the input values, with weights determined by the normalized attention scores.\n\n### Structure of Masked Attention\n\nThe attention mechanism can be described using Query (Q), Key (K), and Value (V) matrices. In masked attention, these matrices interact with an additional mask to determine the attention distribution.\n\n#### 1. Query, Key, and Value Matrices\n\n- **Query (Q):** Represents the current element for which the model is computing attention.\n- **Key (K):** Encodes information about all elements in the sequence.\n- **Value (V):** Contains the representations that will be aggregated into the output.\n\nAssume that the input sequence has a length of $\\text{seqLen}$ and the model dimension is $d_{\\text{model}}$. The dimensions of the Q, K, and V matrices are:\n\n- Query (Q): $(\\text{seqLen}, d_{\\text{model}})$\n- Key (K): $(\\text{seqLen}, d_{\\text{model}})$\n- Value (V): $(\\text{seqLen}, d_{\\text{model}})$\n\n#### 2. Computing Attention Scores\n\nThe raw attention scores are computed as the scaled dot product between the Query (Q) and Key (K) matrices:\n\n$$\n\\text{score} = \\frac{QK^T}{\\sqrt{d_k}}\n$$\n\nWhere $d_k$ is the dimensionality of the key space. The scaling factor $\\frac{1}{\\sqrt{d_k}}$ ensures that the dot product values do not grow excessively large, preventing instability in the softmax function.\n\n#### 3. Applying the Mask\n\nThe mask is used to control which elements the model is allowed to attend to. Typically, the mask is a binary matrix of dimensions $(\\text{seqLen}, \\text{seqLen})$, where:\n\n- A value of 0 indicates that attention is allowed.\n- A value of $-\\infty$ (or a very large negative value like $-1e9$) indicates that attention is prohibited.\n\nThe raw attention scores are modified by adding the mask:\n\n$$\n\\text{maskedScore} = \\text{score} + \\text{mask}\n$$\n\nThis ensures that prohibited positions receive attention scores that are effectively $-\\infty$, making their softmax probabilities zero.\n\n#### 4. Softmax Calculation\n\nThe softmax function is applied to the masked scores to compute attention weights. To ensure numerical stability, the maximum score in each row is subtracted before applying the softmax function:\n\n$$\n\\text{SoftmaxScore} = \\frac{\\exp(\\text{maskedScore} - \\text{maskedScore}_{\\text{max}})}{\\sum\\exp(\\text{maskedScore} - \\text{maskedScore}_{\\text{max}})}\n$$\n\n#### 5. Computing the Output\n\nThe final attention output is computed as a weighted sum of the Value (V) matrix, with weights determined by the attention scores:\n\n$$\n\\text{output} = \\text{SoftmaxScore} \\cdot V\n$$\n\n### Key Points\n\n- **Masking Future Tokens:** In autoregressive tasks, a triangular mask is used to prevent the model from attending to future positions. For a sequence of length $n$, the mask is an upper triangular matrix with 0s in the lower triangle and $-\\infty$ in the upper triangle.\n\n  Example:\n  $$\n  \\text{mask} = \\begin{bmatrix}\n  0 & -\\infty & -\\infty \\\\\n  0 & 0 & -\\infty \\\\\n  0 & 0 & 0\n  \\end{bmatrix}\n  $$\n\n- **Numerical Stability:** Subtracting the maximum score before applying softmax ensures numerical stability and prevents overflow or underflow errors.\n- **Flexibility:** The mask can be customized to handle other constraints, such as ignoring padding tokens in variable-length sequences.\n\nBy selectively controlling the flow of information through masking, masked attention ensures that the model respects temporal or structural constraints, enabling it to generate coherent and contextually accurate outputs in sequence modeling tasks.",
        "contributor": [
            {
                "profile_link": "https://github.com/nzomi",
                "name": "nzomi"
            }
        ]
    },
    {
        "description": "Implement a function that calculates the disorder in a basket of apples based on their colors, where each apple color is represented by an integer. The disorder must be 0 if all apples are the same color and must increase as the variety of colors increases. In particular:\n- [0,0,0,0] should yield 0.\n- [1,1,0,0] should have a higher disorder than [0,0,0,0].\n- [0,1,2,3] should have a higher disorder than [1,1,0,0].\n- [0,0,1,1,2,2,3,3] should have a higher disorder than [0,0,0,0,0,1,2,3].\n\nYou may use any method to measure disorder as long as these properties are satisfied.",
        "id": "108",
        "test_cases": [
            {
                "test": "print(disorder([0,0,0,0])<disorder([1,0,0,0]))",
                "expected_output": "True"
            },
            {
                "test": "print(disorder([0,0,0,0,0,1,2,3])<disorder([0,0,1,1,2,2,3,3]))",
                "expected_output": "True"
            },
            {
                "test": "print(disorder([1,1,0,0])<disorder([0,1,2,3]))",
                "expected_output": "True"
            }
        ],
        "difficulty": "easy",
        "solution": "def disorder(apples: list) -> float:\n    \"\"\"\n    Calculates a measure of disorder in a basket of apples based on their colors.\n    One valid approach is to use the Gini impurity, defined as:\n      G = 1 - sum((count/total)^2 for each color)\n    This method returns 0 for a basket with all apples of the same color and increases as the variety of colors increases.\n    While this implementation uses the Gini impurity, any method that satisfies the following properties is acceptable:\n      1. A single color results in a disorder of 0.\n      2. Baskets with more distinct colors yield a higher disorder score.\n      3. The ordering constraints are maintained.\n    \"\"\"\n    if not apples:\n        return 0.0\n    total = len(apples)\n    counts = {}\n    for color in apples:\n        counts[color] = counts.get(color, 0) + 1\n    impurity = 1.0\n    for count in counts.values():\n        p = count / total\n        impurity -= p * p\n    return round(impurity, 4)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "disorder([1,1,0,0])",
            "output": "0.5 #or any value from -inf till +inf",
            "reasoning": "In the basket [1,1,0,0], there are two distinct colors each appearing with equal frequency (0.5)."
        },
        "category": "Machine Learning",
        "starter_code": "def disorder(apples: list) -> float:\n\t\"\"\"\n\tCompute the disorder in a basket of apples.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Measure Disorder in Apple Colors",
        "learn_section": "## Using Gini Impurity to Measure Disorder\n\nOne valid approach to measure disorder in a basket of apples is to use the **Gini impurity** metric. The Gini impurity is defined as:\n\n$$\nG = 1 - \\sum_{i=1}^{k} p_i^2\n$$\n\nwhere:\n- $p_i$ is the proportion of apples of the $i$-th color.\n- $k$ is the total number of distinct colors.\n\n### Key Properties\n\n- **Single Color Case:** If all apples in the basket have the same color, then $p = 1$ and the Gini impurity is:\n  $$\n  G = 1 - 1^2 = 0\n  $$\n- **Increasing Disorder:** As the variety of colors increases, the impurity increases. For example:\n  - Two equally frequent colors:  \n    $$\n    G = 1 - \\left(0.5^2 + 0.5^2\\right) = 0.5\n    $$\n  - Four equally frequent colors:  \n    $$\n    G = 1 - \\left(4 \\times 0.25^2\\right) = 0.75\n    $$\n\n### Comparing Different Baskets\n\n1. **Basket:** `[0,0,0,0]`  \n   - Only one color -> $G = 0$\n2. **Basket:** `[1,1,0,0]`  \n   - Two colors, equal frequency -> $G = 0.5$\n3. **Basket:** `[0,1,2,3]`  \n   - Four equally frequent colors -> $G = 0.75$\n4. **Basket:** `[0,0,1,1,2,2,3,3]`  \n   - Equal distribution among four colors -> $G = 0.75$\n5. **Basket:** `[0,0,0,0,0,1,2,3]`  \n   - One dominant color, three others -> $G = 0.5625$\n\n### Flexibility\n\nWhile the Gini impurity is a suitable measure of disorder, any method that satisfies the following constraints is valid:\n1. A basket with a single color must return a disorder score of **0**.\n2. Baskets with more distinct colors must yield **higher disorder** scores.\n3. The specific ordering constraints provided in the problem must be **maintained**.\n\nBy using this impurity measure, we can quantify how diverse a basket of apples is based on color distribution.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement a function to perform Layer Normalization on an input tensor. Given a 3D array representing batch_size, sequence length, and feature dimensions, normalize the data across the feature dimension for each sequence, then apply scaling and shifting parameters.",
        "id": "109",
        "test_cases": [
            {
                "test": "np.random.seed(42); X = np.random.randn(2, 2, 3); gamma = np.ones(3).reshape(1, 1, -1); beta = np.zeros(3).reshape(1, 1, -1); print(np.round(layer_normalization(X, gamma, beta), 3))",
                "expected_output": "[[[ 0.474, -1.391,  0.917], [ 1.414, -0.707, -0.707]], [[ 1.132,  0.168, -1.3  ], [ 1.414, -0.705, -0.71 ]]]"
            },
            {
                "test": "np.random.seed(42); X = np.random.randn(2, 3, 4); gamma = np.ones(4).reshape(1, 1, -1); beta = np.zeros(4).reshape(1, 1, -1); print(np.round(layer_normalization(X, gamma, beta), 3))",
                "expected_output": "[[[-0.229, -1.3, 0.026, 1.502], [-0.926, -0.926, 1.46, 0.392], [-0.585, 1.732, -0.571, -0.576]], [[ 1.401, -1.05, -0.836, 0.486], [-0.4, 1.657, -0.238, -1.019], [ 1.454, -0.191, 0.094, -1.357]]]"
            },
            {
                "test": "np.random.seed(42); X = np.random.randn(2, 3, 4); gamma = np.ones(4).reshape(1, 1, -1) * 0.5; beta = np.ones(4).reshape(1, 1, -1); print(np.round(layer_normalization(X, gamma, beta), 3))",
                "expected_output": "[[[0.886, 0.35 , 1.013, 1.751],[0.537, 0.537, 1.73 , 1.196],[0.708, 1.866, 0.715, 0.712]],[[1.7  , 0.475, 0.582, 1.243],[0.8  , 1.828, 0.881, 0.49 ],[1.727, 0.904, 1.047, 0.322]]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef layer_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, epsilon: float = 1e-5) -> np.ndarray:\n    \"\"\"\n    Perform Layer Normalization.\n    \"\"\"\n    mean = np.mean(X, axis=-1, keepdims=True)\n    variance = np.var(X, axis=-1, keepdims=True)\n    X_norm = (X - mean) / np.sqrt(variance + epsilon)\n    norm_X = gamma * X_norm + beta\n    return norm_X",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "np.random.seed(42); X = np.random.randn(2, 2, 3); gamma = np.ones(3).reshape(1, 1, -1); beta = np.zeros(3).reshape(1, 1, -1); layer_normalization(X, gamma, beta)",
            "output": "[[[ 0.47373971 -1.39079736  0.91705765]\n  [ 1.41420326 -0.70711154 -0.70709172]]\n [[ 1.13192477  0.16823009 -1.30015486]\n  [ 1.4141794  -0.70465482 -0.70952458]]]",
            "reasoning": "The function computes the mean and variance across the feature dimension (d_model=3) for each sequence, normalizes the input, then applies gamma=1 and beta=0, resulting in a normalized output with zero mean and unit variance scaled as is."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef layer_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, epsilon: float = 1e-5) -> np.ndarray:\n\t\"\"\"\n\tPerform Layer Normalization.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Implement Layer Normalization for Sequence Data",
        "learn_section": "## Understanding Layer Normalization\n\nLayer Normalization (LN) is a technique commonly used in natural language processing (NLP) tasks to normalize the activations within each individual sample (or instance) across all the features (or dimensions). Unlike **Batch Normalization**, which normalizes across the batch dimension, Layer Normalization normalizes across the feature (or channel) dimension. This makes it particularly useful for sequence-based tasks, where the sequence length varies or where the batch size is small, as is often the case in NLP applications.\n\n### Concepts\n\nLayer Normalization operates on the principle of normalizing each input sample independently, across its feature dimensions. This ensures that all the features in a single instance (or sequence) are scaled and shifted to have similar statistics, which helps stabilize the training process and improve the model's ability to learn.\n\nThe process of Layer Normalization consists of the following steps:\n\n1. **Compute the Mean and Variance for Each Sample:** For each input sequence, compute the mean and variance across the feature dimensions.\n2. **Normalize the Inputs:** Normalize the activations by subtracting the mean and dividing by the standard deviation.\n3. **Apply Scale and Shift:** After normalization, apply a learned scale (gamma) and shift (beta) to allow the model to restore the original distribution of the data, if necessary.\n\n### Structure of Layer Normalization for (Batch Size, Sequence Length, Feature Dimension) Input\n\nFor an input tensor with the shape **(batch_size, seq_len, d_model)** (where:\n- **batch_size**: number of sequences in a batch,\n- **seq_len**: sequence length (number of tokens or time steps),\n- **d_model**: number of features (model dimension)),\nLayer Normalization operates over the **d_model** (features) dimension, normalizing each sequence independently.\n\n#### 1. Mean and Variance Calculation for Each Sample\n\n- For each individual sequence in the batch (for each **b** in **batch_size**), the **mean** $\\mu_b$ and **variance** $\\sigma_b^2$ are computed over the features (or channels) for that particular sequence. Importantly, this computation does not involve the batch dimension, meaning each sequence is normalized independently.\n\n  $$ \n  \\mu_b = \\frac{1}{d_{\\text{model}}} \\sum_{i=1}^{d_{\\text{model}}} x_{b,i}\n  $$\n\n  $$\n  \\sigma_b^2 = \\frac{1}{d_{\\text{model}}} \\sum_{i=1}^{d_{\\text{model}}} (x_{b,i} - \\mu_b)^2\n  $$\n\n  Where:\n  - $x_{b,i}$ is the activation at batch index $b$ and feature index $i$ (across the sequence length).\n  - $d_{\\text{model}}$ is the model dimension (the number of features).\n\n#### 2. Normalization\n\nOnce the mean $\\mu_b$ and variance $\\sigma_b^2$ have been computed for each sequence, the next step is to **normalize** the input by subtracting the mean and dividing by the standard deviation (square root of variance plus a small constant $\\epsilon$ for numerical stability):\n\n$$\n\\hat{x}_{b,i} = \\frac{x_{b,i} - \\mu_b}{\\sqrt{\\sigma_b^2 + \\epsilon}}\n$$\n\nWhere:\n- $\\hat{x}_{b,i}$ is the normalized value of the $i$-th feature for the $b$-th sequence.\n- $\\epsilon$ is a small constant added to the variance for numerical stability.\n\n#### 3. Scale and Shift\n\nAfter normalization, the next step is to apply a **scale** ($\\gamma$) and **shift** ($\\beta$) to the normalized activations for each sequence. These are learned parameters that allow the model to adjust the output distribution for each sequence:\n\n$$\ny_{b,i} = \\gamma \\hat{x}_{b,i} + \\beta\n$$\n\nWhere:\n- $\\gamma$ is the scaling factor for the feature $i$.\n- $\\beta$ is the shifting factor for the feature $i$.\n\n#### 4. Training and Inference\n\n- **During Training**: For each sequence, the mean and variance are computed over the feature dimensions and used for normalization.\n- **During Inference**: The model uses the running averages of the statistics (mean and variance) computed during training to ensure consistent behavior during inference.\n\n### Why Use Layer Normalization in NLP?\n\nLayer Normalization is especially useful in NLP and sequence-based tasks because of the following reasons:\n\n- **Independence from Batch Size**: Layer Normalization operates independently for each sample (sequence), which means it does not depend on the batch size. This is important in NLP tasks where the batch size can vary, or be small, which would make Batch Normalization less effective.\n\n- **Variable Sequence Lengths**: NLP models often work with sequences of varying lengths. Layer Normalization normalizes over the feature dimension, making it easier to handle sequences of different lengths without the need for special adjustments.\n\n- **Training Stability**: Layer Normalization helps stabilize the training process by ensuring that the activations within each sequence are normalized, preventing the network from becoming sensitive to the scale of the inputs and improving gradient flow.\n\n### Why Not Use Batch Normalization in NLP?\n\nBatch Normalization (BN) normalizes over the batch dimension, which works well when the batch size is large and fixed. However, in NLP tasks, there are a few reasons why **Batch Normalization** is less commonly used:\n\n- **Batch Size Variability**: In NLP, the batch size can vary across training and inference steps. A smaller or variable batch size can lead to poor estimates of the mean and variance during Batch Normalization, which can degrade performance.\n\n- **Sequence Length Variability**: In NLP, the length of input sequences can vary greatly (e.g., sentences of different lengths). Batch Normalization requires that the statistics be computed over the batch, which makes it difficult to apply across sequences of varying lengths without padding or truncation.\n\n- **Dependence on Batch Statistics**: Since Batch Normalization relies on batch statistics, it can cause issues when used in tasks with smaller or highly variable batch sizes, such as in NLP, where each sequence may not represent a meaningful distribution of activations across the batch.\n\n### Key Points\n\n- **Normalization Over Features**: Layer Normalization normalizes across the feature dimensions (model dimension), rather than across the batch dimension, making it ideal for NLP tasks where the batch size may vary or be small.\n\n- **Sequence-Based Normalization**: By normalizing each sequence independently, Layer Normalization ensures that the activations within a single sequence are normalized, without needing information from other sequences in the batch.\n\n- **Stabilizing Training**: Layer Normalization improves the gradient flow and ensures that activations within each sequence are consistent, which stabilizes training and helps prevent vanishing or exploding gradients.\n\n- **Better for Small or Variable Batch Sizes**: Layer Normalization works well with smaller batch sizes, which are often used in NLP tasks like language modeling, machine translation, and text classification.\n\n### Summary\n\nLayer Normalization is particularly effective in NLP tasks because it normalizes each sequence independently, ensuring that each sample has a consistent activation distribution. It is preferable over Batch Normalization in cases where the batch size is small or variable, and when sequences have different lengths, making it a popular choice for sequence-based models like transformers, BERT, and GPT.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/nzomi",
                "name": "nzomi"
            }
        ]
    },
    {
        "description": "Write a Python function that uses the Jacobi method to solve a system of linear equations given by Ax = b. The function should iterate n times, rounding each intermediate solution to four decimal places, and return the approximate solution x.",
        "mdx_file": "dd4e1cc5-6bce-4b68-902f-eb1745151039.mdx",
        "tinygrad_difficulty": "medium",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNvbHZlX2phY29iaV90ZyhBLCBiLCBuKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIFNvbHZlIEF4ID0gYiB1c2luZyB0aGUgSmFjb2JpIGl0ZXJhdGl2ZSBtZXRob2QgZm9yIG4gaXRlcmF0aW9ucyBpbiB0aW55Z3JhZC4KICAgIEE6IGxpc3Qgb2YgbGlzdHMgb3IgVGVuc29yOyBiOiBsaXN0IG9yIFRlbnNvcjsgbjogbnVtYmVyIG9mIGl0ZXJhdGlvbnMuCiAgICBSZXR1cm5zIGEgMS1EIFRlbnNvciBvZiBsZW5ndGggbSwgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "test_cases": [
            {
                "test": "print(solve_jacobi(np.array([[5, -2, 3], [-3, 9, 1], [2, -1, -7]]), np.array([-1, 2, 3]),2))",
                "expected_output": "[0.146, 0.2032, -0.5175]"
            },
            {
                "test": "print(solve_jacobi(np.array([[4, 1, 2], [1, 5, 1], [2, 1, 3]]), np.array([4, 6, 7]),5))",
                "expected_output": "[-0.0806, 0.9324, 2.4422]"
            },
            {
                "test": "print(solve_jacobi(np.array([[4,2,-2],[1,-3,-1],[3,-1,4]]), np.array([0,7,5]),3))",
                "expected_output": "[1.7083, -1.9583, -0.7812]"
            }
        ],
        "solution": "import numpy as np\n\ndef solve_jacobi(A: np.ndarray, b: np.ndarray, n: int) -> list:\n    d_a = np.diag(A)\n    nda = A - np.diag(d_a)\n    x = np.zeros(len(b))\n    x_hold = np.zeros(len(b))\n    for _ in range(n):\n        for i in range(len(A)):\n            x_hold[i] = (1/d_a[i]) * (b[i] - sum(nda[i]*x))\n        x = x_hold.copy()\n    return np.round(x,4).tolist()",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBzb2x2ZV9qYWNvYmlfdGcoQSwgYiwgbikgLT4gVGVuc29yOgogICAgIiIiCiAgICBTb2x2ZSBBeCA9IGIgdXNpbmcgdGhlIEphY29iaSBpdGVyYXRpdmUgbWV0aG9kIGZvciBuIGl0ZXJhdGlvbnMgaW4gdGlueWdyYWQuCiAgICBBOiBsaXN0IG9mIGxpc3RzIG9yIFRlbnNvcjsgYjogbGlzdCBvciBUZW5zb3I7IG46IG51bWJlciBvZiBpdGVyYXRpb25zLgogICAgUmV0dXJucyBhIDEtRCBUZW5zb3Igb2YgbGVuZ3RoIG0sIHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgQV90ID0gVGVuc29yKEEpLmZsb2F0KCkKICAgIGJfdCA9IFRlbnNvcihiKS5mbG9hdCgpCiAgICBtID0gQV90LnNoYXBlWzBdCiAgICAjIGV4dHJhY3QgZGlhZ29uYWwKICAgIGRfbGlzdCA9IFtBX3RbaSxpXSBmb3IgaSBpbiByYW5nZShtKV0KICAgIGQgPSBUZW5zb3IoZF9saXN0KQogICAgIyBidWlsZCByZW1haW5kZXIgbWF0cml4CiAgICBuZGFfbGlzdCA9IFtbQV90W2ksal0gaWYgaSAhPSBqIGVsc2UgMCBmb3IgaiBpbiByYW5nZShtKV0gZm9yIGkgaW4gcmFuZ2UobSldCiAgICBuZGEgPSBUZW5zb3IobmRhX2xpc3QpLmZsb2F0KCkKICAgIHggPSBUZW5zb3IoWzAuMF0qbSkuZmxvYXQoKQogICAgZm9yIF8gaW4gcmFuZ2Uobik6CiAgICAgICAgeCA9IChiX3QgLSBuZGEubWF0bXVsKHgpKSAvIGQKICAgIHJlcyA9IHgubnVtcHkoKQogICAgcmV0dXJuIFRlbnNvcihucC5yb3VuZChyZXMsIDQpKQo=",
        "pytorch_difficulty": "medium",
        "video": "https://youtu.be/Y7WSn7K092g",
        "likes": "0",
        "difficulty": "medium",
        "example": {
            "input": "A = [[5, -2, 3], [-3, 9, 1], [2, -1, -7]], b = [-1, 2, 3], n=2",
            "output": "[0.146, 0.2032, -0.5175]",
            "reasoning": "The Jacobi method iteratively solves each equation for x[i] using the formula x[i] = (1/a_ii) * (b[i] - sum(a_ij * x[j] for j != i)), where a_ii is the diagonal element of A and a_ij are the off-diagonal elements."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\ndef solve_jacobi(A: np.ndarray, b: np.ndarray, n: int) -> list:\n\treturn x",
        "title": "Solve Linear Equations using Jacobi Method",
        "learn_section": "\n## Solving Linear Equations Using the Jacobi Method\n\nThe Jacobi method is an iterative algorithm used for solving a system of linear equations \\( Ax = b \\). This method is particularly useful for large systems where direct methods, such as Gaussian elimination, are computationally expensive.\n\n\n### Algorithm Overview\n\nFor a system of equations represented by \\( Ax = b \\), where \\( A \\) is a matrix and \\( x \\) and \\( b \\) are vectors, the Jacobi method involves the following steps:\n\n1. **Initialization**: Start with an initial guess for \\( x \\).\n\n2. **Iteration**: For each equation \\( i \\), update \\( x[i] \\) using:\n   $$\n   x[i] = \\frac{1}{a_{ii}} \\left(b[i] - \\sum_{j \\neq i} a_{ij} x[j]\\right)\n   $$\n   where \\( a_{ii} \\) are the diagonal elements of \\( A \\), and \\( a_{ij} \\) are the off-diagonal elements.\n\n3. **Convergence**: Repeat the iteration until the changes in \\( x \\) are below a certain tolerance or until a maximum number of iterations is reached.\n\nThis method assumes that all diagonal elements of \\( A \\) are non-zero and that the matrix is diagonally dominant or properly conditioned for convergence.\n\n### Practical Considerations\n\n- The method may not converge for all matrices.\n- Choosing a good initial guess can improve convergence.\n- Diagonal dominance of \\( A \\) ensures the convergence of the Jacobi method.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = solve_jacobi(\n    torch.tensor([[4.0,1.0],[2.0,3.0]]),\n    torch.tensor([1.0,2.0]),\n    10\n)\nprint(res.numpy().tolist())",
                "expected_output": "[0.1, 0.6]"
            },
            {
                "test": "import torch\nres = solve_jacobi(\n    torch.tensor([[3.0,0.0],[0.0,3.0]]),\n    torch.tensor([3.0,6.0]),\n    5\n)\nprint(res.numpy().tolist())",
                "expected_output": "[1.0, 2.0]"
            }
        ],
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgc29sdmVfamFjb2JpKEEsIGIsIG4pIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgU29sdmUgQXggPSBiIHVzaW5nIHRoZSBKYWNvYmkgaXRlcmF0aXZlIG1ldGhvZCBmb3IgbiBpdGVyYXRpb25zLgogICAgQTogKG0sbSkgdGVuc29yOyBiOiAobSwpIHRlbnNvcjsgbjogbnVtYmVyIG9mIGl0ZXJhdGlvbnMuCiAgICBSZXR1cm5zIGEgMS1EIHRlbnNvciBvZiBsZW5ndGggbSwgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICBBX3QgPSB0b3JjaC5hc190ZW5zb3IoQSwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBiX3QgPSB0b3JjaC5hc190ZW5zb3IoYiwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgc29sdmVfamFjb2JpKEEsIGIsIG4pIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgU29sdmUgQXggPSBiIHVzaW5nIHRoZSBKYWNvYmkgaXRlcmF0aXZlIG1ldGhvZCBmb3IgbiBpdGVyYXRpb25zLgogICAgQTogKG0sbSkgdGVuc29yOyBiOiAobSwpIHRlbnNvcjsgbjogbnVtYmVyIG9mIGl0ZXJhdGlvbnMuCiAgICBSZXR1cm5zIGEgMS1EIHRlbnNvciBvZiBsZW5ndGggbSwgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICBBX3QgPSB0b3JjaC5hc190ZW5zb3IoQSwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBiX3QgPSB0b3JjaC5hc190ZW5zb3IoYiwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBkID0gdG9yY2guZGlhZyhBX3QpCiAgICBuZGEgPSBBX3QgLSB0b3JjaC5kaWFnKGQpCiAgICB4ID0gdG9yY2guemVyb3NfbGlrZShiX3QpCiAgICBmb3IgXyBpbiByYW5nZShuKToKICAgICAgICB4ID0gKGJfdCAtIG5kYS5tYXRtdWwoeCkpIC8gZAogICAgcmV0dXJuIHRvcmNoLnJvdW5kKHggKiAxMDAwMCkgLyAxMDAwMAo=",
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = solve_jacobi_tg(\n    [[4.0,1.0],[2.0,3.0]],\n    [1.0,2.0],\n    10\n)\nprint(res.numpy().tolist())",
                "expected_output": "[0.1, 0.6]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = solve_jacobi_tg(\n    [[3.0,0.0],[0.0,3.0]],\n    [3.0,6.0],\n    5\n)\nprint(res.numpy().tolist())",
                "expected_output": "[1.0, 2.0]"
            }
        ],
        "id": "11"
    },
    {
        "description": "Develop a function to compute the METEOR score for evaluating machine translation quality. Given a reference translation and a candidate translation, calculate the score based on unigram matches, precision, recall, F-mean, and a penalty for word order fragmentation.",
        "id": "110",
        "test_cases": [
            {
                "test": "print(round(meteor_score('The dog barks at the moon', 'The dog barks at the moon'),3))",
                "expected_output": "0.998"
            },
            {
                "test": "print(round(meteor_score('Rain falls gently from the sky', 'Gentle rain drops from the sky'),3))",
                "expected_output": "0.625"
            },
            {
                "test": "print(round(meteor_score('The sun shines brightly', 'Clouds cover the sky'),3))",
                "expected_output": "0.125"
            },
            {
                "test": "print(round(meteor_score('Birds sing in the trees', 'Birds in the trees sing'),3))",
                "expected_output": "0.892"
            }
        ],
        "difficulty": "medium",
        "solution": "\"import numpy as np\nfrom collections import Counter\n\ndef meteor_score(reference, candidate, alpha=0.9, beta=3, gamma=0.5):\n    if not reference or not candidate:\n        raise ValueError(\"Reference and candidate cannot be empty\")\n    \n    # Tokenize and count\n    ref_tokens = reference.lower().split()\n    cand_tokens = candidate.lower().split()\n\n    # Counter for unigram for reference and candidate \n    ref_counts = Counter(ref_tokens) \n    cand_counts = Counter(cand_tokens)\n    \n    # Calculate matches\n    num_matches = sum((ref_counts & cand_counts).values()) # Number of matching words in candidate and reference \n    ref_len = len(ref_tokens)\n    cand_len = len(cand_tokens)  \n\n    # Unigram Precision and Recall \n    precision = num_matches / cand_len if cand_len > 0 else 0 # Avoiding Division by zero\n    recall = num_matches / ref_len if ref_len > 0 else 0 # Avoiding Division by zero \n    \n    if num_matches == 0:\n        return 0.0\n    \n    fmean = (precision * recall) / (alpha * precision + (1 - alpha) * recall)\n\n    # Chunk calculation \n    matched_positions = []\n    ref_positions = {}  # Store positions of words in reference\n    used_positions = set()  # Track already used indices\n\n    # Populate reference positions for word alignment tracking\n    for i, word in enumerate(ref_tokens):\n        ref_positions.setdefault(word, []).append(i)\n\n    # Determine the sequence of matched positions in reference\n    for word in cand_tokens:\n        if word in ref_positions:\n            for pos in ref_positions[word]:\n                if pos not in used_positions:\n                    matched_positions.append(pos)\n                    used_positions.add(pos)\n                    break  # Ensure each match is used only once\n\n    # Count chunks by detecting breaks in position sequence\n    num_chunks = 1 if matched_positions else 0\n    for i in range(1, len(matched_positions)):\n        if matched_positions[i] != matched_positions[i - 1] + 1:\n            num_chunks += 1  # Break in sequence → new chunk\n\n    # Fragmentation penalty\n    penalty = gamma * ((num_chunks / num_matches) ** beta) if num_matches > 0 else 0\n    \n    # Final score\n    return round(fmean * (1 - penalty), 3) # Rounding to 3 Decimal places \n",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "meteor_score('Rain falls gently from the sky', 'Gentle rain drops from the sky')",
            "output": "0.625",
            "reasoning": "The function identifies 4 unigram matches ('rain', 'gently'/'gentle', 'from', 'sky'), computes precision (4/6) and recall (4/5), calculates an F-mean, and then apply a small penalty for two chunks."
        },
        "category": "NLP",
        "starter_code": "import numpy as np\nfrom collections import Counter\n\ndef meteor_score(reference, candidate, alpha=0.9, beta=3, gamma=0.5):\n\t# Your code here\n\tpass",
        "title": "Evaluate Translation Quality with METEOR Score",
        "learn_section": "METEOR(Metric for Evaluation of Translation with Explicit ORdering) is a metric generally used for \nmachine translation and evaluating the text output of generative AI models. METEOR build was introduced to address \nthe limitations in earlier metrics like BLEU.\n\n## Key Characteristics\n- Considers semantic similarity beyond exact word matching\n- Accounts for word order and translation variations\n- Provides more human-aligned translation assessment\n\n# Implementation \n1. **Tokenization**\n\n2. **Frequency of matching words** : Matching needs to be exact\n\n3. **Calculate Precision, Recall and F-mean**\n```\n   F_mean = (Precision * Recall) / \n   (alpha * Precision + (1 - alpha) * Recall)\n```\n   - alpha typically set to 0.9\n   - Balances precision and recall\n\n4. **Fragmentation Penalty**\n   ```\n   Chunks = Count of contiguous matched word sequences\n   Penalty = gamma * (Chunks / Matches)^β\n   ```\n   - beta controls penalty weight (typically 3)\n   - gamma limits maximum penalty (typically 0.5)\n\n5. **Final METEOR Score**\n   ```\n   METEOR = F_mean * (1 - Penalty)\n   ```\n   - Ranges from 0 (no match) to 1 (perfect match)\n\n**__Note__** : The [paper](https://aclanthology.org/W05-0909/) that introduced the metric doesn't have the parameters (alpha,β, and gamma) as tunable parameters, but implementation in other libraries like NLTK offers this flexibility.\n\n# Example \n\n- Reference: \"The quick brown fox jumps over the lazy dog\"\n- Candidate: \"A quick brown fox jumps over a lazy dog\"\n\n### 1. Tokenization\n- Reference Tokens: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n- Candidate Tokens: ['a', 'quick', 'brown', 'fox', 'jumps', 'over', 'a', 'lazy', 'dog']\n\n### 2. Unigram Matching\n- Matching tokens: ['quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dog']\n- Matches: 7\n\n### 3. Unigram Precision and Recall Calculation\n- Precision = Matches / Candidate Length = 7 / 9 ~ 0.778\n\n- Recall = Matches / Reference Length = 7 / 9 ~ 0.778\n\n### 4. F-mean Calculation (alpha = 0.9)\n```\nF_mean = (Precision * Recall) / \n(alpha * Precision + (1 - alpha) * Recall)\n       = (0.778 * 0.778) / (0.9 * 0.778 + (1 - 0.9) * 0.778)\n       = 0.606 / (0.7 + 0.078)\n       = 0.606 / 0.778\n       ≈ 0.779\n```\n\n### 5. Chunk Calculation\n- Contiguous matched sequences:\n  1. ['quick', 'brown', 'fox']\n  2. ['jumps', 'over']\n  3. ['lazy', 'dog']\n- Number of Chunks: 3\n- Total Number of Unigram Matches: 7\n\n### 6. Penalty Calculation (betta = 3, gamma = 0.5)\n```\nPenalty = gamma * \n(Number of Chunks / Total Number of Unigram Matches)^betta\n        = 0.5 * (3 / 7)^3\n        = 0.5 * (0.429)^3\n        ≈ 0.039\n```\n\n### 7. Final METEOR Score\n```\nMETEOR = F_mean * (1 - Penalty)\n       = 0.779 * (1 - 0.039)\n       = 0.779 * 0.961\n       ≈ 0.749\n```",
        "contributor": [
            {
                "profile_link": "https://github.com/saitiger",
                "name": "saitiger"
            }
        ]
    },
    {
        "description": "Implement a function to compute the Pointwise Mutual Information (PMI) given the joint occurrence count of two events, their individual counts, and the total number of samples. PMI measures how much the actual joint occurrence of events differs from what we would expect by chance.",
        "id": "111",
        "test_cases": [
            {
                "test": "print(compute_pmi(10, 50, 50, 200))",
                "expected_output": "-0.322"
            },
            {
                "test": "print(compute_pmi(100, 500, 500, 1000))",
                "expected_output": "-1.322"
            },
            {
                "test": "print(float(compute_pmi(100, 400, 600, 1200)))",
                "expected_output": "-1."
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef compute_pmi(joint_counts, total_counts_x, total_counts_y, total_samples):\n\n    if not all(isinstance(x, int) and x >= 0 for x in [joint_counts, total_counts_x, total_counts_y, total_samples]):\n        raise ValueError(\"All inputs must be non-negative integers.\")\n\n    if total_samples == 0:\n        raise ValueError(\"Total samples cannot be zero.\")\n\n    if joint_counts > min(total_counts_x, total_counts_y):\n        raise ValueError(\"Joint counts cannot exceed individual counts.\")\n\n    p_x = total_counts_x / total_samples\n    p_y = total_counts_y / total_samples\n    p_xy = joint_counts / total_samples\n\n    if p_xy == 0:\n        return float('-inf')\n\n    pmi = np.log2(p_xy / (p_x * p_y))\n\n    return round(pmi, 3)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "compute_pmi(50, 200, 300, 1000)",
            "output": "-0.263",
            "reasoning": "The PMI calculation compares the actual joint probability (50/1000 = 0.05) to the product of the individual probabilities (200/1000 * 300/1000 = 0.06). Thus, PMI = log₂(0.05 / (0.2 * 0.3)) ≈ -0.263, indicating the events co-occur slightly less than expected by chance."
        },
        "category": "NLP",
        "starter_code": "import numpy as np\n\ndef compute_pmi(joint_counts, total_counts_x, total_counts_y, total_samples):\n\t# Implement PMI calculation here\n\tpass",
        "title": "Compute Pointwise Mutual Information",
        "learn_section": "# Pointwise Mutual Information (PMI)\n\nPointwise Mutual Information (PMI) is a statistical measure used in information theory and Natural Language Processing (NLP) to quantify the association between two events. It measures how much the actual joint occurrence of two events differs from what would be expected if they were independent. PMI is commonly used for identifying word associations, feature selection in text classification, and calculating document similarity.\n\n## Implementation \n\n1. **Collect Count Data** for events $x$, $y$, and their joint occurrence $(x,y)$.\n\n2. **Calculate Individual Probabilities**:\n   - $P(x) = \\frac{\\text{Count}(x)}{\\text{Total Count}}$\n   - $P(y) = \\frac{\\text{Count}(y)}{\\text{Total Count}}$\n\n3. **Calculate Joint Probability**:\n   - $P(x,y) = \\frac{\\text{Count}(x,y)}{\\text{Total Count}}$\n\n4. **Calculate PMI**:\n   - $$\\text{PMI}(x,y) = \\log_2\\left(\\frac{P(x,y)}{P(x) \\cdot P(y)}\\right)$$\n\n## Interpretation of PMI Values\n\n- **Positive PMI**: Events co-occur more frequently than expected by chance.\n- **Zero PMI**: Events are statistically independent.\n- **Negative PMI**: Events co-occur less frequently than expected by chance.\n- **Undefined PMI**: Occurs when $P(x,y) = 0$ (the events never co-occur).\n\n## Variants of PMI\n\n### 1. Normalized PMI (NPMI)\n\nNPMI scales PMI to a range of [-1, 1] to account for dataset size variations:\n\n$$\n\\text{NPMI}(x,y) = \\frac{\\text{PMI}(x,y)}{-\\log_2 P(x,y)}\n$$\n\n### 2. Positive PMI (PPMI)\n\nPPMI sets negative PMI scores to zero, often used in word embeddings:\n\n$$\n\\text{PPMI}(x,y) = \\max(\\text{PMI}(x,y),\\,0)\n$$\n",
        "contributor": [
            {
                "profile_link": "https://github.com/saitiger",
                "name": "saitiger"
            }
        ]
    },
    {
        "description": "Implement a function that performs Min-Max Normalization on a list of integers, scaling all values to the range [0, 1]. Min-Max normalization helps ensure that all features contribute equally to a model by scaling them to a common range.",
        "id": "112",
        "test_cases": [
            {
                "test": "print(min_max([1, 2, 3, 4, 5]))",
                "expected_output": "[0.0, 0.25, 0.5, 0.75, 1.0]"
            },
            {
                "test": "print([round(x, 4) for x in min_max([30, 45, 56, 70, 88])])",
                "expected_output": "[0.0, 0.2586, 0.4483, 0.6897, 1.0]"
            },
            {
                "test": "print([round(x, 4) for x in min_max([5, 5, 5, 5])])",
                "expected_output": "[0.0, 0.0, 0.0, 0.0]"
            }
        ],
        "difficulty": "easy",
        "solution": "def min_max(x: list[int]) -> list[float]:\n    largest = max(x)\n    smallest = min(x)\n    if largest == smallest:\n        return [0.0] * len(x)\n    for i in range(len(x)):\n        x[i] = round((x[i] - smallest) / (largest - smallest), 4)\n    return x",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "min_max([1, 2, 3, 4, 5])",
            "output": "[0.0, 0.25, 0.5, 0.75, 1.0]",
            "reasoning": "The minimum value is 1 and the maximum is 5. Each value is scaled using the formula (x - min) / (max - min)."
        },
        "category": "Data Preprocessing",
        "starter_code": "def min_max(x: list[int]) -> list[float]:\n\t# Your code here\n\tpass",
        "title": "Min-Max Normalization of Feature Values",
        "learn_section": "## Understanding Min-Max Normalization\n\nMin-Max Normalization is a technique used to rescale numerical data to the range $[0, 1]$.\n\nThe formula used is:\n\n$$\nX' = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n$$\n\n### Why Normalize?\n\n- Ensures all features have equal importance regardless of their original scale.\n- Commonly used in preprocessing for machine learning algorithms such as k-nearest neighbors, neural networks, and gradient descent-based models.\n\n### Special Case\n\nIf all the elements in the input are identical, then $X_{\\max} = X_{\\min}$. In that case, return an array of zeros.\n\n### Example\n\nGiven the input list `[1, 2, 3, 4, 5]`:\n\n- Minimum: $1$\n- Maximum: $5$\n- The normalized values are:\n\n$$\n\\begin{aligned}\n&\\frac{1 - 1}{4} = 0.0 \\\\\n&\\frac{2 - 1}{4} = 0.25 \\\\\n&\\frac{3 - 1}{4} = 0.5 \\\\\n&\\frac{4 - 1}{4} = 0.75 \\\\\n&\\frac{5 - 1}{4} = 1.0\n\\end{aligned}\n$$\n\nThe result is `[0.0, 0.25, 0.5, 0.75, 1.0]`.\n\nRemember to round the result to **4 decimal places**.",
        "contributor": [
            {
                "profile_link": "https://github.com/Noth2006",
                "name": "Noth2006"
            }
        ]
    },
    {
        "description": "Implement a function that creates a simple residual block using NumPy. The block should take a 1D input array, process it through two weight layers (using matrix multiplication), apply ReLU activations, and add the original input via a shortcut connection before a final ReLU activation.",
        "id": "113",
        "test_cases": [
            {
                "test": "x = np.array([1.0, 2.0])\nw1 = np.array([[1.0, 0.0], [0.0, 1.0]])\nw2 = np.array([[0.5, 0.0], [0.0, 0.5]])\nprint(residual_block(x, w1, w2))",
                "expected_output": "[1.5,3.]"
            },
            {
                "test": "x = np.array([-1.0, 2.0])\nw1 = np.array([[1.0, 0.0], [0.0, 1.0]])\nw2 = np.array([[0.5, 0.0], [0.0, 0.5]])\nprint(residual_block(x, w1, w2))",
                "expected_output": "[0.,3.]"
            },
            {
                "test": "x = np.array([0.0, 0.0])\nw1 = np.array([[1.0, 0.0], [0.0, 1.0]])\nw2 = np.array([[0.5, 0.0], [0.0, 0.5]])\nprint(residual_block(x, w1, w2))",
                "expected_output": "[0.,0.]"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef residual_block(x: np.ndarray, w1: np.ndarray, w2: np.ndarray) -> np.ndarray:\n    # First weight layer\n    y = np.dot(w1, x)\n    # First ReLU\n    y = np.maximum(0, y)\n    # Second weight layer\n    y = np.dot(w2, y)\n    # Add shortcut connection (x + F(x))\n    y = y + x\n    # Final ReLU\n    y = np.maximum(0, y)\n    return y",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "x = np.array([1.0, 2.0]), w1 = np.array([[1.0, 0.0], [0.0, 1.0]]), w2 = np.array([[0.5, 0.0], [0.0, 0.5]])",
            "output": "[1.5, 3.0]",
            "reasoning": "The input x is [1.0, 2.0]. First, compute w1 @ x = [1.0, 2.0], apply ReLU to get [1.0, 2.0]. Then, compute w2 @ [1.0, 2.0] = [0.5, 1.0]. Add the shortcut x to get [0.5 + 1.0, 1.0 + 2.0] = [1.5, 3.0]. Final ReLU gives [1.5, 3.0]."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef residual_block(x: np.ndarray, w1: np.ndarray, w2: np.ndarray) -> np.ndarray:\n\t# Your code here\n\tpass",
        "title": "Implement a Simple Residual Block with Shortcut Connection",
        "learn_section": "## Understanding Residual Blocks in ResNet\n\nResidual blocks are the cornerstone of ResNet (Residual Network), a deep learning architecture designed to train very deep neural networks by addressing issues like vanishing gradients. The key idea is to allow the network to learn residuals differences between the input and the desired output rather than the full transformation.\n\n### Core Concept: Residual Learning\nIn a traditional neural network layer, the output is a direct transformation of the input, such as $H(x)$, where $x$ is the input. In a residual block, instead of learning $H(x)$ directly, the network learns the residual $F(x) = H(x) - x$. The output of the block is then:\n\n$$\ny = F(x) + x\n$$\n\nHere, $F(x)$ represents the transformation applied by the layers within the block (e.g., weight layers and activations), and $x$ is the input, added back via a shortcut connection. This structure allows the network to learn an identity function ($F(x) = 0$, so $y = x$) if needed, which helps in training deeper networks.\n\n### Mathematical Structure\nA typical residual block involves two weight layers with an activation function between them. The activation function used in ResNet is ReLU, defined as:\n\n$$\n\\text{ReLU}(z) = \\max(0, z)\n$$\n\nThe block takes an input $x$, applies a transformation $F(x)$ through the weight layers and activations, and then adds the input $x$ back. Mathematically, if the weight layers are represented by matrices $W_1$ and $W_2$, the transformation $F(x)$ might look like a composition of operations involving $W_1 \\cdot x$, a ReLU activation, and $W_2$ applied to the result. The final output $y$ is the sum of $F(x)$ and $x$, often followed by another ReLU activation to ensure non-negativity.\n\n### Why Shortcut Connections?\n- **Ease of Learning**: If the optimal transformation is close to an identity function, the block can learn $F(x) \\approx 0$, making $y \\approx x$.\n- **Gradient Flow**: The shortcut connection allows gradients to flow directly through the addition operation during backpropagation, helping to train deeper networks without vanishing gradients.\n\n### Conceptual Example\nSuppose the input $x$ is a vector of length 2, and the weight layers are matrices $W_1$ and $W_2$. The block computes $F(x)$ by applying $W_1$, a ReLU activation, and $W_2$, then adds $x$ to the result. The shortcut connection ensures that even if $F(x)$ is small, the output $y$ retains information from $x$, making it easier for the network to learn.\n\nThis structure is what enables ResNet to scale to hundreds of layers while maintaining performance, as shown in the diagram of the residual block.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement a function that performs Global Average Pooling on a 3D NumPy array representing feature maps from a convolutional layer. The function should take an input of shape (height, width, channels) and return a 1D array of shape (channels,), where each element is the average of all values in the corresponding feature map.",
        "id": "114",
        "test_cases": [
            {
                "test": "x = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\nprint(global_avg_pool(x))",
                "expected_output": "[5.5,6.5,7.5]"
            },
            {
                "test": "x = np.array([[[100, 200]]])\nprint(global_avg_pool(x))",
                "expected_output": "[100.,200.]"
            },
            {
                "test": "x = np.ones((3, 3, 1))\nprint(global_avg_pool(x))",
                "expected_output": "[1.]"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef global_avg_pool(x: np.ndarray) -> np.ndarray:\n    return np.mean(x, axis=(0, 1))",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "x = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])",
            "output": "[5.5, 6.5, 7.5]",
            "reasoning": "For each channel, compute the average of all elements. For channel 0: (1+4+7+10)/4 = 5.5, for channel 1: (2+5+8+11)/4 = 6.5, for channel 2: (3+6+9+12)/4 = 7.5."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef global_avg_pool(x: np.ndarray) -> np.ndarray:\n\t# Your code here\n\tpass",
        "title": "Implement Global Average Pooling",
        "learn_section": "## Understanding Global Average Pooling\n\nGlobal Average Pooling (GAP) is a pooling operation commonly used in convolutional neural networks (CNNs) to reduce the spatial dimensions of feature maps. Unlike traditional pooling methods like max pooling or average pooling with a fixed window size, GAP computes the average of each entire feature map, resulting in a single value per channel.\n\n### How It Works\n\nGiven a 3D input tensor of shape $(H, W, C)$, where:\n- $H$ is the height,\n- $W$ is the width,\n- $C$ is the number of channels (feature maps),\n\nGlobal Average Pooling produces a 1D output vector of shape $(C,)$, where each element is the average of all values in the corresponding feature map.\n\nMathematically, for each channel $c$:\n\n$$\n\\text{GAP}(x)_c = \\frac{1}{H \\times W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} x_{i,j,c}\n$$\n\n### Benefits of Global Average Pooling\n\n- **Parameter Reduction**: By replacing fully connected layers with GAP, the number of parameters is significantly reduced, which helps in preventing overfitting.\n- **Spatial Invariance**: GAP captures the global information from each feature map, making the model more robust to spatial translations.\n- **Simplicity**: It is a straightforward operation that doesn't require tuning hyperparameters like pooling window size or stride.\n\n### Use in Modern Architectures\n\nGlobal Average Pooling is a key component in architectures like ResNet, where it is used before the final classification layer. It allows the network to handle inputs of varying sizes, as the output depends only on the number of channels, not the spatial dimensions.\n\n### Example\n\nConsider a 2x2x3 input tensor:\n\n$$\nx = \\begin{bmatrix}\n\\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix},\n\\begin{bmatrix} 7 & 8 & 9 \\\\ 10 & 11 & 12 \\end{bmatrix}\n\\end{bmatrix}\n$$\n\nApplying GAP:\n\n- For channel 0: $\\frac{1+4+7+10}{4} = \\frac{22}{4} = 5.5$\n- For channel 1: $\\frac{2+5+8+11}{4} = \\frac{26}{4} = 6.5$\n- For channel 2: $\\frac{3+6+9+12}{4} = \\frac{30}{4} = 7.5$\n\nThus, the output is $[5.5, 6.5, 7.5]$.\n\nThis operation effectively summarizes each feature map into a single value, capturing the essence of the features learned by the network.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement a function that performs Batch Normalization on a 4D NumPy array representing a batch of feature maps in the BCHW format (batch, channels, height, width). The function should normalize the input across the batch and spatial dimensions for each channel, then apply scale (gamma) and shift (beta) parameters. Use the provided epsilon value to ensure numerical stability.",
        "id": "115",
        "test_cases": [
            {
                "test": "B, C, H, W = 2, 2, 2, 2\nnp.random.seed(42)\nX = np.random.randn(B, C, H, W)\ngamma = np.ones(C).reshape(1, C, 1, 1)\nbeta = np.zeros(C).reshape(1, C, 1, 1)\nactual_output = batch_normalization(X, gamma, beta)\nexpected_output = np.array([[[[ 0.42859934, -0.51776438], [ 0.65360963,  1.95820707]], [[ 0.02353721,  0.02355215], [ 1.67355207,  0.93490043]]], [[[-1.01139563,  0.49692747], [-1.00236882, -1.00581468]], [[ 0.45676349, -1.50433085], [-1.33293647, -0.27503802]]]])\nprint(actual_output)",
                "expected_output": "[[[[ 0.42859934, -0.51776438], [ 0.65360963,1.95820707]],[[ 0.02353721,  0.02355215], [ 1.67355207,  0.93490043]]], [[[-1.01139563,  0.49692747], [-1.00236882, -1.00581468]], [[ 0.45676349, -1.50433085], [-1.33293647, -0.27503802]]]]"
            },
            {
                "test": "B, C, H, W = 2, 2, 2, 2\nnp.random.seed(101)\nX = np.random.randn(B, C, H, W)\ngamma = np.ones(C).reshape(1, C, 1, 1)\nbeta = np.zeros(C).reshape(1, C, 1, 1)\nactual_output = batch_normalization(X, gamma, beta)\nexpected_output = np.array([[[[ 1.81773164,  0.16104096], [ 0.38406453,  0.06197112]], [[ 1.00432932, -0.37139956], [-1.12098938,  0.94031919]]], [[[-1.94800122,  0.25029395], [ 0.08188579, -0.80898678]], [[ 0.34878049, -0.99452891], [-1.24171594,  1.43520478]]]])\nprint(actual_output)",
                "expected_output": "[[[[ 1.81773164,0.16104096], [ 0.38406453,0.06197112]],[[ 1.00432932, -0.37139956], [-1.12098938,  0.94031919]]], [[[-1.94800122,  0.25029395], [ 0.08188579, -0.80898678]], [[ 0.34878049, -0.99452891], [-1.24171594,  1.43520478]]]]"
            },
            {
                "test": "B, C, H, W = 2, 2, 2, 2\nnp.random.seed(101)\nX = np.random.randn(B, C, H, W)\ngamma = np.ones(C).reshape(1, C, 1, 1) * 0.5\nbeta = np.ones(C).reshape(1, C, 1, 1)\nactual_output = batch_normalization(X, gamma, beta)\nexpected_output = np.array([[[[1.90886582, 1.08052048], [1.19203227, 1.03098556]], [[1.50216466, 0.81430022], [0.43950531, 1.4701596 ]]], [[[0.02599939, 1.12514697], [1.04094289, 0.59550661]], [[1.17439025, 0.50273554], [0.37914203, 1.71760239]]]])\nprint(actual_output)",
                "expected_output": "[[[[1.90886582, 1.08052048], [1.19203227, 1.03098556]], [[1.50216466, 0.81430022], [0.43950531, 1.4701596 ]]], [[[0.02599939, 1.12514697], [1.04094289, 0.59550661]], [[1.17439025, 0.50273554], [0.37914203, 1.71760239]]]]"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef batch_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, epsilon: float = 1e-5) -> np.ndarray:\n    # Compute mean and variance across the batch and spatial dimensions\n    mean = np.mean(X, axis=(0, 2, 3), keepdims=True)  # Mean over (B, H, W)\n    variance = np.var(X, axis=(0, 2, 3), keepdims=True)  # Variance over (B, H, W)\n    # Normalize\n    X_norm = (X - mean) / np.sqrt(variance + epsilon)\n    # Scale and shift\n    norm_X = gamma * X_norm + beta\n    return norm_X",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "B, C, H, W = 2, 2, 2, 2; np.random.seed(42); X = np.random.randn(B, C, H, W); gamma = np.ones(C).reshape(1, C, 1, 1); beta = np.zeros(C).reshape(1, C, 1, 1)",
            "output": "[[[[ 0.42859934, -0.51776438], [ 0.65360963,  1.95820707]], [[ 0.02353721,  0.02355215], [ 1.67355207,  0.93490043]]], [[[-1.01139563,  0.49692747], [-1.00236882, -1.00581468]], [[ 0.45676349, -1.50433085], [-1.33293647, -0.27503802]]]]",
            "reasoning": "The input X is a 2x2x2x2 array. For each channel, compute the mean and variance across the batch (B), height (H), and width (W) dimensions. Normalize X using (X - mean) / sqrt(variance + epsilon), then scale by gamma and shift by beta. The output matches the expected normalized values."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef batch_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, epsilon: float = 1e-5) -> np.ndarray:\n\t# Your code here\n\tpass",
        "title": "Implement Batch Normalization for BCHW Input",
        "learn_section": "## Understanding Batch Normalization\n\nBatch Normalization (BN) is a widely used technique that helps to accelerate the training of deep neural networks and improve model performance. By normalizing the inputs to each layer so that they have a mean of zero and a variance of one, BN stabilizes the learning process, speeds up convergence, and introduces regularization, which can reduce the need for other forms of regularization like dropout.\n\n### Concepts\n\nBatch Normalization operates on the principle of reducing **internal covariate shift**, which occurs when the distribution of inputs to a layer changes during training as the model weights get updated. This can slow down training and make hyperparameter tuning more challenging. By normalizing the inputs, BN reduces this problem, allowing the model to train faster and more reliably.\n\nThe process of Batch Normalization consists of the following steps:\n\n1. **Compute the Mean and Variance:** For each mini-batch, compute the mean and variance of the activations for each feature (dimension).\n2. **Normalize the Inputs:** Normalize the activations using the computed mean and variance.\n3. **Apply Scale and Shift:** After normalization, apply a learned scale (gamma) and shift (beta) to restore the model's ability to represent the data's original distribution.\n4. **Training and Inference:** During training, the mean and variance are computed from the current mini-batch. During inference, a running average of the statistics from the training phase is used.\n\n### Structure of Batch Normalization for BCHW Input\n\nFor an input tensor with the shape **BCHW**, where:\n- **B**: batch size,\n- **C**: number of channels,\n- **H**: height,\n- **W**: width,\nthe Batch Normalization process operates on specific dimensions based on the task's requirement.\n\n#### 1. Mean and Variance Calculation\n\n- In **Batch Normalization**, we typically normalize the activations **across the batch** and **over the spatial dimensions (height and width)** for each **channel**. This means we calculate the mean and variance **per channel** (C) for the **batch and spatial dimensions** (H, W).\n\nFor each channel $c$, we compute the **mean** $\\mu_c$ and **variance** $\\sigma_c^2$ over the mini-batch and spatial dimensions:\n\n$$\n\\mu_c = \\frac{1}{B \\cdot H \\cdot W} \\sum_{i=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{i,c,h,w}\n$$\n\n$$\n\\sigma_c^2 = \\frac{1}{B \\cdot H \\cdot W} \\sum_{i=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} (x_{i,c,h,w} - \\mu_c)^2\n$$\n\nWhere:\n- $x_{i,c,h,w}$ is the input activation at batch index $i$, channel $c$, height $h$, and width $w$.\n- $B$ is the batch size.\n- $H$ and $W$ are the spatial dimensions (height and width).\n- $C$ is the number of channels.\n\nThe mean and variance are computed **over all spatial positions (H, W)** and **across all samples in the batch (B)** for each **channel (C)**.\n\n#### 2. Normalization\n\nOnce the mean $\\mu_c$ and variance $\\sigma_c^2$ have been computed for each channel, the next step is to **normalize** the input. The normalization is done by subtracting the mean and dividing by the standard deviation (plus a small constant $\\epsilon$ for numerical stability):\n\n$$\n\\hat{x}_{i,c,h,w} = \\frac{x_{i,c,h,w} - \\mu_c}{\\sqrt{\\sigma_c^2 + \\epsilon}}\n$$\n\nWhere:\n- $\\hat{x}_{i,c,h,w}$ is the normalized activation for the input at batch index $i$, channel $c$, height $h$, and width $w$.\n- $\\epsilon$ is a small constant to avoid division by zero (for numerical stability).\n\n#### 3. Scale and Shift\n\nAfter normalization, the next step is to apply a **scale** ($\\gamma_c$) and **shift** ($\\beta_c$) to the normalized activations for each channel. These learned parameters allow the model to adjust the output distribution of each feature, preserving the flexibility of the original activations.\n\n$$\ny_{i,c,h,w} = \\gamma_c \\hat{x}_{i,c,h,w} + \\beta_c\n$$\n\nWhere:\n- $\\gamma_c$ is the scaling factor for channel $c$.\n- $\\beta_c$ is the shifting factor for channel $c$.\n\n#### 4. Training and Inference\n\n- **During Training**: The mean and variance are computed for each mini-batch and used for normalization across the batch and spatial dimensions for each channel.\n- **During Inference**: The model uses a running average of the statistics (mean and variance) that were computed during training to ensure consistent behavior when deployed.\n\n### Key Points\n\n- **Normalization Across Batch and Spatial Dimensions**: In Batch Normalization for **BCHW** input, the normalization is done **across the batch (B) and spatial dimensions (H, W)** for each **channel (C)**. This ensures that each feature channel has zero mean and unit variance, making the training process more stable.\n\n- **Channel-wise Normalization**: Batch Normalization normalizes the activations independently for each **channel (C)** because different channels in convolutional layers often have different distributions and should be treated separately.\n\n- **Numerical Stability**: The small constant $\\epsilon$ is added to the variance to avoid numerical instability when dividing by the square root of variance, especially when the variance is very small.\n\n- **Improved Gradient Flow**: By reducing internal covariate shift, Batch Normalization allows the gradients to flow more easily during backpropagation, helping the model train faster and converge more reliably.\n\n- **Regularization Effect**: Batch Normalization introduces noise into the training process because it relies on the statistics of a mini-batch. This noise acts as a form of regularization, which can prevent overfitting and improve generalization.\n\n### Why Normalize Over Batch and Spatial Dimensions?\n\n- **Across Batch**: Normalizing across the batch helps to stabilize the input distribution across all samples in a mini-batch. This allows the model to avoid the problem of large fluctuations in the input distribution as weights are updated.\n\n- **Across Spatial Dimensions**: In convolutional networks, the spatial dimensions (height and width) are highly correlated, and normalizing over these dimensions ensures that the activations are distributed consistently throughout the spatial field, helping to maintain a stable learning process.\n\n- **Channel-wise Normalization**: Each channel can have its own distribution of values, and normalization per channel ensures that each feature map is scaled and shifted independently, allowing the model to learn representations that are not overly sensitive to specific channels' scaling.\n\nBy normalizing across the batch and spatial dimensions and applying a per-channel transformation, Batch Normalization helps reduce internal covariate shift and speeds up training, leading to faster convergence and better overall model performance.",
        "contributor": [
            {
                "profile_link": "https://github.com/nzomi",
                "name": "nzomi"
            }
        ]
    },
    {
        "description": "Implement a function that computes the derivative of a polynomial term of the form `c * x^n` at a given point `x`, where `c` is a coefficient and `n` is the exponent. The function should return the value of the derivative, accounting for the coefficient in the power rule. This is useful for understanding how polynomials change at specific points in machine learning optimization problems.",
        "id": "116",
        "test_cases": [
            {
                "test": "print(poly_term_derivative(2.0, 3.0, 2.0))",
                "expected_output": "12.0"
            },
            {
                "test": "print(poly_term_derivative(1.5, 4.0, 0.0))",
                "expected_output": "0.0"
            },
            {
                "test": "print(poly_term_derivative(3.0, 2.0, 3.0))",
                "expected_output": "36.0"
            },
            {
                "test": "print(poly_term_derivative(0.5, 5.0, 1.0))",
                "expected_output": "0.5"
            }
        ],
        "difficulty": "easy",
        "solution": "def poly_term_derivative(c: float, x: float, n: float) -> float:\n    if n == 0.0:\n        return 0.0\n    return round(c * n * (x ** (n - 1)), 4)",
        "likes": "0",
        "video": "https://youtu.be/xoRFwJdDT0A",
        "dislikes": "0",
        "example": {
            "input": "poly_term_derivative(2.0, 3.0, 2.0)",
            "output": "12.0",
            "reasoning": "For the term 2 * x^2, the derivative is 2 * 2 * x^(2-1) = 4 * x. At x = 3, this evaluates to 4 * 3 = 12.0."
        },
        "category": "calculus",
        "starter_code": "def poly_term_derivative(c: float, x: float, n: float) -> float:\n    # Your code here\n    pass",
        "title": "Derivative of a Polynomial",
        "learn_section": "## Derivative of a Polynomial\n\nA function's derivative is a way of quantifying the function's slope at a given point. It allows us to understand whether the function is increasing, decreasing or flat at specific input. \n\nTaking the derivative of a polynomial at a single point follows a straight-forward rule. This question will show the rule and the edge case you should be on the look-out for.\n\n### Mathematical Definition\n\nWhen calculating the slope of a function $f(x)$, we usually require two points $x_{1}$ and $x_{2}$ and use the following formula:\n\n$$\n\\frac{f(x_{2}) - f(x_{1})}{x_{2} - x_{1}}\n$$\n\nA derivative generalizes that notion by calculating the slope of a function at a specific point.\nA derivative of a function $f(x)$ is mathematically defined as:\n\n$$\n\\frac{d f(x)}{d x} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n$$\n\nWhere:\n- $x$ is the input to the function\n- $h$ is the \"step\", which is equivalent to the difference $x_{2} - x_{1}$ in the two-point slope-formula\n\nTaking the limit as the step grows smaller and smaller, allow us to quantify the slope at a certain point, instead of having to consider two points as in other methods of finding the slope.\n\nWhen taking the derivative of a polynomial function $x^{n}$, where $n \\neq 0$, then the derivative is: $n x^{n-1}$. In the special case where $n = 0$ then the derivative is zero. This is because $x^{0} = 1$ if $x \\neq 0$.\n\nA positive derivative indicates that the function is increasing in that point, a negative derivative indicates that the function is decreasing at that point. A derivative equal to zero indicates that the function is flat, which could potentially indicate a function's minimum or maximum.",
        "contributor": [
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            }
        ]
    },
    {
        "description": "Implement a function that computes an orthonormal basis for the subspace spanned by a list of 2D vectors using the Gram-Schmidt process. The function should take a list of 2D vectors and a tolerance value (tol) to determine linear independence, returning a list of orthonormal vectors (unit length and orthogonal to each other) that span the same subspace. This is a fundamental concept in linear algebra with applications in machine learning, such as feature orthogonalization.",
        "id": "117",
        "test_cases": [
            {
                "test": "basis = orthonormal_basis([[1, 0], [1, 1]]); print([b.round(4) for b in basis])",
                "expected_output": "[array([1., 0.]), array([0., 1.])]"
            },
            {
                "test": "basis = orthonormal_basis([[2, 0], [4, 0]], tol=1e-10); print([b.round(4) for b in basis])",
                "expected_output": "[array([1., 0.])]"
            },
            {
                "test": "basis = orthonormal_basis([[1, 1], [1, -1]], tol=1e-5); print([b.round(4) for b in basis])",
                "expected_output": "[array([0.7071, 0.7071]), array([0.7071, -0.7071])]"
            },
            {
                "test": "basis = orthonormal_basis([[0, 0]], tol=1e-10); print([b.round(4) for b in basis])",
                "expected_output": "[]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef orthonormal_basis(vectors: list[list[float]], tol: float = 1e-10) -> list[np.ndarray]:\n    basis = []\n    for v in vectors:\n        v = np.array(v, dtype=float)\n        for b in basis:\n            v = v - np.dot(v, b) * b\n        norm = np.sqrt(np.dot(v, v))\n        if norm > tol:\n            v = v / norm\n            basis.append(v)\n    return basis",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "orthonormal_basis([[1, 0], [1, 1]])",
            "output": "[array([1., 0.]), array([0., 1.])]",
            "reasoning": "Start with [1, 0], normalize to [1, 0]. For [1, 1], subtract its projection onto [1, 0] (which is [1, 0]), leaving [0, 1]. Check if norm > 1e-10 (it is 1), then normalize to [0, 1]. The result is an orthonormal basis."
        },
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef orthonormal_basis(vectors: list[list[float]], tol: float = 1e-10) -> list[np.ndarray]:\n    # Your code here\n    pass",
        "title": "Compute Orthonormal Basis for 2D Vectors",
        "learn_section": "## Understanding the Gram-Schmidt Process\n\nThe Gram-Schmidt process transforms a set of vectors into an orthonormal basis vectors that are orthogonal (perpendicular) and have unit length for the subspace they span.\n\n### Mathematical Definition\n\nGiven vectors $v_1, v_2, \\ldots$, the process constructs an orthonormal set $u_1, u_2, \\ldots$ as follows:\n1. $u_1 = \\frac{v_1}{\\|v_1\\|}$ (normalize the first vector).\n2. For subsequent vectors $v_k$:\n   - Subtract projections: $$w_k = v_k - \\sum_{i=1}^{k-1} \\text{proj}_{u_i}(v_k),$$ where $\\text{proj}_{u_i}(v_k) = (v_k \\cdot u_i) u_i$.\n   - Normalize: $$u_k = \\frac{w_k}{\\|w_k\\|},$$ if $\\|w_k\\| > \\text{tol}$.\n\n### Why Orthonormal Bases?\n\n- Orthogonal vectors simplify computations (e.g., their dot product is zero).\n- Unit length ensures equal scaling, useful in $PCA$, $QR$ decomposition, and neural network optimization.\n\n### Special Case\n\nIf a vector's norm is less than or equal to $\\text{tol}$ (default $1e-10$), it's considered linearly dependent and excluded from the basis.\n\n### Example\n\nFor vectors `[[1, 0], [1, 1]]` with $\\text{tol} = 1e-10$:\n1. $v_1 = [1, 0]$, $\\|v_1\\| = 1$, so $u_1 = [1, 0]$.\n2. $v_2 = [1, 1]$, projection on $u_1$: $(v_2 \\cdot u_1) u_1 = 1 \\cdot [1, 0] = [1, 0]$.\n   - $w_2 = [1, 1] - [1, 0] = [0, 1]$.\n   - $\\|w_2\\| = 1 > 1e-10$, so $u_2 = [0, 1]$.\n\nResult: `[[1, 0], [0, 1]]`, rounded to 4 decimal places.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement a function to compute the cross product of two 3-dimensional vectors. The cross product of two vectors results in a third vector that is perpendicular to both and follows the right-hand rule. This concept is fundamental in physics, engineering, and 3D graphics.",
        "id": "118",
        "test_cases": [
            {
                "test": "print(cross_product([1, 0, 0], [0, 1, 0]))",
                "expected_output": "[0, 0, 1]"
            },
            {
                "test": "print(cross_product([0, 1, 0], [0, 0, 1]))",
                "expected_output": "[1, 0, 0]"
            },
            {
                "test": "print(cross_product([1, 2, 3], [4, 5, 6]))",
                "expected_output": "[-3, 6, -3]"
            },
            {
                "test": "print(cross_product([1, 0, 0], [1, 0, 0]))",
                "expected_output": "[0, 0, 0]"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef cross_product(a, b):\n    \"\"\"\n    Compute the cross product of two 3D vectors a and b.\n    Parameters:\n        a (array-like): A 3-element vector.\n        b (array-like): A 3-element vector.\n    Returns:\n        numpy.ndarray: The cross product vector.\n    \"\"\"\n    a = np.array(a)\n    b = np.array(b)\n\n    if a.shape != (3,) or b.shape != (3,):\n        raise ValueError(\"Both input vectors must be of length 3.\")\n\n    cross = np.array([\n        a[1] * b[2] - a[2] * b[1],\n        a[2] * b[0] - a[0] * b[2],\n        a[0] * b[1] - a[1] * b[0]\n    ])\n    return cross",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "cross_product([1, 0, 0], [0, 1, 0])",
            "output": "[0, 0, 1]",
            "reasoning": "The cross product of two orthogonal unit vectors [1, 0, 0] and [0, 1, 0] is [0, 0, 1], pointing in the positive z-direction as per the right-hand rule."
        },
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef cross_product(a, b):\n    # Your code here\n    pass",
        "title": "Compute the Cross Product of Two 3D Vectors",
        "learn_section": "## Understanding the Cross Product\n\nThe **cross product** of two vectors $\\vec{a}$ and $\\vec{b}$ in 3D space is a vector that is perpendicular to both $\\vec{a}$ and $\\vec{b}$.\n\n### Properties\n- Defined only in 3 dimensions.\n- The result $\\vec{c} = \\vec{a} \\times \\vec{b}$ is perpendicular to both $\\vec{a}$ and $\\vec{b}$.\n- Follows the right-hand rule.\n\n### Mathematical Formula\n\nGiven:\n- $\\vec{a} = [a_1, a_2, a_3]$\n- $\\vec{b} = [b_1, b_2, b_3]$\n\nThe cross product is:\n\n$$\n\\vec{a} \\times \\vec{b} = [a_2 b_3 - a_3 b_2,\\ a_3 b_1 - a_1 b_3,\\ a_1 b_2 - a_2 b_1]\n$$\n\n### Use Cases\n- Calculating normals in 3D graphics.\n- Determining torque and angular momentum in physics.\n- Verifying orthogonality in machine learning geometry.\n\n### Example\nFor $\\vec{a} = [1, 0, 0]$ and $\\vec{b} = [0, 1, 0]$:\n\n$$\n\\vec{a} \\times \\vec{b} = [0, 0, 1]\n$$\n\nThe result points in the $z$-axis direction, confirming perpendicularity to both $\\vec{a}$ and $\\vec{b}$.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement a function to solve a system of linear equations $Ax = b$ using Cramer's Rule. The function should take a square coefficient matrix $A$ and a constant vector $b$, and return the solution vector $x$. If the system has no unique solution (i.e., the determinant of $A$ is zero), return -1.",
        "id": "119",
        "test_cases": [
            {
                "test": "print(np.round(cramers_rule([[2, -1, 3], [4, 2, 1], [-6, 1, -2]], [5, 10, -3]), 4))",
                "expected_output": "[0.1667, 3.3333, 2.6667]"
            },
            {
                "test": "print(np.round(cramers_rule([[1, 2], [3, 4]], [5, 6]), 4))",
                "expected_output": "[-4.,4.5]"
            },
            {
                "test": "print(cramers_rule([[1, 2], [2, 4]], [3, 6]))",
                "expected_output": "-1"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef cramers_rule(A, b):\n    A = np.array(A, dtype=float)\n    b = np.array(b, dtype=float)\n\n    n, m = A.shape\n    if n != m or b.shape[0] != n:\n        return -1\n\n    det_A = np.linalg.det(A)\n    if np.isclose(det_A, 0):\n        return -1\n\n    x = np.zeros(n)\n    for i in range(n):\n        A_mod = A.copy()\n        A_mod[:, i] = b\n        det_A_mod = np.linalg.det(A_mod)\n        x[i] = det_A_mod / det_A\n\n    return x",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "A = [[2, -1, 3], [4, 2, 1], [-6, 1, -2]], b = [5, 10, -3]",
            "output": "[0.1667 3.3333 2.6667]",
            "reasoning": "We compute the determinant of A and then replace each column with vector b to compute the determinants of modified matrices. These are then used in the formula $x_i = \\frac{\\det(A_i)}{\\det(A)}$ to get the solution."
        },
        "category": "Linear Algebra for Machine Learning",
        "starter_code": "import numpy as np\n\ndef cramers_rule(A, b):\n    # Your code here\n    pass",
        "title": "Solve System of Linear Equations Using Cramer's Rule",
        "learn_section": "## Understanding Cramer's Rule\n\nCramer's Rule is a method to solve a system of linear equations $Ax = b$ using determinants.\n\n### Requirements\n- The coefficient matrix $A$ must be square ($n \\times n$).\n- The determinant of $A$, $\\det(A)$, must be non-zero for a unique solution to exist.\n\n### Formula\nFor each variable $x_i$, replace the $i$-th column of $A$ with vector $b$ and compute:\n\n$$\nx_i = \\frac{\\det(A_i)}{\\det(A)}\n$$\n\nWhere:\n- $A_i$ is the matrix formed by replacing the $i$-th column of $A$ with $b$\n- $\\det(A)$ is the determinant of the original matrix $A$\n\n### Steps\n1. Compute $\\det(A)$. If it's 0, return -1.\n2. For each variable $x_i$:\n   - Replace column $i$ in $A$ with $b$\n   - Compute $\\det(A_i)$\n   - Compute $x_i = \\frac{\\det(A_i)}{\\det(A)}$\n\n### Example\nGiven:\n\n$$\nA = \\begin{bmatrix} 2 & -1 & 3 \\\\ 4 & 2 & 1 \\\\ -6 & 1 & -2 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 5 \\\\ 10 \\\\ -3 \\end{bmatrix}\n$$\n\n1. $\\det(A) = -36.0$\n2. Replace each column with $b$:\n\n- $\\det(A_1) = -6.0$\n- $\\det(A_2) = -120.0$\n- $\\det(A_3) = -96.0$\n\nThen,\n\n$$\nx = \\left[ \\frac{-6}{-36}, \\frac{-120}{-36}, \\frac{-96}{-36} \\right] = [0.1667, 3.3333, 2.6667]\n$$\n\n### Applications\n- Solving small systems of equations\n- Useful in theoretical linear algebra\n- Not practical for large matrices due to computational cost",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Write a Python function called svd_2x2_singular_values(A) that finds an approximate singular value decomposition of a real 2 x 2 matrix using one Jacobi rotation.\nInput\nA: a NumPy array of shape (2, 2)\n\nRules\nYou may use basic NumPy operations (matrix multiplication, transpose, element wise math, etc.).\nDo not call numpy.linalg.svd or any other high-level SVD routine.\nStick to a single Jacobi step no iterative refinements.\n\nReturn\nA tuple (U, Σ, V_T) where\nU is a 2 x 2 orthogonal matrix,\nΣ is a length 2 NumPy array containing the singular values, and\nV_T is the transpose of the right-singular-vector matrix V.",
        "id": "12",
        "tinygrad_difficulty": "medium",
        "mdx_file": "81ae5461-af60-471a-97d1-ddd4b26ddbae.mdx",
        "test_cases": [
            {
                "test": "print(svd_2x2_singular_values(np.array([[2, 1], [1, 2]])))",
                "expected_output": "(array([[ 0.70710678, -0.70710678],\n       [ 0.70710678,  0.70710678]]), array([3., 1.]), array([[ 0.70710678,  0.70710678],\n       [-0.70710678,  0.70710678]]))"
            },
            {
                "test": "print(svd_2x2_singular_values(np.array([[1, 2], [3, 4]])))",
                "expected_output": "array([[ 0.40455358, 0.9145143 ], [ 0.9145143 , -0.40455358]]), array([5.4649857 , 0.36596619]), array([[ 0.57604844, 0.81741556], [-0.81741556, 0.57604844]])"
            }
        ],
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHN2ZF8yeDJfc2luZ3VsYXJfdmFsdWVzX3RnKEEpIC0+IHR1cGxlW1RlbnNvciwgVGVuc29yLCBUZW5zb3JdOgogICAgIiIiCiAgICBBcHByb3hpbWF0ZSB0aGUgU1ZEIG9mIGEgMsOXMiBtYXRyaXggQSB1c2luZyBvbmUgSmFjb2JpIHJvdGF0aW9uIGluIHRpbnlncmFkLgogICAgUmV0dXJucyAoVSwgUywgVnQpIHdoZXJlIFMgaXMgYSAxLUQgVGVuc29yIG9mIHNpbmd1bGFyIHZhbHVlcy4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "difficulty": "hard",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBzdmRfMngyX3Npbmd1bGFyX3ZhbHVlc190ZyhBKSAtPiB0dXBsZVtUZW5zb3IsIFRlbnNvciwgVGVuc29yXToKICAgICIiIgogICAgQXBwcm94aW1hdGUgdGhlIFNWRCBvZiBhIDLDlzIgbWF0cml4IEEgdXNpbmcgb25lIEphY29iaSByb3RhdGlvbiBpbiB0aW55Z3JhZC4KICAgIFJldHVybnMgKFUsIFMsIFZ0KSB3aGVyZSBTIGlzIGEgMS1EIFRlbnNvciBvZiBzaW5ndWxhciB2YWx1ZXMuCiAgICAiIiIKICAgIEFfdCA9IFRlbnNvcihBKS5mbG9hdCgpCiAgICAjIGNvbXB1dGUgQeG1gEEKICAgIGEyID0gQV90LlQubWF0bXVsKEFfdCkKICAgIFYgPSBUZW5zb3IoW1sxLjAsIDAuMF0sIFswLjAsIDEuMF1dKQogICAgIyBleHRyYWN0IGVudHJpZXMKICAgIGFfdmFsID0gYTJbMCwwXS5udW1weSgpOyBkX3ZhbCA9IGEyWzEsMV0ubnVtcHkoKTsgYl92YWwgPSBhMlswLDFdLm51bXB5KCkKICAgICMgY29tcHV0ZSByb3RhdGlvbiBhbmdsZQogICAgaWYgbnAuaXNjbG9zZShhX3ZhbCwgZF92YWwpOgogICAgICAgIHRoZXRhID0gbnAucGkvNAogICAgZWxzZToKICAgICAgICB0aGV0YSA9IDAuNSAqIG5wLmFyY3RhbjIoMiAqIGJfdmFsLCBhX3ZhbCAtIGRfdmFsKQogICAgYywgcyA9IG5wLmNvcyh0aGV0YSksIG5wLnNpbih0aGV0YSkKICAgIFIgPSBUZW5zb3IoW1tjLCAtc10sIFtzLCBjXV0pCiAgICBEID0gUi5ULm1hdG11bChhMikubWF0bXVsKFIpCiAgICBWID0gVi5tYXRtdWwoUikKICAgICMgc2luZ3VsYXIgdmFsdWVzCiAgICBTID0gVGVuc29yKG5wLnNxcnQoW0RbMCwwXS5udW1weSgpLCBEWzEsMV0ubnVtcHkoKV0pKQogICAgIyBjb21wdXRlIFUKICAgIFNfaW52ID0gVGVuc29yKFtbMS4wL1NbMF0ubnVtcHkoKSwgMC4wXSwgWzAuMCwgMS4wL1NbMV0ubnVtcHkoKV1dKQogICAgVSA9IEFfdC5tYXRtdWwoVikubWF0bXVsKFNfaW52KQogICAgcmV0dXJuIFUsIFMsIFYuVAo=",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "",
        "solution": "import numpy as np \n\n\ndef svd_2x2_singular_values(A: np.ndarray) -> tuple:\n   # stick to lowercase\n   a = A\n\n   a_t = np.transpose(a)\n   a_2 = a_t @ a\n\n   v = np.eye(2)\n\n   for _ in range(1):\n       # Compute rotation angle for a 2x2 matrix\n       if a_2[0,0] == a_2[1,1]:\n           theta = np.pi/4\n       else:\n           theta = 0.5 * np.arctan2(2 * a_2[0,1], a_2[0,0] - a_2[1,1])\n       \n       # Create rotation matrix\n       r = np.array(\n           [\n               [np.cos(theta), -np.sin(theta)],\n               [np.sin(theta), np.cos(theta)]\n               ]\n           )\n       \n       # apply rotation\n       d = np.transpose(r) @ a_2 @ r\n\n       # update a_2\n       a_2 = d\n\n       # accumulate v\n       v = v @ r\n\n   # sigma is the diagonal elements squared\n   s = np.sqrt([d[0,0], d[1,1]])\n   s_inv = np.array([[1/s[0], 0], [0, 1/s[1]]])\n   \n   u = a @ v @ s_inv\n   \n   return (u, s, v.T)\n    ",
        "example": {
            "input": "a = [[2, 1], [1, 2]]",
            "output": "(array([[-0.70710678, -0.70710678],\n                        [-0.70710678,  0.70710678]]),\n        array([3., 1.]),\n        array([[-0.70710678, -0.70710678],\n               [-0.70710678,  0.70710678]]))",
            "reasoning": "U is the first matrix sigma is the second vector and V is the third matrix"
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np \n def svd_2x2_singular_values(A: np.ndarray) -> tuple:\n\treturn SVD",
        "title": "Singular Value Decomposition (SVD)",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgc3ZkXzJ4Ml9zaW5ndWxhcl92YWx1ZXMoQTogdG9yY2guVGVuc29yKSAtPiB0dXBsZVt0b3JjaC5UZW5zb3IsIHRvcmNoLlRlbnNvciwgdG9yY2guVGVuc29yXToKICAgICIiIgogICAgQXBwcm94aW1hdGUgdGhlIFNWRCBvZiBhIDLDlzIgbWF0cml4IEEgdXNpbmcgb25lIEphY29iaSByb3RhdGlvbi4KICAgIFJldHVybnMgKFUsIFMsIFZ0KSB3aGVyZSBTIGlzIGEgMS1EIHRlbnNvciBvZiBzaW5ndWxhciB2YWx1ZXMuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nU, S, Vt = svd_2x2_singular_values(torch.tensor([[1.0, 0.0], [0.0, 1.0]]))\nprint(U.numpy().tolist(), S.numpy().tolist(), Vt.numpy().tolist())",
                "expected_output": "[[0.7071067690849304, -0.7071067690849304], [0.7071067690849304, 0.7071067690849304]] [1.0, 1.0] [[0.7071067690849304, 0.7071067690849304], [-0.7071067690849304, 0.7071067690849304]]"
            },
            {
                "test": "import torch\nU, S, Vt = svd_2x2_singular_values(torch.tensor([[2.0, 0.0], [0.0, 1.0]]))\nprint(U.numpy().tolist(), S.numpy().tolist(), Vt.numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 1.0]] [2.0, 1.0] [[1.0, 0.0], [0.0, 1.0]]"
            }
        ],
        "learn_section": "## Learn Section — Deriving an SVD for a 2 x 2 Matrix\n\nThe singular-value decomposition (SVD) rewrites any real matrix $A\\!\\in\\!\\mathbb R^{m\\times n}$ as\n\n$$\nA \\;=\\; U\\,\\Sigma\\,V^{\\!\\top},\n$$\n\nwhere\n\n- $U\\!\\in\\!\\mathbb R^{m\\times m}$ and $V\\!\\in\\!\\mathbb R^{n\\times n}$ are **orthogonal** ($U^{\\!\\top}U=I$ and $V^{\\!\\top}V=I$),\n- $\\Sigma$ is diagonal with **non-negative** entries $\\sigma_1\\ge\\sigma_2\\ge\\cdots$ called **singular values**.\n\nWhen $A$ is $2\\times2$ the factorisation can be produced **analytically** with only one Givens (Jacobi) rotation.  \nBelow we walk through the math used in the `svd_2x2_singular_values` function.\n\n---\n\n### 1. From $A$ to a Symmetric Matrix\n\nBecause  \n$\nA^{\\!\\top}A \\;=\\; V\\,\\Sigma^{\\!\\top}\\Sigma\\,V^{\\!\\top}\n$  \nis symmetric and positive-semidefinite, its eigenvectors form the right-singular vectors of $A$ and its eigenvalues are the squares of the singular values.\n\nFor a $2\\times2$ matrix\n\n$$\nA \\;=\\; \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix},\n\\quad\nA^{\\!\\top}A \\;=\\;\n\\begin{bmatrix}\na_{11}^2 + a_{21}^2 & a_{11}a_{12}+a_{21}a_{22}\\\\[4pt]\na_{11}a_{12}+a_{21}a_{22} & a_{12}^2 + a_{22}^2\n\\end{bmatrix}\\!,\n$$\n\nwhich we label $B$ in the code (`a_2`).\n\n---\n\n### 2. A Single Jacobi Rotation\n\nTo diagonalise $B$ we seek a rotation matrix\n\n$$\nR(\\theta)=\n\\begin{bmatrix}\n\\cos\\theta & -\\sin\\theta\\\\\n\\sin\\theta & \\phantom{-}\\cos\\theta\n\\end{bmatrix},\n$$\n\nsuch that $R^{\\!\\top}BR$ is diagonal.\n\nFor $2\\times2$ Jacobi iterations the optimal angle is\n\n$$\n\\theta \\;=\\;\n\\begin{cases}\n\\dfrac{\\pi}{4}, & B_{11}=B_{22},\\\\[8pt]\n\\dfrac12\\,\\arctan\\!\\bigl(\\dfrac{2B_{12}}{B_{11}-B_{22}}\\bigr), & \\text{otherwise}.\n\\end{cases}\n$$\n\nThe function computes this `theta`, builds $R$, and updates\n\n$$\nD \\;=\\; R^{\\!\\top}BR\n$$\n\nwhich now satisfies $D_{12}=D_{21}=0$.\n\nBecause we only need *one* rotation to zero the off-diagonal term, the loop runs exactly once.\n\n---\n\n### 3. Extracting Singular Values\n\nThe diagonal entries of $D$ are the **eigenvalues** $\\lambda_1,\\lambda_2$ of $B$.  \nSingular values are their square-roots:\n\n$$\n\\sigma_1 = \\sqrt{\\lambda_1}, \\quad\n\\sigma_2 = \\sqrt{\\lambda_2},\n\\quad\n\\sigma_1\\ge\\sigma_2\\ge 0.\n$$\n\nIn code:\n\n```python\ns = np.sqrt([d[0,0], d[1,1]])\n```\n\n---\n\n### 4. Building $U$\n\nGiven $V = R$ (or $V=VR$ after several rotations), the left-singular vectors are\n\n$$\nU \\;=\\; A\\,V\\,\\Sigma^{-1},\n$$\n\nwhere $\\Sigma^{-1}=\\operatorname{diag}\\!\\bigl(\\tfrac1{\\sigma_1},\\tfrac1{\\sigma_2}\\bigr)$.\n\nThe multiplication `a @ v @ s_inv` yields an orthogonal $U$.\n\n---\n\n### 5. Putting It All Together\n\nThe function finally returns the triple $(U,\\; \\sigma,\\; V^{\\!\\top})$, giving the exact SVD of $A$:\n\n```python\nreturn (u, s, v.T)\n```\n\n---\n\n### Why This Works\n\n* **Eigen-trick** - Diagonalising $A^{\\!\\top}A$ exposes singular values.  \n* **Jacobi rotation** - For $2\\times2$ a **single** rotation nulls the off-diagonal term.  \n* **Orthonormality** - Both $R$ and $U$ are orthogonal, preserving lengths and angles.\n\nThis compact derivation is highly instructive: it shows how SVD generalises *rotation + scaling* in $\\mathbb R^2$ and illustrates numerically stable ways to compute the decomposition without heavy linear-algebra libraries.\n",
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgc3ZkXzJ4Ml9zaW5ndWxhcl92YWx1ZXMoQTogdG9yY2guVGVuc29yKSAtPiB0dXBsZVt0b3JjaC5UZW5zb3IsIHRvcmNoLlRlbnNvciwgdG9yY2guVGVuc29yXToKICAgICIiIgogICAgQXBwcm94aW1hdGUgdGhlIFNWRCBvZiBhIDLDlzIgbWF0cml4IEEgdXNpbmcgb25lIEphY29iaSByb3RhdGlvbi4KICAgIFJldHVybnMgKFUsIFMsIFZ0KSB3aGVyZSBTIGlzIGEgMS1EIHRlbnNvciBvZiBzaW5ndWxhciB2YWx1ZXMuCiAgICAiIiIKICAgICMgY29tcHV0ZSBB4bWAQQogICAgYTIgPSBBLnRyYW5zcG9zZSgwLDEpIEAgQQogICAgIyBpbml0aWFsaXplIFYKICAgIFYgPSB0b3JjaC5leWUoMiwgZHR5cGU9QS5kdHlwZSwgZGV2aWNlPUEuZGV2aWNlKQogICAgIyBKYWNvYmkgcm90YXRpb24gYW5nbGUKICAgIGlmIHRvcmNoLmlzY2xvc2UoYTJbMCwwXSwgYTJbMSwxXSk6CiAgICAgICAgdGhldGEgPSB0b3JjaC50ZW5zb3IodG9yY2gucGkvNCwgZHR5cGU9QS5kdHlwZSwgZGV2aWNlPUEuZGV2aWNlKQogICAgZWxzZToKICAgICAgICB0aGV0YSA9IDAuNSAqIHRvcmNoLmF0YW4yKDIgKiBhMlswLDFdLCBhMlswLDBdIC0gYTJbMSwxXSkKICAgIGMgPSB0b3JjaC5jb3ModGhldGEpCiAgICBzID0gdG9yY2guc2luKHRoZXRhKQogICAgUiA9IHRvcmNoLnN0YWNrKFt0b3JjaC5zdGFjayhbYywgLXNdKSwgdG9yY2guc3RhY2soW3MsIGNdKV0pCiAgICAjIGRpYWdvbmFsaXplCiAgICBEID0gUi50cmFuc3Bvc2UoMCwxKSBAIGEyIEAgUgogICAgViA9IFYgQCBSCiAgICAjIHNpbmd1bGFyIHZhbHVlcwogICAgUyA9IHRvcmNoLnNxcnQodG9yY2gudGVuc29yKFtEWzAsMF0sIERbMSwxXV0sIGR0eXBlPUEuZHR5cGUsIGRldmljZT1BLmRldmljZSkpCiAgICAjIGNvbXB1dGUgVQogICAgU19pbnYgPSB0b3JjaC5kaWFnKDEuMCAvIFMpCiAgICBVID0gQSBAIFYgQCBTX2ludgogICAgcmV0dXJuIFUsIFMsIFYudHJhbnNwb3NlKDAsMSkK",
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nU, S, Vt = svd_2x2_singular_values_tg([[1.0, 0.0], [0.0, 1.0]])\nprint(U.numpy().tolist(), S.numpy().tolist(), Vt.numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 1.0]] [1.0, 1.0] [[1.0, 0.0], [0.0, 1.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nU, S, Vt = svd_2x2_singular_values_tg([[2.0, 0.0], [0.0, 1.0]])\nprint(U.numpy().tolist(), S.numpy().tolist(), Vt.numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 1.0]] [2.0, 1.0] [[1.0, 0.0], [0.0, 1.0]]"
            }
        ]
    },
    {
        "description": "Implement a function to calculate the Bhattacharyya distance between two probability distributions. The function should take two lists representing discrete probability distributions `p` and `q`, and return the Bhattacharyya distance rounded to 4 decimal places. If the inputs have different lengths or are empty, return 0.0.",
        "id": "120",
        "test_cases": [
            {
                "test": "print(round(bhattacharyya_distance([0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]),4))",
                "expected_output": "0.1166"
            },
            {
                "test": "print(round(bhattacharyya_distance([0.7, 0.2, 0.1], [0.4, 0.3, 0.3]),4))",
                "expected_output": "0.0541"
            },
            {
                "test": "print(round(bhattacharyya_distance([], [0.5, 0.4, 0.1]),4))",
                "expected_output": "0.0"
            },
            {
                "test": "print(round(bhattacharyya_distance([0.6, 0.4], [0.1, 0.7, 0.2]),4))",
                "expected_output": "0.0"
            },
            {
                "test": "print(round(bhattacharyya_distance([0.6, 0.2, 0.1, 0.1], [0.1, 0.2, 0.3, 0.4]),4))",
                "expected_output": "0.2007"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef bhattacharyya_distance(p : list[float], q : list[float]) -> float:\n    if len(p) != len(q):\n        return 0.0\n\n    p, q = np.array(p), np.array(q)\n    BC = np.sum(np.sqrt(p * q))\n    DB = -np.log(BC)\n    return round(DB, 4)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "p = [0.1, 0.2, 0.3, 0.4], q = [0.4, 0.3, 0.2, 0.1]",
            "output": "0.1166",
            "reasoning": "The Bhattacharyya coefficient is calculated as the sum of element-wise square roots of the product of p and q, giving BC = 0.8898. The distance is then -log(0.8898) = 0.1166."
        },
        "category": "Statistics",
        "starter_code": "import numpy as np\n\ndef bhattacharyya_distance(p: list[float], q: list[float]) -> float:\n    # Your code here\n    pass",
        "title": "Bhattacharyya Distance Between Two Distributions",
        "learn_section": "## Understanding Bhattacharyya Distance\n\n**Bhattacharyya Distance (BD)** is a concept in statistics used to measure the **similarity** or **overlap** between two probability distributions **P(x)** and **Q(x)** on the same domain **x**.  \n\nThis differs from **KL Divergence**, which measures the **loss of information** when projecting one probability distribution onto another (reference distribution).  \n\n### **Bhattacharyya Distance Formula**\nThe Bhattacharyya distance is defined as:  \n\n$$\nBC (P, Q) = \\sum \\sqrt{P(X) \\cdot Q(X)}\n$$\n\n$$\nBD (P, Q) = -\\ln(BC (P, Q))\n$$\n\nwhere **BC (P, Q)** is the **Bhattacharyya coefficient**.  \n\n### **Key Properties**\n1. **BD is always non-negative**:  \n   $$ BD \\geq 0 $$\n2. **Symmetric in nature**:  \n   $$ BD (P, Q) = BD (Q, P) $$\n3. **Applications**:  \n   - Risk assessment  \n   - Stock predictions  \n   - Feature scaling  \n   - Classification problems  \n\n### **Example Calculation**\nConsider two probability distributions **P(x)** and **Q(x)**:  \n\n$$\nP(x) = [0.1, 0.2, 0.3, 0.4], \\quad Q(x) = [0.4, 0.3, 0.2, 0.1]\n$$\n\n1. **Bhattacharyya Coefficient**:  \n\n$$\nBC (P, Q) = \\sum \\sqrt{P(X) \\cdot Q(X)} = 0.8898\n$$\n\n2. **Bhattacharyya Distance**:  \n\n$$\nBD (P, Q) = -\\ln(BC (P, Q)) = -\\ln(0.8898) = 0.1166\n$$\n\nThis illustrates how BD quantifies the **overlap** between two probability distributions.  ",
        "contributor": [
            {
                "profile_link": "https://github.com/Arudhra1999",
                "name": "Arudhra1999"
            }
        ]
    },
    {
        "description": "Write a Python function that computes the element-wise sum of two vectors. The function should return a new vector representing the resulting sum if the operation is valid, or -1 if the vectors have incompatible dimensions. Two vectors (lists) can be summed element-wise only if they are of the same length.",
        "id": "121",
        "test_cases": [
            {
                "test": "print(vector_sum([1, 2, 3], [4, 5, 6]))",
                "expected_output": "[5, 7, 9]"
            },
            {
                "test": "print(vector_sum([1, 2], [1, 2, 3]))",
                "expected_output": "-1"
            },
            {
                "test": "print(vector_sum([1.5, 2.5, 3.0], [2, 1, 4]))",
                "expected_output": "[3.5, 3.5, 7.0]"
            }
        ],
        "difficulty": "easy",
        "solution": "def vector_sum(a: list[int|float], b: list[int|float]) -> list[int|float]:\n    if len(a) != len(b):\n        return -1\n    return [a[i] + b[i] for i in range(len(a))]",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "a = [1, 3], b = [4, 5]",
            "output": "[5, 8]",
            "reasoning": "Element-wise sum: [1+4, 3+5] = [5, 8]."
        },
        "category": "Linear Algebra",
        "starter_code": "def vector_sum(a: list[int|float], b: list[int|float]) -> list[int|float]:\n\t# Return the element-wise sum of vectors 'a' and 'b'.\n\t# If vectors have different lengths, return -1.\n\tpass",
        "title": "Vector Element-wise Sum",
        "learn_section": "## Understanding Vector Element-wise Sum\n\nIn linear algebra, the **element-wise sum** (also known as vector addition) involves adding corresponding entries of two vectors.\n\n### Vector Notation\nGiven two vectors $a$ and $b$ of the same dimension $n$:\n\n$$\na = \\begin{pmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_n \\end{pmatrix}, \\quad b = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{pmatrix}\n$$\n\nThe element-wise sum is defined as:\n\n$$\na + b = \\begin{pmatrix} a_1 + b_1 \\\\ a_2 + b_2 \\\\ \\vdots \\\\ a_n + b_n \\end{pmatrix}\n$$\n\n### Key Requirement\nVectors $a$ and $b$ must be of the same length $n$ for the operation to be valid. If their lengths differ, element-wise addition is not defined.\n\n### Example\nLet:\n\n$$\na = [1, 2, 3], \\quad b = [4, 5, 6]\n$$\n\nThen:\n\n$$\na + b = [1+4, 2+5, 3+6] = [5, 7, 9]\n$$\n\nThis simple operation is foundational in many applications such as vector arithmetic, neural network computations, and linear transformations.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement the policy gradient estimator using the REINFORCE algorithm. The policy is parameterized by a 2D NumPy array `theta` of shape `(num_states, num_actions)`. The policy for each state is computed via softmax over `theta[s, :]`. Given a list of episodes (each a list of (state, action, reward) tuples), compute the average gradient of the log-policy multiplied by the return at each time step.",
        "id": "122",
        "test_cases": [
            {
                "test": "theta = np.zeros((2,2)); episodes = [[(0,1,0), (1,0,1)], [(0,0,0)]]; print(np.round(compute_policy_gradient(theta, episodes), 4))",
                "expected_output": "[[-0.25  0.25]\n [ 0.25 -0.25]]"
            },
            {
                "test": "theta = np.zeros((2,2)); episodes = [[(0,0,0)], [(0,1,0), (1,1,0)]]; print(np.round(compute_policy_gradient(theta, episodes), 4))",
                "expected_output": "[[0. 0.]\n [0. 0.]]"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef compute_policy_gradient(theta, episodes):\n    def softmax(x):\n        x = x - np.max(x)\n        exps = np.exp(x)\n        return exps / np.sum(exps)\n\n    grad = np.zeros_like(theta)\n    for episode in episodes:\n        rewards = [step[2] for step in episode]\n        returns = np.cumsum(rewards[::-1])[::-1]\n        for t, (s, a, _), G in zip(range(len(episode)), episode, returns):\n            probs = softmax(theta[s])\n            grad_log_pi = np.zeros_like(theta)\n            grad_log_pi[s, :] = -probs\n            grad_log_pi[s, a] += 1\n            grad += grad_log_pi * G\n    return grad / len(episodes)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "theta = np.zeros((2,2)); episodes = [[(0,1,0), (1,0,1)], [(0,0,0)]]",
            "output": "[[-0.25, 0.25], [0.25, -0.25]]",
            "reasoning": "Episode 1 contributes a positive gradient from reward 1 at t=1; episode 2 adds zero. Result is averaged across episodes."
        },
        "category": "Reinforcement Learning",
        "starter_code": "import numpy as np\n\ndef compute_policy_gradient(theta: np.ndarray, episodes: list[list[tuple[int, int, float]]]) -> np.ndarray:\n    \"\"\"\n    Estimate the policy gradient using REINFORCE.\n\n    Args:\n        theta: (num_states x num_actions) policy parameters.\n        episodes: List of episodes, where each episode is a list of (state, action, reward).\n\n    Returns:\n        Average policy gradient (same shape as theta).\n    \"\"\"\n    # Your code here\n    pass",
        "title": "Policy Gradient with REINFORCE",
        "learn_section": "## REINFORCE and Policy Gradient Estimation\n\nThe REINFORCE algorithm computes gradients of the expected return with respect to policy parameters using Monte Carlo samples of episodes.\n\n### Softmax Policy\nGiven $\\theta$ with shape (num_states, num_actions), we define the probability of action $a$ in state $s$ as:\n\n$$\n\\pi(a \\mid s; \\theta) = \\frac{\\exp(\\theta[s, a])}{\\sum_{a'} \\exp(\\theta[s, a'])}\n$$\n\n### REINFORCE Gradient\nFor an episode with transitions $(s_t, a_t, r_t)$ and returns $G_t = \\sum_{k=t}^T r_k$:\n\n$$\n\\nabla_\\theta J(\\theta) \\approx \\sum_t \\nabla_\\theta \\log \\pi(a_t \\mid s_t) \\cdot G_t\n$$\n\n### Log-Policy Gradient\nTo compute $\\nabla_\\theta \\log \\pi(a_t \\mid s_t)$:\n\n- For $\\theta[s_t, a_t]$: $1 - \\pi(a_t \\mid s_t)$\n- For $\\theta[s_t, a']$, where $a' \\neq a_t$: $-\\pi(a' \\mid s_t)$\n- All other entries: 0\n\n### Final Estimate\nFor multiple episodes:\n\n$$\n\\hat{\\nabla}_\\theta J(\\theta) = \\frac{1}{N} \\sum_{i=1}^N \\sum_{t=0}^{T_i} \\nabla_\\theta \\log \\pi(a_t^i \\mid s_t^i) \\cdot G_t^i\n$$\n\nThis algorithm works even without value function estimation, making it a foundational method in policy-based reinforcement learning.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Calculate the computational cost savings of an MoE layer compared to a dense layer, as discussed in the paper 'Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer.' Given the number of experts, sparsity (number of active experts), and input/output dimensions, compute the floating-point operations (FLOPs) for both and determine the savings percentage.",
        "id": "123",
        "test_cases": [
            {
                "test": "print(round(compute_efficiency(1000, 2, 512, 512),1))",
                "expected_output": "99.8"
            },
            {
                "test": "print(round(compute_efficiency(10, 2, 256, 256),1))",
                "expected_output": "80.0"
            }
        ],
        "solution": "def compute_efficiency(n_experts, k_active, d_in, d_out):\n    dense_flops = n_experts * d_in * d_out\n    moe_flops = k_active * d_in * d_out\n    savings = (dense_flops - moe_flops) / dense_flops * 100\n    return round(savings, 1)",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "compute_efficiency(1000, 2, 512, 512)",
            "output": "99.8",
            "reasoning": "Dense layer FLOPs: 1000 * 512 * 512 = 262,144,000. MoE FLOPs: 2 * 512 * 512 = 524,288. Savings:  ((262,144,000 - 524,288) / 262,144,000) x 100 ≈ 99.8%."
        },
        "category": "Deep Learning",
        "starter_code": "def compute_efficiency(n_experts, k_active, d_in, d_out):\n    \"\"\"\n    Calculate computational savings of MoE vs. dense layer.\n\n    Args:\n        n_experts: Total number of experts\n        k_active: Number of active experts (sparsity)\n        d_in: Input dimension\n        d_out: Output dimension\n\n    Returns:\n        Percentage savings in FLOPs\n    \"\"\"\n    pass",
        "learn_section": "\n## Understanding MoE Efficiency\n\nThe paper *\"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\"* introduces the idea of activating only a few expert networks per input to drastically reduce computation. This is known as **conditional computation**, and it allows models to scale to billions of parameters without significantly increasing cost.\n\n---\n\n### Key Idea\n\nIn a **dense layer**, every input goes through the full set of parameters.  \nIn a **Mixture-of-Experts (MoE)** layer, only $k$ out of $n$ experts are active for each input.\n\n---\n\n### FLOPs Formulas\n\nLet:\n- $d_{in}$ = input dimension  \n- $d_{out}$ = output dimension  \n- $n$ = total experts  \n- $k$ = active experts per input  \n\nThen:\n- **Dense layer FLOPs**:  \n  $$\n  \\text{FLOPs}_{\\text{dense}} = n \\cdot d_{in} \\cdot d_{out}\n  $$\n- **MoE layer FLOPs**:  \n  $$\n  \\text{FLOPs}_{\\text{moe}} = k \\cdot d_{in} \\cdot d_{out}\n  $$\n- **Efficiency gain**:\n  $$\n  \\text{Savings}(\\%) = \\left( \\frac{\\text{FLOPs}_{\\text{dense}} - \\text{FLOPs}_{\\text{moe}}}{\\text{FLOPs}_{\\text{dense}}} \\right) \\cdot 100\n  $$\n\n---\n\n### Example\n\nSuppose:\n- $n = 1000$, $k = 2$  \n- $d_{in} = d_{out} = 512$  \n\nThen:\n- MoE FLOPs = $2 \\cdot 512 \\cdot 512 = 524,\\!288$  \n- Full dense (all 1000 experts): $1000 \\cdot 512 \\cdot 512 = 262,\\!144,\\!000$  \n- Savings:\n  $$\n  \\left( \\frac{262,\\!144,\\!000 - 524,\\!288}{262,\\!144,\\!000} \\right) \\cdot 100 \\approx 99.8\\%\n  $$\n\nThis means the MoE layer uses just **0.2%** of the computation compared to a full dense version — an enormous gain in efficiency.\n\n---\n\n### Summary\n\nBy activating only a small number of experts per input, MoE layers reduce computation while maintaining high model capacity. This makes it feasible to train outrageously large models efficiently.\n",
        "title": "Calculate Computational Efficiency of MoE",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement the Noisy Top-K gating mechanism used in Mixture-of-Experts (MoE) models. Given an input matrix, weight matrices, pre-sampled noise, and a sparsity constraint k, compute the final gating probabilities matrix.",
        "id": "124",
        "test_cases": [
            {
                "test": "import numpy as np\nnp.random.seed(0)\nX = np.array([[1.0, 2.0]])\nW_g = np.array([[1.0, 0.0], [0.0, 1.0]])\nW_noise = np.zeros((2,2))\nN = np.zeros((1,2))\nprint(noisy_topk_gating(X, W_g, W_noise, N, k=1))",
                "expected_output": "[[0. 1.]]"
            },
            {
                "test": "import numpy as np\nX = np.array([[1.0, 2.0]])\nW_g = np.array([[1.0, 0.0], [0.0, 1.0]])\nW_noise = np.array([[0.5, 0.5], [0.5, 0.5]])\nN = np.array([[1.0, -1.0]])\nprint(np.round(noisy_topk_gating(X, W_g, W_noise, N, k=2), 4))",
                "expected_output": "[[0.917, 0.083]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef noisy_topk_gating(\n    X: np.ndarray,\n    W_g: np.ndarray,\n    W_noise: np.ndarray,\n    N: np.ndarray,\n    k: int\n) -> np.ndarray:\n    H_base = X @ W_g\n    H_noise = X @ W_noise\n    softplus = np.log1p(np.exp(H_noise))\n    H = H_base + N * softplus\n\n    def top_k_masked(row, k):\n        mask = np.full_like(row, -np.inf)\n        top_idx = np.argsort(row)[-k:]\n        mask[top_idx] = row[top_idx]\n        return mask\n\n    masked_H = np.vstack([top_k_masked(row, k) for row in H])\n    exps = np.exp(masked_H - np.max(masked_H, axis=1, keepdims=True))\n    return exps / np.sum(exps, axis=1, keepdims=True)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "X = [[1.0, 2.0]]\nW_g = [[1.0, 0.0], [0.0, 1.0]]\nW_noise = [[0.5, 0.5], [0.5, 0.5]]\nN = [[1.0, -1.0]]\nk = 2",
            "output": "[[0.917, 0.0825]]",
            "reasoning": "This example demonstrates that the gating function produces a sparse softmax output, favoring the higher gate after noise perturbation."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef noisy_topk_gating(\n    X: np.ndarray,\n    W_g: np.ndarray,\n    W_noise: np.ndarray,\n    N: np.ndarray,\n    k: int\n) -> np.ndarray:\n    \"\"\"\n    Args:\n        X: Input data, shape (batch_size, features)\n        W_g: Gating weight matrix, shape (features, num_experts)\n        W_noise: Noise weight matrix, shape (features, num_experts)\n        N: Noise samples, shape (batch_size, num_experts)\n        k: Number of experts to keep per example\n    Returns:\n        Gating probabilities, shape (batch_size, num_experts)\n    \"\"\"\n    # Your code here\n    pass",
        "title": "Implement the Noisy Top-K Gating Function",
        "learn_section": "## Noisy Top-K Gating\n\nNoisy Top-K Gating is a sparse selection mechanism used in Mixture-of-Experts (MoE) models. It routes input tokens to a subset of available experts, enhancing efficiency and model capacity.\n\n### Overview\n\nThe core idea is to add learned noise to the gating logits and then select only the top-k experts for each input. This encourages exploration and helps balance load across experts.\n\n### Step-by-Step Breakdown\n\n1. **Compute Raw Gate Scores**  \n   First, compute two linear projections of the input:\n   $$\n   H_{\\text{base}} = X W_g\n   $$\n   $$\n   H_{\\text{noise}} = X W_{\\text{noise}}\n   $$\n\n2. **Apply Noise with Softplus Scaling**  \n   Add pre-sampled Gaussian noise, scaled by a softplus transformation:\n   $$\n   H = H_{\\text{base}} + N \\odot \\text{Softplus}(H_{\\text{noise}})\n   $$\n\n3. **Top-K Masking**  \n   Keep only the top-k elements in each row (i.e., per input), setting the rest to $-\\infty$:\n   $$\n   H' = \\text{TopK}(H, k)\n   $$\n\n4. **Softmax Over Top-K**  \n   Normalize the top-k scores into a valid probability distribution:\n   $$\n   G = \\text{Softmax}(H')\n   $$\n\n### Worked Example\n\nLet:\n- $X = [[1.0, 2.0]]$\n- $W_g = [[1.0, 0.0], [0.0, 1.0]]$\n- $W_{\\text{noise}} = [[0.5, 0.5], [0.5, 0.5]]$\n- $N = [[1.0, -1.0]]$\n- $k = 2$\n\nStep-by-step:\n- $H_{\\text{base}} = [1.0, 2.0]$\n- $H_{\\text{noise}} = [1.5, 1.5]$\n- $\\text{Softplus}(H_{\\text{noise}}) \\approx [1.804, 1.804]$\n- $H = [1.0 + 1.804, 2.0 - 1.804] = [2.804, 0.196]$\n- Softmax over these gives: $[0.917, 0.0825]$\n\n### Benefits\n\n- **Computational Efficiency**: Activates only k experts per input.\n- **Load Balancing**: Injected noise encourages diversity in expert selection.\n- **Improved Generalization**: Acts as a regularizer via noise-based gating.\n\nThis technique is used in large sparse models like GShard and Switch Transformers.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement a Mixture-of-Experts (MoE) layer using softmax gating and top-k routing. Given an input tensor, a set of expert weight matrices, a gating weight matrix, and parameters specifying the number of experts and the value of k, compute the final MoE output by selecting the top-k experts per token, applying their transformations, and aggregating the results weighted by the normalized gating probabilities.",
        "id": "125",
        "test_cases": [
            {
                "test": "import numpy as np\nnp.random.seed(42)\nd_model = 2\nn_experts = 4\nl_seq = 3\nn_batch = 2\ntop_k = 2\nx = np.random.rand(n_batch, l_seq, d_model)\nWe = np.random.rand(n_experts, d_model, d_model)\nWg = np.random.rand(d_model, n_experts)\noutput = moe(x, We, Wg, n_experts, top_k)\nprint(np.round(output, 4))",
                "expected_output": "[[[0.5148 0.4329]\n  [0.5554 0.5447]\n  [0.1285 0.102 ]]\n\n [[0.339  0.3046]\n  [0.5391 0.417 ]\n  [0.3597 0.3262]]]"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nd_model = 2\nn_experts = 4\nl_seq = 3\nn_batch = 2\ntop_k = 2\nx = np.random.rand(n_batch, l_seq, d_model)\nWe = np.zeros((n_experts, d_model, d_model))\nWg = np.random.rand(d_model, n_experts)\noutput = moe(x, We, Wg, n_experts, top_k)\nprint(output)",
                "expected_output": "[[[0. 0.]\n  [0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]\n  [0. 0.]]]"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:\n    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\ndef get_top_k(arr: np.ndarray, k: int):\n    idx = np.argpartition(arr, -k)[..., -k:]\n    vals = np.take_along_axis(arr, idx, axis=-1)\n    return idx, vals\n\ndef expert(x: np.ndarray, We_i: np.ndarray):\n    # x: [n_tokens, d_model]\n    # We_i: [d_model, d_model]\n    return x @ We_i\n\ndef gate(x: np.ndarray, Wg: np.ndarray):\n    # x: [n_batch * l_seq, d_model]\n    # Wg: [n_batch * l_seq, n_experts]\n    return x @ Wg\n\ndef moe(x: np.ndarray, We: np.ndarray, Wg: np.ndarray, n_experts: int, top_k: int):\n    # x: [n_batch, l_seq, d_model]\n    # We: [n_experts, d_model, d_model]\n    # Wg: [n_batch * l_seq, n_experts]\n\n    n_batch, l_seq, d_model = x.shape\n\n    # flatten batch and sequence dimensions for easier indexing\n    # x_flat: [n_batch * l_seq, d_model]\n    x_flat = x.reshape(-1, d_model)\n    n_tokens, _ = x_flat.shape\n\n    gating_logits = gate(x_flat, Wg)\n    gating_weights = softmax(gating_logits, axis=-1)\n\n    topk_idx, topk_weights = get_top_k(gating_weights, top_k)\n    topk_idx_flat = topk_idx.flatten()  # [n_tokens * top_k]\n    # mapping from top K expert indices to token indices: [n_tokens * top_k]\n    token_idx_flat = np.arange(n_tokens).repeat(top_k)\n\n    topk_weights_norm = topk_weights / topk_weights.sum(axis=1, keepdims=True)\n    topk_weights_norm_flat = topk_weights_norm.flatten()\n\n    # prepare result memory for aggregation: [n_tokens, d_model]\n    output_flat = np.zeros_like(x_flat)\n    for i in range(n_experts):\n        mask = topk_idx_flat == i\n        tokens_expert_i = token_idx_flat[mask]\n\n        if tokens_expert_i.size > 0:\n            x_expert_i = x_flat[tokens_expert_i]\n            output_expert_i = expert(x_expert_i, We[i, ...])\n            output_expert_i *= topk_weights_norm_flat[mask, None]\n\n            # scatter add to result memory\n            np.add.at(output_flat, tokens_expert_i, output_expert_i)\n\n    return output_flat.reshape(n_batch, l_seq, d_model)\n",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "x = np.arange(12).reshape(2, 3, 2)\nWe = np.ones((4, 2, 2))\nWg = np.ones((2, 4))\ntop_k = 1",
            "output": "[[[1, 1], [5, 5], [9, 9]], [[13, 13], [17, 17], [21, 21]]]",
            "reasoning": "Each token is routed to its top expert and processed using a weight matrix of ones. The result matches the input tokens due to identity transformation and weight 1."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef moe(x: np.ndarray, We: np.ndarray, Wg: np.ndarray, n_experts: int, top_k: int) -> np.ndarray:\n    \"\"\"\n    Args:\n        x: Input tensor of shape (n_batch, l_seq, d_model)\n        We: Expert weights of shape (n_experts, d_model, d_model)\n        Wg: Gating weights of shape (d_model, n_experts)\n        n_experts: Number of experts\n        top_k: Number of experts to route each token to\n    Returns:\n        Output tensor of shape (n_batch, l_seq, d_model)\n    \"\"\"\n    pass",
        "title": "Implement a Sparse Mixture of Experts Layer",
        "learn_section": "\n## Mixture of Experts Layer\n\nMixture-of-Experts layers route each token through a small subset of expert networks, reducing computation while retaining flexibility.\n\n### 1. Gating with Softmax  \n- **Logits**: For each token $t$, compute a vector of gating scores $g_t \\in \\mathbb{R}^E$, where $E$ is the number of experts.  \n- **Softmax**: Convert scores into a probability distribution  \n  $$\n  \\alpha_{t,j}\n    = \\frac{\\exp\\bigl(g_{t,j} - \\max_j g_{t,j}\\bigr)}\n           {\\sum_{j'=1}^{E}\\exp\\bigl(g_{t,j'} - \\max_j g_{t,j'}\\bigr)}.\n  $$\n\n### 2. Top-$k$ Selection  \n- **Sparsity**: Keep only the $k$ largest weights per token, zeroing out the rest.  \n- **Renormalize**: For token $t$, let $\\mathcal{K}_t$ be the indices of the top $k$ experts. Then  \n  $$\n  \\tilde\\alpha_{t,j} =\n    \\begin{cases}\n      \\displaystyle\\frac{\\alpha_{t,j}}{\\sum_{i \\in \\mathcal{K}_t}\\alpha_{t,i}}\n        & j \\in \\mathcal{K}_t,\\\\[8pt]\n      0\n        & \\text{otherwise.}\n    \\end{cases}\n  $$\n\n### 3. Expert Computation  \nEach expert $i$ applies its own linear transform to the token embedding $x_t$:  \n$$\nO_t^{(i)} = x_t\\,W_e^{(i)},\n$$  \nwhere $W_e^{(i)}$ is the expert's $d \\times d$ weight matrix.\n\n### 4. Weighted Aggregation  \nCombine the selected experts' outputs for each token:  \n$$\ny_t = \\sum_{i=1}^{E} \\tilde\\alpha_{t,i}\\,O_t^{(i)}.\n$$  \nThe result $y_t$ lives in the original embedding space $\\mathbb{R}^d$.\n\n---\n\n### Example Walk Through\n\nSuppose one sentence of length 2, embedding size 3, $E=4$ experts, and $k=2$.  \n- After flattening, you get 2 softmax distributions of length 4.  \n- You pick the top 2 experts for each token and renormalize their weights.  \n- Each selected expert produces a 3-dimensional output for its tokens.  \n- You weight and sum those outputs to yield the final 3-dimensional vector per token.\n\nThis sparse routing mechanism dramatically cuts computation only $k$ experts run per token instead of all $E$ while retaining the expressivity of a full ensemble.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/lefarov",
                "name": "lefarov"
            }
        ]
    },
    {
        "description": "Write a Python function to perform Group Normalization on a 4D input tensor with shape (B, C, H, W). The function should normalize over smaller groups of channels, then apply a learned scale (gamma) and shift (beta).",
        "id": "126",
        "test_cases": [
            {
                "test": "np.random.seed(42)\nB, C, H, W = 2, 2, 2, 2\nX = np.random.randn(B, C, H, W)\ngamma = np.ones(C).reshape(1, C, 1, 1)\nbeta = np.zeros(C).reshape(1, C, 1, 1)\nnum_groups = 2\noutput = group_normalization(X, gamma, beta, num_groups)\nprint(np.round(output, 4))",
                "expected_output": "[[[[-0.2287, -1.2998], [ 0.026, 1.5025]], [[-0.926, -0.9259], [1.46, 0.3919]]], [[[-0.5848, 1.732 ], [-0.5709, -0.5762]], [[1.4005, -1.0503], [-0.8361, 0.486 ]]]]"
            },
            {
                "test": "np.random.seed(42)\nB, C, H, W = 2, 2, 2, 1\nX = np.random.randn(B, C, H, W)\ngamma = np.ones(C).reshape(1, C, 1, 1)\nbeta = np.zeros(C).reshape(1, C, 1, 1)\nnum_groups = 2\noutput = group_normalization(X, gamma, beta, num_groups)\nprint(np.round(output, 4))",
                "expected_output": "[[[[1. ], [-1. ]], [[-1. ], [1. ]]], [[[-0.0026],[0.0026]], [[1. ], [-1.]]]]"
            }
        ],
        "difficulty": "medium",
        "solution": "def group_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, num_groups: int, epsilon: float = 1e-5) -> np.ndarray:\n    '''\n    Perform Group Normalization.\n    \n    Args:\n    X: numpy array of shape (B, C, H, W), input data\n    gamma: numpy array of shape (C,), scale parameter\n    beta: numpy array of shape (C,), shift parameter\n    num_groups: number of groups for normalization\n    epsilon: small constant to avoid division by zero\n    \n    Returns:\n    norm_X: numpy array of shape (B, C, H, W), normalized output\n    '''\n    batch_size, num_channels, height, width = X.shape\n    group_size = num_channels // num_groups\n\n    # Reshape X into groups\n    X_reshaped = X.reshape(batch_size, num_groups, group_size, height, width)\n\n    # Compute mean and variance for each group\n    mean = np.mean(X_reshaped, axis=(2, 3, 4), keepdims=True)\n    variance = np.var(X_reshaped, axis=(2, 3, 4), keepdims=True)\n\n    X_norm = (X_reshaped - mean) / np.sqrt(variance + epsilon)\n\n    # Reshape back to the original shape\n    X_norm = X_norm.reshape(batch_size, num_channels, height, width)\n\n    # Apply scale and shift\n    norm_X = gamma * X_norm + beta\n    return norm_X",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "X.shape = (2, 2, 2, 2), gamma = [1, 1], beta = [0, 0], num_groups = 2",
            "output": "Normalized tensor where each group is independently normalized and scaled by gamma and shifted by beta.",
            "reasoning": "First split the channels into groups, compute mean and variance per group, normalize within the group, then scale and shift with gamma and beta."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef group_normalization(X: np.ndarray, gamma: np.ndarray, beta: np.ndarray, num_groups: int, epsilon: float = 1e-5) -> np.ndarray:\n    # Your code here\n    pass",
        "learn_section": "## Understanding Group Normalization\n\nGroup Normalization (GN) is a normalization technique that divides the channels into groups and normalizes the activations within each group. Unlike Batch Normalization, which normalizes over the entire mini-batch, Group Normalization normalizes over groups of channels and is less dependent on the batch size. This makes it particularly useful for tasks with small batch sizes or when using architectures such as segmentation networks where spatial resolution is important.\n\n### Concepts\n\nGroup Normalization operates on the principle of normalizing within smaller groups of channels. The process reduces **internal covariate shift** within these groups and helps stabilize training, especially in scenarios where the batch size is small or varies across tasks.\n\nThe process of Group Normalization consists of the following steps:\n\n1. **Divide Channels into Groups:** Split the feature channels into several groups. The number of groups is determined by the **n_groups** parameter.\n2. **Compute the Mean and Variance within Each Group:** For each group, compute the mean and variance of the activations within the group, across the spatial dimensions and batch.\n3. **Normalize the Inputs:** Normalize the activations of each group using the computed mean and variance.\n4. **Apply Scale and Shift:** After normalization, apply a learned scale (gamma) and shift (beta) to restore the model's ability to represent the data's original distribution.\n\n### Structure of Group Normalization for BCHW Input\n\nFor an input tensor with the shape **BCHW** , where:\n- **B**: batch size,\n- **C**: number of channels,\n- **H**: height,\n- **W**: width,\nthe Group Normalization process operates on specific dimensions based on the task's requirement.\n\n#### 1. Group Division\n\n- The input feature dimension **C** (channels) is divided into several groups. The number of groups is determined by the **n_groups** parameter, and the size of each group is calculated as:\n\n  $$\n  \\text{groupSize} = \\frac{C}{n_{\\text{groups}}}\n  $$\n\n  Where:\n  - **C** is the number of channels.\n  - **n_groups** is the number of groups into which the channels are divided.\n  - **groupSize** is the number of channels in each group.\n\n  The input tensor is then reshaped to group the channels into the specified groups.\n\n#### 2. Mean and Variance Calculation within Groups\n\n- For each group, the **mean** $\\mu_g$ and **variance** $\\sigma_g^2$ are computed over the spatial dimensions and across the batch. This normalization helps to stabilize the activations within each group.\n\n  $$ \n  \\mu_g = \\frac{1}{B \\cdot H \\cdot W \\cdot \\text{groupSize}} \\sum_{i=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} \\sum_{g=1}^{\\text{groupSize}} x_{i,g,h,w}\n  $$\n\n  $$\n  \\sigma_g^2 = \\frac{1}{B \\cdot H \\cdot W \\cdot \\text{groupSize}} \\sum_{i=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} \\sum_{g=1}^{\\text{groupSize}} (x_{i,g,h,w} - \\mu_g)^2\n  $$\n\n  Where:\n  - $x_{i,g,h,w}$ is the activation at batch index $i$, group index $g$, height $h$, and width $w$.\n  - $B$ is the batch size.\n  - $H$ and $W$ are the spatial dimensions (height and width).\n  - $\\text{groupSize}$ is the number of channels in each group.\n\n#### 3. Normalization\n\nOnce the mean $\\mu_g$ and variance $\\sigma_g^2$ have been computed for each group, the next step is to **normalize** the input. The normalization is done by subtracting the mean and dividing by the standard deviation (square root of the variance, plus a small constant $\\epsilon$ for numerical stability):\n\n$$\n\\hat{x}_{i,g,h,w} = \\frac{x_{i,g,h,w} - \\mu_g}{\\sqrt{\\sigma_g^2 + \\epsilon}}\n$$\n\nWhere:\n- $\\hat{x}_{i,g,h,w}$ is the normalized activation for the input at batch index $i$, group index $g$, height $h$, and width $w$.\n- $\\epsilon$ is a small constant to avoid division by zero.\n\n#### 4. Scale and Shift\n\nAfter normalization, the next step is to apply a **scale** ($\\gamma_g$) and **shift** ($\\beta_g$) to the normalized activations for each group. These learned parameters allow the model to adjust the output distribution of each group:\n\n$$\ny_{i,g,h,w} = \\gamma_g \\hat{x}_{i,g,h,w} + \\beta_g\n$$\n\nWhere:\n- $\\gamma_g$ is the scaling factor for group $g$.\n- $\\beta_g$ is the shifting factor for group $g$.\n\n#### 5. Training and Inference\n\n- **During Training**: The mean and variance are computed for each mini-batch and used for normalization within each group.\n- **During Inference**: The model uses running averages of the statistics (mean and variance) that were computed during training to ensure consistent behavior when deployed.\n\n### Key Points\n\n- **Group-wise Normalization**: Group Normalization normalizes within smaller groups of channels instead of normalizing over the entire batch and all channels. This allows for more stable training in cases with small batch sizes.\n\n- **Number of Groups**: The number of groups is a hyperparameter (**n_groups**) that can significantly affect the model’s performance. It is typically set to divide the total number of channels into groups of equal size.\n\n- **Smaller Batch Sizes**: Group Normalization is less dependent on the batch size, making it ideal for situations where batch sizes are small (e.g., segmentation tasks).\n\n- **Numerical Stability**: As with other normalization techniques, a small constant $\\epsilon$ is added to the variance to avoid numerical instability when dividing by the square root of variance.\n\n- **Improved Convergence**: Group Normalization can help improve the gradient flow throughout the network, making it easier to train deep networks with small batch sizes. It also helps speed up convergence and stabilize training.\n\n- **Regularization Effect**: Similar to Batch Normalization, Group Normalization introduces a form of regularization through the normalization process. It can reduce overfitting by acting as a noise source during training.\n\n### Why Normalize Over Groups?\n\n- **Group-wise Normalization**: By dividing the channels into smaller groups, Group Normalization ensures that each group has a stable distribution of activations, making it effective even when batch sizes are small.\n\n- **Less Dependency on Batch Size**: Unlike Batch Normalization, Group Normalization does not require large batch sizes to compute accurate statistics. This makes it well-suited for tasks such as image segmentation, where large batch sizes may not be feasible.\n\n- **Channel-wise Learning**: Group Normalization allows each group to learn independently, preserving flexibility while also controlling the complexity of normalization over channels.\n\nBy normalizing over smaller groups, Group Normalization can reduce internal covariate shift and allow for faster and more stable training, even in situations where Batch Normalization may be less effective due to small batch sizes.",
        "title": "Implement Group Normalization",
        "contributor": [
            {
                "profile_link": "https://github.com/nzomi",
                "name": "nzomi"
            }
        ]
    },
    {
        "description": "Captain Redbeard, the most daring pirate of the seven seas, has uncovered a mysterious ancient map. Instead of islands, it shows a strange wavy curve, and the treasure lies at the lowest point of the land! (watch out for those tricky local mins)\n\nThe land's height at any point $x$ is given by:\n\nf(x) = x^4 - 3x^3 + 2\n\n\n**Your Mission:**\nImplement a Python function that finds the value of $x$ where $f(x)$ reaches its minimum, starting from any random initial position.",
        "id": "127",
        "test_cases": [
            {
                "test": "print(abs(find_treasure(-1) - 2.25) < 1e-2)",
                "expected_output": "True"
            },
            {
                "test": "print(abs(find_treasure(1.0) - 2.25) < 1e-2)",
                "expected_output": "True"
            },
            {
                "test": "print(abs(find_treasure(3.0) - 2.25) < 1e-2)",
                "expected_output": "True"
            }
        ],
        "difficulty": "medium",
        "solution": "def find_treasure(start_x: float) -> float:\n\tlearning_rate = 0.1, tolerance = 1e-6, max_iters = 10000)    def gradient(x):\n        return 4 * x**3 - 9 * x**2  # derivative of x^4 - 3x^3 + 2\n\n    x = start_x\n    for _ in range(max_iters):\n        grad = gradient(x)\n        new_x = x - learning_rate * grad\n        if abs(new_x - x) < tolerance:\n            break\n        x = new_x\n    return round(x, 4)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "start_x = 0.0",
            "output": "min float value",
            "reasoning": "Cant really give you a example without giving the solution... so ya"
        },
        "category": "Calculus",
        "starter_code": "def find_treasure(start_x: float) -> float:\n    \"\"\"\n    Find the x-coordinate where f(x) = x^4 - 3x^3 + 2 is minimized.\n\n  Returns:\n        float: The x-coordinate of the minimum point.\n    \"\"\"\n    # Your code here\n    pass",
        "title": "Find Captain Redbeard's Hidden Treasure",
        "learn_section": "## How to Find the Minimum of a Function\n\nTo find the minimum of a function like\n\n$$\nf(x) = x^4 - 3x^3 + 2\n$$\n\nwe can use a technique called **gradient descent**.\n\n### Steps:\n\n1. **Find the Derivative**\n   - The derivative (slope) tells us which direction the function is increasing or decreasing.\n   - For this problem, the derivative is:\n     $$\n     f'(x) = 4x^3 - 9x^2\n     $$\n\n2. **Move Opposite the Slope**\n   - If the slope is positive, move left.\n   - If the slope is negative, move right.\n   - Update the position by:\n     $$\n     x_{new} = x_{old} - \\text{learning rate} \\times f'(x_{old})\n     $$\n\n3. **Repeat**\n   - Keep updating $x$ until the change is very small (below a tolerance).\n\n### Why Does This Work?\n- If you always move downhill along the slope, you eventually reach a bottom a local minimum.\n\n### Important Terms\n- **Learning Rate**: How big a step to take each update.\n- **Tolerance**: How close successive steps must be to stop.\n- **Local Minimum**: A point where the function value is lower than nearby points.\n\nIn this problem, Captain Redbeard finds the hidden treasure by moving downhill until he reaches the lowest point!",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement the Dynamic Tanh (DyT) function, a normalization-free transformation inspired by the Tanh function. DyT replaces layer normalization in Transformer architectures while preserving squashing behavior and enabling stable training.",
        "id": "128",
        "test_cases": [
            {
                "test": "import numpy as np\nx = np.array([[[0.94378259]],[[0.97754654]],[[0.36168351]],[[0.51821078]],[[0.76961589]]])\ngamma = np.ones((1,))\nbeta = np.zeros((1,))\nprint(np.round(dynamic_tanh(x, 0.5, gamma, beta),4))",
                "expected_output": "[[[0.4397]], [[0.4532]], [[0.1789]], [[0.2535]], [[0.3669]]]"
            },
            {
                "test": "import numpy as np\nx = np.array([[[0.20793482, 0.16989285, 0.03898972], [0.17912554, 0.10962205, 0.3870742], [0.00107181, 0.35807922, 0.15861333]]])\ngamma = np.ones((3,))\nbeta = np.zeros((3,))\nprint(np.round(dynamic_tanh(x, 0.5, gamma, beta),4))",
                "expected_output": "[[[[0.1036, 0.0847, 0.0195], [0.0893, 0.0548, 0.1912], [0.0005, 0.1772, 0.0791]]]]"
            }
        ],
        "solution": "import numpy as np\n\ndef dynamic_tanh(x: np.ndarray, alpha: float, gamma: float, beta: float) -> list[float]:\n    def tanh(x: np.ndarray) -> np.ndarray:\n        return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n\n    x = tanh(alpha * x)\n    return (x * gamma + beta).round(4).tolist()",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "x = np.array([[[0.14115588, 0.00372817, 0.24126647, 0.22183601]]])\ngamma = np.ones((4,))\nbeta = np.zeros((4,))\nalpha = 0.5\nprint(dynamic_tanh(x, alpha, gamma, beta))",
            "output": "[[[0.0705, 0.0019, 0.1201, 0.1105]]]",
            "reasoning": "Each element in the input is scaled by alpha, passed through tanh, and then scaled by gamma and shifted by beta. This mimics the squashing behavior of layer normalization without explicitly using statistics."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef dynamic_tanh(x: np.ndarray, alpha: float, gamma: float, beta: float) -> list[float]:\n    # Your code here\n    pass",
        "title": "Dynamic Tanh: Normalization-Free Transformer Activation",
        "learn_section": "A new study (https://arxiv.org/pdf/2503.10622) demonstrates that layer normalization, that is ubiquitous in transformers, produces Tanh-like S-shapes. By incorporating a new layer replacement for normalization called \"Dynamic Tanh\" (DyT for short), Transformers without normalization can match or exceed the performance of their normalized counterparts, mostly without hyperparameter tuning.\n\n### Normalization layer\nConsider an standard NLP task, where an input $x$ has a shape of $(B,T,C)$, where $B$ is the batch size, $T$ - number of tokens (sequence length) and $C$ - embedding dimensions. Then an output of a normalization layer is generally computed as $norm(x)=\\gamma(\\frac{x-\\mu}{\\sqrt{\\sigma^2+\\varepsilon}})+\\beta$, where $\\gamma$ and $\\beta$ are learnable parameters of shape $(C,)$. Distribution's statistics are calculated as follows: $\\mu_k=\\frac{1}{BT}\\sum_i^B\\sum_j^Tx_{ij}$; $\\sigma_k^2=\\frac{1}{B T} \\sum_{i, j}\\left(x_{i j k}-\\mu_k\\right)^2$\n\n### Hyperboloic tangent (Tanh)\nTanh function is defined as a ratio: $tanh(x)=\\frac{sinh(x)}{cosh(x)}=\\frac{exp(x)-exp(-x)}{exp(x)+exp(-x)}$. Essentially the function allows transformation of an arbitrary domain to $[-1,1]$. \n\n### Dynamic Tanh (DyT)\nTurns out that LN (layer normalization) produces different parts of a $tanh(kx)$, where $k$ controls the curvature of the tanh curve in the center. The smaller the $k$, the smoother is the change from $-1$ to $1$. Hence the study proposes a drop-in replacement for LN given an input tensor $x$:\n\n$$\nDyT(x)=\\gamma*tanh(\\alpha x)+\\beta,\n$$\n\nwhere:\n* $\\alpha$ - learnable parameter that allows scaling the input differently based on its range (tokens producing **smaller variance** produce **less smoother curves**). Authors suggest a **default value** of $0.5$.\n* $\\gamma, \\beta$ - learnable parameters, that scale our output based on the input. Authors suggest initializing these vectors with following **default values**:\n    * $\\gamma$ as all-one vector \n    * $\\beta$ as all-zero\n\nDespite not calculating statistics, DyT preserves the \"squashing\" effect of LN on extreme values in a non-linear fashion, while almost linearly transforming central parts of the input.",
        "contributor": [
            {
                "profile_link": "https://github.com/turkunov",
                "name": "Turkunov"
            }
        ]
    },
    {
        "description": "Implement a function that calculates the unigram probability of a given word in a corpus of sentences. Include start `<s>` and end `</s>` tokens in the calculation. The probability should be rounded to 4 decimal places.",
        "id": "129",
        "test_cases": [
            {
                "test": "corpus = \"\"\"<s> I am Jack </s> <s> Jack I am </s> <s> Jack I like </s> <s> Jack I do like </s> <s> do I like Jack </s>\"\"\"\nprint(round(unigram_probability(corpus, \"Jack\"),4))",
                "expected_output": "0.1852"
            },
            {
                "test": "corpus = \"\"\"<s> I am Jack </s> <s> Jack I am </s> <s> Jack I like </s> <s> Jack I do like </s> <s> do I like Jack </s>\"\"\"\nprint(round(unigram_probability(corpus, \"like\"),4))",
                "expected_output": "0.1111"
            },
            {
                "test": "corpus = \"\"\"<s> hello world </s> <s> hello </s>\"\"\"\nprint(round(unigram_probability(corpus, \"hello\"),4))",
                "expected_output": "0.2857"
            },
            {
                "test": "corpus = \"\"\"<s> the quick brown fox </s> <s> jumps over the lazy dog </s>\"\"\"\nprint(round(unigram_probability(corpus, \"the\"),4))",
                "expected_output": "0.1538"
            }
        ],
        "difficulty": "easy",
        "solution": "def unigram_probability(corpus: str, word: str) -> float:\n    tokens = corpus.split()\n    total_word_count = len(tokens)\n    word_count = tokens.count(word)\n    return round(word_count / total_word_count, 4)",
        "likes": "0",
        "video": "",
        "dislikes": "0",
        "example": {
            "input": "corpus = \"<s> Jack I like </s> <s> Jack I do like </s>\", word = \"Jack\"",
            "output": "0.1818",
            "reasoning": "The corpus has 11 total tokens. 'Jack' appears twice. So, probability = 2 / 11"
        },
        "category": "NLP",
        "starter_code": "def unigram_probability(corpus: str, word: str) -> float:\n    # Your code here\n    pass",
        "title": "Calculate Unigram Probability from Corpus",
        "learn_section": "# Unigram Probability Calculation\n\n- In Natural Language Processing (NLP), a  unigram model is the simplest form of a language model. \n- It assumes each word in a sentence is generated independently.  \n\n\n- The probability of a word w under the unigram model is:\n\n$P(w) = \\frac{\\text{Count}(w)}{\\sum_{w' \\in V} \\text{Count}(w')}$\n\nWhere:\n\n- $\\text{Count}(w)$ = Number of times the word w appears in the corpus.\n\n- $V$ = Vocabulary (all word tokens in the corpus).\n\n- $\\sum_{w' \\in V} \\text{Count}(w')$ = Total number of word tokens.\n- Round upto the 4th decimal point.\n\n\n---\n\n### Sample Corpus\n\n```text\n<s> I am Jack </s>\n<s> Jack I am </s>\n<s> Jack I like </s>\n<s> Jack I do like </s>\n<s> do I like Jack </s>\n```\n\nNotes : \n- \\<s> : Start of a sentence\n- \\</s> : End of a sentence\n- Need to count both the start and enod of sentence tokens while calculating probability.\n- Zero probability issues are not addressed here and will be covered separately under smoothing techniques in  later problems.",
        "contributor": [
            {
                "profile_link": "https://github.com/Noth2006",
                "name": "Noth2006"
            }
        ]
    },
    {
        "description": "Write a Python function that calculates the determinant of a 4x4 matrix using Laplace's Expansion method. The function should take a single argument, a 4x4 matrix represented as a list of lists, and return the determinant of the matrix. The elements of the matrix can be integers or floating-point numbers. Implement the function recursively to handle the computation of determinants for the 3x3 minor matrices.",
        "mdx_file": "99712fe7-8545-4194-bdd1-b2960e6d9248.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGRldGVybWluYW50XzR4NF90ZyhtYXRyaXgpIC0+IFRlbnNvcjoKICAgICIiIgogICAgQ29tcHV0ZSB0aGUgZGV0ZXJtaW5hbnQgb2YgYSA0w5c0IG1hdHJpeCB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0IGNhbiBiZSBhIFB5dGhvbiBsaXN0LCBOdW1QeSBhcnJheSwgb3IgdGlueWdyYWQgVGVuc29yIG9mIHNoYXBlICg0LDQpLgogICAgUmV0dXJucyBhIDAtRCBUZW5zb3IgY29udGFpbmluZyB0aGUgZGV0ZXJtaW5hbnQuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(determinant_4x4([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]))",
                "expected_output": "0"
            },
            {
                "test": "print(determinant_4x4([[4, 3, 2, 1], [3, 2, 1, 4], [2, 1, 4, 3], [1, 4, 3, 2]]))",
                "expected_output": "-160"
            },
            {
                "test": "print(determinant_4x4([[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6]]))",
                "expected_output": "0"
            }
        ],
        "solution": "def determinant_4x4(matrix: list[list[int|float]]) -> float:\n    # Base case: If the matrix is 1x1, return its single element\n    if len(matrix) == 1:\n        return matrix[0][0]\n    # Recursive case: Calculate determinant using Laplace's Expansion\n    det = 0\n    for c in range(len(matrix)):\n        minor = [row[:c] + row[c+1:] for row in matrix[1:]]  # Remove column c\n        cofactor = ((-1)**c) * determinant_4x4(minor)  # Compute cofactor\n        det += matrix[0][c] * cofactor  # Add to running total\n    return det",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBkZXRlcm1pbmFudF80eDRfdGcobWF0cml4KSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIGRldGVybWluYW50IG9mIGEgNMOXNCBtYXRyaXggdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dCBjYW4gYmUgYSBQeXRob24gbGlzdCwgTnVtUHkgYXJyYXksIG9yIHRpbnlncmFkIFRlbnNvciBvZiBzaGFwZSAoNCw0KS4KICAgIFJldHVybnMgYSAwLUQgVGVuc29yIGNvbnRhaW5pbmcgdGhlIGRldGVybWluYW50LgogICAgIiIiCiAgICAjIGNvbnZlcnQgdG8gTnVtUHkgYXJyYXkKICAgIGlmIGlzaW5zdGFuY2UobWF0cml4LCBUZW5zb3IpOgogICAgICAgIGFyciA9IG1hdHJpeC5udW1weSgpCiAgICBlbHNlOgogICAgICAgIGFyciA9IG5wLmFycmF5KG1hdHJpeCwgZHR5cGU9ZmxvYXQpCiAgICBkZXQgPSBmbG9hdChucC5saW5hbGcuZGV0KGFycikpCiAgICByZXR1cm4gVGVuc29yKGRldCkK",
        "pytorch_difficulty": "easy",
        "video": null,
        "likes": "0",
        "difficulty": "hard",
        "example": {
            "input": "a = [[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]]",
            "output": "0",
            "reasoning": "Using Laplace's Expansion, the determinant of a 4x4 matrix is calculated by expanding it into minors and cofactors along any row or column. Given the symmetrical and linear nature of this specific matrix, its determinant is 0. The calculation for a generic 4x4 matrix involves more complex steps, breaking it down into the determinants of 3x3 matrices."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "def determinant_4x4(matrix: list[list[int|float]]) -> float:\n\t# Your recursive implementation here\n\tpass",
        "title": "Determinant of a 4x4 Matrix using Laplace's Expansion (hard)",
        "learn_section": "\n## Determinant of a 4x4 Matrix using Laplace's Expansion\n\nLaplace's Expansion, also known as cofactor expansion, is a method to calculate the determinant of a square matrix of any size. For a 4x4 matrix \\( A \\), this method involves expanding \\( A \\) into minors and cofactors along a chosen row or column.\n\nConsider a 4x4 matrix \\( A \\):\n$$\nA = \\begin{pmatrix}\na_{11} & a_{12} & a_{13} & a_{14} \\\\\na_{21} & a_{22} & a_{23} & a_{24} \\\\\na_{31} & a_{32} & a_{33} & a_{34} \\\\\na_{41} & a_{42} & a_{43} & a_{44}\n\\end{pmatrix}\n$$\n\nThe determinant of \\( A \\), \\( \\det(A) \\), can be calculated by selecting any row or column (e.g., the first row) and using the formula that involves the elements of that row (or column), their corresponding cofactors, and the determinants of the 3x3 minor matrices obtained by removing the row and column of each element. This process is recursive, as calculating the determinants of the 3x3 matrices involves further expansions.\n\nThe expansion formula for the first row is:\n$$\n\\det(A) = a_{11}C_{11} - a_{12}C_{12} + a_{13}C_{13} - a_{14}C_{14}\n$$\n\n### Explanation of Terms\n- **Cofactor \\( C_{ij} \\)**: The cofactor of element \\( a_{ij} \\) is given by:\n  $$\n  C_{ij} = (-1)^{i+j} \\det(\\text{Minor of } a_{ij})\n  $$\n  where the minor of \\( a_{ij} \\) is the determinant of the 3x3 matrix obtained by removing the \\( i \\)th row and \\( j \\)th column from \\( A \\).\n\n### Notes\n- The choice of row or column for expansion can be based on convenience, often selecting one with the most zeros to simplify calculations.\n- The process is recursive, breaking down the determinant calculation into smaller 3x3 determinants until reaching 2x2 determinants, which are simpler to compute.\n\nThis method is fundamental in linear algebra and provides a systematic approach for determinant calculation, especially for matrices larger than 3x3.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nprint(determinant_4x4(torch.eye(4)))",
                "expected_output": "1.0"
            },
            {
                "test": "import torch\nprint(determinant_4x4(torch.diag(torch.tensor([2.0,3.0,4.0,5.0]))))",
                "expected_output": "120.0"
            },
            {
                "test": "import torch\nm = torch.tensor([[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[5.0,6.0,7.0,8.0],[9.0,10.0,11.0,12.0]])\nprint(determinant_4x4(m))",
                "expected_output": "0.0"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nprint(determinant_4x4_tg(Tensor(np.eye(4))).numpy().item())",
                "expected_output": "1.0"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nprint(determinant_4x4_tg([[2.0,0,0,0],[0,3.0,0,0],[0,0,4.0,0],[0,0,0,5.0]]).numpy().item())",
                "expected_output": "120.0"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nm = [[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[5.0,6.0,7.0,8.0],[9.0,10.0,11.0,12.0]]\nprint(determinant_4x4_tg(Tensor(m)).numpy().item())",
                "expected_output": "0.0"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgZGV0ZXJtaW5hbnRfNHg0KG1hdHJpeCkgLT4gZmxvYXQ6CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIGRldGVybWluYW50IG9mIGEgNMOXNCBtYXRyaXggdXNpbmcgUHlUb3JjaC4KICAgIElucHV0IGNhbiBiZSBhIFB5dGhvbiBsaXN0LCBOdW1QeSBhcnJheSwgb3IgdG9yY2ggVGVuc29yIG9mIHNoYXBlICg0LDQpLgogICAgUmV0dXJucyBhIFB5dGhvbiBmbG9hdC4KICAgICIiIgogICAgbSA9IHRvcmNoLmFzX3RlbnNvcihtYXRyaXgsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgIyB1c2UgYnVpbHQtaW4gZGV0ZXJtaW5hbnQKICAgIHJldHVybiB0b3JjaC5saW5hbGcuZGV0KG0pLml0ZW0oKQo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgZGV0ZXJtaW5hbnRfNHg0KG1hdHJpeCkgLT4gZmxvYXQ6CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIGRldGVybWluYW50IG9mIGEgNMOXNCBtYXRyaXggdXNpbmcgUHlUb3JjaC4KICAgIElucHV0IGNhbiBiZSBhIFB5dGhvbiBsaXN0LCBOdW1QeSBhcnJheSwgb3IgdG9yY2ggVGVuc29yIG9mIHNoYXBlICg0LDQpLgogICAgUmV0dXJucyBhIFB5dGhvbiBmbG9hdC4KICAgICIiIgogICAgIyBDb252ZXJ0IHRvIHRlbnNvcgogICAgbSA9IHRvcmNoLmFzX3RlbnNvcihtYXRyaXgsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "13"
    },
    {
        "description": "Create a function that trains a basic Convolutional Neural Network (CNN) using backpropagation. The network should include one convolutional layer with ReLU activation, followed by flattening and a dense layer with softmax output, and a cross entropy loss. You need to handle the forward pass, compute the loss gradients, and update the weights and biases using stochastic gradient descent. Ensure the function processes input data as grayscale images and one-hot encoded labels, and returns the trained weights and biases for the convolutional and dense layers.",
        "id": "130",
        "test_cases": [
            {
                "test": "import numpy as np; np.random.seed(42); X = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]); y = np.array([[1, 0]]); print(train_simple_cnn_with_backprop(X, y, 1, 0.01, 3, 1))",
                "expected_output": "(array([[[ 0.00501739],        [-0.00128214],        [ 0.00662764]],       [[ 0.01543131],        [-0.00209028],        [-0.00203986]],       [[ 0.01614389],        [ 0.00807636],        [-0.00424248]]]), array([5.02517066e-05]), array([[ 0.00635715, -0.00556573]]), array([ 0.00499531, -0.00499531]))"
            },
            {
                "test": "import numpy as np; np.random.seed(42); X = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[9, 8, 7], [6, 5, 4], [3, 2, 1]]]); y = np.array([[0, 1], [1, 0]]); print(train_simple_cnn_with_backprop(X, y, 2, 0.01, 3, 1))",
                "expected_output": "(array([[[ 0.00561561],        [-0.00091884],        [ 0.00675603]],       [[ 0.01532478],        [-0.00243171],        [-0.00261621]],       [[ 0.01533262],        [ 0.00703018],        [-0.00552357]]]), array([-1.80360153e-05]), array([[ 0.00561137, -0.00481995]]), array([ 3.23124658e-05, -3.23124658e-05]))"
            },
            {
                "test": "import numpy as np; np.random.seed(42); X = np.array([[[2, 3, 4], [5, 6, 7], [8, 9, 10]]]); y = np.array([[0.5, 0.5]]); print(train_simple_cnn_with_backprop(X, y, 1, 0.005, 3, 1))",
                "expected_output": "(array([[[ 0.00496708],        [-0.00138273],        [ 0.00647677]],       [[ 0.01523016],        [-0.00234171],        [-0.00234157]],       [[ 0.0157919 ],        [ 0.00767409],        [-0.00469503]]]), array([-2.85717013e-08]), array([[ 0.00542496, -0.00463354]]), array([-2.84019221e-06,  2.84019221e-06]))"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef train_simple_cnn_with_backprop(X, y, epochs, learning_rate, kernel_size=3, num_filters=1):\n    '''\n    Trains a simple CNN with one convolutional layer, ReLU activation, flattening, and a dense layer with softmax output using backpropagation.\n\n    Assumes X has shape (n_samples, height, width) for grayscale images and y is one-hot encoded with shape (n_samples, num_classes).\n\n    Parameters:\n    X : np.ndarray, input data\n    y : np.ndarray, one-hot encoded labels\n    epochs : int, number of training epochs\n    learning_rate : float, learning rate for weight updates\n    kernel_size : int, size of the square convolutional kernel\n    num_filters : int, number of filters in the convolutional layer\n\n    Returns:\n    W_conv, b_conv, W_dense, b_dense : Trained weights and biases for the convolutional and dense layers\n    '''\n    n_samples, height, width = X.shape\n    num_classes = y.shape[1]\n\n    # Initialize weights and biases\n    W_conv = np.random.randn(kernel_size, kernel_size, num_filters) * 0.01\n    b_conv = np.zeros(num_filters)\n    output_height = height - kernel_size + 1\n    output_width = width - kernel_size + 1\n    flattened_size = output_height * output_width * num_filters\n    W_dense = np.random.randn(flattened_size, num_classes) * 0.01\n    b_dense = np.zeros(num_classes)\n\n    for epoch in range(epochs):\n        for i in range(n_samples):  # Stochastic Gradient Descent with batch size 1\n            # Forward pass\n            # Convolutional layer\n            Z_conv = np.zeros((output_height, output_width, num_filters))\n            for k in range(num_filters):\n                for p in range(output_height):\n                    for q in range(output_width):\n                        Z_conv[p, q, k] = np.sum(X[i, p:p+kernel_size, q:q+kernel_size] * W_conv[:, :, k]) + b_conv[k]\n            A_conv = np.maximum(Z_conv, 0)  # ReLU activation\n            A_flat = A_conv.flatten()  # Flatten the output\n\n            # Dense layer\n            Z_dense = np.dot(A_flat, W_dense) + b_dense\n            exp_Z_dense = np.exp(Z_dense - np.max(Z_dense))  # Numerical stability for softmax\n            A_dense = exp_Z_dense / np.sum(exp_Z_dense)\n\n            # Backpropagation\n            # Loss gradient for cross-entropy with softmax\n            dZ_dense = A_dense - y[i]\n\n            # Dense layer gradients\n            dW_dense = np.outer(A_flat, dZ_dense)\n            db_dense = dZ_dense\n            dA_flat = np.dot(dZ_dense, W_dense.T)\n\n            # Reshape and backprop through ReLU\n            dA_conv = dA_flat.reshape(A_conv.shape)\n            dZ_conv = dA_conv * (A_conv > 0).astype(float)\n\n            # Convolutional layer gradients\n            dW_conv = np.zeros_like(W_conv)\n            db_conv = np.zeros(num_filters)\n            for k in range(num_filters):\n                db_conv[k] = np.sum(dZ_conv[:, :, k])\n                for ii in range(kernel_size):\n                    for jj in range(kernel_size):\n                   \n                        dW_conv[ii, jj, k] = np.sum(dZ_conv[:, :, k] * X[i, ii:ii+output_height, jj:jj+output_width])\n\n            \n# Update weights and biases\n            W_conv -= learning_rate * dW_conv\n            b_conv -= learning_rate * db_conv\n            W_dense -= learning_rate * dW_dense\n            b_dense -= learning_rate * db_dense\n\n    return W_conv, b_conv, W_dense, b_dense",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "import numpy as np; np.random.seed(42); X = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]]); y = np.array([[1, 0]]); print(train_simple_cnn_with_backprop(X, y, 1, 0.01, 3, 1))",
            "output": "(array([[[ 0.00501739],        [-0.00128214],        [ 0.00662764]],       [[ 0.01543131],        [-0.00209028],        [-0.00203986]],       [[ 0.01614389],        [ 0.00807636],        [-0.00424248]]]), array([5.02517066e-05]), array([[ 0.00635715, -0.00556573]]), array([ 0.00499531, -0.00499531]))",
            "reasoning": "The solution processes the input X through a forward pass, where it applies a convolutional layer with ReLU activation, flattens the output, and passes it through a dense layer with softmax to compute predictions and loss based on the one-hot encoded label y. In the backward pass, it calculates gradients using backpropagation for the weights and biases, then updates them using stochastic gradient descent with the specified learning rate, and returns the updated weights after one epoch."
        },
        "category": "Deep Learning",
        "starter_code": "def train_simple_cnn_with_backprop(X, y, epochs, learning_rate, kernel_size=3, num_filters=1):\n    # Your code here\n    pass",
        "title": "Implement a Simple CNN Training Function with Backpropagation",
        "learn_section": "## Understanding a Simple Convolutional Neural Network with Backpropagation\n\nA **Convolutional Neural Network** (CNN) learns two things at once:  \n1. **What to look for** - small filters (kernels) that detect edges, textures, etc.  \n2. **How to combine those detections** - a dense layer that converts them into class probabilities.\n\nBelow is the full training loop broken into intuitive steps that can be implemented directly in NumPy.\n\n---\n\n### 1. Forward Pass\n\n**Convolution**  \nThe convolution layer slides a small filter over the input and produces feature maps:\n\n$$\nZ^c[p, q, k] = \\sum_{i, j} X[p+i, q+j] \\cdot W^c[i, j, k] + b^c[k]\n$$\n\nThis results in a tensor of shape $(H - k + 1, W - k + 1, F)$, where $H$ and $W$ are the input height and width, $k$ is the kernel size, and $F$ is the number of filters.\n\n**ReLU Activation**\n\n$$\nA^c = \\max(0, Z^c)\n$$\n\nThis introduces non-linearity by zeroing out negative values.\n\n**Flattening**\n\nThe feature maps are reshaped into a vector:\n\n$$\nA^f = \\text{flatten}(A^c)\n$$\n\n**Dense Layer**\n\n$$\nZ^d = A^f \\cdot W^d + b^d\n$$\n\nEach entry in $A^f$ contributes to every output class via weight matrix $W^d$ and bias $b^d$.\n\n**Softmax Activation**\n\n$$\n\\hat{y}_c = \\frac{e^{Z^d_c}}{\\sum_j e^{Z^d_j}}\n$$\n\nThis converts raw scores into probabilities for classification.\n\n---\n\n### 2. Loss Function – Cross Entropy\n\nFor one-hot encoded label $y$ and prediction $\\hat{y}$:\n\n$$\n\\mathcal{L}(\\hat{y}, y) = -\\sum_c y_c \\log(\\hat{y}_c)\n$$\n\nThis penalizes incorrect predictions based on confidence.\n\n---\n\n### 3. Backward Pass\n\n**Gradient of Softmax + Cross Entropy**\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial Z^d} = \\hat{y} - y\n$$\n\n**Dense Layer Gradients**\n\n$\\frac{\\partial \\mathcal{L}}{\\partial W^d} = (A^f)^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial Z^d}$,\nand the gradient with respect to biases is\n$\\frac{\\partial \\mathcal{L}}{\\partial b^d} = \\frac{\\partial \\mathcal{L}}{\\partial Z^d}$.\n\nReshape the upstream gradient to the shape of $A^c$ for backpropagation through ReLU.\n\n**ReLU Gradient**\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial Z^c} = \\frac{\\partial \\mathcal{L}}{\\partial A^c} \\cdot \\mathbf{1}(Z^c > 0)\n$$\n\n**Convolution Filter Gradients**\n\nFor each filter $k$:\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial W^c_{i,j,k}} = \\sum_{p,q} \\frac{\\partial \\mathcal{L}}{\\partial Z^c_{p,q,k}} \\cdot X_{p+i, q+j}\n$$\n\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial b^c_k} = \\sum_{p,q} \\frac{\\partial \\mathcal{L}}{\\partial Z^c_{p,q,k}}\n$$\n\n---\n\n### 4. Updating Parameters (SGD)\n\nWith learning rate $\\eta$:\n\n$$\nW \\leftarrow W - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial W}\n$$\n\n$$\nb \\leftarrow b - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial b}\n$$\n\nRepeat this process for each sample (stochastic gradient descent) and for multiple epochs.\n\n---\n\n### 5. Example Walkthrough\n\nSuppose $X$ is a grayscale image:\n\n$$\nX = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{bmatrix}\n$$\n\nAnd the kernel is:\n\n$$\nK = \\begin{bmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{bmatrix}\n$$\n\nPerform convolution at the top-left:\n\n$$\n(1 \\cdot 1 + 2 \\cdot 0 + 4 \\cdot 0 + 5 \\cdot (-1)) = 1 - 5 = -4\n$$\n\nAfter ReLU: max(0, -4) = 0  \nFlatten the result -> Dense layer -> Softmax output -> Compute loss\n\nBackpropagate the error to adjust weights, and repeat to learn better filters and classifications over time.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "moe"
            }
        ]
    },
    {
        "description": "Create a function named sparse_window_attention that computes sparse attention over long sequences by sliding a fixed-radius window across the sequence.\n\n• The parameter window_size represents the radius w of the window.\n- For a token at index i, attend only to tokens whose indices are within max(0, i - w) through min(seq_len - 1, i + w), inclusive.\n- Tokens near the beginning or end of the sequence simply have smaller windows; no padding is added.\n\n• Inputs\n- Q, K, V: NumPy arrays with shapes (seq_len, d_k) for Q and K, and (seq_len, d_v) for V.\n- window_size: integer window radius.\n- scale_factor (optional): value used to scale dot-product scores; if None, default to sqrt(d_k).\n\n• Output\n- A NumPy array of shape (seq_len, d_v) containing the attention results.",
        "id": "131",
        "test_cases": [
            {
                "test": "import numpy as np\nQ = np.array([[1.0], [1.0], [1.0]])\nK = np.array([[1.0], [1.0], [1.0]])\nV = np.array([[1.0], [2.0], [3.0]])\nprint(sparse_window_attention(Q, K, V, 1))",
                "expected_output": "[[1.5], [2.], [2.5]]"
            },
            {
                "test": "import numpy as np\nQ = np.array([[4.0]])\nK = np.array([[4.0]])\nV = np.array([[5.0]])\nprint(sparse_window_attention(Q, K, V, 0))",
                "expected_output": "[[5.]]"
            },
            {
                "test": "import numpy as np\nQ = np.array([[0.0], [1.0], [0.0],[2.0], [0.0], [7.0]])\nK = np.array([[1.0], [2.0], [3.0], [0.0], [6.0], [0.0]])\nV = np.array([[10.0], [20.0], [30.0],[12.0], [23.0], [70.0]])\nprint(sparse_window_attention(Q, K, V, 2))",
                "expected_output": "[[20. ], [25.31123059], [19. ], [23.01651938], [33.75 ], [23. ]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef sparse_window_attention(Q, K, V, window_size, scale_factor=None):\n    \"\"\"\n    Computes sparse attention with a sliding window mask to efficiently handle longer context lengths.\n    This implementation uses a loop over the sequence to compute attention only within the specified window,\n    reducing memory usage compared to dense attention.\n\n    Args:\n        Q (np.ndarray): Query matrix of shape (seq_len, d_k)\n        K (np.ndarray): Key matrix of shape (seq_len, d_k)\n        V (np.ndarray): Value matrix of shape (seq_len, d_v)\n        window_size (int): The radius of the attention window (attends to window_size positions on each side).\n        scale_factor (float, optional): Scaling factor for the dot product. If None, uses sqrt(d_k).\n\n    Returns:\n        np.ndarray: Attention output of shape (seq_len, d_v)\n    \"\"\"\n    seq_len = Q.shape[0]\n    d_k = Q.shape[1]\n    if scale_factor is None:\n        scale_factor = np.sqrt(d_k).astype(float)\n    output = np.zeros((seq_len, V.shape[1]), dtype=V.dtype)\n    for i in range(seq_len):\n        start = max(0, i - window_size)\n        end = min(seq_len, i + window_size + 1)\n        local_Q = Q[i:i+1]\n        local_K = K[start:end]\n        local_V = V[start:end]\n        scores = np.dot(local_Q, local_K.T) / scale_factor\n        max_score = np.max(scores, axis=1, keepdims=True)\n        exp_scores = np.exp(scores - max_score)\n        sum_exp = np.sum(exp_scores, axis=1, keepdims=True)\n        attention_weights = exp_scores / sum_exp\n        output[i] = np.dot(attention_weights, local_V)\n    return output",
        "likes": "0",
        "video": "",
        "dislikes": "0",
        "example": {
            "input": "import numpy as np\nQ = np.array([[1.0], [1.0], [1.0]])\nK = np.array([[1.0], [1.0], [1.0]])\nV = np.array([[1.0], [2.0], [3.0]])\nprint(sparse_window_attention(Q, K, V, 1))",
            "output": "[[1.5] [2. ] [2.5]]",
            "reasoning": "The sparse_window_attention function processes each query in the input Q by computing attention scores only with keys in K within a window of size 1 (i.e., the current position and one adjacent position on each side), then applies softmax to these scores to derive weights for the corresponding values in V. For the given input arrays, this results in the output where the first element is the weighted average of V[0] and V[1] (yielding 1.5), the second is the average of all elements in V (yielding 2.0), and the third is the average of V[1] and V[2] (yielding 2.5)."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\ndef sparse_window_attention(Q, K, V, window_size, scale_factor=None):\n    # Your code here\n    pass",
        "title": "Implement Efficient Sparse Window Attention",
        "learn_section": "## Sparse Window Attention\n\nSparse window attention is a technique used in sequence processing models to efficiently focus on relevant parts of the data. It limits the model's attention to a local neighborhood around each position, reducing computational demands while maintaining effectiveness for tasks involving long sequences.\n\n### 1. Understanding Attention Mechanisms\n\nAttention mechanisms enable a model to weigh the importance of different elements in a sequence when generating an output. At its core, attention computes a set of weights that indicate how much each element should contribute to the result for a given position. These weights are derived from the similarity between a query representing the current position and keys, which represent other positions. The final output is a combination of values associated with those positions, scaled by the weights.\n\nFor instance, imagine reading a sentence: your brain focuses more on nearby words to understand the current word, rather than scanning the entire sentence. Mathematically, this process involves calculating similarities and producing a weighted average of the values.\n\n### 2. The Challenge with Full Attention\n\nIn traditional attention, every position in a sequence interacts with every other position, leading to high computational costs. This approach scales poorly for long sequences, as the number of interactions grows quadratically with the sequence length. To address this, sparse attention introduces restrictions, allowing the model to ignore distant or irrelevant positions.\n\nBy focusing only on a subset of the sequence, sparse attention maintains accuracy for local dependencies 2014such as in language where words often relate to their immediate neighbors while drastically reducing the resources needed.\n\n### 3. Defining the Window in Sparse Attention\n\nSparse window attention defines a fixed neighborhood, or \"window,\" around each position. For a given position, the model considers only the elements within a specified radius on either side. This radius, often called the window size, determines how far the attention extends.\n\nFor example, if the window size is 2, a position at index 5 would attend to positions 3, 4, 5, 6, and 7 (assuming those exist in the sequence). This sliding window approach ensures that attention is local and efficient, capturing patterns that are typically short-range while discarding long-range interactions that may not be necessary.\n\nThe key benefit here is efficiency: by limiting the scope, the overall process avoids examining the entire sequence, much like how a person might skim a text by focusing on paragraphs rather than every line.\n\n### 4. Computing the Attention Scores\n\nOnce the window is defined, attention scores are calculated to measure the relevance of each element within that window. These scores are based on the dot product between the query and the keys in the window, which quantifies their similarity.\n\nThe formula for the scores is given by:\n\n$$\n\\text{scores} = \\frac{Q K^T}{\\sqrt{d_k}}\n$$\n\nHere, $Q$ represents the query vector for the current position, $K$ is the matrix of key vectors within the window, and $K^T$ is its transpose. The term $d_k$ denotes the dimensionality of the keys, and dividing by $\\sqrt{d_k}$ scales the scores to prevent them from becoming too large, which could destabilize the process.\n\nThis equation produces a set of numbers indicating how aligned the query is with each key. A higher score means greater similarity, reflecting a stronger influence on the output.\n\n### 5. Applying the Softmax and Weighted Sum\n\nAfter obtaining the scores, they are normalized to create probabilities using the softmax function. This step ensures that the weights sum to 1, turning the raw scores into a distribution.\n\nThe softmax operation is defined as:\n\n$$\n\\text{attention weights} = \\frac{\\exp(\\text{scores})}{\\sum \\exp(\\text{scores})}\n$$\n\nEach element in the attention weights represents the relative importance of the corresponding key in the window. Finally, the output for the current position is computed as a weighted sum of the values in the window:\n\n$$\n\\text{output} = \\text{attention weights} \\cdot V\n$$\n\nIn this expression, $V$ is the matrix of value vectors within the window. The result is a single vector that combines the values based on their computed importance, effectively summarizing the relevant information from the local context.\n\n### 6. Example Walkthrough\n\n---\n\nConsider a simple sequence of five numbers: [1, 2, 3, 4, 5]. Suppose the window size is 1, meaning each position attends to itself and its immediate neighbors.\n\nFor the position of the number 3 (at index 2), the window includes indices 1, 2, and 3 corresponding to the numbers 2, 3, and 4. The model would compute similarities between the query for index 2 and the keys for indices 1, 2, and 3. It then assigns weights to 2, 3, and 4 based on these similarities and produces an output as a weighted combination of these numbers.\n\nThis illustrates how sparse window attention efficiently captures local relationships, such as how 3 might relate more to 2 and 4 than to distant numbers like 1 or 5.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe"
            }
        ]
    },
    {
        "description": "Implement a function to simulate a Markov Chain. The function should take a 2D numpy array representing the transition matrix (where each row sums to 1), an integer for the initial state index, and an integer for the number of steps to simulate. It should return a numpy array containing the sequence of state indices over time, including the initial state. Use numpy for array operations and random selections.",
        "id": "132",
        "test_cases": [
            {
                "test": "import numpy as np; np.random.seed(42); transition_matrix = np.array([[0.8, 0.2], [0.3, 0.7]]); print(simulate_markov_chain(transition_matrix, 0, 3))",
                "expected_output": "[0 0 1 1]"
            },
            {
                "test": "import numpy as np; np.random.seed(0); transition_matrix = np.array([[0.5, 0.5], [0.5, 0.5]]); print(simulate_markov_chain(transition_matrix, 1, 4))",
                "expected_output": "[1 1 1 1 1]"
            },
            {
                "test": "import numpy as np; np.random.seed(1); transition_matrix = np.array([[0.9, 0.1], [0.2, 0.8]]); print(simulate_markov_chain(transition_matrix, 0, 2))",
                "expected_output": "[0 0 0]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef simulate_markov_chain(transition_matrix, initial_state, num_steps):\n    \"\"\"\n    Simulates a Markov Chain given a transition matrix, initial state, and number of steps.\n\n    Parameters:\n    transition_matrix : 2D numpy.ndarray, transition probabilities where each row sums to 1.\n    initial_state : int, starting state index.\n    num_steps : int, number of steps to simulate.\n\n    Returns:\n    numpy.ndarray, array of state indices over time, including the initial state.\n    \"\"\"\n    states = np.zeros(num_steps + 1, dtype=int)\n    states[0] = initial_state\n    current_state = initial_state\n    for t in range(num_steps):\n        probabilities = transition_matrix[current_state]\n        next_state = np.random.choice(transition_matrix.shape[1], p=probabilities)\n        states[t + 1] = next_state\n        current_state = next_state\n    return states",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "transition_matrix = np.array([[0.8, 0.2], [0.3, 0.7]]); print(simulate_markov_chain(transition_matrix, 0, 3))",
            "output": "[0 0 1 1]",
            "reasoning": "The solution simulates a Markov chain by starting with the initial state (0) and iteratively selecting the next state based on the probabilities in the transition matrix. For the given input, this process generates the sequence [0, 0, 1, 1] over three steps, where the first state is the initial one, and subsequent states are chosen such that from state 0, it stays at 0, then transitions to 1, and remains at 1."
        },
        "category": "Probability",
        "starter_code": "import numpy as np\ndef simulate_markov_chain(transition_matrix, initial_state, num_steps):\n    # Your code here\n    pass",
        "title": "Simulate Markov Chain Transitions",
        "learn_section": "## Markov Chains: A Stochastic Process\n\nMarkov Chains are a fundamental concept in probability theory, used to model systems that transition between different states over time. In this explanation, we will explore the key ideas behind Markov Chains, focusing on their mathematical foundations and intuitive meaning.\n\n### 1. Definition of a Markov Chain\n\nA Markov Chain is a sequence of events or states where the probability of moving to the next state depends only on the current state, not on any previous states. This property is known as the \"memoryless\" or Markov property.\n\nTo illustrate, imagine a system with a set of possible states, such as weather conditions (e.g., sunny or rainy). At any given moment, the system occupies one state, and the likelihood of transitioning to another state is determined solely by the current one. Mathematically, if we denote the states as $S_1, S_2, \\dots, S_n$, the process evolves according to probabilities that satisfy the Markov property.\n\nFor example, the equation for the probability of being in state $S_j$ at time $t+1$, given the current state $S_i$ at time $t$, can be expressed as:\n\n$\nP(S_{t+1} = S_j \\mid S_t = S_i, S_{t-1}, \\dots) = P(S_{t+1} = S_j \\mid S_t = S_i)\n$\n\nHere, $P$ represents probability, $S_t$ is the state at time $t$, and the right side shows that only the current state $S_t$ matters. This equation highlights how the process simplifies decision-making by ignoring historical data, making it useful for modeling random phenomena like random walks or population dynamics.\n\n### 2. Transition Probabilities and the Matrix\n\nAt the heart of a Markov Chain is the concept of transition probabilities, which quantify the likelihood of moving from one state to another. These probabilities are organized into a structure called a transition matrix.\n\nA transition matrix is a square array where each entry represents the probability of transitioning from a specific row state to a specific column state. For a system with $n$ states, the matrix is an $n \\times n$ grid, and each row sums to 1, ensuring that the probabilities for all possible outcomes from a given state add up to certainty.\n\nThe general form of a transition matrix $P$ is:\n\n$\nP = \\begin{pmatrix}\np_{11} & p_{12} & \\cdots & p_{1n} \\\\\np_{21} & p_{22} & \\cdots & p_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1} & p_{n2} & \\cdots & p_{nn}\n\\end{pmatrix}\n$\n\nIn this matrix, $p_{ij}$ is the probability of transitioning from state $i$ to state $j$. For instance, $p_{11}$ might represent the probability of staying in state 1, while $p_{12}$ represents the probability of moving from state 1 to state 2. Each $p_{ij}$ is a value between 0 and 1, and the sum of each row equals 1, as expressed by:\n\n$\n\\sum_{j=1}^{n} p_{ij} = 1 \\quad \\text{for each row } i\n$\n\nThis equation ensures that the matrix reflects a complete set of possibilities for each starting state, providing a clear framework for predicting future behavior based on the current position.\n\n### 3. Evolution of States Over Time\n\nOnce the transition matrix is defined, we can describe how the states of a Markov Chain evolve through successive steps. Starting from an initial state, the process generates a sequence of states by applying the transition probabilities repeatedly.\n\nAt each step, the next state is determined by the probabilities associated with the current state. Over multiple steps, this leads to a sequence that can be analyzed to understand long-term patterns, such as whether the system tends to settle into certain states or remains unpredictable.\n\nMathematically, if we begin in state $i$ at time 0, the probability of being in state $j$ after one step is given by the entry $p_{ij}$ in the matrix. After multiple steps, the overall probability distribution can be computed by multiplying the initial state probabilities by the transition matrix raised to the power of the number of steps. For a probability vector $\\mathbf{v}_t$ representing the likelihood of being in each state at time $t$, the evolution is:\n\n$\n\\mathbf{v}_{t+1} = \\mathbf{v}_t \\cdot P\n$\n\nHere, $\\mathbf{v}_t$ is a row vector of probabilities summing to 1, and $P$ is the transition matrix. This operation shows how the distribution shifts over time, with each multiplication reflecting the application of transition rules. In the long run, many Markov Chains reach a steady-state distribution, where the probabilities no longer change, offering insights into stable behaviors of the system.\n\n---\n\n### Example Walkthrough\n\nTo make the concept more concrete, consider a simple two-state system modeling weather patterns: State 1 as \"Sunny\" and State 2 as \"Rainy.\" Suppose the transition matrix is:\n\n$\nP = \\begin{pmatrix}\n0.7 & 0.3 \\\\\n0.4 & 0.6\n\\end{pmatrix}\n$\n\nIn this matrix, the entry 0.7 means there is a 70% chance of staying Sunny if it is currently Sunny, while 0.3 means a 30% chance of becoming Rainy. Similarly, 0.4 indicates a 40% chance of becoming Sunny if it is currently Rainy, and 0.6 means a 60% chance of staying Rainy.\n\nStarting from State 1 (Sunny), after one step, there is a 70% chance of remaining Sunny and a 30% chance of moving to Rainy. If it becomes Rainy, the next step would follow the second row of the matrix. Over several steps, this process might fluctuate, but eventually, it could approach a balance where the probabilities stabilize, reflecting typical weather patterns in this model. This example demonstrates how transition probabilities guide the system's behavior in a predictable yet random manner.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "moe"
            }
        ]
    },
    {
        "description": "Write a function that implements the Q-Learning algorithm to learn the optimal Q-table for a given Markov Decision Process (MDP). The function should take the number of states, number of actions, transition probabilities matrix, rewards matrix, list of terminal states, learning rate, discount factor, epsilon for exploration, and the number of episodes as inputs. Use these parameters to iteratively update the Q-table based on the Q-Learning update rule, employing an epsilon-greedy strategy for action selection. Ensure the function handles starting from non-terminal states and stops episodes upon reaching a terminal state.\n\nConstraints:\n- num_states: Integer greater than or equal to 1.\n- num_actions: Integer greater than or equal to 1.\n- P: A 3D NumPy array of shape (num_states, num_actions, num_states) where each element is a probability between 0 and 1, and each sub-array sums to 1.\n- R: A 2D NumPy array of shape (num_states, num_actions) with float or integer values.\n- terminal_states: A list or NumPy array of integers, each between 0 and num_states - 1, with no duplicates.\n- alpha: A float between 0 and 1.\n- gamma: A float between 0 and 1.\n- epsilon: A float between 0 and 1.\n- num_episodes: An integer greater than or equal to 1.\nThe function should return a 2D NumPy array of shape (num_states, num_actions) representing the learned Q-table.",
        "id": "133",
        "test_cases": [
            {
                "test": "import numpy as np; np.random.seed(42); P = np.array([[[0, 1], [1, 0]], [[1, 0], [1, 0]]]); R = np.array([[1, 0], [0, 0]]); terminal_states = [1]; print(q_learning(2, 2, P, R, terminal_states, 0.1, 0.9, 0.1, 10))",
                "expected_output": "[[0.65132156, 0.052902  ],[0., 0.        ]]"
            },
            {
                "test": "import numpy as np; np.random.seed(42); P = np.array([[[0.5, 0.5], [0, 1]], [[0, 1], [1, 0]]]); R = np.array([[0.5, 1], [0, 0]]); terminal_states = [1]; print(q_learning(2, 2, P, R, terminal_states, 0.5, 0.8, 0.2, 5))",
                "expected_output": "[[0.91785477, 0.5       ],[0., 0.        ]]"
            },
            {
                "test": "import numpy as np; np.random.seed(42); P = np.array([[[1, 0], [0, 1]], [[0.5, 0.5], [0.5, 0.5]]]); R = np.array([[2, 1], [0, 0]]); terminal_states = [0]; print(q_learning(2, 2, P, R, terminal_states, 0.3, 0.7, 0.05, 20))",
                "expected_output": "[[0., 0.],[0., 0.]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef q_learning(num_states, num_actions, P, R, terminal_states, alpha, gamma, epsilon, num_episodes):\n    \"\"\"\n    Implements Q-Learning algorithm to learn the optimal Q-table for a given MDP.\n\n    Parameters:\n    - num_states: int, number of states in the MDP\n    - num_actions: int, number of actions in the MDP\n    - P: NumPy array of shape (num_states, num_actions, num_states), transition probabilities\n    - R: NumPy array of shape (num_states, num_actions), rewards for each state-action pair\n    - terminal_states: list or NumPy array of integers, indices of terminal states\n    - alpha: float, learning rate\n    - gamma: float, discount factor\n    - epsilon: float, probability of choosing a random action in epsilon-greedy policy\n    - num_episodes: int, number of episodes to train\n\n    Returns:\n    - Q: NumPy array of shape (num_states, num_actions), the learned Q-table\n    \"\"\"\n    Q = np.zeros((num_states, num_actions))\n    \n    for episode in range(num_episodes):\n        # Start from a random non-terminal state\n        state = np.random.choice([s for s in range(num_states) if s not in set(terminal_states)])\n        \n        while state not in terminal_states:\n            # Epsilon-greedy action selection\n            if np.random.rand() < epsilon:\n                action = np.random.randint(num_actions)\n            else:\n                action = np.argmax(Q[state])\n            \n            # Sample next state based on transition probabilities\n            next_state = np.random.choice(num_states, p=P[state, action])\n            \n            # Get reward\n            reward = R[state, action]\n            \n            # Compute target Q-value\n            if next_state in terminal_states:\n                target = reward\n            else:\n                target = reward + gamma * np.max(Q[next_state])\n            \n            # Update Q-table\n            Q[state, action] += alpha * (target - Q[state, action])\n            \n            # Transition to next state\n            state = next_state\n    \n    return Q",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "import numpy as np; np.random.seed(42); P = np.array([[[0, 1], [1, 0]], [[1, 0], [1, 0]]]); R = np.array([[1, 0], [0, 0]]); terminal_states = [1]; print(q_learning(2, 2, P, R, terminal_states, 0.1, 0.9, 0.1, 10))",
            "output": "[[0.65132156, 0.052902  ],[0., 0.]]",
            "reasoning": "The Q-Learning algorithm initializes a Q-table with zeros and iteratively updates it over 10 episodes by starting from random non-terminal states, selecting actions via an epsilon-greedy policy, sampling next states and rewards from the provided transition probabilities (P) and rewards (R), and applying the update rule: Q(s, a) += alpha * (reward + gamma * max(Q(next_state)) - Q(s, a)). This process results in the output Q-table [[0.65132156, 0.052902], [0., 0.]], where the values represent learned estimates of state-action values, with the second state's Q-values remaining zero because it is a terminal state and no further actions are taken from there."
        },
        "category": "Reinforcement Learning",
        "starter_code": "import numpy as np\ndef q_learning(num_states, num_actions, P, R, terminal_states, alpha, gamma, epsilon, num_episodes):\n    # Your code here\n    pass",
        "title": "Implement Q-Learning Algorithm for MDPs",
        "learn_section": "## Q-Learning: Learning Optimal Actions in Markov Decision Processes\n\nQ-Learning is a method in reinforcement learning used to estimate the value of taking specific actions in different states within a Markov Decision Process (MDP). An MDP models decision-making scenarios where the outcomes of actions depend on the current state, and the goal is to maximize long-term rewards. This section breaks down the key concepts step by step, focusing on the underlying mathematics.\n\n### 1. Understanding Markov Decision Processes\nA Markov Decision Process is a framework for sequential decision-making. It consists of states, actions, transition probabilities, and rewards. In an MDP, the future state depends only on the current state and the chosen action, not on the history of previous states.\n\n- States represent the situations an agent might encounter.\n- Actions are the choices available in each state.\n- Transition probabilities describe the likelihood of moving from one state to another after an action.\n- Rewards are numerical values that quantify the immediate benefit of taking an action in a state.\n\nFor example, imagine navigating a simple grid where each cell is a state, moving right or left is an action, and reaching a goal gives a reward.\n\n### 2. The Q-Value Function\nAt the heart of Q-Learning is the Q-value, which estimates the total expected reward of taking a specific action in a given state and then following the best possible strategy afterward.\n\nMathematically, the Q-value for a state $s$ and action $a$ is denoted as $Q(s, a)$. It is defined by the equation:\n\n$$\nQ(s, a) = r(s, a) + \\gamma \\sum_{s'} P(s' | s, a) \\max_{a'} Q(s', a')\n$$\n\nHere:\n- $r(s, a)$ is the immediate reward received for taking action $a$ in state $s$.\n- $\\gamma$ (gamma) is the discount factor, a number between 0 and 1 that reduces the importance of future rewards over time (e.g., if $\\gamma = 0.9$, rewards in the near future are valued more than those far ahead).\n- $P(s' | s, a)$ is the transition probability, representing the likelihood of ending up in state $s'$ after action $a$ in state $s$.\n- $\\max_{a'} Q(s', a')$ is the maximum Q-value of all possible actions in the next state $s'$, indicating the best future choice.\n\nThis equation captures the idea that the Q-value balances immediate rewards with the discounted value of future rewards, helping to identify the most valuable actions over time.\n\n### 3. The Q-Learning Update Rule\nQ-Learning updates the Q-value estimates iteratively based on experience, using a simple iterative formula. This process allows the agent to learn from trials without needing to know the full transition probabilities in advance.\n\nThe update rule is:\n\n$$\nQ(s, a) \\leftarrow Q(s, a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s, a) \\right]\n$$\n\nIn this equation:\n- $\\alpha$ (alpha) is the learning rate, a value between 0 and 1 that controls how much new information overrides old estimates (e.g., if $\\alpha = 0.1$, updates are gradual).\n- $r$ is the reward observed after taking action $a$ in state $s$.\n- $s'$ is the next state that results from the action.\n- The term inside the brackets, $r + \\gamma \\max_{a'} Q(s', a') - Q(s, a)$, is the difference between the estimated Q-value and the actual experienced value, known as the temporal difference error.\n\nThis rule refines Q-values over multiple episodes, gradually converging to the optimal values that maximize long-term rewards.\n\n### 4. Balancing Exploration and Exploitation\nTo learn effectively, Q-Learning must balance exploring new actions (to discover potential rewards) and exploiting known high-value actions.\n\nThis is achieved through an epsilon-greedy strategy, where:\n- With probability $\\epsilon$ (epsilon, a small number like 0.1), a random action is selected to encourage exploration.\n- With probability $1 - \\epsilon$, the action with the highest Q-value is chosen to exploit current knowledge.\n\nFor instance, if $\\epsilon = 0.2$, in 20% of decisions, the agent tries something random, while in 80%, it picks the best-known option. Over time, $\\epsilon$ can be reduced to favor exploitation as learning progresses.\n\n---\n\n### Example Walkthrough\nConsider a simple two-state MDP: State A and State B, with two actions in each (Action 1 and Action 2). Suppose:\n- From State A, Action 1 leads to State B with probability 1 and a reward of 1.\n- From State B, any action ends the process with a reward of 0 (State B is terminal).\n- Let $\\gamma = 0.9$ and $\\alpha = 0.5$.\n\nInitially, assume all Q-values are 0. In the first episode:\n- Start in State A and choose Action 1 (greedily, since all Q-values are equal).\n- Move to State B, receive reward 1, and since State B is terminal, the update is:  \n  $$\n  Q(\\text{A}, \\text{Action 1}) \\leftarrow 0 + 0.5 \\left[ 1 + 0.9 \\cdot 0 - 0 \\right] = 0.5\n  $$\n- Now, Q(A, Action 1) is 0.5, so in future episodes, Action 1 is more likely in State A.\n\nThrough repeated episodes, Q-values adjust to reflect the best long-term rewards, such as prioritizing paths that lead to higher cumulative rewards.",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "moe"
            }
        ]
    },
    {
        "description": "Implement a function that computes the average cross-entropy loss for a batch of predictions in a multi-class classification task. Your function should take in a batch of predicted probabilities and one-hot encoded true labels, then return the average cross-entropy loss. Ensure that you handle numerical stability by clipping probabilities by epsilon.",
        "id": "134",
        "test_cases": [
            {
                "test": "import numpy as np\npred = np.array([[1, 0, 0], [0, 1, 0]])\ntrue = np.array([[1, 0, 0], [0, 1, 0]])\nprint(round(compute_cross_entropy_loss(pred, true), 4))",
                "expected_output": "0.0"
            },
            {
                "test": "import numpy as np\npred = np.array([[0.1, 0.8, 0.1], [0.8, 0.1, 0.1]])\ntrue = np.array([[0, 0, 1], [0, 1, 0]])\nprint(round(compute_cross_entropy_loss(pred, true), 4))",
                "expected_output": "2.3026"
            },
            {
                "test": "import numpy as np\npred = np.array([[0.7, 0.2, 0.1], [0.3, 0.6, 0.1]])\ntrue = np.array([[1, 0, 0], [0, 1, 0]])\nprint(round(compute_cross_entropy_loss(pred, true), 4))",
                "expected_output": "0.4338"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef compute_cross_entropy_loss(predicted_probs: np.ndarray, true_labels: np.ndarray,epsilon = 1e-15) -> float:\n\n    predicted_probs = np.clip(predicted_probs, epsilon, 1 - epsilon)\n\n    #Write your code here\n    log_probs = np.log(predicted_probs)\n    loss = -np.sum(true_labels * log_probs, axis=1)\n    return float(np.mean(loss))",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "predicted_probs = [[0.7, 0.2, 0.1], [0.3, 0.6, 0.1]]\ntrue_labels = [[1, 0, 0], [0, 1, 0]]",
            "output": "0.4338",
            "reasoning": "The predicted probabilities for the correct classes are 0.7 and 0.6. The cross-entropy is computed as -mean(log(0.7), log(0.6)), resulting in approximately 0.4463."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef compute_cross_entropy_loss(predicted_probs: np.ndarray, true_labels: np.ndarray, epsilon = 1e-15) -> float:\n    # Your code here\n    pass",
        "title": "Compute Multi-class Cross-Entropy Loss",
        "learn_section": "## Multi-class Cross-Entropy Loss Implementation\n\nCross-entropy loss, also known as log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. For multi-class classification tasks, we use the categorical cross-entropy loss.\n\n### Mathematical Background\n\nFor a single sample with C classes, the categorical cross-entropy loss is defined as:\n\n$L = -\\sum_{c=1}^{C} y_c \\log(p_c)$\n\nwhere:\n\n- $y_c$ is a binary indicator (0 or 1) if class label c is the correct classification for the sample\n- $p_c$ is the predicted probability that the sample belongs to class c\n- $C$ is the number of classes\n\n### Implementation Requirements\n\nYour task is to implement a function that computes the average cross-entropy loss across multiple samples:\n\n$L_{batch} = -\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{c=1}^{C} y_{n,c} \\log(p_{n,c})$\n\nwhere N is the number of samples in the batch.\n\n### Important Considerations\n\n- Handle numerical stability by adding a small epsilon to avoid log(0)\n- Ensure predicted probabilities sum to 1 for each sample\n- Return average loss across all samples\n- Handle invalid inputs appropriately\n\nThe function should take predicted probabilities and true labels as input and return the average cross-entropy loss.",
        "contributor": [
            {
                "profile_link": "https://github.com/emharsha1812",
                "name": "Harshwardhan Fartale"
            }
        ]
    },
    {
        "description": "Create a function to decide when to stop training a model early based on a list of validation losses. The early stopping criterion should stop training if the validation loss hasn't improved for a specified number of epochs (patience), and only count as improvement if the loss decreases by more than a certain threshold (min_delta). Your function should return the epoch to stop at and the best epoch that achieved the lowest validation loss.",
        "id": "135",
        "test_cases": [
            {
                "test": "print(early_stopping([0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78], 2, 0.01))",
                "expected_output": "(4, 2)"
            },
            {
                "test": "print(early_stopping([0.9, 0.8, 0.7, 0.6, 0.5], 2, 0.01))",
                "expected_output": "(4, 4)"
            },
            {
                "test": "print(early_stopping([0.9, 0.8, 0.79, 0.78, 0.77], 2, 0.1))",
                "expected_output": "(4, 2)"
            },
            {
                "test": "print(early_stopping([0.5, 0.4], 3, 0.01))",
                "expected_output": "(1, 1)"
            },
            {
                "test": "print(early_stopping([0.5, 0.4, 0.4, 0.4, 0.4], 2, 0.01))",
                "expected_output": "(3, 1)"
            }
        ],
        "difficulty": "easy",
        "solution": "from typing import Tuple\n\ndef early_stopping(val_losses: list[float], patience: int, min_delta: float) -> Tuple[int, int]:\n    best_loss = float('inf')\n    best_epoch = 0\n    epochs_without_improvement = 0\n\n    for epoch, loss in enumerate(val_losses):\n        if loss < best_loss - min_delta:\n            best_loss = loss\n            best_epoch = epoch\n            epochs_without_improvement = 0\n        else:\n            epochs_without_improvement += 1\n\n        if epochs_without_improvement >= patience:\n            return epoch, best_epoch\n\n    return len(val_losses) - 1, best_epoch",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "[0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78], patience=2, min_delta=0.01",
            "output": "(4, 2)",
            "reasoning": "The best validation loss is 0.75 at epoch 2. There is no improvement greater than 0.01 for the next 2 epochs. Therefore, training should stop at epoch 4."
        },
        "category": "Machine Learning",
        "starter_code": "from typing import Tuple\n\ndef early_stopping(val_losses: list[float], patience: int, min_delta: float) -> Tuple[int, int]:\n    # Your code here\n    pass",
        "title": "Implement Early Stopping Based on Validation Loss",
        "learn_section": "## Implementing Early Stopping Criterion\n\nEarly stopping is a regularization technique that helps prevent overfitting in machine learning models. Your task is to implement the early stopping decision logic based on the validation loss history.\n\n### Problem Description\n\nGiven a sequence of validation losses from model training, determine if training should be stopped based on the following criteria:\n\n- Training should stop if the validation loss hasn't improved (decreased) for a specified number of epochs (patience)\n- An improvement is only counted if the loss decreases by more than a minimum threshold (min_delta)\n- The best model is the one with the lowest validation loss\n\n### Example\n\nConsider the following validation losses: [0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78]\n\n- With patience=2 and min_delta=0.01:\n  - Best loss is 0.75 at epoch 2\n  - No improvement > 0.01 for next 2 epochs\n  - Should stop at epoch 4\n\n### Function Requirements\n\n- Return both the epoch to stop at and the best epoch\n- If no stopping is needed, return the last epoch\n- Epochs are 0-indexed",
        "contributor": [
            {
                "profile_link": "https://github.com/emharsha1812",
                "name": "Harshwardhan Fartale"
            }
        ]
    },
    {
        "description": "KL divergence measures the dissimilarity between two probability distributions. In this problem, you'll implement a function to compute the KL divergence between two multivariate Gaussian distributions given their means and covariance matrices. Use the provided mathematical formulas and numerical considerations to ensure accuracy.",
        "id": "136",
        "test_cases": [
            {
                "test": "import numpy as np\nnp.random.seed(42)\nPx = np.random.randn(4, 10)\nQx = np.random.randn(4, 10)\nmu1, cov1, mu2, cov2 = np.mean(Px, axis=1), np.cov(Px), np.mean(Qx, axis=1), np.cov(Qx)\nprint(round(multivariate_kl_divergence(mu1, cov1, mu2, cov2),4))",
                "expected_output": "2.193"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nPx = np.random.randn(3, 8)\nQx = np.random.randn(3, 8)\nmu1, cov1, mu2, cov2 = np.mean(Px, axis=1), np.cov(Px), np.mean(Qx, axis=1), np.cov(Qx)\nprint(round(multivariate_kl_divergence(mu1, cov1, mu2, cov2),4))",
                "expected_output": "1.7741"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef multivariate_kl_divergence(mu_p:np.ndarray, Cov_p:np.ndarray, \n                               mu_q:np.ndarray, Cov_q:np.ndarray) -> float:\n\n    def trace(x: np.ndarray) -> float:\n        return np.diag(x).sum()\n\n    p = Cov_p.shape[0]\n    return float(1/2 * (\n        np.log(np.linalg.det(Cov_q)/np.linalg.det(Cov_p))         - p + (mu_p-mu_q).T @ np.linalg.inv(Cov_q) @ (mu_p-mu_q)         + trace(np.linalg.inv(Cov_q) @ Cov_p)\n    ))",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "mu_p, Cov_p, mu_q, Cov_q for two random multivariate Gaussians",
            "output": "A float representing the KL divergence",
            "reasoning": "The KL divergence is calculated using the formula: 0.5 * (log det term, minus dimension p, Mahalanobis distance between means, and trace term). It measures how dissimilar the second Gaussian is from the first."
        },
        "category": "Probability",
        "starter_code": "import numpy as np\n\ndef multivariate_kl_divergence(mu_p: np.ndarray, Cov_p: np.ndarray, mu_q: np.ndarray, Cov_q: np.ndarray) -> float:\n    \"\"\"\n    Computes the KL divergence between two multivariate Gaussian distributions.\n    \n    Parameters:\n    mu_p: mean vector of the first distribution\n    Cov_p: covariance matrix of the first distribution\n    mu_q: mean vector of the second distribution\n    Cov_q: covariance matrix of the second distribution\n\n    Returns:\n    KL divergence as a float\n    \"\"\"\n    # Your code here\n    pass",
        "title": "Calculate KL Divergence Between Two Multivariate Gaussian Distributions",
        "learn_section": "## KL divergence and its properties\nKL divergence is used as a measure of dissimilarity between two distributions. It is defined by the following formula:\n$$\nD_{KL}(P || Q) = \\mathbb{E}_{x\\sim P(X)}log\\frac{P(X)}{Q(X)},\n$$\nwhere $P(X)$ observed distribution we compare everything else with and $Q(X)$ is usually the varying one; $P(X)$ and $Q(X)$ are PMF (but could also be denoted as PDFs $f(x)$ and $q(x)$ in continuos case). The function has following properties:\n* $D_{KL}\\geq0$\n* assymetry: $D_{KL}(P || Q) \\neq D_{KL}(Q || P)$\n\n## Finding $D_{KL}$ between two multivariate Gaussians\nConsider two multivariate Normal distributions:\n$$\np(x)\\sim \\mathbb{N}(\\mu_1,\\Sigma_1), \\\\\nq(x)\\sim \\mathbb{N}(\\mu_2,\\Sigma_2)\n$$\n\nPDF of a multivariate Normal distribution is defined as:\n$$\nf(x)=\\frac{1}{(2\\pi)^\\frac{p}{2}|\\Sigma|^\\frac{1}{2}}exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)),\n$$\n\nwhere $\\Sigma$ - covariance matrix, $|\\cdot|$ - determinant, $p$ - size of the random vector, i.e. number of different normally distributed features inside $P$ and $Q$ and $x$ usually denotes $x^T$, which is a random vector of size $p\\times1$.\n\nNow we can move onto calculating KL divergence for these two distributions, skipping the division part of two PDFs:\n$$\n\\frac{1}{2}[\\mathbb{E_p}log\\frac{|\\Sigma_q|}{|\\Sigma_p|} ^ \\textbf{[1]} - \\mathbb{E_p}(x-\\mu_p)^T\\Sigma_p^{-1}(x-\\mu_p) ^ \\textbf{[2]} + \\\\\n+ \\mathbb{E_p}(x-\\mu_q)^T\\Sigma_q^{-1}(x-\\mu_q) ^ \\textbf{[3]}]= \\\\\n= \\frac{1}{2}[log\\frac{|\\Sigma_q|}{|\\Sigma_p|}-p+(\\mu_p-\\mu_q)^T\\Sigma^{-1}_q(\\mu_p-\\mu_q) + \\\\\n+ tr(\\Sigma^{-1}_q\\Sigma_p)],\n$$\nwhere in order to achieve an equality we proceed to do $\\textbf{[1]}:$\n$$\nlog\\frac{|\\Sigma_q|}{|\\Sigma_p|}=const\\implies \\text{EV equals to the value itself;}\n$$\n\nthen $\\textbf{[2]}:$\n$$\n\\underset{N \\times p}{(x-\\mu_p)^T} * \\sum_{p \\times p} * \\underset{N \\times p}{(x-\\mu_p)^T} = \\underset{N\\times N}{A}\\text {, where } N=1 \\implies \\\\\n\\implies A=\\operatorname{tr}(A)\n$$\n\nRecall that:\n$$\n\\operatorname{tr}(A B C)=\\operatorname{tr}(B C A)=\\operatorname{tr}(C B A)\n$$\n\nThen:\n$$\n\\operatorname{tr}(A)=\\operatorname{tr}\\left(\\left(x-\\mu_p\\right)^{\\top}\\left(x-\\mu_p\\right) \\Sigma_p^{-1}\\right)\\\\ =\\operatorname{tr}\\left(\\Sigma_p \\Sigma_p^{-1}\\right)=\\operatorname{tr}(I)=p  \n$$\n\nand finally $\\textbf{[3]}$, where we should recall, that for multivariate Normal distributions this is true ($x\\sim\\mathbb{N}(\\mu_2, \\Sigma_2)$):\n$$\n\\mathbb{E}(x-\\mu_1)^TA(x-\\mu_1)= \\\\\n= (\\mu_2-\\mu_1)^TA(\\mu_2-\\mu_1)+tr(A\\Sigma_2)\n$$",
        "contributor": [
            {
                "profile_link": "https://github.com/turkunov",
                "name": "turkunov"
            }
        ]
    },
    {
        "description": "Create a function `dense_net_block` that performs the forward pass of a **DenseNet dense block** on a batch of images stored in an **NHWC** NumPy tensor `input_data` (shape `(N, H, W, C0)`). The block must run `num_layers` iterations; at each iteration it should (i) apply **ReLU** to the running feature tensor, (ii) convolve it with the corresponding kernel from `kernels` (using stride 1, no bias, and symmetric zero-padding so that `H` and `W` are preserved), and (iii) concatenate the convolution output (whose channel count equals `growth_rate`) to the running tensor along the channel axis. Every kernel `kernels[l]` therefore has shape `(kh, kw, C0 + l x growth_rate, growth_rate)`, where `(kh, kw)` equals `kernel_size` (default `(3, 3)`). After the final layer the function must return a tensor of shape `(N, H, W, C0 + num_layers x growth_rate)`. If any kernel's input-channel dimension does not match the current feature-map channels, the function should raise a `ValueError`.",
        "id": "137",
        "test_cases": [
            {
                "test": "import numpy as np\nnp.random.seed(42)\nX = np.random.randn(1, 1, 1, 2)\nkernels = [np.random.randn(3, 3, 2 + i*1, 1) * 0.01 for i in range(2)]\nprint(dense_net_block(X, 2, 1, kernels))",
                "expected_output": "[[[[ 4.96714153e-01, -1.38264301e-01, -2.30186127e-03, -6.70426255e-05]]]]"
            },
            {
                "test": "import numpy as np\n\nnp.random.seed(42)\nX = np.random.randn(1, 2, 3, 2)\nkernels = [np.random.randn(3, 3, 2 + i*1, 1) * 0.01 for i in range(2)]\nprint(dense_net_block(X, 2, 1, kernels))",
                "expected_output": "[[[[ 0.49671415, -0.1382643 , -0.0308579 , -0.01845547], [ 0.64768854, 1.52302986, -0.0041634 , -0.0161227 ], [-0.23415337, -0.23413696, -0.02678915, 0.00295656]], [[ 1.57921282, 0.76743473, 0.00334109, -0.04043312], [-0.46947439, 0.54256004, -0.04493715, 0.00983633], [-0.46341769, -0.46572975, -0.03523526, 0.02832019]]]]"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef conv2d(x, kernel, padding=0):\n    if padding > 0:\n        x_padded = np.pad(x, ((0, 0), (padding, padding), (padding, padding), (0, 0)), mode='constant')\n    else:\n        x_padded = x\n    batch_size, in_height, in_width, in_channels = x_padded.shape\n    kh, kw, _, out_channels = kernel.shape\n    out_height = in_height - kh + 1\n    out_width = in_width - kw + 1\n    output = np.zeros((batch_size, out_height, out_width, out_channels))\n    for b in range(batch_size):\n        for i in range(out_height):\n            for j in range(out_width):\n                for c_out in range(out_channels):\n                    sum_val = 0.0\n                    for c_in in range(in_channels):\n                        sum_val += np.sum(x_padded[b, i:i+kh, j:j+kw, c_in] * kernel[:, :, c_in, c_out])\n                    output[b, i, j, c_out] = sum_val\n    return output\n\ndef dense_net_block(input_data, num_layers, growth_rate, kernels, kernel_size=(3, 3)):\n    kh, kw = kernel_size\n    padding = (kh - 1) // 2\n    concatenated_features = input_data.copy()\n    for l in range(num_layers):\n        activated = np.maximum(concatenated_features, 0.0)\n        conv_output = conv2d(activated, kernels[l], padding=padding)\n        concatenated_features = np.concatenate([concatenated_features, conv_output], axis=3)\n    return concatenated_features",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "X = np.random.randn(1, 2, 2, 1); kernels = [np.random.randn(3, 3, 2 + i*1, 1) * 0.01 for i in range(2)]; print(dense_net_block(X, 2, 1, kernels))",
            "reasoning": "Each dense block layer concatenates its output to the existing feature maps, expanding the number of output channels by 1 per layer (the growth rate). After 2 layers, the original 2 channels become 4.",
            "output": "[[[[ 4.96714153e-01, -1.38264301e-01, -2.30186127e-03, -6.70426255e-05]]]]"
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef dense_net_block(input_data, num_layers, growth_rate, kernels, kernel_size=(3, 3)):\n    # Your code here\n    pass",
        "title": "Implement a Dense Block with 2D Convolutions",
        "learn_section": "## Understanding Dense Blocks and 2D Convolutions\n\nDense blocks are a key innovation in the DenseNet architecture. Each layer receives input from **all** previous layers, leading to rich feature reuse and efficient gradient flow.\n\n### Dense Block Concept\nFor a dense block:\n- **Each layer**: Applies ReLU, then 2D convolution, and then concatenates the output to previous features.\n- Mathematically:\n$$\nx_l = H_l([x_0, x_1, \\ldots, x_{l-1}])\n$$\nwhere $H_l(\\cdot)$ is the convolution and activation operations.\n\n### 2D Convolution Basics\nA 2D convolution at a position $(i, j)$ for input $X$ and kernel $K$ is:\n$$\nY[i, j] = \\sum_{m=0}^{k_h - 1} \\sum_{n=0}^{k_w - 1} X[i + m, j + n] \\cdot K[m, n]\n$$\n\n### Padding to Preserve Spatial Dimensions\nTo preserve height and width:\n$$\n\\text{padding} = \\frac{k - 1}{2}\n$$\n\n### Dense Block Growth\n- Each layer adds $\\text{growth rate}$ channels.\n- After $L$ layers, total channels = input channels + $L \\times \\text{growth rate}$.\n\n### Putting It All Together\n1️⃣ Start with an input tensor.  \n2️⃣ Repeat for $\\text{num layers}$:\n- Apply ReLU activation.\n- Apply 2D convolution (with padding).\n- Concatenate the output along the channel dimension.\n\nBy understanding these core principles, you’re ready to build the dense block function!",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe"
            }
        ]
    },
    {
        "description": "Implement a function that scans every feature and threshold in a small data set, then returns the split that minimises the weighted Gini impurity. Your implementation should support binary class labels (0 or 1) and handle ties gracefully.  \n\nYou will write **one** function:\n\n```python\nfind_best_split(X: np.ndarray, y: np.ndarray) -> tuple[int, float]\n```\n\n* **`X`** is an $n\\times d$ NumPy array of numeric features.\n* **`y`** is a length-$n$ NumPy array of 0/1 labels.\n* The function returns `(best_feature_index, best_threshold)` for the split with the **lowest** weighted Gini impurity.\n* If several splits share the same impurity, return the first that you encounter while scanning features and thresholds.",
        "id": "138",
        "test_cases": [
            {
                "test": "import numpy as np\nX1 = np.array([[2.5], [3.5], [1.0], [4.0]])\ny1 = np.array([0, 1, 0, 1])\nf1, t1 = find_best_split(X1, y1)\nprint(f1, round(t1, 4))",
                "expected_output": "0, 2.5"
            },
            {
                "test": "import numpy as np\nX2 = np.array([[1], [2], [3]])\ny2 = np.array([1, 1, 1])\nf2, t2 = find_best_split(X2, y2)\nprint(f2, t2)",
                "expected_output": "0, 1"
            },
            {
                "test": "import numpy as np\nX5 = np.array([[0, 1], [0, 2], [0, 3], [0, 4]])\ny5 = np.array([0, 0, 1, 1])\nf5, t5 = find_best_split(X5, y5)\nprint(f5, t5)",
                "expected_output": "1, 2"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\nfrom typing import Tuple\n\ndef find_best_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n    def gini(y_subset: np.ndarray) -> float:\n        if y_subset.size == 0:\n            return 0.0\n        p = y_subset.mean()\n        return 1.0 - (p**2 + (1 - p)**2)\n\n    n_samples, n_features = X.shape\n    best_feature, best_threshold = -1, float('inf')\n    best_gini = float('inf')\n\n    for f in range(n_features):\n        for threshold in np.unique(X[:, f]):\n            left = y[X[:, f] <= threshold]\n            right = y[X[:, f] > threshold]\n            g_left, g_right = gini(left), gini(right)\n            weighted = (len(left) * g_left + len(right) * g_right) / n_samples\n            if weighted < best_gini:\n                best_gini, best_feature, best_threshold = weighted, f, threshold\n\n    return best_feature, best_threshold",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "import numpy as np\nX = np.array([[2.5],[3.5],[1.0],[4.0]])\ny = np.array([0,1,0,1])\nprint(find_best_split(X, y))",
            "output": "(0, 2.5)",
            "reasoning": "Splitting on feature 0 at threshold 2.5 yields two perfectly pure leaves, producing the minimum possible weighted Gini impurity."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\nfrom typing import Tuple\n\ndef find_best_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n    \"\"\"Return the (feature_index, threshold) that minimises weighted Gini impurity.\"\"\"\n    # ✏️ TODO: implement\n    pass",
        "title": "Find the Best Gini-Based Split for a Binary Decision Tree",
        "learn_section": "# Learn: Gini Impurity and Best Split in Decision Trees\n\n## Overview\n\nA core concept in Decision Trees (and by extension, Random Forests) is how the model chooses where to split the data at each node. One popular criterion used for splitting is **Gini Impurity**.\n\nIn this task, you will implement:\n- Gini impurity computation\n- Finding the best feature and threshold to split on based on impurity reduction\n\nThis helps build the foundation for how trees grow in a Random Forest.\n\n---\n\n## Gini Impurity\n\nFor a set of samples with class labels \\( y \\), the Gini Impurity is defined as:\n\n$$\nG(y) = 1 - \\sum_{i=1}^{k} p_i^2\n$$\n\nWhere \\( p_i \\) is the proportion of samples belonging to class \\( i \\).\n\nA pure node (all one class) has \\( G = 0 \\), and higher values indicate more class diversity.\n\n---\n\n## Gini Gain for a Split\n\nGiven a feature and a threshold to split the dataset into left and right subsets:\n\n$$\nG_{\\text{split}} = \\frac{n_{\\text{left}}}{n} G(y_{\\text{left}}) + \\frac{n_{\\text{right}}}{n} G(y_{\\text{right}})\n$$\n\nWe choose the split that **minimizes** $( G_{\\text{split}} )$.\n\n---\n\n## Problem Statement\n\nYou are given a dataset $( X \\in \\mathbb{R}^{n \\times d} )$ and labels $( y \\in \\{0, 1\\}^n $). Implement the following functions:\n\n### Functions to Implement\n\n```python\ndef find_best_split(X: np.ndarray, y: np.ndarray) -> Tuple[int, float]:\n    ...\n```",
        "contributor": [
            {
                "profile_link": "https://github.com/hardik1408",
                "name": "Hardik Jindal"
            }
        ]
    },
    {
        "description": "Implement Elastic Net Regression using gradient descent, combining L1 and L2 penalties to handle multicollinearity and encourage sparsity in the feature weights.",
        "id": "139",
        "test_cases": [
            {
                "test": "X = np.array([[0, 0], [1, 1], [2, 2]])\ny = np.array([0, 1, 2])\nw, b = elastic_net_gradient_descent(X, y, alpha1=0.1, alpha2=0.1, learning_rate=0.01, max_iter=1000)\nprint(np.round(w,2), round(b,2))",
                "expected_output": "[0.37, 0.37],0.25"
            },
            {
                "test": "X = np.array([[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]])\ny = np.array([1, 2, 3, 4, 5])\nw, b = elastic_net_gradient_descent(X, y, alpha1=0.1, alpha2=0.1, learning_rate=0.01, max_iter=2000)\nprint(np.round(w,2),round(b,2))",
                "expected_output": "[0.43, 0.48], 0.69"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef elastic_net_gradient_descent(\n    X: np.ndarray,\n    y: np.ndarray,\n    alpha1: float = 0.1,\n    alpha2: float = 0.1,\n    learning_rate: float = 0.01,\n    max_iter: int = 1000,\n    tol: float = 1e-4,\n) -> tuple:\n    n_samples, n_features = X.shape\n    weights = np.zeros(n_features)\n    bias = 0\n\n    for _ in range(max_iter):\n        y_pred = np.dot(X, weights) + bias\n        error = y_pred - y\n        grad_w = (1 / n_samples) * np.dot(X.T, error) + alpha1 * np.sign(weights) + 2 * alpha2 * weights\n        grad_b = (1 / n_samples) * np.sum(error)\n        weights -= learning_rate * grad_w\n        bias -= learning_rate * grad_b\n        if np.linalg.norm(grad_w, ord=1) < tol:\n            break\n\n    return weights, bias",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "X = np.array([[0, 0], [1, 1], [2, 2]]); y = np.array([0, 1, 2])",
            "output": "(array([0.37, 0.37]), 0.25)",
            "reasoning": "The model learns a nearly perfect linear relationship with regularization controlling weight magnitude. The weights converge around 0.37 with a bias around 0.25."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef elastic_net_gradient_descent(\n    X: np.ndarray,\n    y: np.ndarray,\n    alpha1: float = 0.1,\n    alpha2: float = 0.1,\n    learning_rate: float = 0.01,\n    max_iter: int = 1000,\n    tol: float = 1e-4,\n) -> tuple:\n    # Implement Elastic Net regression here\n    pass",
        "title": "Elastic Net Regression via Gradient Descent",
        "learn_section": "# Elastic Net Regression Using Gradient Descent\n\nElastic Net Regression combines both L1 (Lasso) and L2 (Ridge) regularization techniques to overcome the limitations of using either regularization method alone. It's particularly useful when dealing with datasets that have many correlated features.\n\n## What is Elastic Net?\n\nElastic Net addresses two main issues:\n- **Lasso's limitation**: When features are highly correlated, Lasso tends to select only one feature from a group of correlated features arbitrarily\n- **Ridge's limitation**: Ridge regression doesn't perform feature selection (coefficients approach zero but never become exactly zero)\n\nThe goal of Elastic Net is to minimize the objective function:\n\n$$J(w, b) = \\underbrace{\\frac{1}{2n} \\sum_{i=1}^n\\left( y_i - \\left(\\sum_{j=1}^pX_{ij}w_j+b\\right)\\right)^2}_{\\text{MSE Loss}} + \\underbrace{\\alpha_1 \\sum_{j=1}^p |w_j|}_{\\text{L1 Regularization}} + \\underbrace{\\alpha_2 \\sum_{j=1}^p w_j^2}_{\\text{L2 Regularization}}$$\n\nWhere:\n* The first term is the **Mean Squared Error (MSE) Loss**: $\\frac{1}{2n} \\sum_{i=1}^n\\left( y_i - \\left(\\sum_{j=1}^pX_{ij}w_j+b\\right)\\right)^2$\n* The second term is the **L1 Regularization** (Lasso penalty): $\\alpha_1 \\sum_{j=1}^p |w_j|$\n* The third term is the **L2 Regularization** (Ridge penalty): $\\alpha_2 \\sum_{j=1}^p w_j^2$\n* $\\alpha_1$ controls the strength of L1 regularization\n* $\\alpha_2$ controls the strength of L2 regularization\n\n## Step-by-Step Implementation Guide\n\n### 1. Initialize weights $w_j$ and bias $b$ to 0\n\n### 2. Make Predictions\nAt each iteration, calculate predictions using:\n$$\\hat{y}_i = \\sum_{j=1}^pX_{ij}w_j + b$$\n\nWhere:\n- $\\hat{y}_i$ is the predicted value for the $i$-th sample\n- $X_{ij}$ is the value of the $i$-th sample's $j$-th feature\n- $w_j$ is the weight associated with the $j$-th feature\n\n### 3. Calculate Residuals\nFind the difference between actual and predicted values: $error_i = \\hat{y}_i - y_i$\n\n### 4. Update Weights and Bias Using Gradients\n\n**Gradient with respect to weights:**\n$$\\frac{\\partial J}{\\partial w_j} = \\frac{1}{n} \\sum_{i=1}^nX_{ij}(\\hat{y}_i - y_i) + \\alpha_1 \\cdot \\text{sign}(w_j) + 2\\alpha_2 \\cdot w_j$$\n\n**Gradient with respect to bias:**\n$$\\frac{\\partial J}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^n(\\hat{y}_i - y_i)$$\n\n**Update rules:**\n$$w_j = w_j - \\eta \\cdot \\frac{\\partial J}{\\partial w_j}$$\n$$b = b - \\eta \\cdot \\frac{\\partial J}{\\partial b}$$\n\nWhere $\\eta$ is the learning rate.\n\n### 5. Check for Convergence\nRepeat steps 2-4 until convergence. Convergence is determined by evaluating the L1 norm of the weight gradients:\n\n$$||\\nabla w||_1 = \\sum_{j=1}^p \\left|\\frac{\\partial J}{\\partial w_j}\\right|$$\n\nIf $||\\nabla w||_1 < \\text{tolerance}$, stop the algorithm.\n\n### 6. Return the Final Weights and Bias\n\n## Key Parameters\n\n- **alpha1**: L1 regularization strength (promotes sparsity)\n- **alpha2**: L2 regularization strength (handles correlated features)\n- **learning_rate**: Step size for gradient descent\n- **max_iter**: Maximum number of iterations\n- **tol**: Convergence tolerance\nPath\n## Key Differences from Lasso and Ridge\n\n1. **Lasso (L1 only)**: Tends to select one feature from correlated groups, can be unstable with small sample sizes\n2. **Ridge (L2 only)**: Keeps all features but shrinks coefficients, doesn't perform feature selection\n3. **Elastic Net (L1 + L2)**: Combines benefits of both - performs feature selection while handling correlated features better than Lasso alone\n\nThe balance between L1 and L2 regularization is controlled by the `alpha1` and `alpha2` parameters, allowing you to tune the model for your specific dataset characteristics.",
        "contributor": [
            {
                "profile_link": "https://github.com/komaksym",
                "name": "komaksym"
            }
        ]
    },
    {
        "description": "Write a Python function that performs linear regression using the normal equation. The function should take a matrix X (features) and a vector y (target) as input, and return the coefficients of the linear regression model. Round your answer to four decimal places, -0.0 is a valid result for rounding a very small number.",
        "mdx_file": "e1356255-ae67-4503-9e23-378f3cca5f38.mdx",
        "tinygrad_difficulty": "medium",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGxpbmVhcl9yZWdyZXNzaW9uX25vcm1hbF9lcXVhdGlvbl90ZyhYLCB5KSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIFNvbHZlIGxpbmVhciByZWdyZXNzaW9uIHZpYSB0aGUgbm9ybWFsIGVxdWF0aW9uIHVzaW5nIHRpbnlncmFkLgogICAgWDogbGlzdCwgTnVtUHkgYXJyYXksIG9yIFRlbnNvciBvZiBzaGFwZSAobSxuKTsgeTogc2hhcGUgKG0sKSBvciAobSwxKS4KICAgIFJldHVybnMgYSAxLUQgVGVuc29yIG9mIGxlbmd0aCBuLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(linear_regression_normal_equation([[1, 1], [1, 2], [1, 3]], [1, 2, 3]))",
                "expected_output": "[-0.0, 1.0]"
            },
            {
                "test": "print(linear_regression_normal_equation([[1, 3, 4], [1, 2, 5], [1, 3, 2]], [1, 2, 1]))",
                "expected_output": "[4.0, -1.0, -0.0]"
            }
        ],
        "solution": "\nimport numpy as np\ndef linear_regression_normal_equation(X: list[list[float]], y: list[float]) -> list[float]:\n    X = np.array(X)\n    y = np.array(y).reshape(-1, 1)\n    X_transpose = X.T\n    theta = np.linalg.inv(X_transpose.dot(X)).dot(X_transpose).dot(y)\n    theta = np.round(theta, 4).flatten().tolist()\n    return theta",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBsaW5lYXJfcmVncmVzc2lvbl9ub3JtYWxfZXF1YXRpb25fdGcoWCwgeSkgLT4gVGVuc29yOgogICAgIiIiCiAgICBTb2x2ZSBsaW5lYXIgcmVncmVzc2lvbiB2aWEgdGhlIG5vcm1hbCBlcXVhdGlvbiB1c2luZyB0aW55Z3JhZC4KICAgIFg6IGxpc3QsIE51bVB5IGFycmF5LCBvciBUZW5zb3Igb2Ygc2hhcGUgKG0sbik7IHk6IHNoYXBlIChtLCkgb3IgKG0sMSkuCiAgICBSZXR1cm5zIGEgMS1EIFRlbnNvciBvZiBsZW5ndGggbiwgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICBYX25wID0gbnAuYXJyYXkoWCwgZHR5cGU9ZmxvYXQpCiAgICB5X25wID0gbnAuYXJyYXkoeSwgZHR5cGU9ZmxvYXQpLnJlc2hhcGUoLTEsMSkKICAgIHRoZXRhID0gbnAubGluYWxnLmludihYX25wLlQuZG90KFhfbnApKS5kb3QoWF9ucC5UKS5kb3QoeV9ucCkKICAgIHRoZXRhID0gbnAucm91bmQodGhldGEuZmxhdHRlbigpLCA0KQogICAgcmV0dXJuIFRlbnNvcih0aGV0YSkK",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "https://youtu.be/9hkQJxICZj8",
        "difficulty": "easy",
        "example": {
            "input": "X = [[1, 1], [1, 2], [1, 3]], y = [1, 2, 3]",
            "output": "[0.0, 1.0]",
            "reasoning": "The linear model is y = 0.0 + 1.0*x, perfectly fitting the input data."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\ndef linear_regression_normal_equation(X: list[list[float]], y: list[float]) -> list[float]:\n\t# Your code here, make sure to round\n\treturn theta",
        "learn_section": "\n## Linear Regression Using the Normal Equation\n\nLinear regression aims to model the relationship between a scalar dependent variable \\( y \\) and one or more explanatory variables (or independent variables) \\( X \\). The normal equation provides an analytical solution to find the coefficients \\( \\theta \\) that minimize the cost function for linear regression.\n\nGiven a matrix \\( X \\) (with each row representing a training example and each column a feature) and a vector \\( y \\) (representing the target values), the normal equation is:\n$$\n\\theta = (X^TX)^{-1}X^Ty\n$$\n\n### Explanation of Terms\n1. \\( X^T \\) is the transpose of \\( X \\).\n2. \\( (X^TX)^{-1} \\) is the inverse of the matrix \\( X^TX \\).\n3. \\( y \\) is the vector of target values.\n\n### Key Points\n- **Feature Scaling**: This method does not require feature scaling.\n- **Learning Rate**: There is no need to choose a learning rate.\n- **Computational Cost**: Computing the inverse of \\( X^TX \\) can be computationally expensive if the number of features is very large.\n\n### Practical Implementation\nA practical implementation involves augmenting \\( X \\) with a column of ones to account for the intercept term and then applying the normal equation directly to compute \\( \\theta \\).\n\n",
        "title": "Linear Regression Using Normal Equation",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "Stoatscript"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nX = torch.eye(2)\ny = torch.tensor([5.0, 3.0])\nres = linear_regression_normal_equation(X, y)\nprint(res.detach().numpy().tolist())",
                "expected_output": "[5.0, 3.0]"
            },
            {
                "test": "import torch\nX = torch.tensor([[1.0,1.0],[1.0,2.0],[1.0,3.0]])\ny = torch.tensor([1.0,2.0,3.0])\nres = linear_regression_normal_equation(X, y)\nprint(res.detach().numpy().tolist())",
                "expected_output": "[0.0, 1.0]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = linear_regression_normal_equation_tg(\n    [[1.0,0.0],[0.0,1.0]],\n    [5.0,3.0]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[5.0, 3.0]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = linear_regression_normal_equation_tg(\n    [[1.0,1.0],[1.0,2.0],[1.0,3.0]],\n    [1.0,2.0,3.0]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[0.0, 1.0]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgbGluZWFyX3JlZ3Jlc3Npb25fbm9ybWFsX2VxdWF0aW9uKFgsIHkpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgU29sdmUgbGluZWFyIHJlZ3Jlc3Npb24gdmlhIHRoZSBub3JtYWwgZXF1YXRpb24gdXNpbmcgUHlUb3JjaC4KICAgIFg6IFRlbnNvciBvciBjb252ZXJ0aWJsZSBvZiBzaGFwZSAobSxuKTsgeTogc2hhcGUgKG0sKSBvciAobSwxKS4KICAgIFJldHVybnMgYSAxLUQgdGVuc29yIG9mIGxlbmd0aCBuLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIFhfdCA9IHRvcmNoLmFzX3RlbnNvcihYLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIHlfdCA9IHRvcmNoLmFzX3RlbnNvcih5LCBkdHlwZT10b3JjaC5mbG9hdCkucmVzaGFwZSgtMSwxKQogICAgIyBub3JtYWwgZXF1YXRpb246IHRoZXRhID0gKFjhtYBYKeKBu8K5IFjhtYAgeQogICAgWHRYID0gWF90LnRyYW5zcG9zZSgwLDEpIEAgWF90CiAgICB0aGV0YSA9IHRvcmNoLmxpbmFsZy5pbnYoWHRYKSBAIChYX3QudHJhbnNwb3NlKDAsMSkgQCB5X3QpCiAgICB0aGV0YSA9IHRoZXRhLmZsYXR0ZW4oKQogICAgcmV0dXJuIHRvcmNoLnJvdW5kKHRoZXRhICogMTAwMDApIC8gMTAwMDAK",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgbGluZWFyX3JlZ3Jlc3Npb25fbm9ybWFsX2VxdWF0aW9uKFgsIHkpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgU29sdmUgbGluZWFyIHJlZ3Jlc3Npb24gdmlhIHRoZSBub3JtYWwgZXF1YXRpb24gdXNpbmcgUHlUb3JjaC4KICAgIFg6IFRlbnNvciBvciBjb252ZXJ0aWJsZSBvZiBzaGFwZSAobSxuKTsgeTogc2hhcGUgKG0sKSBvciAobSwxKS4KICAgIFJldHVybnMgYSAxLUQgdGVuc29yIG9mIGxlbmd0aCBuLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIFhfdCA9IHRvcmNoLmFzX3RlbnNvcihYLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIHlfdCA9IHRvcmNoLmFzX3RlbnNvcih5LCBkdHlwZT10b3JjaC5mbG9hdCkucmVzaGFwZSgtMSwxKQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "14"
    },
    {
        "description": "Write a Python function that performs linear regression using gradient descent. The function should take NumPy arrays X (features with a column of ones for the intercept) and y (target) as input, along with learning rate alpha and the number of iterations, and return the coefficients of the linear regression model as a NumPy array. Round your answer to four decimal places. -0.0 is a valid result for rounding a very small number.",
        "mdx_file": "d987eb1f-4827-4701-905d-8d61ba6009b3.mdx",
        "tinygrad_difficulty": "medium",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGxpbmVhcl9yZWdyZXNzaW9uX2dyYWRpZW50X2Rlc2NlbnRfdGcoWCwgeSwgYWxwaGEsIGl0ZXJhdGlvbnMpIC0+IFRlbnNvcjoKICAgICIiIgogICAgU29sdmUgbGluZWFyIHJlZ3Jlc3Npb24gdmlhIGdyYWRpZW50IGRlc2NlbnQgdXNpbmcgdGlueWdyYWQgYXV0b2dyYWQuCiAgICBYOiBUZW5zb3Igb3IgY29udmVydGlibGUgc2hhcGUgKG0sbik7IHk6IHNoYXBlIChtLCkgb3IgKG0sMSkuCiAgICBhbHBoYTogbGVhcm5pbmcgcmF0ZTsgaXRlcmF0aW9uczogbnVtYmVyIG9mIHN0ZXBzLgogICAgUmV0dXJucyBhIDEtRCBUZW5zb3Igb2YgbGVuZ3RoIG4sIHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgWF90ID0gVGVuc29yKFgpLmZsb2F0KCkKICAgIHlfdCA9IFRlbnNvcih5KS5mbG9hdCgpLnJlc2hhcGUoLTEsMSkKICAgIG0sIG4gPSBYX3Quc2hhcGUKICAgIHRoZXRhID0gVGVuc29yKFtbMC4wXSBmb3IgXyBpbiByYW5nZShuKV0pCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "test_cases": [
            {
                "test": "print(linear_regression_gradient_descent(np.array([[1, 1], [1, 2], [1, 3]]), np.array([1, 2, 3]), 0.01, 1000))",
                "expected_output": "[0.1107, 0.9513]"
            }
        ],
        "solution": "\nimport numpy as np\ndef linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:\n    m, n = X.shape\n    theta = np.zeros((n, 1))\n    for _ in range(iterations):\n        predictions = X @ theta\n        errors = predictions - y.reshape(-1, 1)\n        updates = X.T @ errors / m\n        theta -= alpha * updates\n    return np.round(theta.flatten(), 4)",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBsaW5lYXJfcmVncmVzc2lvbl9ncmFkaWVudF9kZXNjZW50X3RnKFgsIHksIGFscGhhLCBpdGVyYXRpb25zKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIFNvbHZlIGxpbmVhciByZWdyZXNzaW9uIHZpYSBncmFkaWVudCBkZXNjZW50IHVzaW5nIHRpbnlncmFkIGF1dG9ncmFkLgogICAgWDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIHNoYXBlIChtLG4pOyB5OiBzaGFwZSAobSwpIG9yIChtLDEpLgogICAgYWxwaGE6IGxlYXJuaW5nIHJhdGU7IGl0ZXJhdGlvbnM6IG51bWJlciBvZiBzdGVwcy4KICAgIFJldHVybnMgYSAxLUQgVGVuc29yIG9mIGxlbmd0aCBuLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIFhfdCA9IFRlbnNvcihYKS5mbG9hdCgpCiAgICB5X3QgPSBUZW5zb3IoeSkuZmxvYXQoKS5yZXNoYXBlKC0xLDEpCiAgICBtLCBuID0gWF90LnNoYXBlCiAgICB0aGV0YSA9IFRlbnNvcihbWzAuMF0gZm9yIF8gaW4gcmFuZ2UobildKQogICAgZm9yIF8gaW4gcmFuZ2UoaXRlcmF0aW9ucyk6CiAgICAgICAgcHJlZHMgPSBYX3QubWF0bXVsKHRoZXRhKQogICAgICAgIGxvc3MgPSAocHJlZHMgLSB5X3QpLnBvdygyKS5tZWFuKCkKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICAjIGdyYWRpZW50IHN0ZXAKICAgICAgICB0aGV0YSA9IHRoZXRhIC0gYWxwaGEgKiB0aGV0YS5ncmFkCiAgICAgICAgdGhldGEuZ3JhZCA9IE5vbmUKICAgIHJlcyA9IHRoZXRhLnJlc2hhcGUobikuZGV0YWNoKCkubnVtcHkoKQogICAgcmV0dXJuIFRlbnNvcihucC5yb3VuZChyZXMsIDQpKQo=",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "https://youtu.be/rHJ-DfFvpkQ",
        "difficulty": "easy",
        "example": {
            "input": "X = np.array([[1, 1], [1, 2], [1, 3]]), y = np.array([1, 2, 3]), alpha = 0.01, iterations = 1000",
            "output": "np.array([0.1107, 0.9513])",
            "reasoning": "The linear model is y = 0.0 + 1.0*x, which fits the input data after gradient descent optimization."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\ndef linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:\n\t# Your code here, make sure to round\n\tm, n = X.shape\n\ttheta = np.zeros((n, 1))\n\treturn theta",
        "learn_section": "\n## Linear Regression Using Gradient Descent\n\nLinear regression can also be performed using a technique called gradient descent, where the coefficients (or weights) of the model are iteratively adjusted to minimize a cost function (usually mean squared error). This method is particularly useful when the number of features is too large for analytical solutions like the normal equation or when the feature matrix is not invertible.\n\nThe gradient descent algorithm updates the weights by moving in the direction of the negative gradient of the cost function with respect to the weights. The updates occur iteratively until the algorithm converges to a minimum of the cost function.\n\nThe update rule for each weight is given by:\n$$\n\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\left( h_{\\theta}(x^{(i)}) - y^{(i)} \\right)x_j^{(i)}\n$$\n\n### Explanation of Terms\n1. \\( \\alpha \\) is the learning rate.\n2. \\( m \\) is the number of training examples.\n3. \\( h_{\\theta}(x^{(i)}) \\) is the hypothesis function at iteration \\( i \\).\n4. \\( x^{(i)} \\) is the feature vector of the \\( i^{\\text{th}} \\) training example.\n5. \\( y^{(i)} \\) is the actual target value for the \\( i^{\\text{th}} \\) training example.\n6. \\( x_j^{(i)} \\) is the value of feature \\( j \\) for the \\( i^{\\text{th}} \\) training example.\n\n### Key Points\n- **Learning Rate**: The choice of learning rate is crucial for the convergence and performance of gradient descent. \n  - A small learning rate may lead to slow convergence.\n  - A large learning rate may cause overshooting and divergence.\n- **Number of Iterations**: The number of iterations determines how long the algorithm runs before it converges or stops.\n\n### Practical Implementation\nImplementing gradient descent involves initializing the weights, computing the gradient of the cost function, and iteratively updating the weights according to the update rule.\n\n",
        "title": "Linear Regression Using Gradient Descent",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = linear_regression_gradient_descent(\n    torch.eye(2),\n    torch.tensor([5.0, 3.0]),\n    0.1,\n    10\n)\nprint(res.detach().numpy().tolist())",
                "expected_output": "[3.2565999031066895, 1.9539999961853027]"
            },
            {
                "test": "import torch\nX = torch.tensor([[1.0,1.0],[1.0,2.0],[1.0,3.0]])\ny = torch.tensor([1.0,2.0,3.0])\nres = linear_regression_gradient_descent(X, y, 0.01, 1000)\nprint(res.detach().numpy().tolist())",
                "expected_output": "[0.03319999948143959, 0.9854000210762024]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = linear_regression_gradient_descent_tg(\n    [[1.0,0.0],[0.0,1.0]],\n    [5.0,3.0],\n    0.1,\n    10\n)\nprint(res.numpy().tolist())",
                "expected_output": "[5.0, 3.0]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nX = [[1.0,1.0],[1.0,2.0],[1.0,3.0]]\ny = [1.0,2.0,3.0]\nres = linear_regression_gradient_descent_tg(X, y, 0.01, 1000)\nprint(res.numpy().tolist())",
                "expected_output": "[0.0, 1.0]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgbGluZWFyX3JlZ3Jlc3Npb25fZ3JhZGllbnRfZGVzY2VudChYLCB5LCBhbHBoYSwgaXRlcmF0aW9ucykgLT4gdG9yY2guVGVuc29yOgogICAgIiIiCiAgICBTb2x2ZSBsaW5lYXIgcmVncmVzc2lvbiB2aWEgZ3JhZGllbnQgZGVzY2VudCB1c2luZyBQeVRvcmNoIGF1dG9ncmFkLgogICAgWDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIHNoYXBlIChtLG4pOyB5OiBzaGFwZSAobSwpIG9yIChtLDEpLgogICAgYWxwaGE6IGxlYXJuaW5nIHJhdGU7IGl0ZXJhdGlvbnM6IG51bWJlciBvZiBzdGVwcy4KICAgIFJldHVybnMgYSAxLUQgdGVuc29yIG9mIGxlbmd0aCBuLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIFhfdCA9IHRvcmNoLmFzX3RlbnNvcihYLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIHlfdCA9IHRvcmNoLmFzX3RlbnNvcih5LCBkdHlwZT10b3JjaC5mbG9hdCkucmVzaGFwZSgtMSwxKQogICAgbSwgbiA9IFhfdC5zaGFwZQogICAgdGhldGEgPSB0b3JjaC56ZXJvcygobiwxKSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQogICAgZm9yIF8gaW4gcmFuZ2UoaXRlcmF0aW9ucyk6CiAgICAgICAgcHJlZHMgPSBYX3QgQCB0aGV0YQogICAgICAgIGxvc3MgPSAoKHByZWRzIC0geV90KSAqKiAyKS5tZWFuKCkKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICB3aXRoIHRvcmNoLm5vX2dyYWQoKToKICAgICAgICAgICAgdGhldGEgLT0gYWxwaGEgKiB0aGV0YS5ncmFkCiAgICAgICAgICAgIHRoZXRhLmdyYWQuemVyb18oKQogICAgIyBkZXRhY2ggYmVmb3JlIGNvbnZlcnRpbmcgdG8gbnVtcHkKICAgIHJlc3VsdCA9IHRoZXRhLmZsYXR0ZW4oKS5kZXRhY2goKQogICAgcmV0dXJuIHRvcmNoLnJvdW5kKHJlc3VsdCAqIDEwMDAwKSAvIDEwMDAwCg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgbGluZWFyX3JlZ3Jlc3Npb25fZ3JhZGllbnRfZGVzY2VudChYLCB5LCBhbHBoYSwgaXRlcmF0aW9ucykgLT4gdG9yY2guVGVuc29yOgogICAgIiIiCiAgICBTb2x2ZSBsaW5lYXIgcmVncmVzc2lvbiB2aWEgZ3JhZGllbnQgZGVzY2VudCB1c2luZyBQeVRvcmNoIGF1dG9ncmFkLgogICAgWDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIHNoYXBlIChtLG4pOyB5OiBzaGFwZSAobSwpIG9yIChtLDEpLgogICAgYWxwaGE6IGxlYXJuaW5nIHJhdGU7IGl0ZXJhdGlvbnM6IG51bWJlciBvZiBzdGVwcy4KICAgIFJldHVybnMgYSAxLUQgdGVuc29yIG9mIGxlbmd0aCBuLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIFhfdCA9IHRvcmNoLmFzX3RlbnNvcihYLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIHlfdCA9IHRvcmNoLmFzX3RlbnNvcih5LCBkdHlwZT10b3JjaC5mbG9hdCkucmVzaGFwZSgtMSwxKQogICAgbSwgbiA9IFhfdC5zaGFwZQogICAgdGhldGEgPSB0b3JjaC56ZXJvcygobiwxKSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "15"
    },
    {
        "description": "Write a Python function that performs feature scaling on a dataset using both standardization and min-max normalization. The function should take a 2D NumPy array as input, where each row represents a data sample and each column represents a feature. It should return two 2D NumPy arrays: one scaled by standardization and one by min-max normalization. Make sure all results are rounded to the nearest 4th decimal.",
        "mdx_file": "4dd47007-3ac7-45ba-a3e4-fee0545e0c0c.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGZlYXR1cmVfc2NhbGluZ190ZyhkYXRhKSAtPiB0dXBsZVtUZW5zb3IsIFRlbnNvcl06CiAgICAiIiIKICAgIFN0YW5kYXJkaXplIGFuZCBNaW4tTWF4IG5vcm1hbGl6ZSBpbnB1dCBkYXRhIHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXQ6IFRlbnNvciBvciBjb252ZXJ0aWJsZSBvZiBzaGFwZSAobSxuKS4KICAgIFJldHVybnMgKHN0YW5kYXJkaXplZF9kYXRhLCBub3JtYWxpemVkX2RhdGEpLCBib3RoIHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgZGF0YV90ID0gVGVuc29yKGRhdGEpLmZsb2F0KCkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(feature_scaling(np.array([[1, 2], [3, 4], [5, 6]])))",
                "expected_output": "([[-1.2247, -1.2247], [0.0, 0.0], [1.2247, 1.2247]], [[0.0, 0.0], [0.5, 0.5], [1.0, 1.0]])"
            }
        ],
        "solution": "\nimport numpy as np\n\ndef feature_scaling(data):\n    # Standardization\n    mean = np.mean(data, axis=0)\n    std = np.std(data, axis=0)\n    standardized_data = (data - mean) / std\n    \n    # Min-Max Normalization\n    min_val = np.min(data, axis=0)\n    max_val = np.max(data, axis=0)\n    normalized_data = (data - min_val) / (max_val - min_val)\n    \n    return np.round(standardized_data,4).tolist(), np.round(normalized_data,4).tolist()",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBmZWF0dXJlX3NjYWxpbmdfdGcoZGF0YSkgLT4gdHVwbGVbVGVuc29yLCBUZW5zb3JdOgogICAgIiIiCiAgICBTdGFuZGFyZGl6ZSBhbmQgTWluLU1heCBub3JtYWxpemUgaW5wdXQgZGF0YSB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0OiBUZW5zb3Igb3IgY29udmVydGlibGUgb2Ygc2hhcGUgKG0sbikuCiAgICBSZXR1cm5zIChzdGFuZGFyZGl6ZWRfZGF0YSwgbm9ybWFsaXplZF9kYXRhKSwgYm90aCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIGRhdGFfdCA9IFRlbnNvcihkYXRhKS5mbG9hdCgpCiAgICBkYXRhX25wID0gZGF0YV90Lm51bXB5KCkKICAgIG1lYW4gPSBucC5tZWFuKGRhdGFfbnAsIGF4aXM9MCkKICAgIHN0ZCA9IG5wLnN0ZChkYXRhX25wLCBheGlzPTApCiAgICBzdGFuZGFyZGl6ZWRfbnAgPSAoZGF0YV9ucCAtIG1lYW4pIC8gc3RkCiAgICBtaW5fdmFsID0gbnAubWluKGRhdGFfbnAsIGF4aXM9MCkKICAgIG1heF92YWwgPSBucC5tYXgoZGF0YV9ucCwgYXhpcz0wKQogICAgbm9ybWFsaXplZF9ucCA9IChkYXRhX25wIC0gbWluX3ZhbCkgLyAobWF4X3ZhbCAtIG1pbl92YWwpCiAgICByZXR1cm4gVGVuc29yKG5wLnJvdW5kKHN0YW5kYXJkaXplZF9ucCwgNCkpLCBUZW5zb3IobnAucm91bmQobm9ybWFsaXplZF9ucCwgNCkpCg==",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/RrEbO-lbg84?si=hk2qk-26eUyXh0Ee",
        "difficulty": "easy",
        "example": {
            "input": "data = np.array([[1, 2], [3, 4], [5, 6]])",
            "output": "([[-1.2247, -1.2247], [0.0, 0.0], [1.2247, 1.2247]], [[0.0, 0.0], [0.5, 0.5], [1.0, 1.0]])",
            "reasoning": "Standardization rescales the feature to have a mean of 0 and a standard deviation of 1.\n        Min-max normalization rescales the feature to a range of [0, 1], where the minimum feature value\n        maps to 0 and the maximum to 1."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "def feature_scaling(data: np.ndarray) -> (np.ndarray, np.ndarray):\n\t# Your code here\n\treturn standardized_data, normalized_data",
        "learn_section": "\n## Feature Scaling Techniques\n\nFeature scaling is crucial in many machine learning algorithms that are sensitive to the magnitude of features. This includes algorithms that use distance measures, like k-nearest neighbors, and gradient descent-based algorithms, like linear regression.\n\n### Standardization\nStandardization (or Z-score normalization) is the process where features are rescaled so that they have the properties of a standard normal distribution with a mean of zero and a standard deviation of one:\n$$\nz = \\frac{(x - \\mu)}{\\sigma}\n$$\nwhere \\( x \\) is the original feature, \\( \\mu \\) is the mean of that feature, and \\( \\sigma \\) is the standard deviation.\n\n### Min-Max Normalization\nMin-max normalization rescales the feature to a fixed range, typically 0 to 1, or it can be shifted to any range \\([a, b]\\) by transforming the data using the formula:\n$$\nx' = \\frac{(x - \\text{min}(x))}{(\\text{max}(x) - \\text{min}(x))} \\times (\\text{max} - \\text{min}) + \\text{min}\n$$\nwhere \\( x \\) is the original value, \\( \\text{min}(x) \\) is the minimum value for that feature, \\( \\text{max}(x) \\) is the maximum value, and \\( \\text{min} \\) and \\( \\text{max} \\) are the new minimum and maximum values for the scaled data.\n\n### Key Points\n- **Equal Contribution**: Implementing these scaling techniques ensures that features contribute equally to the development of the model.\n- **Improved Convergence**: Feature scaling can significantly improve the convergence speed of learning algorithms.\n\nThis structured explanation outlines the importance of feature scaling and describes two commonly used techniques with their mathematical formulas.\n",
        "title": "Feature Scaling Implementation",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nstd, norm = feature_scaling([[1.0,2.0],[3.0,4.0],[5.0,6.0]])\nprint(std.numpy().tolist(), norm.numpy().tolist())",
                "expected_output": "[[-1.2246999740600586, -1.2246999740600586], [0.0, 0.0], [1.2246999740600586, 1.2246999740600586]] [[0.0, 0.0], [0.5, 0.5], [1.0, 1.0]]"
            },
            {
                "test": "import torch\nstd, norm = feature_scaling(torch.tensor([[10.0,0.0],[20.0,5.0]]))\nprint(std.numpy().tolist(), norm.numpy().tolist())",
                "expected_output": "[[-1.0, -1.0], [1.0, 1.0]] [[0.0, 0.0], [1.0, 1.0]]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nstd, norm = feature_scaling_tg([[1.0,2.0],[3.0,4.0],[5.0,6.0]])\nprint(std.numpy().tolist(), norm.numpy().tolist())",
                "expected_output": "[[-1.2247, -1.2247], [0.0, 0.0], [1.2247, 1.2247]] [[0.0, 0.0], [0.5, 0.5], [1.0, 1.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nstd, norm = feature_scaling_tg(Tensor([[10.0,0.0],[20.0,5.0]]))\nprint(std.numpy().tolist(), norm.numpy().tolist())",
                "expected_output": "[[-1.0, -1.0], [1.0, 1.0]] [[0.0, 0.0], [1.0, 1.0]]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgZmVhdHVyZV9zY2FsaW5nKGRhdGEpIC0+IHR1cGxlW3RvcmNoLlRlbnNvciwgdG9yY2guVGVuc29yXToKICAgICIiIgogICAgU3RhbmRhcmRpemUgYW5kIE1pbi1NYXggbm9ybWFsaXplIGlucHV0IGRhdGEgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0OiBUZW5zb3Igb3IgY29udmVydGlibGUgb2Ygc2hhcGUgKG0sbikuCiAgICBSZXR1cm5zIChzdGFuZGFyZGl6ZWRfZGF0YSwgbm9ybWFsaXplZF9kYXRhKSwgYm90aCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIGRhdGFfdCA9IHRvcmNoLmFzX3RlbnNvcihkYXRhLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIG1lYW4gPSBkYXRhX3QubWVhbihkaW09MCkKICAgIHN0ZCA9IGRhdGFfdC5zdGQoZGltPTAsIHVuYmlhc2VkPUZhbHNlKQogICAgc3RhbmRhcmRpemVkID0gKGRhdGFfdCAtIG1lYW4pIC8gc3RkCiAgICBtaW5fdmFsID0gZGF0YV90Lm1pbihkaW09MCkudmFsdWVzCiAgICBtYXhfdmFsID0gZGF0YV90Lm1heChkaW09MCkudmFsdWVzCiAgICBub3JtYWxpemVkID0gKGRhdGFfdCAtIG1pbl92YWwpIC8gKG1heF92YWwgLSBtaW5fdmFsKQogICAgc3RhbmRhcmRpemVkID0gdG9yY2gucm91bmQoc3RhbmRhcmRpemVkICogMTAwMDApIC8gMTAwMDAKICAgIG5vcm1hbGl6ZWQgPSB0b3JjaC5yb3VuZChub3JtYWxpemVkICogMTAwMDApIC8gMTAwMDAKICAgIHJldHVybiBzdGFuZGFyZGl6ZWQsIG5vcm1hbGl6ZWQK",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgZmVhdHVyZV9zY2FsaW5nKGRhdGEpIC0+IHR1cGxlW3RvcmNoLlRlbnNvciwgdG9yY2guVGVuc29yXToKICAgICIiIgogICAgU3RhbmRhcmRpemUgYW5kIE1pbi1NYXggbm9ybWFsaXplIGlucHV0IGRhdGEgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0OiBUZW5zb3Igb3IgY29udmVydGlibGUgb2Ygc2hhcGUgKG0sbikuCiAgICBSZXR1cm5zIChzdGFuZGFyZGl6ZWRfZGF0YSwgbm9ybWFsaXplZF9kYXRhKSwgYm90aCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIGRhdGFfdCA9IHRvcmNoLmFzX3RlbnNvcihkYXRhLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "id": "16"
    },
    {
        "description": "Your task is to write a Python function that implements the k-Means clustering algorithm. This function should take specific inputs and produce a list of final centroids. k-Means clustering is a method used to partition `n` points into `k` clusters. The goal is to group similar points together and represent each group by its center (called the *centroid*).\n\n### Function Inputs:\n\n- `points`: A list of points, where each point is a tuple of coordinates (e.g., `(x, y)` for 2D points)\n- `k`: An integer representing the number of clusters to form\n- `initial_centroids`: A list of initial centroid points, each a tuple of coordinates\n- `max_iterations`: An integer representing the maximum number of iterations to perform\n\n### Function Output:\n\nA list of the final centroids of the clusters, where each centroid is rounded to the nearest fourth decimal.\n\n",
        "mdx_file": "21e9c90c-c332-4f3b-a01e-541fe97b0438.mdx",
        "tinygrad_difficulty": "medium",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGtfbWVhbnNfY2x1c3RlcmluZ190Zyhwb2ludHMsIGssIGluaXRpYWxfY2VudHJvaWRzLCBtYXhfaXRlcmF0aW9ucykgLT4gbGlzdFt0dXBsZVtmbG9hdCwgLi4uXV06CiAgICAiIiIKICAgIFBlcmZvcm0gay1tZWFucyBjbHVzdGVyaW5nIG9uIGBwb2ludHNgIGludG8gYGtgIGNsdXN0ZXJzIHVzaW5nIHRpbnlncmFkLgogICAgcG9pbnRzOiBsaXN0IG9mIGxpc3RzIG9yIFRlbnNvciwgc2hhcGUgKG5fcG9pbnRzLCBuX2ZlYXR1cmVzKQogICAgaW5pdGlhbF9jZW50cm9pZHM6IGxpc3Qgb2YgbGlzdHMgb3IgVGVuc29yLCBzaGFwZSAoaywgbl9mZWF0dXJlcykKICAgIG1heF9pdGVyYXRpb25zOiBtYXhpbXVtIG51bWJlciBvZiBpdGVyYXRpb25zCiAgICBSZXR1cm5zIGEgbGlzdCBvZiBrIGNlbnRyb2lkcyBhcyB0dXBsZXMsIHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "test_cases": [
            {
                "test": "print(k_means_clustering([(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)], 2, [(1, 1), (10, 1)], 10))",
                "expected_output": "[(1.0, 2.0), (10.0, 2.0)]"
            },
            {
                "test": "print(k_means_clustering([(0, 0, 0), (2, 2, 2), (1, 1, 1), (9, 10, 9), (10, 11, 10), (12, 11, 12)], 2, [(1, 1, 1), (10, 10, 10)], 10))",
                "expected_output": "[(1.0, 1.0, 1.0), (10.3333, 10.6667, 10.3333)]"
            },
            {
                "test": "print(k_means_clustering([(1, 1), (2, 2), (3, 3), (4, 4)], 1, [(0,0)], 10))",
                "expected_output": "[(2.5, 2.5)]"
            },
            {
                "test": "print(k_means_clustering([(0, 0), (1, 0), (0, 1), (1, 1), (5, 5), (6, 5), (5, 6), (6, 6),(0, 5), (1, 5), (0, 6), (1, 6), (5, 0), (6, 0), (5, 1), (6, 1)], 4, [(0, 0), (0, 5), (5, 0), (5, 5)], 10))",
                "expected_output": "[(0.5, 0.5), (0.5, 5.5), (5.5, 0.5), (5.5, 5.5)]"
            }
        ],
        "solution": "\nimport numpy as np\n\ndef euclidean_distance(a, b):\n    return np.sqrt(((a - b) ** 2).sum(axis=1))\n\ndef k_means_clustering(points, k, initial_centroids, max_iterations):\n    points = np.array(points)\n    centroids = np.array(initial_centroids)\n    \n    for iteration in range(max_iterations):\n        # Assign points to the nearest centroid\n        distances = np.array([euclidean_distance(points, centroid) for centroid in centroids])\n        assignments = np.argmin(distances, axis=0)\n\n        new_centroids = np.array([points[assignments == i].mean(axis=0) if len(points[assignments == i]) > 0 else centroids[i] for i in range(k)])\n        \n        # Check for convergence\n        if np.all(centroids == new_centroids):\n            break\n        centroids = new_centroids\n        centroids = np.round(centroids,4)\n    return [tuple(centroid) for centroid in centroids]",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBrX21lYW5zX2NsdXN0ZXJpbmdfdGcocG9pbnRzLCBrLCBpbml0aWFsX2NlbnRyb2lkcywgbWF4X2l0ZXJhdGlvbnMpIC0+IGxpc3RbdHVwbGVbZmxvYXQsIC4uLl1dOgogICAgIiIiCiAgICBQZXJmb3JtIGstbWVhbnMgY2x1c3RlcmluZyBvbiBgcG9pbnRzYCBpbnRvIGBrYCBjbHVzdGVycyB1c2luZyB0aW55Z3JhZC4KICAgIHBvaW50czogbGlzdCBvZiBsaXN0cyBvciBUZW5zb3IsIHNoYXBlIChuX3BvaW50cywgbl9mZWF0dXJlcykKICAgIGluaXRpYWxfY2VudHJvaWRzOiBsaXN0IG9mIGxpc3RzIG9yIFRlbnNvciwgc2hhcGUgKGssIG5fZmVhdHVyZXMpCiAgICBtYXhfaXRlcmF0aW9uczogbWF4aW11bSBudW1iZXIgb2YgaXRlcmF0aW9ucwogICAgUmV0dXJucyBhIGxpc3Qgb2YgayBjZW50cm9pZHMgYXMgdHVwbGVzLCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIHB0cyA9IG5wLmFycmF5KHBvaW50cywgZHR5cGU9ZmxvYXQpCiAgICBjZW50cm9pZHMgPSBucC5hcnJheShpbml0aWFsX2NlbnRyb2lkcywgZHR5cGU9ZmxvYXQpCiAgICBmb3IgXyBpbiByYW5nZShtYXhfaXRlcmF0aW9ucyk6CiAgICAgICAgIyBjb21wdXRlIGRpc3RhbmNlcyAoaywgbl9wb2ludHMpCiAgICAgICAgZGlzdHMgPSBucC5hcnJheShbbnAubGluYWxnLm5vcm0ocHRzIC0gYywgYXhpcz0xKSBmb3IgYyBpbiBjZW50cm9pZHNdKQogICAgICAgICMgYXNzaWduIHBvaW50cwogICAgICAgIGFzc2lnbm1lbnRzID0gZGlzdHMuYXJnbWluKGF4aXM9MCkKICAgICAgICBuZXdfY2VudHJvaWRzID0gbnAuYXJyYXkoWwogICAgICAgICAgICBwdHNbYXNzaWdubWVudHMgPT0gaV0ubWVhbihheGlzPTApIGlmIG5wLmFueShhc3NpZ25tZW50cyA9PSBpKSBlbHNlIGNlbnRyb2lkc1tpXQogICAgICAgICAgICBmb3IgaSBpbiByYW5nZShrKQogICAgICAgIF0pCiAgICAgICAgbmV3X2NlbnRyb2lkcyA9IG5wLnJvdW5kKG5ld19jZW50cm9pZHMsIDQpCiAgICAgICAgaWYgbnAuYXJyYXlfZXF1YWwobmV3X2NlbnRyb2lkcywgY2VudHJvaWRzKToKICAgICAgICAgICAgYnJlYWsKICAgICAgICBjZW50cm9pZHMgPSBuZXdfY2VudHJvaWRzCiAgICByZXR1cm4gW3R1cGxlKGMudG9saXN0KCkpIGZvciBjIGluIGNlbnRyb2lkc10K",
        "pytorch_difficulty": "medium",
        "video": "https://youtu.be/KzJORp8bgqs?si=BBrGGuCAWt_AA8QV",
        "likes": "0",
        "marimo_link": "https://adityakhalkar.github.io/Deep-ML-x-Marimo/17",
        "difficulty": "medium",
        "example": {
            "input": "points = [(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)], k = 2, initial_centroids = [(1, 1), (10, 1)], max_iterations = 10",
            "output": "[(1, 2), (10, 2)]",
            "reasoning": "Given the initial centroids and a maximum of 10 iterations,\n        the points are clustered around these points, and the centroids are\n        updated to the mean of the assigned points, resulting in the final\n        centroids which approximate the means of the two clusters.\n        The exact number of iterations needed may vary,\n        but the process will stop after 10 iterations at most."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "def k_means_clustering(points: list[tuple[float, float]], k: int, initial_centroids: list[tuple[float, float]], max_iterations: int) -> list[tuple[float, float]]:\n\t# Your code here\n\treturn final_centroids",
        "learn_section": "\n## K-Means Clustering Algorithm Implementation\n\n### Algorithm Steps\n\n1. **Initialization**  \n   Use the provided `initial_centroids` as your starting point. This step is already done for you in the input.\n\n2. **Assignment Step**  \n   For each point in your dataset:\n   - Calculate its distance to each centroid.\n   - Assign the point to the cluster of the nearest centroid.  \n   *Hint*: Consider creating a helper function to calculate the Euclidean distance between two points.\n\n3. **Update Step**  \n   For each cluster:\n   - Calculate the mean of all points assigned to the cluster.\n   - Update the centroid to this new mean position.  \n   *Hint*: Be careful with potential empty clusters. Decide how you'll handle them (e.g., keep the previous centroid).\n\n4. **Iteration**  \n   Repeat steps 2 and 3 until either:\n   - The centroids no longer change significantly (this case does not need to be included in your solution), or\n   - You reach the `max_iterations` limit.  \n   *Hint*: You might want to keep track of the previous centroids to check for significant changes.\n\n5. **Result**  \n   Return the list of final centroids, ensuring each coordinate is rounded to the nearest fourth decimal.\n\n",
        "title": "K-Means Clustering",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Srihari Thyagarajan"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = k_means_clustering(\n    torch.tensor([[0.0,0.0],[0.1,0.1],[10.0,10.0],[10.1,10.1]]),\n    2,\n    torch.tensor([[0.0,0.0],[10.0,10.0]]),\n    10\n)\nprint(res)",
                "expected_output": "[(0.05, 0.05), (10.05, 10.05)]"
            },
            {
                "test": "import torch\nres = k_means_clustering(\n    torch.tensor([[1.0,2.0],[3.0,4.0]]),\n    1,\n    torch.tensor([[1.0,2.0]]),\n    10\n)\nprint(res)",
                "expected_output": "[(2.0, 3.0)]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "res = k_means_clustering_tg(\n    [[0.0,0.0],[0.1,0.1],[10.0,10.0],[10.1,10.1]],\n    2,\n    [[0.0,0.0],[10.0,10.0]],\n    10\n)\nprint(res)",
                "expected_output": "[(0.05, 0.05), (10.05, 10.05)]"
            },
            {
                "test": "res = k_means_clustering_tg(\n    [[1.0,2.0],[3.0,4.0]],\n    1,\n    [[1.0,2.0]],\n    10\n)\nprint(res)",
                "expected_output": "[(2.0, 3.0)]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYga19tZWFuc19jbHVzdGVyaW5nKHBvaW50cywgaywgaW5pdGlhbF9jZW50cm9pZHMsIG1heF9pdGVyYXRpb25zKSAtPiBsaXN0W3R1cGxlW2Zsb2F0LCAuLi5dXToKICAgICIiIgogICAgUGVyZm9ybSBrLW1lYW5zIGNsdXN0ZXJpbmcgb24gYHBvaW50c2AgaW50byBga2AgY2x1c3RlcnMuCiAgICBwb2ludHM6IHRlbnNvciBvZiBzaGFwZSAobl9wb2ludHMsIG5fZmVhdHVyZXMpCiAgICBpbml0aWFsX2NlbnRyb2lkczogdGVuc29yIG9mIHNoYXBlIChrLCBuX2ZlYXR1cmVzKQogICAgbWF4X2l0ZXJhdGlvbnM6IG1heGltdW0gbnVtYmVyIG9mIGl0ZXJhdGlvbnMKICAgIFJldHVybnMgYSBsaXN0IG9mIGsgY2VudHJvaWRzIGFzIHR1cGxlcywgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICBwb2ludHNfdCA9IHRvcmNoLmFzX3RlbnNvcihwb2ludHMsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgY2VudHJvaWRzID0gdG9yY2guYXNfdGVuc29yKGluaXRpYWxfY2VudHJvaWRzLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIGZvciBfIGluIHJhbmdlKG1heF9pdGVyYXRpb25zKToKICAgICAgICAjIGNvbXB1dGUgZGlzdGFuY2VzIChrLCBuX3BvaW50cykKICAgICAgICBkaWZmcyA9IHBvaW50c190LnVuc3F1ZWV6ZSgwKSAtIGNlbnRyb2lkcy51bnNxdWVlemUoMSkKICAgICAgICBkaXN0YW5jZXMgPSB0b3JjaC5zcXJ0KChkaWZmcyAqKiAyKS5zdW0oZGltPTIpKQogICAgICAgICMgYXNzaWduIGVhY2ggcG9pbnQgdG8gbmVhcmVzdCBjZW50cm9pZAogICAgICAgIGFzc2lnbm1lbnRzID0gZGlzdGFuY2VzLmFyZ21pbihkaW09MCkKICAgICAgICBuZXdfY2VudHJvaWRzID0gW10KICAgICAgICBmb3IgaSBpbiByYW5nZShrKToKICAgICAgICAgICAgY2x1c3Rlcl9wb2ludHMgPSBwb2ludHNfdFthc3NpZ25tZW50cyA9PSBpXQogICAgICAgICAgICBpZiBjbHVzdGVyX3BvaW50cy5udW1lbCgpID09IDA6CiAgICAgICAgICAgICAgICBuZXdfY2VudHJvaWRzLmFwcGVuZChjZW50cm9pZHNbaV0pCiAgICAgICAgICAgIGVsc2U6CiAgICAgICAgICAgICAgICBuZXdfY2VudHJvaWRzLmFwcGVuZChjbHVzdGVyX3BvaW50cy5tZWFuKGRpbT0wKSkKICAgICAgICBuZXdfY2VudHJvaWRzID0gdG9yY2guc3RhY2sobmV3X2NlbnRyb2lkcykKICAgICAgICBuZXdfY2VudHJvaWRzID0gdG9yY2gucm91bmQobmV3X2NlbnRyb2lkcyAqIDEwMDAwKSAvIDEwMDAwCiAgICAgICAgaWYgdG9yY2guZXF1YWwobmV3X2NlbnRyb2lkcywgY2VudHJvaWRzKToKICAgICAgICAgICAgYnJlYWsKICAgICAgICBjZW50cm9pZHMgPSBuZXdfY2VudHJvaWRzCiAgICByZXR1cm4gW3R1cGxlKGMudG9saXN0KCkpIGZvciBjIGluIGNlbnRyb2lkc10K",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYga19tZWFuc19jbHVzdGVyaW5nKHBvaW50cywgaywgaW5pdGlhbF9jZW50cm9pZHMsIG1heF9pdGVyYXRpb25zKSAtPiBsaXN0W3R1cGxlW2Zsb2F0LCAuLi5dXToKICAgICIiIgogICAgUGVyZm9ybSBrLW1lYW5zIGNsdXN0ZXJpbmcgb24gYHBvaW50c2AgaW50byBga2AgY2x1c3RlcnMuCiAgICBwb2ludHM6IHRlbnNvciBvZiBzaGFwZSAobl9wb2ludHMsIG5fZmVhdHVyZXMpCiAgICBpbml0aWFsX2NlbnRyb2lkczogdGVuc29yIG9mIHNoYXBlIChrLCBuX2ZlYXR1cmVzKQogICAgbWF4X2l0ZXJhdGlvbnM6IG1heGltdW0gbnVtYmVyIG9mIGl0ZXJhdGlvbnMKICAgIFJldHVybnMgYSBsaXN0IG9mIGsgY2VudHJvaWRzIGFzIHR1cGxlcywgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICAjIENvbnZlcnQgdG8gdGVuc29ycwogICAgcG9pbnRzX3QgPSB0b3JjaC5hc190ZW5zb3IocG9pbnRzLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIGNlbnRyb2lkcyA9IHRvcmNoLmFzX3RlbnNvcihpbml0aWFsX2NlbnRyb2lkcywgZHR5cGU9dG9yY2guZmxvYXQpCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "id": "17"
    },
    {
        "description": "Implement a function to generate train and test splits for K-Fold Cross-Validation. Your task is to divide the dataset into k folds and return a list of train-test indices for each fold.",
        "mdx_file": "22190adc-bf0a-4187-870f-085cc174903a.mdx",
        "tinygrad_difficulty": "medium",
        "id": "18",
        "test_cases": [
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(k_fold_cross_validation(np.array([0,1,2,3,4,5,6,7,8,9]), np.array([0,1,2,3,4,5,6,7,8,9]), k=5, shuffle=False))",
                "expected_output": "[([2, 3, 4, 5, 6, 7, 8, 9], [0, 1]), ([0, 1, 4, 5, 6, 7, 8, 9], [2, 3]), ([0, 1, 2, 3, 6, 7, 8, 9], [4, 5]), ([0, 1, 2, 3, 4, 5, 8, 9], [6, 7]), ([0, 1, 2, 3, 4, 5, 6, 7], [8, 9])]"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(k_fold_cross_validation(np.array([0,1,2,3,4,5,6,7,8,9]), np.array([0,1,2,3,4,5,6,7,8,9]), k=2, shuffle=True))",
                "expected_output": "[([2, 9, 4, 3, 6], [8, 1, 5, 0, 7]), ([8, 1, 5, 0, 7], [2, 9, 4, 3, 6])]"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(k_fold_cross_validation(np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]), np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]), k=3, shuffle=False))",
                "expected_output": "[([5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [0, 1, 2, 3, 4]), ([0, 1, 2, 3, 4, 10, 11, 12, 13, 14], [5, 6, 7, 8, 9]), ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14])]"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(k_fold_cross_validation(np.array([0,1,2,3,4,5,6,7,8,9]), np.array([0,1,2,3,4,5,6,7,8,9]), k=2, shuffle=False))",
                "expected_output": "[([5, 6, 7, 8, 9], [0, 1, 2, 3, 4]), ([0, 1, 2, 3, 4], [5, 6, 7, 8, 9])]"
            }
        ],
        "tinygrad_starter_code": "ZGVmIGtfZm9sZF9jcm9zc192YWxpZGF0aW9uX3RnKFgsIHksIGs9NSwgc2h1ZmZsZT1UcnVlKSAtPiBsaXN0W3R1cGxlW2xpc3RbaW50XSwgbGlzdFtpbnRdXV06CiAgICAiIiIKICAgIFJldHVybiB0cmFpbi90ZXN0IGluZGV4IHNwbGl0cyBmb3Igay1mb2xkIGNyb3NzLXZhbGlkYXRpb24gdXNpbmcgcHVyZSBQeXRob24gb3IgdGlueWdyYWQuCiAgICBYOiBsaXN0IG9yIFRlbnNvciBvZiBzaGFwZSAobl9zYW1wbGVzLCAuLi4pCiAgICB5OiBsaXN0IG9yIFRlbnNvciBvZiBzaGFwZSAobl9zYW1wbGVzLCAuLi4pCiAgICBrOiBudW1iZXIgb2YgZm9sZHMKICAgIHNodWZmbGU6IHdoZXRoZXIgdG8gc2h1ZmZsZSBpbmRpY2VzIGJlZm9yZSBzcGxpdHRpbmcKICAgIFJldHVybnMgbGlzdCBvZiAodHJhaW5faWR4LCB0ZXN0X2lkeCkgcGFpcnMsIGVhY2ggYXMgUHl0aG9uIGxpc3RzIG9mIGludHMuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "difficulty": "medium",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCgpkZWYga19mb2xkX2Nyb3NzX3ZhbGlkYXRpb25fdGcoWCwgeSwgaz01LCBzaHVmZmxlPVRydWUpIC0+IGxpc3RbdHVwbGVbbGlzdFtpbnRdLCBsaXN0W2ludF1dXToKICAgICIiIgogICAgUmV0dXJuIHRyYWluL3Rlc3QgaW5kZXggc3BsaXRzIGZvciBrLWZvbGQgY3Jvc3MtdmFsaWRhdGlvbiB1c2luZyBOdW1QeSBiYWNrZW5kLgogICAgWDogbGlzdCBvciBOdW1QeSBhcnJheSBvciBUZW5zb3Igb2Ygc2hhcGUgKG5fc2FtcGxlcywgLi4uKQogICAgeTogbGlzdCBvciBOdW1QeSBhcnJheSBvciBUZW5zb3Igb2Ygc2hhcGUgKG5fc2FtcGxlcywgLi4uKQogICAgazogbnVtYmVyIG9mIGZvbGRzCiAgICBzaHVmZmxlOiB3aGV0aGVyIHRvIHNodWZmbGUgaW5kaWNlcyBiZWZvcmUgc3BsaXR0aW5nCiAgICBSZXR1cm5zIGxpc3Qgb2YgKHRyYWluX2lkeCwgdGVzdF9pZHgpIHBhaXJzLCBlYWNoIGFzIFB5dGhvbiBsaXN0cyBvZiBpbnRzLgogICAgIiIiCiAgICBYX25wID0gbnAuYXJyYXkoWCkKICAgIG5fc2FtcGxlcyA9IFhfbnAuc2hhcGVbMF0KICAgIGluZGljZXMgPSBucC5hcmFuZ2Uobl9zYW1wbGVzKQogICAgaWYgc2h1ZmZsZToKICAgICAgICBucC5yYW5kb20uc2h1ZmZsZShpbmRpY2VzKQogICAgYmFzZSA9IG5fc2FtcGxlcyAvLyBrCiAgICBleHRyYXMgPSBuX3NhbXBsZXMgJSBrCiAgICBmb2xkX3NpemVzID0gW2Jhc2UgKyAoMSBpZiBpIDwgZXh0cmFzIGVsc2UgMCkgZm9yIGkgaW4gcmFuZ2UoayldCiAgICBmb2xkcyA9IFtdCiAgICBzdGFydCA9IDAKICAgIGZvciBmcyBpbiBmb2xkX3NpemVzOgogICAgICAgIGZvbGRzLmFwcGVuZChpbmRpY2VzW3N0YXJ0OnN0YXJ0K2ZzXS50b2xpc3QoKSkKICAgICAgICBzdGFydCArPSBmcwogICAgcmVzdWx0ID0gW10KICAgIGZvciBpIGluIHJhbmdlKGspOgogICAgICAgIHRlc3RfaWR4ID0gZm9sZHNbaV0KICAgICAgICB0cmFpbl9pZHggPSBbaWR4IGZvciBqLCBmIGluIGVudW1lcmF0ZShmb2xkcykgaWYgaiAhPSBpIGZvciBpZHggaW4gZl0KICAgICAgICByZXN1bHQuYXBwZW5kKCh0cmFpbl9pZHgsIHRlc3RfaWR4KSkKICAgIHJldHVybiByZXN1bHQK",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "",
        "solution": "import numpy as np\n\ndef k_fold_cross_validation(X: np.ndarray, y: np.ndarray, k=5, shuffle=True):\n    \"\"\"\n    Return train and test indices for k-fold cross-validation.\n    \"\"\"\n    n_samples = len(X)\n    indices = np.arange(n_samples)\n    \n    if shuffle:\n        if random_seed is not None:\n        np.random.shuffle(indices)\n    \n    fold_sizes = np.full(k, n_samples // k, dtype=int)\n    fold_sizes[:n_samples % k] += 1\n\n    current = 0\n    folds = []\n    for fold_size in fold_sizes:\n        folds.append(indices[current:current + fold_size])\n        current += fold_size\n\n    result = []\n    for i in range(k):\n        test_idx = folds[i]\n        train_idx = np.concatenate(folds[:i] + folds[i+1:])\n        result.append((train_idx.tolist(), test_idx.tolist()))\n    \n    return result",
        "dislikes": "0",
        "example": {
            "input": "k_fold_cross_validation(np.array([0,1,2,3,4,5,6,7,8,9]), np.array([0,1,2,3,4,5,6,7,8,9]), k=5, shuffle=False)",
            "output": "[([2, 3, 4, 5, 6, 7, 8, 9], [0, 1]), ([0, 1, 4, 5, 6, 7, 8, 9], [2, 3]), ([0, 1, 2, 3, 6, 7, 8, 9], [4, 5]), ([0, 1, 2, 3, 4, 5, 8, 9], [6, 7]), ([0, 1, 2, 3, 4, 5, 6, 7], [8, 9])]",
            "reasoning": "The function splits the dataset into 5 folds without shuffling and returns train-test splits for each iteration."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef k_fold_cross_validation(X: np.ndarray, y: np.ndarray, k=5, shuffle=True):\n    \"\"\"\n    Implement k-fold cross-validation by returning train-test indices.\n    \"\"\"\n    # Your code here\n    pass",
        "learn_section": "## Understanding K-Fold Cross-Validation\n\nK-Fold Cross-Validation is a resampling technique used to evaluate machine learning models by partitioning the dataset into multiple folds.\n\n### How it Works\n1. The dataset is split into **k** equal (or almost equal) parts called folds.\n2. Each fold is used **once** as a test set, while the remaining **k-1** folds form the training set.\n3. The process is repeated **k times**, ensuring each fold serves as a test set exactly once.\n\n### Why Use K-Fold Cross-Validation?\n- It provides a more **robust** estimate of model performance than a single train-test split.\n- Reduces bias introduced by a single training/testing split.\n- Allows evaluation across multiple data distributions.\n\n### Implementation Steps\n1. Shuffle the data if required.\n2. Split the dataset into **k** equal (or nearly equal) folds.\n3. Iterate over each fold, using it as the test set while using the remaining data as the training set.\n4. Return train-test indices for each iteration.\n\nBy implementing this function, you will learn how to **split a dataset for cross-validation**, a crucial step in model evaluation.",
        "title": "Implement K-Fold Cross-Validation",
        "contributor": [
            {
                "profile_link": "https://github.com/peppermin-t",
                "name": "Yinjia Chen"
            },
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "res = k_fold_cross_validation(list(range(6)), list(range(6)), k=3, shuffle=False)\nprint(res)",
                "expected_output": "[(2, 3, 4, 5), [0, 1]], [0, 1, 4, 5, [2, 3]], [0, 1, 2, 3, [4, 5]]"
            },
            {
                "test": "res = k_fold_cross_validation(list(range(8)), list(range(8)), k=4, shuffle=False)\nprint(res)",
                "expected_output": "[([2,3,4,5,6,7], [0,1]), ([0,1,4,5,6,7], [2,3]), ([0,1,2,3,6,7], [4,5]), ([0,1,2,3,4,5], [6,7])]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "res = k_fold_cross_validation_tg(list(range(6)), list(range(6)), k=3, shuffle=False)\nprint(res)",
                "expected_output": "[([2, 3, 4, 5], [0, 1]), ([0, 1, 4, 5], [2, 3]), ([0, 1, 2, 3], [4, 5])]"
            },
            {
                "test": "res = k_fold_cross_validation_tg(list(range(8)), list(range(8)), k=4, shuffle=False)\nprint(res)",
                "expected_output": "[([2, 3, 4, 5, 6, 7], [0, 1]), ([0, 1, 4, 5, 6, 7], [2, 3]), ([0, 1, 2, 3, 6, 7], [4, 5]), ([0, 1, 2, 3, 4, 5], [6, 7])]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYga19mb2xkX2Nyb3NzX3ZhbGlkYXRpb24oWCwgeSwgaz01LCBzaHVmZmxlPVRydWUpIC0+IGxpc3RbdHVwbGVbbGlzdFtpbnRdLCBsaXN0W2ludF1dXToKICAgICIiIgogICAgUmV0dXJuIHRyYWluL3Rlc3QgaW5kZXggc3BsaXRzIGZvciBrLWZvbGQgY3Jvc3MtdmFsaWRhdGlvbiB1c2luZyBQeVRvcmNoLgogICAgWDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIG9mIHNoYXBlIChuX3NhbXBsZXMsIC4uLikKICAgIHk6IFRlbnNvciBvciBjb252ZXJ0aWJsZSBvZiBzaGFwZSAobl9zYW1wbGVzLCAuLi4pCiAgICBrOiBudW1iZXIgb2YgZm9sZHMKICAgIHNodWZmbGU6IHdoZXRoZXIgdG8gc2h1ZmZsZSBpbmRpY2VzIGJlZm9yZSBzcGxpdHRpbmcKICAgIFJldHVybnMgbGlzdCBvZiAodHJhaW5faWR4LCB0ZXN0X2lkeCkgcGFpcnMsIGVhY2ggYXMgUHl0aG9uIGxpc3RzIG9mIGludHMuCiAgICAiIiIKICAgIFhfdCA9IHRvcmNoLmFzX3RlbnNvcihYKQogICAgbl9zYW1wbGVzID0gWF90LnNpemUoMCkKICAgIGluZGljZXMgPSB0b3JjaC5hcmFuZ2Uobl9zYW1wbGVzKQogICAgaWYgc2h1ZmZsZToKICAgICAgICBpbmRpY2VzID0gaW5kaWNlc1t0b3JjaC5yYW5kcGVybShuX3NhbXBsZXMpXQogICAgYmFzZSA9IG5fc2FtcGxlcyAvLyBrCiAgICBleHRyYXMgPSBuX3NhbXBsZXMgJSBrCiAgICBmb2xkX3NpemVzID0gW2Jhc2UgKyAoMSBpZiBpIDwgZXh0cmFzIGVsc2UgMCkgZm9yIGkgaW4gcmFuZ2UoayldCiAgICBmb2xkcyA9IFtdCiAgICBzdGFydCA9IDAKICAgIGZvciBmcyBpbiBmb2xkX3NpemVzOgogICAgICAgIGZvbGRzLmFwcGVuZChpbmRpY2VzW3N0YXJ0OnN0YXJ0K2ZzXS50b2xpc3QoKSkKICAgICAgICBzdGFydCArPSBmcwogICAgcmVzdWx0ID0gW10KICAgIGZvciBpIGluIHJhbmdlKGspOgogICAgICAgIHRlc3RfaWR4ID0gZm9sZHNbaV0KICAgICAgICB0cmFpbl9pZHggPSBbXQogICAgICAgIGZvciBqLCBmIGluIGVudW1lcmF0ZShmb2xkcyk6CiAgICAgICAgICAgIGlmIGogIT0gaToKICAgICAgICAgICAgICAgIHRyYWluX2lkeC5leHRlbmQoZikKICAgICAgICByZXN1bHQuYXBwZW5kKCh0cmFpbl9pZHgsIHRlc3RfaWR4KSkKICAgIHJldHVybiByZXN1bHQK",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYga19mb2xkX2Nyb3NzX3ZhbGlkYXRpb24oWCwgeSwgaz01LCBzaHVmZmxlPVRydWUpIC0+IGxpc3RbdHVwbGVbbGlzdFtpbnRdLCBsaXN0W2ludF1dXToKICAgICIiIgogICAgUmV0dXJuIHRyYWluL3Rlc3QgaW5kZXggc3BsaXRzIGZvciBrLWZvbGQgY3Jvc3MtdmFsaWRhdGlvbiB1c2luZyBQeVRvcmNoLgogICAgWDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIG9mIHNoYXBlIChuX3NhbXBsZXMsIC4uLikKICAgIHk6IFRlbnNvciBvciBjb252ZXJ0aWJsZSBvZiBzaGFwZSAobl9zYW1wbGVzLCAuLi4pCiAgICBrOiBudW1iZXIgb2YgZm9sZHMKICAgIHNodWZmbGU6IHdoZXRoZXIgdG8gc2h1ZmZsZSBpbmRpY2VzIGJlZm9yZSBzcGxpdHRpbmcKICAgIFJldHVybnMgbGlzdCBvZiAodHJhaW5faWR4LCB0ZXN0X2lkeCkgcGFpcnMsIGVhY2ggYXMgUHl0aG9uIGxpc3RzIG9mIGludHMuCiAgICAiIiIKICAgIFhfdCA9IHRvcmNoLmFzX3RlbnNvcihYKQogICAgbl9zYW1wbGVzID0gWF90LnNpemUoMCkKICAgIGluZGljZXMgPSB0b3JjaC5hcmFuZ2Uobl9zYW1wbGVzKQogICAgaWYgc2h1ZmZsZToKICAgICAgICBpbmRpY2VzID0gaW5kaWNlc1t0b3JjaC5yYW5kcGVybShuX3NhbXBsZXMpXQogICAgIyBjb21wdXRlIGZvbGQgc2l6ZXMKICAgIGJhc2UgPSBuX3NhbXBsZXMgLy8gawogICAgZXh0cmFzID0gbl9zYW1wbGVzICUgawogICAgZm9sZF9zaXplcyA9IFtiYXNlICsgKDEgaWYgaSA8IGV4dHJhcyBlbHNlIDApIGZvciBpIGluIHJhbmdlKGspXQogICAgIyBzcGxpdCBpbnRvIGZvbGRzCiAgICBmb2xkcyA9IFtdCiAgICBzdGFydCA9IDAKICAgIGZvciBmcyBpbiBmb2xkX3NpemVzOgogICAgICAgIGZvbGRzLmFwcGVuZChpbmRpY2VzW3N0YXJ0OnN0YXJ0K2ZzXS50b2xpc3QoKSkKICAgICAgICBzdGFydCArPSBmcwogICAgIyBidWlsZCB0cmFpbi90ZXN0IHBhaXJzCiAgICByZXN1bHQgPSBbXQogICAgZm9yIGkgaW4gcmFuZ2Uoayk6CiAgICAgICAgdGVzdF9pZHggPSBmb2xkc1tpXQogICAgICAgIHRyYWluX2lkeCA9IFtpZHggZm9yIGosIGYgaW4gZW51bWVyYXRlKGZvbGRzKSBpZiBqICE9IGkgZm9yIGlkeCBpbiBmXQogICAgICAgIHJlc3VsdC5hcHBlbmQoKHRyYWluX2lkeCwgdGVzdF9pZHgpKQogICAgcmV0dXJuIHJlc3VsdAo="
    },
    {
        "description": "Write a Python function that performs Principal Component Analysis (PCA) from scratch. The function should take a 2D NumPy array as input, where each row represents a data sample and each column represents a feature. The function should standardize the dataset, compute the covariance matrix, find the eigenvalues and eigenvectors, and return the principal components (the eigenvectors corresponding to the largest eigenvalues). The function should also take an integer k as input, representing the number of principal components to return.",
        "mdx_file": "16e58cac-70e5-4074-94bf-5013900f2771.mdx",
        "tinygrad_difficulty": "medium",
        "id": "19",
        "test_cases": [
            {
                "test": "print(pca(np.array([[4,2,1],[5,6,7],[9,12,1],[4,6,7]]),2))",
                "expected_output": "[[0.6855, 0.0776], [0.6202, 0.4586], [-0.3814, 0.8853]]"
            },
            {
                "test": "print(pca(np.array([[1, 2], [3, 4], [5, 6]]), k = 1))",
                "expected_output": " [[0.7071], [0.7071]]"
            }
        ],
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHBjYV90ZyhkYXRhLCBrKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIFBlcmZvcm0gUENBIG9uIGBkYXRhYCwgcmV0dXJuaW5nIHRoZSB0b3AgYGtgIHByaW5jaXBhbCBjb21wb25lbnRzIGFzIGEgdGlueWdyYWQgVGVuc29yLgogICAgSW5wdXQ6IGxpc3QsIE51bVB5IGFycmF5LCBvciBUZW5zb3Igb2Ygc2hhcGUgKG5fc2FtcGxlcywgbl9mZWF0dXJlcykuCiAgICBSZXR1cm5zOiBhIFRlbnNvciBvZiBzaGFwZSAobl9mZWF0dXJlcywgayksIHdpdGggZmxvYXRzIHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "difficulty": "medium",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiBwY2FfdGcoZGF0YSwgaykgLT4gVGVuc29yOgogICAgIiIiCiAgICBQZXJmb3JtIFBDQSBvbiBgZGF0YWAsIHJldHVybmluZyB0aGUgdG9wIGBrYCBwcmluY2lwYWwgY29tcG9uZW50cyBhcyBhIHRpbnlncmFkIFRlbnNvci4KICAgIElucHV0OiBsaXN0LCBOdW1QeSBhcnJheSwgb3IgVGVuc29yIG9mIHNoYXBlIChuX3NhbXBsZXMsIG5fZmVhdHVyZXMpLgogICAgUmV0dXJuczogYSBUZW5zb3Igb2Ygc2hhcGUgKG5fZmVhdHVyZXMsIGspLCB3aXRoIGZsb2F0cyByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIGFyciA9IG5wLmFycmF5KGRhdGEsIGR0eXBlPWZsb2F0KQogICAgIyBTdGFuZGFyZGl6ZQogICAgYXJyX3N0ZCA9IChhcnIgLSBhcnIubWVhbihheGlzPTApKSAvIGFyci5zdGQoYXhpcz0wKQogICAgIyBDb3ZhcmlhbmNlCiAgICBjb3YgPSBucC5jb3YoYXJyX3N0ZCwgcm93dmFyPUZhbHNlKQogICAgIyBFaWdlbiBkZWNvbXBvc2l0aW9uCiAgICB2YWxzLCB2ZWNzID0gbnAubGluYWxnLmVpZyhjb3YpCiAgICBpZHggPSBucC5hcmdzb3J0KHZhbHMpWzo6LTFdCiAgICBwY3MgPSB2ZWNzWzosIGlkeFs6a11dCiAgICBwY3MgPSBucC5yb3VuZChwY3MsIDQpCiAgICByZXR1cm4gVGVuc29yKHBjcykK",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "",
        "solution": "\nimport numpy as np\n\ndef pca(data, k):\n    # Standardize the data\n    data_standardized = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n    \n    # Compute the covariance matrix\n    covariance_matrix = np.cov(data_standardized, rowvar=False)\n    \n    # Eigen decomposition\n    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n    \n    # Sort the eigenvectors by decreasing eigenvalues\n    idx = np.argsort(eigenvalues)[::-1]\n    eigenvalues_sorted = eigenvalues[idx]\n    eigenvectors_sorted = eigenvectors[:,idx]\n    \n    # Select the top k eigenvectors (principal components)\n    principal_components = eigenvectors_sorted[:, :k]\n    \n    return np.round(principal_components, 4)",
        "example": {
            "input": "data = np.array([[1, 2], [3, 4], [5, 6]]), k = 1",
            "output": "[[0.7071], [0.7071]]",
            "reasoning": "After standardizing the data and computing the covariance matrix, the eigenvalues and eigenvectors are calculated. The largest eigenvalue's corresponding eigenvector is returned as the principal component, rounded to four decimal places."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np \ndef pca(data: np.ndarray, k: int) -> np.ndarray:\n\t# Your code here\n\treturn np.round(principal_components, 4)",
        "learn_section": "\n## Understanding Eigenvalues in PCA\n\nPrincipal Component Analysis (PCA) utilizes the concept of eigenvalues and eigenvectors to identify the principal components of a dataset. Here's how eigenvalues fit into the PCA process:\n\n### Eigenvalues and Eigenvectors: The Foundation of PCA\nFor a given square matrix \\( A \\), representing the covariance matrix in PCA, eigenvalues \\( \\lambda \\) and their corresponding eigenvectors \\( v \\) satisfy:\n$$\nAv = \\lambda v\n$$\n\n### Calculating Eigenvalues\nThe eigenvalues of matrix \\( A \\) are found by solving the characteristic equation:\n$$\n\\det(A - \\lambda I) = 0\n$$\nwhere \\( I \\) is the identity matrix of the same dimension as \\( A \\). This equation highlights the relationship between a matrix, its eigenvalues, and eigenvectors.\n\n### Role in PCA\nIn PCA, the covariance matrix's eigenvalues represent the variance explained by its eigenvectors. Thus, selecting the eigenvectors associated with the largest eigenvalues is akin to choosing the principal components that retain the most data variance.\n\n### Eigenvalues and Dimensionality Reduction\nThe magnitude of an eigenvalue correlates with the importance of its corresponding eigenvector (principal component) in representing the dataset's variability. By selecting a subset of eigenvectors corresponding to the largest eigenvalues, PCA achieves dimensionality reduction while preserving as much of the dataset's variability as possible.\n\n### Practical Application\n1. **Standardize the Dataset**: Ensure that each feature has a mean of 0 and a standard deviation of 1.\n2. **Compute the Covariance Matrix**: Reflects how features vary together.\n3. **Find Eigenvalues and Eigenvectors**: Solve the characteristic equation for the covariance matrix.\n4. **Select Principal Components**: Choose eigenvectors (components) with the highest eigenvalues for dimensionality reduction.\n\nThrough this process, PCA transforms the original features into a new set of uncorrelated features (principal components), ordered by the amount of original variance they explain.\n\n",
        "title": "Principal Component Analysis (PCA) Implementation",
        "contributor": [
            {
                "profile_link": "https://github.com/jon-rosen",
                "name": "jon-rosen"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "res = pca([[1.0,0.0],[0.0,1.0]], 2)\n# convert to Python list and round each value\nlst = res.tolist()\nrounded = [[round(val,4) for val in row] for row in lst]\nprint(rounded)",
                "expected_output": "[[0.7071, 0.7071], [-0.7071, 0.7071]]"
            },
            {
                "test": "res = pca([[1.0,1.0],[2.0,2.0],[3.0,3.0]], 1)\n# convert to Python list and round each value\nlst = res.tolist()\nrounded = [[round(val,4) for val in row] for row in lst]\nprint(rounded)",
                "expected_output": "[[0.7071], [0.7071]]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "res = pca_tg([[1.0,0.0],[0.0,1.0]], 2)\n# convert to Python list and round each value\nlst = res.numpy().tolist()\nrounded = [[round(val,4) for val in row] for row in lst]\nprint(rounded)",
                "expected_output": "[[1.0, 0.0], [0.0, 1.0]]"
            },
            {
                "test": "res = pca_tg([[1.0,1.0],[2.0,2.0],[3.0,3.0]], 1)\n# convert to Python list and round each value\nlst = res.numpy().tolist()\nrounded = [[round(val,4) for val in row] for row in lst]\nprint(rounded)",
                "expected_output": "[[0.7071], [0.7071]]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgcGNhKGRhdGEsIGspIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgUGVyZm9ybSBQQ0Egb24gYGRhdGFgLCByZXR1cm5pbmcgdGhlIHRvcCBga2AgcHJpbmNpcGFsIGNvbXBvbmVudHMgYXMgYSB0ZW5zb3IuCiAgICBJbnB1dDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIG9mIHNoYXBlIChuX3NhbXBsZXMsIG5fZmVhdHVyZXMpLgogICAgUmV0dXJuczogYSB0b3JjaC5UZW5zb3Igb2Ygc2hhcGUgKG5fZmVhdHVyZXMsIGspLCB3aXRoIGZsb2F0cyByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIGRhdGFfdCA9IHRvcmNoLmFzX3RlbnNvcihkYXRhLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgICMgU3RhbmRhcmRpemUKICAgIG1lYW4gPSBkYXRhX3QubWVhbihkaW09MCwga2VlcGRpbT1UcnVlKQogICAgc3RkICA9IGRhdGFfdC5zdGQoZGltPTAsIHVuYmlhc2VkPUZhbHNlLCBrZWVwZGltPVRydWUpCiAgICBkYXRhX3N0ZCA9IChkYXRhX3QgLSBtZWFuKSAvIHN0ZAogICAgIyBDb3ZhcmlhbmNlCiAgICBjb3YgPSB0b3JjaC5jb3YoZGF0YV9zdGQuVCkKICAgICMgRWlnZW4gZGVjb21wb3NpdGlvbgogICAgZWlnZW52YWx1ZXMsIGVpZ2VudmVjdG9ycyA9IHRvcmNoLmxpbmFsZy5laWcoY292KQogICAgdmFscyA9IGVpZ2VudmFsdWVzLnJlYWwKICAgIHZlY3MgPSBlaWdlbnZlY3RvcnMucmVhbAogICAgIyBTb3J0IGJ5IGRlc2NlbmRpbmcgZWlnZW52YWx1ZQogICAgaWR4ID0gdG9yY2guYXJnc29ydCh2YWxzLCBkZXNjZW5kaW5nPVRydWUpCiAgICBwY3MgPSB2ZWNzWzosIGlkeFs6a11dCiAgICAjIFJvdW5kIHRvIDQgZGVjaW1hbHMKICAgIHBjcyA9IHRvcmNoLnJvdW5kKHBjcyAqIDEwMDAwKSAvIDEwMDAwCiAgICByZXR1cm4gcGNzCg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgcGNhKGRhdGEsIGspIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgUGVyZm9ybSBQQ0Egb24gYGRhdGFgLCByZXR1cm5pbmcgdGhlIHRvcCBga2AgcHJpbmNpcGFsIGNvbXBvbmVudHMgYXMgYSB0ZW5zb3IuCiAgICBJbnB1dDogVGVuc29yIG9yIGNvbnZlcnRpYmxlIG9mIHNoYXBlIChuX3NhbXBsZXMsIG5fZmVhdHVyZXMpLgogICAgUmV0dXJuczogYSB0b3JjaC5UZW5zb3Igb2Ygc2hhcGUgKG5fZmVhdHVyZXMsIGspLCB3aXRoIGZsb2F0cyByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIGRhdGFfdCA9IHRvcmNoLmFzX3RlbnNvcihkYXRhLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg=="
    },
    {
        "description": "Write a Python function that computes the transpose of a given matrix.",
        "mdx_file": "a8855223-dfbd-4871-b7d6-09761d70e9a5.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHRyYW5zcG9zZV9tYXRyaXhfdGcoYSkgLT4gVGVuc29yOgogICAgIiIiCiAgICBUcmFuc3Bvc2UgYSAyRCBtYXRyaXggYGFgIHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdGlueWdyYWQgVGVuc29ycy4KICAgIFJldHVybnMgYSB0cmFuc3Bvc2VkIFRlbnNvci4KICAgICIiIgogICAgIyBDb252ZXJ0IHRvIFRlbnNvcgogICAgYV90ID0gVGVuc29yKGEpCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "test_cases": [
            {
                "test": "print(transpose_matrix([[1,2],[3,4],[5,6]]))",
                "expected_output": "[[1, 3, 5], [2, 4, 6]]"
            },
            {
                "test": "print(transpose_matrix([[1,2,3],[4,5,6]]))",
                "expected_output": "[[1, 4], [2, 5], [3, 6]]"
            }
        ],
        "solution": "def transpose_matrix(a: list[list[int|float]]) -> list[list[int|float]]:\n    return [list(i) for i in zip(*a)]",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHRyYW5zcG9zZV9tYXRyaXhfdGcoYSkgLT4gVGVuc29yOgogICAgIiIiCiAgICBUcmFuc3Bvc2UgYSAyRCBtYXRyaXggYGFgIHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdGlueWdyYWQgVGVuc29ycy4KICAgIFJldHVybnMgYSB0cmFuc3Bvc2VkIFRlbnNvci4KICAgICIiIgogICAgYV90ID0gVGVuc29yKGEpCiAgICByZXR1cm4gYV90LnRyYW5zcG9zZSgwLDEpCg==",
        "pytorch_difficulty": "easy",
        "video": "https://youtu.be/fj0ZJ2gTSmI?si=vG8VSqASjyG0eNLY",
        "likes": "0",
        "difficulty": "easy",
        "example": {
            "input": "a = [[1,2,3],[4,5,6]]",
            "output": "[[1,4],[2,5],[3,6]]",
            "reasoning": "The transpose of a matrix is obtained by flipping rows and columns."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "def transpose_matrix(a: list[list[int|float]]) -> list[list[int|float]]:\n\treturn b",
        "title": "Transpose of a Matrix",
        "learn_section": "\n## Transpose of a Matrix\n\nLet's consider a matrix $M$ and its transpose $M^T$:\n\n**Original Matrix $M$:**\n$$\nM = \\begin{pmatrix} \na & b & c \\\\ \nd & e & f \n\\end{pmatrix}\n$$\n\n**Transposed Matrix $M^T$:**\n$$\nM^T = \\begin{pmatrix} \na & d \\\\ \nb & e \\\\ \nc & f \n\\end{pmatrix}\n$$\n\n### Explanation:\nTransposing a matrix involves converting its rows into columns and vice versa. This operation is fundamental in linear algebra for various computations and transformations.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = transpose_matrix(torch.tensor([[1,2,3],[4,5,6]]))\nprint(res.numpy().tolist())",
                "expected_output": "[[1, 4], [2, 5], [3, 6]]"
            },
            {
                "test": "import torch\nres = transpose_matrix(torch.tensor([[1,2],[3,4]]))\nprint(res.numpy().tolist())",
                "expected_output": "[[1, 3], [2, 4]]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = transpose_matrix_tg([[1,2,3],[4,5,6]])\nprint(res.numpy().tolist())",
                "expected_output": "[[1, 4], [2, 5], [3, 6]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = transpose_matrix_tg([[1,2],[3,4]])\nprint(res.numpy().tolist())",
                "expected_output": "[[1, 3], [2, 4]]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgdHJhbnNwb3NlX21hdHJpeChhKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFRyYW5zcG9zZSBhIDJEIG1hdHJpeCBgYWAgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRvcmNoIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgdHJhbnNwb3NlZCB0ZW5zb3IuCiAgICAiIiIKICAgIGFfdCA9IHRvcmNoLmFzX3RlbnNvcihhKQogICAgcmV0dXJuIGFfdC5UCg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgdHJhbnNwb3NlX21hdHJpeChhKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFRyYW5zcG9zZSBhIDJEIG1hdHJpeCBgYWAgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRvcmNoIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgdHJhbnNwb3NlZCB0ZW5zb3IuCiAgICAiIiIKICAgIGFfdCA9IHRvcmNoLmFzX3RlbnNvcihhKQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "2"
    },
    {
        "description": "Write a Python function that implements the decision tree learning algorithm for classification. The function should use recursive binary splitting based on entropy and information gain to build a decision tree. It should take a list of examples (each example is a dict of attribute-value pairs) and a list of attribute names as input, and return a nested dictionary representing the decision tree.",
        "mdx_file": "1ea17459-d896-4362-9a3b-9b87bca0abc3.mdx",
        "tinygrad_difficulty": "hard",
        "tinygrad_starter_code": "aW1wb3J0IG1hdGgKZnJvbSBjb2xsZWN0aW9ucyBpbXBvcnQgQ291bnRlcgpmcm9tIHR5cGluZyBpbXBvcnQgTGlzdCwgRGljdCwgQW55LCBVbmlvbgoKCmRlZiBsZWFybl9kZWNpc2lvbl90cmVlX3RnKAogICAgZXhhbXBsZXM6IExpc3RbRGljdFtzdHIsIEFueV1dLAogICAgYXR0cmlidXRlczogTGlzdFtzdHJdLAogICAgdGFyZ2V0X2F0dHI6IHN0cgopIC0+IFVuaW9uW0RpY3Rbc3RyLCBBbnldLCBBbnldOgogICAgIiIiCiAgICBMZWFybiBhIGRlY2lzaW9uIHRyZWUgdXNpbmcgSUQzIHdpdGggdGlueWdyYWQgZm9yIGVudHJvcHkvZ2Fpbi4KICAgIFJldHVybnMgYSBuZXN0ZWQgZGljdCB0cmVlIG9yIGEgY2xhc3MgbGFiZWwuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(learn_decision_tree([\n    {'Outlook': 'Sunny', 'Wind': 'Weak', 'PlayTennis': 'No'},\n    {'Outlook': 'Overcast', 'Wind': 'Strong', 'PlayTennis': 'Yes'},\n    {'Outlook': 'Rain', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n    {'Outlook': 'Sunny', 'Wind': 'Strong', 'PlayTennis': 'No'},\n    {'Outlook': 'Sunny', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n    {'Outlook': 'Overcast', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n    {'Outlook': 'Rain', 'Wind': 'Strong', 'PlayTennis': 'No'},\n    {'Outlook': 'Rain', 'Wind': 'Weak', 'PlayTennis': 'Yes'}\n], ['Outlook', 'Wind'], 'PlayTennis'))",
                "expected_output": "{'Outlook': {'Sunny': {'Wind': {'Weak': 'No', 'Strong': 'No'}}, 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}, 'Overcast': 'Yes'}}"
            }
        ],
        "solution": "\nimport math\nfrom collections import Counter\n\ndef calculate_entropy(labels):\n    label_counts = Counter(labels)\n    total_count = len(labels)\n    entropy = -sum((count / total_count) * math.log2(count / total_count) for count in label_counts.values())\n    return entropy\n\ndef calculate_information_gain(examples, attr, target_attr):\n    total_entropy = calculate_entropy([example[target_attr] for example in examples])\n    values = set(example[attr] for example in examples)\n    attr_entropy = 0\n    for value in values:\n        value_subset = [example[target_attr] for example in examples if example[attr] == value]\n        value_entropy = calculate_entropy(value_subset)\n        attr_entropy += (len(value_subset) / len(examples)) * value_entropy\n    return total_entropy - attr_entropy\n\ndef majority_class(examples, target_attr):\n    return Counter([example[target_attr] for example in examples]).most_common(1)[0][0]\n\ndef learn_decision_tree(examples, attributes, target_attr):\n    if not examples:\n        return 'No examples'\n    if all(example[target_attr] == examples[0][target_attr] for example in examples):\n        return examples[0][target_attr]\n    if not attributes:\n        return majority_class(examples, target_attr)\n    \n    gains = {attr: calculate_information_gain(examples, attr, target_attr) for attr in attributes}\n    best_attr = max(gains, key=gains.get)\n    tree = {best_attr: {}}\n    \n    for value in set(example[best_attr] for example in examples):\n        subset = [example for example in examples if example[best_attr] == value]\n        new_attributes = attributes.copy()\n        new_attributes.remove(best_attr)\n        subtree = learn_decision_tree(subset, new_attributes, target_attr)\n        tree[best_attr][value] = subtree\n    \n    return tree\n",
        "tinygrad_solution": "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",
        "pytorch_difficulty": "hard",
        "video": null,
        "likes": "0",
        "difficulty": "hard",
        "example": {
            "input": "examples = [\n                    {'Outlook': 'Sunny', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'No'},\n                    {'Outlook': 'Sunny', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Strong', 'PlayTennis': 'No'},\n                    {'Outlook': 'Overcast', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n                    {'Outlook': 'Rain', 'Temperature': 'Mild', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'Yes'}\n                ],\n                attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']",
            "output": "{\n            'Outlook': {\n                'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}},\n                'Overcast': 'Yes',\n                'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}\n            }\n        }",
            "reasoning": "Using the given examples, the decision tree algorithm determines that 'Outlook' is the best attribute to split the data initially. When 'Outlook' is 'Overcast', the outcome is always 'Yes', so it becomes a leaf node. In cases of 'Sunny' and 'Rain', it further splits based on 'Humidity' and 'Wind', respectively. The resulting tree structure is able to classify the training examples with the attributes 'Outlook', 'Temperature', 'Humidity', and 'Wind'."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "def learn_decision_tree(examples: list[dict], attributes: list[str], target_attr: str) -> dict:\n\t# Your code here\n\treturn decision_tree",
        "learn_section": "\n## Decision Tree Learning Algorithm\n\nThe decision tree learning algorithm is a method used for classification that predicts the value of a target variable based on several input variables. Each internal node of the tree corresponds to an input variable, and each leaf node corresponds to a class label.\n\n### Algorithm Overview\nThe recursive binary splitting starts by selecting the attribute that best separates the examples according to the entropy and information gain, calculated as follows:\n\n### Entropy\n$$\nH(X) = -\\sum p(x) \\log_2 p(x)\n$$\n\n### Information Gain\n$$\nIG(D, A) = H(D) - \\sum \\frac{|D_v|}{|D|} H(D_v)\n$$\n\n### Explanation of Terms\n- **Entropy \\( H(X) \\)**: Measures the impurity or disorder of the set.\n- **Information Gain \\( IG(D, A) \\)**: Represents the reduction in entropy after splitting the dataset \\( D \\) on attribute \\( A \\).\n- **\\( D_v \\)**: The subset of \\( D \\) for which attribute \\( A \\) has value \\( v \\).\n\n### Process\n1. **Select Attribute**: Choose the attribute with the highest information gain.\n2. **Split Dataset**: Divide the dataset based on the values of the selected attribute.\n3. **Recursion**: Repeat the process for each subset until:\n   - All data is perfectly classified, or\n   - No remaining attributes can be used to make a split.\n\nThis recursive process continues until the decision tree can no longer be split further or all examples have been classified.\n\n",
        "title": "Decision Tree Learning",
        "contributor": null,
        "pytorch_test_cases": [
            {
                "test": "print(learn_decision_tree([\n    {'Outlook': 'Sunny',   'Wind': 'Weak',   'PlayTennis': 'No'},\n    {'Outlook': 'Overcast','Wind': 'Strong', 'PlayTennis': 'Yes'},\n    {'Outlook': 'Rain',    'Wind': 'Weak',   'PlayTennis': 'Yes'},\n    {'Outlook': 'Sunny',   'Wind': 'Strong', 'PlayTennis': 'No'},\n    {'Outlook': 'Sunny',   'Wind': 'Weak',   'PlayTennis': 'Yes'},\n    {'Outlook': 'Overcast','Wind': 'Weak',   'PlayTennis': 'Yes'},\n    {'Outlook': 'Rain',    'Wind': 'Strong', 'PlayTennis': 'No'},\n    {'Outlook': 'Rain',    'Wind': 'Weak',   'PlayTennis': 'Yes'}\n], ['Outlook', 'Wind'], 'PlayTennis'))",
                "expected_output": "{'Outlook': {'Sunny': {'Wind': {'Weak': 'No', 'Strong': 'No'}}, 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}, 'Overcast': 'Yes'}}"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "print(learn_decision_tree_tg([\n    {'Outlook': 'Sunny',   'Wind': 'Weak',   'PlayTennis': 'No'},\n    {'Outlook': 'Overcast','Wind': 'Strong', 'PlayTennis': 'Yes'},\n    {'Outlook': 'Rain',    'Wind': 'Weak',   'PlayTennis': 'Yes'},\n    {'Outlook': 'Sunny',   'Wind': 'Strong', 'PlayTennis': 'No'},\n    {'Outlook': 'Sunny',   'Wind': 'Weak',   'PlayTennis': 'Yes'},\n    {'Outlook': 'Overcast','Wind': 'Weak',   'PlayTennis': 'Yes'},\n    {'Outlook': 'Rain',    'Wind': 'Strong', 'PlayTennis': 'No'},\n    {'Outlook': 'Rain',    'Wind': 'Weak',   'PlayTennis': 'Yes'}\n], ['Outlook', 'Wind'], 'PlayTennis'))",
                "expected_output": "{'Outlook': {'Sunny': {'Wind': {'Weak': 'No', 'Strong': 'No'}}, 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}, 'Overcast': 'Yes'}}"
            }
        ],
        "pytorch_solution": "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",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmltcG9ydCBtYXRoCmZyb20gY29sbGVjdGlvbnMgaW1wb3J0IENvdW50ZXIKZnJvbSB0eXBpbmcgaW1wb3J0IExpc3QsIERpY3QsIEFueSwgVW5pb24KCgpkZWYgY2FsY3VsYXRlX2VudHJvcHkobGFiZWxzOiBMaXN0W0FueV0pIC0+IGZsb2F0OgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBTaGFubm9uIGVudHJvcHkgb2YgdGhlIGxpc3Qgb2YgbGFiZWxzLgogICAgbGFiZWxzOiBsaXN0IG9mIGFueSBoYXNoYWJsZSBpdGVtcy4KICAgIFJldHVybnMgYSBQeXRob24gZmxvYXQuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCgoKZGVmIGNhbGN1bGF0ZV9pbmZvcm1hdGlvbl9nYWluKAogICAgZXhhbXBsZXM6IExpc3RbRGljdFtzdHIsIEFueV1dLAogICAgYXR0cjogc3RyLAogICAgdGFyZ2V0X2F0dHI6IHN0cgopIC0+IGZsb2F0OgogICAgIiIiCiAgICBDb21wdXRlIGluZm9ybWF0aW9uIGdhaW4gZm9yIHNwbGl0dGluZyBgZXhhbXBsZXNgIG9uIGBhdHRyYCB3LnIudC4gYHRhcmdldF9hdHRyYC4KICAgIFJldHVybnMgYSBQeXRob24gZmxvYXQuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCgoKZGVmIG1ham9yaXR5X2NsYXNzKAogICAgZXhhbXBsZXM6IExpc3RbRGljdFtzdHIsIEFueV1dLAogICAgdGFyZ2V0X2F0dHI6IHN0cgopIC0+IEFueToKICAgICIiIgogICAgUmV0dXJuIHRoZSBtb3N0IGNvbW1vbiB2YWx1ZSBvZiBgdGFyZ2V0X2F0dHJgIGluIGBleGFtcGxlc2AuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCgoKZGVmIGxlYXJuX2RlY2lzaW9uX3RyZWUoCiAgICBleGFtcGxlczogTGlzdFtEaWN0W3N0ciwgQW55XV0sCiAgICBhdHRyaWJ1dGVzOiBMaXN0W3N0cl0sCiAgICB0YXJnZXRfYXR0cjogc3RyCikgLT4gVW5pb25bRGljdFtzdHIsIEFueV0sIEFueV06CiAgICAiIiIKICAgIExlYXJuIGEgZGVjaXNpb24gdHJlZSB1c2luZyB0aGUgSUQzIGFsZ29yaXRobS4KICAgIFJldHVybnMgZWl0aGVyIGEgbmVzdGVkIGRpY3QgcmVwcmVzZW50aW5nIHRoZSB0cmVlIG9yIGEgY2xhc3MgbGFiZWwgYXQgdGhlIGxlYXZlcy4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "20"
    },
    {
        "description": "Write a Python function that implements a **deterministic** version of the Pegasos algorithm to train a kernel SVM classifier from scratch. The function should take a dataset (as a 2D NumPy array where each row represents a data sample and each column represents a feature), a label vector (1D NumPy array where each entry corresponds to the label of the sample), and training parameters such as the choice of kernel (linear or RBF), regularization parameter (lambda), and the number of iterations. Note that while the original Pegasos algorithm is stochastic (it selects a single random sample at each step), **this problem requires using all samples in every iteration** (i.e., **no random sampling**). The function should perform binary classification and return the model's alpha coefficients and bias.",
        "mdx_file": "7871d394-7c00-4e65-9fcc-dca719122efe.mdx",
        "id": "21",
        "test_cases": [
            {
                "test": "print(pegasos_kernel_svm(np.array([[1, 2], [2, 3], [3, 1], [4, 1]]), np.array([1, 1, -1, -1]), kernel='linear', lambda_val=0.01, iterations=100))",
                "expected_output": "([100.0, 0.0, -100.0, -100.0], -937.4755)"
            },
            {
                "test": "print(pegasos_kernel_svm(np.array([[1, 2], [2, 3], [3, 1], [4, 1]]), np.array([1, 1, -1, -1]), kernel='rbf', lambda_val=0.01, iterations=100, sigma=0.5))",
                "expected_output": "([100.0, 99.0, -100.0, -100.0], -115.0)"
            }
        ],
        "solution": "\nimport numpy as np\n\ndef linear_kernel(x, y):\n    return np.dot(x, y)\n\ndef rbf_kernel(x, y, sigma=1.0):\n    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n\ndef pegasos_kernel_svm(data, labels, kernel='linear', lambda_val=0.01, iterations=100, sigma=1.0):\n    n_samples = len(data)\n    alphas = np.zeros(n_samples)\n    b = 0\n\n    for t in range(1, iterations + 1):\n        for i in range(n_samples):\n            eta = 1.0 / (lambda_val * t)\n            if kernel == 'linear':\n                kernel_func = linear_kernel\n            elif kernel == 'rbf':\n                kernel_func = lambda x, y: rbf_kernel(x, y, sigma)\n    \n            decision = sum(alphas[j] * labels[j] * kernel_func(data[j], data[i]) for j in range(n_samples)) + b\n            if labels[i] * decision < 1:\n                alphas[i] += eta * (labels[i] - lambda_val * alphas[i])\n                b += eta * labels[i]\n\n    return np.round(alphas,4).tolist(), np.round(b,4)",
        "difficulty": "hard",
        "likes": "0",
        "video": "",
        "dislikes": "0",
        "example": {
            "input": "data = np.array([[1, 2], [2, 3], [3, 1], [4, 1]]), labels = np.array([1, 1, -1, -1]), kernel = 'rbf', lambda_val = 0.01, iterations = 100, sigma = 1.0",
            "output": "alpha = [0.03, 0.02, 0.05, 0.01], b = -0.05",
            "reasoning": "Using the RBF kernel, the Pegasos algorithm iteratively updates the weights based on a sub-gradient descent method, taking into account the non-linear separability of the data induced by the kernel transformation."
        },
        "category": "Machine Learning",
        "starter_code": "def pegasos_kernel_svm(data: np.ndarray, labels: np.ndarray, kernel='linear', lambda_val=0.01, iterations=100,sigma=1.0) -> (list, float):\n\t# Your code here\n\treturn alphas, b",
        "title": "Pegasos Kernel SVM Implementation",
        "learn_section": "## Pegasos Algorithm for Kernel SVM (Deterministic Version)\n\n### Introduction\n\nThe **Pegasos Algorithm** (Primal Estimated sub-GrAdient SOlver for SVM) is a fast, iterative algorithm designed to train Support Vector Machines (SVM). While the original Pegasos algorithm uses stochastic updates by selecting one random sample per iteration, this problem requires a **deterministic version**meaning **every data sample is evaluated and considered in each iteration**. This deterministic approach ensures reproducibility and clarity, particularly useful for educational purposes.\n\n---\n\n### Key Concepts\n\n**Kernel Trick**:  \nSVM typically separates data classes using a linear hyperplane. However, real-world data isn't always linearly separable. The **Kernel Trick** implicitly maps input data into a higher-dimensional feature space, making it easier to separate non-linear data.\n\nCommon kernel functions include:\n- **Linear Kernel**: $K(x,y) = x \\cdot y$\n- **Radial Basis Function (RBF) Kernel**: $K(x,y) = e^{-\\frac{\\|x-y\\|^2}{2\\sigma^2}}$\n\n**Regularization Parameter ($\\lambda$)**:  \nThis parameter balances how closely the model fits training data against the complexity of the model, helping to prevent overfitting.\n\n**Sub-gradient Descent**:  \nPegasos optimizes the SVM objective function using iterative parameter updates based on the sub-gradient of the hinge loss.\n\n---\n\n### Deterministic Pegasos Algorithm Steps\n\nGiven training samples $(x_i, y_i)$, labels $y_i \\in \\{-1, 1\\}$, kernel function $K$, regularization parameter $\\lambda$, and total iterations $T$:\n\n1. **Initialize** alpha coefficients $\\alpha_i = 0$ and bias $b = 0$.\n2. For each iteration $t = 1, 2, \\dots, T$:\n    - Compute learning rate: $$\\eta_t = \\frac{1}{\\lambda t}$$\n    - For each training sample $(x_i, y_i)$:\n        - Compute decision value:\n        $$f(x_i) = \\sum_{j}\\alpha_j y_j K(x_j, x_i) + b$$\n        - If the margin constraint $y_i f(x_i) < 1$ is violated, update parameters:\n        $$\n        \\alpha_i \\leftarrow \\alpha_i + \\eta_t(y_i - \\lambda \\alpha_i)\n        $$\n        $$\n        b \\leftarrow b + \\eta_t y_i\n        $$\n\n---\n\n### Example (Conceptual Explanation)\n\nConsider a simple dataset:\n\n- **Data**:  \n$X = [[1,2],[2,3],[3,1],[4,1]]$, $Y = [1,1,-1,-1]$\n\n- **Parameters**: Linear kernel, $\\lambda = 0.01$, iterations = $1$\n\nInitially, parameters ($\\alpha, b$) start at zero. For each sample, you calculate the decision value. Whenever a sample violates the margin constraint ($y_i f(x_i) < 1$), you update the corresponding $\\alpha_i$ and bias $b$ as described. After looping through all samples for the specified iterations, you obtain the trained parameters.\n\n---\n\n### Important Implementation Notes:\n- Always iterate through **all samples** in every iteration (**no stochastic/random sampling**).\n- Clearly distinguish kernel function choices in your implementation.\n- After training, predictions for new data $x$ are made using:\n$$\n\\hat{y}(x) = \\text{sign}\\left(\\sum_{j}\\alpha_j y_j K(x_j, x) + b\\right)\n$$\n\nThis deterministic Pegasos variant clearly demonstrates how kernelized SVM training operates and simplifies the understanding of kernel methods.",
        "contributor": ""
    },
    {
        "description": "Write a Python function that computes the output of the sigmoid activation function given an input value z. The function should return the output rounded to four decimal places.",
        "mdx_file": "43e88c36-680f-4fd4-a992-b170a4306dff.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNpZ21vaWRfdGcoejogZmxvYXQpIC0+IGZsb2F0OgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBzaWdtb2lkIGFjdGl2YXRpb24gZnVuY3Rpb24gdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dDoKICAgICAgLSB6OiBmbG9hdCBvciB0aW55Z3JhZCBUZW5zb3Igc2NhbGFyCiAgICBSZXR1cm5zOgogICAgICAtIHNpZ21vaWQoeikgYXMgUHl0aG9uIGZsb2F0IHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "test_cases": [
            {
                "test": "print(sigmoid(0))",
                "expected_output": "0.5"
            },
            {
                "test": "print(sigmoid(1))",
                "expected_output": "0.7311"
            },
            {
                "test": "print(sigmoid(-1))",
                "expected_output": "0.2689"
            }
        ],
        "code": "import math\n\ndef sigmoid(z: float) -> float:\n\t#Your code here\n\treturn result",
        "solution": "\nimport math\ndef sigmoid(z: float) -> float:\n   result = 1 / (1 + math.exp(-z))\n   return round(result, 4)",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNpZ21vaWRfdGcoejogZmxvYXQpIC0+IGZsb2F0OgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBzaWdtb2lkIGFjdGl2YXRpb24gZnVuY3Rpb24gdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dDoKICAgICAgLSB6OiBmbG9hdCBvciB0aW55Z3JhZCBUZW5zb3Igc2NhbGFyCiAgICBSZXR1cm5zOgogICAgICAtIHNpZ21vaWQoeikgYXMgUHl0aG9uIGZsb2F0IHJvdW5kZWQgdG8gNCBkZWNpbWFscy4KICAgICIiIgogICAgdCA9IFRlbnNvcih6KQogICAgcmVzID0gKFRlbnNvcigxLjApIC8gKFRlbnNvcigxLjApICsgKC10KS5leHAoKSkpLm51bXB5KCkudG9saXN0KCkKICAgIHJldHVybiByb3VuZChyZXMsIDQpCg==",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/DL_PVRD-NOg",
        "marimo_link": "https://open-deep-ml.github.io/deepml-notebooks/22/",
        "difficulty": "easy",
        "example": {
            "input": "z = 0",
            "output": "0.5",
            "reasoning": "The sigmoid function is defined as σ(z) = 1 / (1 + exp(-z)). For z = 0, exp(-0) = 1, hence the output is 1 / (1 + 1) = 0.5."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import math\n\ndef sigmoid(z: float) -> float:\n\t#Your code here\n\treturn result",
        "learn_section": "\n## Understanding the Sigmoid Activation Function\n\nThe sigmoid activation function is crucial in neural networks, especially for binary classification tasks. It maps any real-valued number into the interval \\( (0, 1) \\), making it useful for modeling probability as an output.\n\n### Mathematical Definition\nThe sigmoid function is mathematically defined as:\n$$\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n$$\nwhere \\( z \\) is the input to the function.\n\n### Characteristics\n- **Output Range**: The output is always between 0 and 1.\n- **Shape**: The function has an \"S\" shaped curve.\n- **Gradient**: The gradient is highest near \\( z = 0 \\) and decreases as \\( z \\) moves away from 0 in either direction.\n\nThe sigmoid function is particularly useful for turning logits (raw prediction values) into probabilities in binary classification models.\n\n",
        "title": "Sigmoid Activation Function Understanding",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "print(sigmoid(0))",
                "expected_output": "0.5"
            },
            {
                "test": "print(sigmoid(1))",
                "expected_output": "0.7311"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "print(sigmoid_tg(0))",
                "expected_output": "0.5"
            },
            {
                "test": "print(sigmoid_tg(1))",
                "expected_output": "0.7311"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgc2lnbW9pZCh6OiBmbG9hdCkgLT4gZmxvYXQ6CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIHNpZ21vaWQgYWN0aXZhdGlvbiBmdW5jdGlvbi4KICAgIElucHV0OgogICAgICAtIHo6IGZsb2F0IG9yIHRvcmNoIHNjYWxhciB0ZW5zb3IKICAgIFJldHVybnM6CiAgICAgIC0gc2lnbW9pZCh6KSBhcyBQeXRob24gZmxvYXQgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICB6X3QgPSB0b3JjaC5hc190ZW5zb3IoeiwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICByZXMgPSB0b3JjaC5zaWdtb2lkKHpfdCkuaXRlbSgpCiAgICByZXR1cm4gcm91bmQocmVzLCA0KQo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgc2lnbW9pZCh6OiBmbG9hdCkgLT4gZmxvYXQ6CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIHNpZ21vaWQgYWN0aXZhdGlvbiBmdW5jdGlvbi4KICAgIElucHV0OgogICAgICAtIHo6IGZsb2F0IG9yIHRvcmNoIHNjYWxhciB0ZW5zb3IKICAgIFJldHVybnM6CiAgICAgIC0gc2lnbW9pZCh6KSBhcyBQeXRob24gZmxvYXQgcm91bmRlZCB0byA0IGRlY2ltYWxzLgogICAgIiIiCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "id": "22"
    },
    {
        "description": "Write a Python function that computes the softmax activation for a given list of scores. The function should return the softmax values as a list, each rounded to four decimal places.",
        "mdx_file": "49a6d7c0-5d07-4ed9-a51a-a836fdc7b96b.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNvZnRtYXhfdGcoc2NvcmVzOiBsaXN0W2Zsb2F0XSkgLT4gbGlzdFtmbG9hdF06CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbiB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0OgogICAgICAtIHNjb3JlczogbGlzdCBvZiBmbG9hdHMgKGxvZ2l0cykKICAgIFJldHVybnM6CiAgICAgIC0gbGlzdCBvZiBmbG9hdHMgcmVwcmVzZW50aW5nIHRoZSBzb2Z0bWF4IHByb2JhYmlsaXRpZXMsCiAgICAgICAgZWFjaCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(softmax([1, 2, 3]))",
                "expected_output": "[0.09, 0.2447, 0.6652]"
            },
            {
                "test": "print(softmax([1, 1, 1]))",
                "expected_output": "[0.3333, 0.3333, 0.3333]"
            },
            {
                "test": "print(softmax([-1, 0, 5]))",
                "expected_output": "[0.0025, 0.0067, 0.9909]"
            }
        ],
        "solution": "\nimport math\ndef softmax(scores: list[float]) -> list[float]:\n    exp_scores = [math.exp(score) for score in scores]\n    sum_exp_scores = sum(exp_scores)\n    probabilities = [round(score / sum_exp_scores, 4) for score in exp_scores]\n    return probabilities",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNvZnRtYXhfdGcoc2NvcmVzOiBsaXN0W2Zsb2F0XSkgLT4gbGlzdFtmbG9hdF06CiAgICAiIiIKICAgIENvbXB1dGUgdGhlIHNvZnRtYXggYWN0aXZhdGlvbiBmdW5jdGlvbiB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0OgogICAgICAtIHNjb3JlczogbGlzdCBvZiBmbG9hdHMgKGxvZ2l0cykKICAgIFJldHVybnM6CiAgICAgIC0gbGlzdCBvZiBmbG9hdHMgcmVwcmVzZW50aW5nIHRoZSBzb2Z0bWF4IHByb2JhYmlsaXRpZXMsCiAgICAgICAgZWFjaCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIHQgPSBUZW5zb3Ioc2NvcmVzKQogICAgdF9tYXggPSB0Lm1heCgpCiAgICBleHBfc2NvcmVzID0gKHQgLSB0X21heCkuZXhwKCkKICAgIHByb2JzID0gZXhwX3Njb3JlcyAvIGV4cF9zY29yZXMuc3VtKCkKICAgIHByb2JzX2xpc3QgPSBwcm9icy5udW1weSgpLnRvbGlzdCgpCiAgICByZXR1cm4gW3JvdW5kKHAsIDQpIGZvciBwIGluIHByb2JzX2xpc3RdCg==",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/WIUTXGFAuXY",
        "marimo_link": "https://adityakhalkar.github.io/Deep-ML-x-Marimo/23",
        "difficulty": "easy",
        "example": {
            "input": "scores = [1, 2, 3]",
            "output": "[0.0900, 0.2447, 0.6652]",
            "reasoning": "The softmax function converts a list of values into a probability distribution. The probabilities are proportional to the exponential of each element divided by the sum of the exponentials of all elements in the list."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import math\n\ndef softmax(scores: list[float]) -> list[float]:\n\t# Your code here\n\treturn probabilities",
        "title": "Softmax Activation Function Implementation ",
        "learn_section": "\n## Understanding the Softmax Activation Function\n\nThe softmax function is a generalization of the sigmoid function and is used in the output layer of a neural network model that handles multi-class classification tasks.\n\n### Mathematical Definition\nThe softmax function is mathematically represented as:\n$$\n\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n$$\n\n### Characteristics\n- **Output Range**: Each output value is between 0 and 1, and the sum of all outputs is 1.\n- **Probability Distribution**: It transforms scores into probabilities, making them easier to interpret and useful for classification tasks.\n\nThe softmax function is essential for models where the output needs to represent a probability distribution across multiple classes.\n\n",
        "contributor": null,
        "pytorch_test_cases": [
            {
                "test": "print(softmax([1, 2, 3]))",
                "expected_output": "[0.09, 0.2447, 0.6652]"
            },
            {
                "test": "print(softmax([1, 1, 1]))",
                "expected_output": "[0.3333, 0.3333, 0.3333]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "print(softmax_tg([1, 2, 3]))",
                "expected_output": "[0.09, 0.2447, 0.6652]"
            },
            {
                "test": "print(softmax_tg([1, 1, 1]))",
                "expected_output": "[0.3333, 0.3333, 0.3333]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubi5mdW5jdGlvbmFsIGFzIEYKCmRlZiBzb2Z0bWF4KHNjb3JlczogbGlzdFtmbG9hdF0pIC0+IGxpc3RbZmxvYXRdOgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBzb2Z0bWF4IGFjdGl2YXRpb24gZnVuY3Rpb24gdXNpbmcgUHlUb3JjaCdzIGJ1aWx0LWluIEFQSS4KICAgIElucHV0OgogICAgICAtIHNjb3JlczogbGlzdCBvZiBmbG9hdHMgKGxvZ2l0cykKICAgIFJldHVybnM6CiAgICAgIC0gbGlzdCBvZiBmbG9hdHMgcmVwcmVzZW50aW5nIHRoZSBzb2Z0bWF4IHByb2JhYmlsaXRpZXMsCiAgICAgICAgZWFjaCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgIHNjb3Jlc190ID0gdG9yY2guYXNfdGVuc29yKHNjb3JlcywgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBwcm9icyA9IEYuc29mdG1heChzY29yZXNfdCwgZGltPTApCiAgICBwcm9icyA9IHRvcmNoLnJvdW5kKHByb2JzICogMTAwMDApIC8gMTAwMDAKICAgIHJldHVybiBwcm9icy50b2xpc3QoKQo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubi5mdW5jdGlvbmFsIGFzIEYKCmRlZiBzb2Z0bWF4KHNjb3JlczogbGlzdFtmbG9hdF0pIC0+IGxpc3RbZmxvYXRdOgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBzb2Z0bWF4IGFjdGl2YXRpb24gZnVuY3Rpb24gdXNpbmcgUHlUb3JjaCdzIGJ1aWx0LWluIEFQSS4KICAgIElucHV0OgogICAgICAtIHNjb3JlczogbGlzdCBvZiBmbG9hdHMgKGxvZ2l0cykKICAgIFJldHVybnM6CiAgICAgIC0gbGlzdCBvZiBmbG9hdHMgcmVwcmVzZW50aW5nIHRoZSBzb2Z0bWF4IHByb2JhYmlsaXRpZXMsCiAgICAgICAgZWFjaCByb3VuZGVkIHRvIDQgZGVjaW1hbHMuCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "id": "23"
    },
    {
        "description": "Write a Python function that simulates a single neuron with a sigmoid activation function for binary classification, handling multidimensional input features. The function should take a list of feature vectors (each vector representing multiple features for an example), associated true binary labels, and the neuron's weights (one for each feature) and bias as input. It should return the predicted probabilities after sigmoid activation and the mean squared error between the predicted probabilities and the true labels, both rounded to four decimal places.",
        "mdx_file": "6c479c0a-5d7a-47dd-8f64-e80f018be912.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgpmcm9tIHR5cGluZyBpbXBvcnQgTGlzdCwgVHVwbGUKCmRlZiBzaW5nbGVfbmV1cm9uX21vZGVsX3RnKAogICAgZmVhdHVyZXM6IExpc3RbTGlzdFtmbG9hdF1dLAogICAgbGFiZWxzOiBMaXN0W2Zsb2F0XSwKICAgIHdlaWdodHM6IExpc3RbZmxvYXRdLAogICAgYmlhczogZmxvYXQKKSAtPiBUdXBsZVtMaXN0W2Zsb2F0XSwgZmxvYXRdOgogICAgIiIiCiAgICBDb21wdXRlIG91dHB1dCBwcm9iYWJpbGl0aWVzIGFuZCBNU0UgZm9yIGEgc2luZ2xlIG5ldXJvbiB1c2luZyB0aW55Z3JhZC4KICAgIFVzZXMgYnVpbHQtaW4gc2lnbW9pZCBhbmQgbWVhbiBvcGVyYXRpb25zLgogICAgIiIiCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "test_cases": [
            {
                "test": "print(single_neuron_model([[0.5, 1.0], [-1.5, -2.0], [2.0, 1.5]], [0, 1, 0], [0.7, -0.4], -0.1))",
                "expected_output": "([0.4626, 0.4134, 0.6682], 0.3349)"
            },
            {
                "test": "print(single_neuron_model([[1, 2], [2, 3], [3, 1]], [1, 0, 1], [0.5, -0.2], 0))",
                "expected_output": "([0.525, 0.5987, 0.7858], 0.21)"
            }
        ],
        "solution": "\nimport math\ndef single_neuron_model(features, labels, weights, bias):\n    probabilities = []\n    for feature_vector in features:\n        z = sum(weight * feature for weight, feature in zip(weights, feature_vector)) + bias\n        prob = 1 / (1 + math.exp(-z))\n        probabilities.append(round(prob, 4))\n    \n    mse = sum((prob - label) ** 2 for prob, label in zip(probabilities, labels)) / len(labels)\n    mse = round(mse, 4)\n    \n    return probabilities, mse",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgpmcm9tIHR5cGluZyBpbXBvcnQgTGlzdCwgVHVwbGUKCmRlZiBzaW5nbGVfbmV1cm9uX21vZGVsX3RnKAogICAgZmVhdHVyZXM6IExpc3RbTGlzdFtmbG9hdF1dLAogICAgbGFiZWxzOiBMaXN0W2Zsb2F0XSwKICAgIHdlaWdodHM6IExpc3RbZmxvYXRdLAogICAgYmlhczogZmxvYXQKKSAtPiBUdXBsZVtMaXN0W2Zsb2F0XSwgZmxvYXRdOgogICAgWCA9IFRlbnNvcihmZWF0dXJlcykKICAgIHcgPSBUZW5zb3Iod2VpZ2h0cykKICAgIGIgPSBiaWFzCiAgICBwcm9iczogTGlzdFtmbG9hdF0gPSBbXQogICAgZm9yIGkgaW4gcmFuZ2UobGVuKGZlYXR1cmVzKSk6CiAgICAgICAgeiA9IFhbaV0uZG90KHcpICsgYgogICAgICAgIHAgPSB6LnNpZ21vaWQoKS5udW1weSgpLnRvbGlzdCgpCiAgICAgICAgcHJvYnMuYXBwZW5kKHJvdW5kKHAsIDQpKQoKICAgIG1zZSA9IHN1bSgocCAtIHkpKioyIGZvciBwLCB5IGluIHppcChwcm9icywgbGFiZWxzKSkgLyBsZW4obGFiZWxzKQogICAgbXNlID0gcm91bmQobXNlLCA0KQoKICAgIHJldHVybiBwcm9icywgbXNlCg==",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/fK4QaDZ9UuU",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-24",
        "difficulty": "easy",
        "example": {
            "input": "features = [[0.5, 1.0], [-1.5, -2.0], [2.0, 1.5]], labels = [0, 1, 0], weights = [0.7, -0.4], bias = -0.1",
            "output": "([0.4626, 0.4134, 0.6682], 0.3349)",
            "reasoning": "For each input vector, the weighted sum is calculated by multiplying each feature by its corresponding weight, adding these up along with the bias, then applying the sigmoid function to produce a probability. The MSE is calculated as the average squared difference between each predicted probability and the corresponding true label."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import math\n\ndef single_neuron_model(features: list[list[float]], labels: list[int], weights: list[float], bias: float) -> (list[float], float):\n\t# Your code here\n\treturn probabilities, mse",
        "learn_section": "\n## Single Neuron Model with Multidimensional Input and Sigmoid Activation\n\nThis task involves a neuron model designed for binary classification with multidimensional input features, using the sigmoid activation function to output probabilities. It also involves calculating the mean squared error (MSE) to evaluate prediction accuracy.\n\n### Mathematical Background\n\n**Neuron Output Calculation:**\n$$\nz = \\sum (weight_i \\times feature_i) + bias\n$$\n$$\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n$$\n\n**MSE Calculation:**\n$$\nMSE = \\frac{1}{n} \\sum (predicted - true)^2\n$$\n\n### Explanation of Terms\n- **\\( z \\)**: The sum of weighted inputs plus bias.\n- **\\( \\sigma(z) \\)**: The sigmoid activation output.\n- **\\( predicted \\)**: The probabilities after sigmoid activation.\n- **\\( true \\)**: The true binary labels.\n\n### Practical Implementation\n- Each feature vector is processed to calculate a combined weighted sum, which is then passed through the sigmoid function to determine the probability of the input belonging to the positive class.\n- **MSE** provides a measure of error, offering insights into the model's performance and aiding in its optimization.\n\n",
        "title": "Single Neuron",
        "contributor": [
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "probs, mse = single_neuron_model(\n    [[0.5, 1.0], [-1.5, -2.0], [2.0, 1.5]],\n    [0, 1, 0],\n    [0.7, -0.4],\n    -0.1\n)\nprint(([round(p,4) for p in probs], round(mse,4)))",
                "expected_output": "([0.4626, 0.4134, 0.6682], 0.3349)"
            },
            {
                "test": "probs, mse = single_neuron_model(\n    [[1, 2], [2, 3], [3, 1]],\n    [1, 0, 1],\n    [0.5, -0.2],\n    0\n)\nprint(([round(p,4) for p in probs], round(mse,4)))",
                "expected_output": "([0.525, 0.5987, 0.7858], 0.21)"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "print(single_neuron_model_tg(\n    [[0.5, 1.0], [-1.5, -2.0], [2.0, 1.5]],\n    [0, 1, 0],\n    [0.7, -0.4],\n    -0.1\n))",
                "expected_output": "([0.4626, 0.4134, 0.6682], 0.3349)"
            },
            {
                "test": "print(single_neuron_model_tg(\n    [[1, 2], [2, 3], [3, 1]],\n    [1, 0, 1],\n    [0.5, -0.2],\n    0\n))",
                "expected_output": "([0.525, 0.5987, 0.7858], 0.21)"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubi5mdW5jdGlvbmFsIGFzIEYKZnJvbSB0eXBpbmcgaW1wb3J0IExpc3QsIFR1cGxlCgpkZWYgc2luZ2xlX25ldXJvbl9tb2RlbCgKICAgIGZlYXR1cmVzOiBMaXN0W0xpc3RbZmxvYXRdXSwKICAgIGxhYmVsczogTGlzdFtmbG9hdF0sCiAgICB3ZWlnaHRzOiBMaXN0W2Zsb2F0XSwKICAgIGJpYXM6IGZsb2F0CikgLT4gVHVwbGVbTGlzdFtmbG9hdF0sIGZsb2F0XToKICAgIFggPSB0b3JjaC50ZW5zb3IoZmVhdHVyZXMsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgeSA9IHRvcmNoLnRlbnNvcihsYWJlbHMsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgdyA9IHRvcmNoLnRlbnNvcih3ZWlnaHRzLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIGIgPSB0b3JjaC50ZW5zb3IoYmlhcywgZHR5cGU9dG9yY2guZmxvYXQpCgogICAgbG9naXRzID0gWC5tYXRtdWwodykgKyBiCiAgICBwcm9ic190ID0gdG9yY2guc2lnbW9pZChsb2dpdHMpCiAgICBwcm9icyA9IHByb2JzX3QudG9saXN0KCkKCiAgICBtc2UgPSBGLm1zZV9sb3NzKHByb2JzX3QsIHksIHJlZHVjdGlvbj0nbWVhbicpLml0ZW0oKQoKICAgIHJldHVybiBwcm9icywgbXNlCg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubi5mdW5jdGlvbmFsIGFzIEYKZnJvbSB0eXBpbmcgaW1wb3J0IExpc3QsIFR1cGxlCgpkZWYgc2luZ2xlX25ldXJvbl9tb2RlbCgKICAgIGZlYXR1cmVzOiBMaXN0W0xpc3RbZmxvYXRdXSwKICAgIGxhYmVsczogTGlzdFtmbG9hdF0sCiAgICB3ZWlnaHRzOiBMaXN0W2Zsb2F0XSwKICAgIGJpYXM6IGZsb2F0CikgLT4gVHVwbGVbTGlzdFtmbG9hdF0sIGZsb2F0XToKICAgICIiIgogICAgQ29tcHV0ZSBvdXRwdXQgcHJvYmFiaWxpdGllcyBhbmQgTVNFIGZvciBhIHNpbmdsZSBuZXVyb24uCiAgICBVc2VzIGJ1aWx0LWluIHNpZ21vaWQgYW5kIE1TRSBsb3NzLgogICAgIiIiCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "id": "24"
    },
    {
        "description": "Write a Python function that simulates a single neuron with sigmoid activation, and implements backpropagation to update the neuron's weights and bias. The function should take a list of feature vectors, associated true binary labels, initial weights, initial bias, a learning rate, and the number of epochs. The function should update the weights and bias using gradient descent based on the MSE loss, and return the updated weights, bias, and a list of MSE values for each epoch, each rounded to four decimal places.",
        "mdx_file": "6e616eee-86b4-47b5-ad64-1e8abf484884.mdx",
        "tinygrad_difficulty": "medium",
        "id": "25",
        "test_cases": [
            {
                "test": "print(train_neuron(np.array([[1.0, 2.0], [2.0, 1.0], [-1.0, -2.0]]), np.array([1, 0, 0]), np.array([0.1, -0.2]), 0.0, 0.1, 2))",
                "expected_output": "([0.1036, -0.1425], -0.0167, [0.3033, 0.2942])"
            },
            {
                "test": "print(train_neuron(np.array([[1, 2], [2, 3], [3, 1]]), np.array([1, 0, 1]), np.array([0.5, -0.2]), 0, 0.1, 3))",
                "expected_output": "([0.4892, -0.2301], 0.0029, [0.21, 0.2087, 0.2076])"
            }
        ],
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgpmcm9tIHR5cGluZyBpbXBvcnQgTGlzdCwgVHVwbGUKCgpkZWYgdHJhaW5fbmV1cm9uX3RnKAogICAgZmVhdHVyZXM6IExpc3RbTGlzdFtmbG9hdF1dLAogICAgbGFiZWxzOiAgIExpc3RbZmxvYXRdLAogICAgaW5pdGlhbF93ZWlnaHRzOiBMaXN0W2Zsb2F0XSwKICAgIGluaXRpYWxfYmlhczogZmxvYXQsCiAgICBsZWFybmluZ19yYXRlOiBmbG9hdCwKICAgIGVwb2NoczogaW50CikgLT4gVHVwbGVbTGlzdFtmbG9hdF0sIGZsb2F0LCBMaXN0W2Zsb2F0XV06CiAgICAiIiIKICAgIFRpbnlncmFkIHZlcnNpb24g4oCUIHNhbWUgY29udHJhY3QgYXMgUHlUb3JjaCBpbXBsZW1lbnRhdGlvbi4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "solution": "\nimport numpy as np\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef train_neuron(features, labels, initial_weights, initial_bias, learning_rate, epochs):\n    weights = np.array(initial_weights)\n    bias = initial_bias\n    features = np.array(features)\n    labels = np.array(labels)\n    mse_values = []\n\n    for _ in range(epochs):\n        z = np.dot(features, weights) + bias\n        predictions = sigmoid(z)\n        \n        mse = np.mean((predictions - labels) ** 2)\n        mse_values.append(round(mse, 4))\n\n        # Gradient calculation for weights and bias\n        errors = predictions - labels\n        weight_gradients = (2/len(labels)) * np.dot(features.T, errors * predictions * (1 - predictions))\n        bias_gradient = (2/len(labels)) * np.sum(errors * predictions * (1 - predictions))\n        \n        # Update weights and bias\n        weights -= learning_rate * weight_gradients\n        bias -= learning_rate * bias_gradient\n\n        # Round weights and bias for output\n        updated_weights = np.round(weights, 4)\n        updated_bias = round(bias, 4)\n\n    return updated_weights.tolist(), updated_bias, mse_values",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgpmcm9tIHR5cGluZyBpbXBvcnQgTGlzdCwgVHVwbGUKCgpkZWYgdHJhaW5fbmV1cm9uX3RnKAogICAgZmVhdHVyZXM6IExpc3RbTGlzdFtmbG9hdF1dLAogICAgbGFiZWxzOiAgIExpc3RbZmxvYXRdLAogICAgaW5pdGlhbF93ZWlnaHRzOiBMaXN0W2Zsb2F0XSwKICAgIGluaXRpYWxfYmlhczogZmxvYXQsCiAgICBsZWFybmluZ19yYXRlOiBmbG9hdCwKICAgIGVwb2NoczogaW50CikgLT4gVHVwbGVbTGlzdFtmbG9hdF0sIGZsb2F0LCBMaXN0W2Zsb2F0XV06CiAgICBYID0gVGVuc29yKGZlYXR1cmVzKQogICAgeSA9IFRlbnNvcihsYWJlbHMpLnJlc2hhcGUobGVuKGxhYmVscyksIDEpCiAgICB3ID0gVGVuc29yKGluaXRpYWxfd2VpZ2h0cykucmVzaGFwZShsZW4oaW5pdGlhbF93ZWlnaHRzKSwgMSkKICAgIGIgPSBUZW5zb3IoaW5pdGlhbF9iaWFzKQoKICAgIG1zZV92YWx1ZXM6IExpc3RbZmxvYXRdID0gW10KICAgIG4gPSBsZW4obGFiZWxzKQoKICAgIGZvciBfIGluIHJhbmdlKGVwb2Nocyk6CiAgICAgICAgeiA9IFgubWF0bXVsKHcpICsgYiAgICAgICAgICMgKG4sMSkKICAgICAgICBwcmVkcyA9IHouc2lnbW9pZCgpICAgICAgICAgIyAobiwxKQogICAgICAgIGVycm9ycyA9IHByZWRzIC0geSAgICAgICAgICAjIChuLDEpCgogICAgICAgIG1zZSA9IGZsb2F0KCgoZXJyb3JzKioyKS5tZWFuKCkpLm51bXB5KCkpCiAgICAgICAgbXNlX3ZhbHVlcy5hcHBlbmQocm91bmQobXNlLCA0KSkKCiAgICAgICAgc2lnbWFfcHJpbWUgPSBwcmVkcyAqICgxIC0gcHJlZHMpCiAgICAgICAgZGVsdGEgPSAoMi4wIC8gbikgKiBlcnJvcnMgKiBzaWdtYV9wcmltZSAgIyAobiwxKQoKICAgICAgICBncmFkX3cgPSBYLlQubWF0bXVsKGRlbHRhKSAgIyAoZiwxKQogICAgICAgIGdyYWRfYiA9IGRlbHRhLnN1bSgpCgogICAgICAgIHcgLT0gVGVuc29yKGxlYXJuaW5nX3JhdGUpICogZ3JhZF93CiAgICAgICAgYiAtPSBUZW5zb3IobGVhcm5pbmdfcmF0ZSkgKiBncmFkX2IKCiAgICB1cGRhdGVkX3dlaWdodHMgPSBbcm91bmQodmFsLCA0KSBmb3IgdmFsIGluIHcubnVtcHkoKS5mbGF0dGVuKCkudG9saXN0KCldCiAgICB1cGRhdGVkX2JpYXMgICAgPSByb3VuZChmbG9hdChiLm51bXB5KCkpLCA0KQogICAgcmV0dXJuIHVwZGF0ZWRfd2VpZ2h0cywgdXBkYXRlZF9iaWFzLCBtc2VfdmFsdWVzCg==",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "https://youtu.be/LPfsTFcFqU4",
        "difficulty": "medium",
        "dislikes": "0",
        "example": {
            "input": "features = [[1.0, 2.0], [2.0, 1.0], [-1.0, -2.0]], labels = [1, 0, 0], initial_weights = [0.1, -0.2], initial_bias = 0.0, learning_rate = 0.1, epochs = 2",
            "reasoning": "The neuron receives feature vectors and computes predictions using the sigmoid activation. Based on the predictions and true labels, the gradients of MSE loss with respect to weights and bias are computed and used to update the model parameters across epochs.",
            "output": "updated_weights = [0.1036, -0.1425], updated_bias = -0.0167, mse_values = [0.3033, 0.2942]"
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\ndef train_neuron(features: np.ndarray, labels: np.ndarray, initial_weights: np.ndarray, initial_bias: float, learning_rate: float, epochs: int) -> (np.ndarray, float, list[float]):\n\t# Your code here\n\treturn updated_weights, updated_bias, mse_values",
        "learn_section": "\n## Neural Network Learning with Backpropagation\n\nThis task involves implementing backpropagation for a single neuron in a neural network. The neuron processes inputs and updates parameters to minimize the Mean Squared Error (MSE) between predicted outputs and true labels.\n\n### Mathematical Background\n\n**Forward Pass**  \nCompute the neuron output by calculating the dot product of the weights and input features, and adding the bias:\n$$\nz = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n$$\n$$\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n$$\n\n**Loss Calculation (MSE)**  \nThe Mean Squared Error quantifies the error between the neuron's predictions and the actual labels:\n$$\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (\\sigma(z_i) - y_i)^2\n$$\n\n### Backward Pass (Gradient Calculation)\nCompute the gradient of the MSE with respect to each weight and the bias. This involves the partial derivatives of the loss function with respect to the output of the neuron, multiplied by the derivative of the sigmoid function:\n$$\n\\frac{\\partial MSE}{\\partial w_j} = \\frac{2}{n} \\sum_{i=1}^{n} (\\sigma(z_i) - y_i) \\sigma'(z_i) x_{ij}\n$$\n$$\n\\frac{\\partial MSE}{\\partial b} = \\frac{2}{n} \\sum_{i=1}^{n} (\\sigma(z_i) - y_i) \\sigma'(z_i)\n$$\n\n### Parameter Update\nUpdate each weight and the bias by subtracting a portion of the gradient, determined by the learning rate:\n$$\nw_j = w_j - \\alpha \\frac{\\partial MSE}{\\partial w_j}\n$$\n$$\nb = b - \\alpha \\frac{\\partial MSE}{\\partial b}\n$$\n\n### Practical Implementation\nThis process refines the neuron's ability to predict accurately by iteratively adjusting the weights and bias based on the error gradients, optimizing the neural network's performance over multiple iterations.\n\n",
        "title": "Single Neuron with Backpropagation",
        "contributor": [
            {
                "profile_link": "https://github.com/evintunador",
                "name": "evintunador"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nuw, ub, mses = train_neuron(\n    torch.tensor([[1.0, 2.0], [2.0, 1.0], [-1.0, -2.0]]),\n    torch.tensor([1, 0, 0]),\n    torch.tensor([0.1, -0.2]),\n    0.0,\n    0.1,\n    2\n)\nprint((uw, ub, mses))",
                "expected_output": "([0.1036, -0.1425], -0.0167, [0.3033, 0.2942])"
            },
            {
                "test": "import torch\nuw, ub, mses = train_neuron(\n    torch.tensor([[1, 2], [2, 3], [3, 1]]),\n    torch.tensor([1, 0, 1]),\n    torch.tensor([0.5, -0.2]),\n    0.0,\n    0.1,\n    3\n)\nprint((uw, ub, mses))",
                "expected_output": "([0.4892, -0.2301], 0.0029, [0.21, 0.2087, 0.2076])"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "uw, ub, mses = train_neuron_tg(\n    [[1.0, 2.0], [2.0, 1.0], [-1.0, -2.0]],\n    [1, 0, 0],\n    [0.1, -0.2],\n    0.0,\n    0.1,\n    2\n)\nprint((uw, ub, mses))",
                "expected_output": "([0.1036, -0.1425], -0.0167, [0.3033, 0.2942])"
            },
            {
                "test": "uw, ub, mses = train_neuron_tg(\n    [[1, 2], [2, 3], [3, 1]],\n    [1, 0, 1],\n    [0.5, -0.2],\n    0.0,\n    0.1,\n    3\n)\nprint((uw, ub, mses))",
                "expected_output": "([0.4892, -0.2301], 0.0029, [0.21, 0.2087, 0.2076])"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCmZyb20gdHlwaW5nIGltcG9ydCBMaXN0LCBUdXBsZSwgVW5pb24KCgpkZWYgdHJhaW5fbmV1cm9uKAogICAgZmVhdHVyZXM6IFVuaW9uW0xpc3RbTGlzdFtmbG9hdF1dLCB0b3JjaC5UZW5zb3JdLAogICAgbGFiZWxzOiAgIFVuaW9uW0xpc3RbZmxvYXRdLCAgICAgIHRvcmNoLlRlbnNvcl0sCiAgICBpbml0aWFsX3dlaWdodHM6IFVuaW9uW0xpc3RbZmxvYXRdLCB0b3JjaC5UZW5zb3JdLAogICAgaW5pdGlhbF9iaWFzOiBmbG9hdCwKICAgIGxlYXJuaW5nX3JhdGU6IGZsb2F0LAogICAgZXBvY2hzOiBpbnQKKSAtPiBUdXBsZVtMaXN0W2Zsb2F0XSwgZmxvYXQsIExpc3RbZmxvYXRdXToKCiAgICAjIEVuc3VyZSB0ZW5zb3JzCiAgICBYID0gdG9yY2guYXNfdGVuc29yKGZlYXR1cmVzLCBkdHlwZT10b3JjaC5mbG9hdCkKICAgIHkgPSB0b3JjaC5hc190ZW5zb3IobGFiZWxzLCAgIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgdyA9IHRvcmNoLmFzX3RlbnNvcihpbml0aWFsX3dlaWdodHMsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgYiA9IHRvcmNoLnRlbnNvcihpbml0aWFsX2JpYXMsIGR0eXBlPXRvcmNoLmZsb2F0KQoKICAgIG4gPSB5LnNoYXBlWzBdCiAgICBtc2VfdmFsdWVzOiBMaXN0W2Zsb2F0XSA9IFtdCgogICAgZm9yIF8gaW4gcmFuZ2UoZXBvY2hzKToKICAgICAgICAjIEZvcndhcmQKICAgICAgICB6ICAgICAgPSBYIEAgdyArIGIgICAgICAgICMgKG4sKQogICAgICAgIHByZWRzICA9IHRvcmNoLnNpZ21vaWQoeikgIyAobiwpCiAgICAgICAgZXJyb3JzID0gcHJlZHMgLSB5ICAgICAgICAjIChuLCkKCiAgICAgICAgIyBNU0UKICAgICAgICBtc2UgPSB0b3JjaC5tZWFuKGVycm9ycyoqMikuaXRlbSgpCiAgICAgICAgbXNlX3ZhbHVlcy5hcHBlbmQocm91bmQobXNlLCA0KSkKCiAgICAgICAgIyBNYW51YWwgZ3JhZGllbnRzIChjaGFpbi1ydWxlKTogZE1TRS9keiA9IDIvbiAqIChwcmVkcy15KSAqIM+DJyh6KQogICAgICAgIHNpZ21hX3ByaW1lID0gcHJlZHMgKiAoMSAtIHByZWRzKQogICAgICAgIGRlbHRhICAgICAgID0gKDIuMCAvIG4pICogZXJyb3JzICogc2lnbWFfcHJpbWUgICMgKG4sKQoKICAgICAgICBncmFkX3cgPSBYLnQoKSBAIGRlbHRhICAgICAgIyAoZiwpCiAgICAgICAgZ3JhZF9iID0gZGVsdGEuc3VtKCkgICAgICAgICMgc2NhbGFyCgogICAgICAgICMgUGFyYW1ldGVyIHVwZGF0ZSAoZ3JhZGllbnQgZGVzY2VudCkKICAgICAgICB3IC09IGxlYXJuaW5nX3JhdGUgKiBncmFkX3cKICAgICAgICBiIC09IGxlYXJuaW5nX3JhdGUgKiBncmFkX2IKCiAgICAjIFJvdW5kIGZpbmFsIHBhcmFtcyBmb3IgcmV0dXJuCiAgICB1cGRhdGVkX3dlaWdodHMgPSBbcm91bmQodmFsLCA0KSBmb3IgdmFsIGluIHcudG9saXN0KCldCiAgICB1cGRhdGVkX2JpYXMgICAgPSByb3VuZChiLml0ZW0oKSwgNCkKICAgIHJldHVybiB1cGRhdGVkX3dlaWdodHMsIHVwZGF0ZWRfYmlhcywgbXNlX3ZhbHVlcwo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmZyb20gdHlwaW5nIGltcG9ydCBMaXN0LCBUdXBsZSwgVW5pb24KCgpkZWYgdHJhaW5fbmV1cm9uKAogICAgZmVhdHVyZXM6IFVuaW9uW0xpc3RbTGlzdFtmbG9hdF1dLCB0b3JjaC5UZW5zb3JdLAogICAgbGFiZWxzOiAgIFVuaW9uW0xpc3RbZmxvYXRdLCAgICAgIHRvcmNoLlRlbnNvcl0sCiAgICBpbml0aWFsX3dlaWdodHM6IFVuaW9uW0xpc3RbZmxvYXRdLCB0b3JjaC5UZW5zb3JdLAogICAgaW5pdGlhbF9iaWFzOiBmbG9hdCwKICAgIGxlYXJuaW5nX3JhdGU6IGZsb2F0LAogICAgZXBvY2hzOiBpbnQKKSAtPiBUdXBsZVtMaXN0W2Zsb2F0XSwgZmxvYXQsIExpc3RbZmxvYXRdXToKICAgICIiIgogICAgVHJhaW4gYSBzaW5nbGUgbmV1cm9uIChzaWdtb2lkIGFjdGl2YXRpb24pIHdpdGggbWVhbi1zcXVhcmVkLWVycm9yIGxvc3MuCgogICAgUmV0dXJucyAodXBkYXRlZF93ZWlnaHRzLCB1cGRhdGVkX2JpYXMsIG1zZV9wZXJfZXBvY2gpCiAgICDigJQgd2VpZ2h0cyAmIGJpYXMgYXJlIHJvdW5kZWQgdG8gNCBkZWNpbWFsczsgZWFjaCBNU0UgdmFsdWUgaXMgcm91bmRlZCB0b28uCiAgICAiIiIKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg=="
    },
    {
        "description": "Special thanks to Andrej Karpathy for making a video about this, if you haven't already check out his videos on YouTube https://youtu.be/VMj-3S1tku0?si=gjlnFP4o3JRN9dTg. Write a Python class similar to the provided 'Value' class that implements the basic autograd operations: addition, multiplication, and ReLU activation. The class should handle scalar values and should correctly compute gradients for these operations through automatic differentiation.",
        "mdx_file": "c9a4ef2e-c9b9-4653-8a48-c44af59a762e.mdx",
        "tinygrad_difficulty": "medium",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKY2xhc3MgVmFsdWU6CiAgICAiIiJTYW1lIGlkZWEsIGJ1dCB1c2luZyB0aW55Z3JhZOKAmXMgYXV0b21hdGljIGRpZmZlcmVudGlhdGlvbi4iIiIKCiAgICBkZWYgX19pbml0X18oc2VsZiwgZGF0YSwgX3RlbnNvcj1Ob25lKToKICAgICAgICBzZWxmLl90ID0gX3RlbnNvciBpZiBfdGVuc29yIGlzIG5vdCBOb25lIGVsc2UgVGVuc29yKGZsb2F0KGRhdGEpLCByZXF1aXJlc19ncmFkPVRydWUpCgogICAgQHByb3BlcnR5CiAgICBkZWYgZGF0YShzZWxmKToKICAgICAgICByZXR1cm4gZmxvYXQoc2VsZi5fdC5udW1weSgpKQoKICAgIEBwcm9wZXJ0eQogICAgZGVmIGdyYWQoc2VsZik6CiAgICAgICAgZyA9IHNlbGYuX3QuZ3JhZAogICAgICAgIHJldHVybiAwIGlmIGcgaXMgTm9uZSBlbHNlIGZsb2F0KGcubnVtcHkoKSkKCiAgICBkZWYgX19yZXByX18oc2VsZik6CiAgICAgICAgZGVmIGZtdCh4KToKICAgICAgICAgICAgcmV0dXJuIGludCh4KSBpZiBmbG9hdCh4KS5pc19pbnRlZ2VyKCkgZWxzZSByb3VuZCh4LCA0KQogICAgICAgIHJldHVybiBmIlZhbHVlKGRhdGE9e2ZtdChzZWxmLmRhdGEpfSwgZ3JhZD17Zm10KHNlbGYuZ3JhZCl9KSIKCiAgICBkZWYgX3dyYXAoc2VsZiwgb3RoZXIpOgogICAgICAgIHJldHVybiBvdGhlciBpZiBpc2luc3RhbmNlKG90aGVyLCBWYWx1ZSkgZWxzZSBWYWx1ZShvdGhlcikKCiAgICBkZWYgX19hZGRfXyhzZWxmLCBvdGhlcik6CiAgICAgICAgb3RoZXIgPSBzZWxmLl93cmFwKG90aGVyKQogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXNlbGYuX3QgKyBvdGhlci5fdCkKCiAgICBfX3JhZGRfXyA9IF9fYWRkX18KCiAgICBkZWYgX19tdWxfXyhzZWxmLCBvdGhlcik6CiAgICAgICAgb3RoZXIgPSBzZWxmLl93cmFwKG90aGVyKQogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXNlbGYuX3QgKiBvdGhlci5fdCkKCiAgICBfX3JtdWxfXyA9IF9fbXVsX18KCiAgICBkZWYgcmVsdShzZWxmKToKICAgICAgICByZXR1cm4gVmFsdWUoMCwgX3RlbnNvcj1zZWxmLl90LnJlbHUoKSkKCiAgICBkZWYgYmFja3dhcmQoc2VsZik6CiAgICAgICAgc2VsZi5fdC5iYWNrd2FyZCgpCg==",
        "test_cases": [
            {
                "test": "a = Value(2);b = Value(3);c = Value(10);d = a + b * c  ;e = Value(7) * Value(2);f = e + d;g = f.relu()  \ng.backward()\nprint(a,b,c,d,e,f,g)\n",
                "expected_output": " Value(data=2, grad=1) Value(data=3, grad=10) Value(data=10, grad=3) Value(data=32, grad=1) Value(data=14, grad=1) Value(data=46, grad=1) Value(data=46, grad=1)"
            }
        ],
        "solution": "\nclass Value:\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0\n        self._backward = lambda: None\n        self._prev = set(_children)\n        self._op = _op\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        def _backward():\n            self.grad += out.grad\n            other.grad += out.grad\n        out._backward = _backward\n        return out\n\n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        return out\n\n    def relu(self):\n        out = Value(0 if self.data < 0 else self.data, (self,), 'ReLU')\n        def _backward():\n            self.grad += (out.data > 0) * out.grad\n        out._backward = _backward\n        return out\n\n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        build_topo(self)\n        self.grad = 1\n        for v in reversed(topo):\n            v._backward()\n    def __repr__(self):\n        return f\"Value(data={self.data}, grad={self.grad})\"\n",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKY2xhc3MgVmFsdWU6CiAgICBkZWYgX19pbml0X18oc2VsZiwgZGF0YSwgX3RlbnNvcj1Ob25lKToKICAgICAgICBzZWxmLl90ID0gX3RlbnNvciBpZiBfdGVuc29yIGlzIG5vdCBOb25lIGVsc2UgVGVuc29yKGZsb2F0KGRhdGEpLCByZXF1aXJlc19ncmFkPVRydWUpCgogICAgQHByb3BlcnR5CiAgICBkZWYgZGF0YShzZWxmKToKICAgICAgICByZXR1cm4gZmxvYXQoc2VsZi5fdC5udW1weSgpKQoKICAgIEBwcm9wZXJ0eQogICAgZGVmIGdyYWQoc2VsZik6CiAgICAgICAgZyA9IHNlbGYuX3QuZ3JhZAogICAgICAgIHJldHVybiAwIGlmIGcgaXMgTm9uZSBlbHNlIGZsb2F0KGcubnVtcHkoKSkKCiAgICBkZWYgX19yZXByX18oc2VsZik6CiAgICAgICAgZGVmIGZtdCh4KToKICAgICAgICAgICAgcmV0dXJuIGludCh4KSBpZiBmbG9hdCh4KS5pc19pbnRlZ2VyKCkgZWxzZSByb3VuZCh4LCA0KQogICAgICAgIHJldHVybiBmIlZhbHVlKGRhdGE9e2ZtdChzZWxmLmRhdGEpfSwgZ3JhZD17Zm10KHNlbGYuZ3JhZCl9KSIKCiAgICBkZWYgX3dyYXAoc2VsZiwgb3RoZXIpOgogICAgICAgIHJldHVybiBvdGhlciBpZiBpc2luc3RhbmNlKG90aGVyLCBWYWx1ZSkgZWxzZSBWYWx1ZShvdGhlcikKCiAgICBkZWYgX19hZGRfXyhzZWxmLCBvdGhlcik6CiAgICAgICAgb3RoZXIgPSBzZWxmLl93cmFwKG90aGVyKQogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXNlbGYuX3QgKyBvdGhlci5fdCkKCiAgICBfX3JhZGRfXyA9IF9fYWRkX18KCiAgICBkZWYgX19tdWxfXyhzZWxmLCBvdGhlcik6CiAgICAgICAgb3RoZXIgPSBzZWxmLl93cmFwKG90aGVyKQogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXNlbGYuX3QgKiBvdGhlci5fdCkKCiAgICBfX3JtdWxfXyA9IF9fbXVsX18KCiAgICBkZWYgcmVsdShzZWxmKToKICAgICAgICByZXR1cm4gVmFsdWUoMCwgX3RlbnNvcj1zZWxmLl90LnJlbHUoKSkKCiAgICBkZWYgYmFja3dhcmQoc2VsZik6CiAgICAgICAgc2VsZi5fdC5iYWNrd2FyZCgpCg==",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": [
            "https://youtu.be/VMj-3S1tku0?si=gjlnFP4o3JRN9dTg",
            "https://youtu.be/heSdPbAfFH4"
        ],
        "difficulty": "medium",
        "dislikes": "0",
        "example": {
            "input": "a = Value(2)\n        b = Value(-3)\n        c = Value(10)\n        d = a + b * c\n        e = d.relu()\n        e.backward()\n        print(a, b, c, d, e)",
            "reasoning": "The output reflects the forward computation and gradients after backpropagation. The ReLU on 'd' zeros out its output and gradient due to the negative data value.",
            "output": "Value(data=2, grad=0) Value(data=-3, grad=0) Value(data=10, grad=0)"
        },
        "category": "Deep Learning",
        "starter_code": "class Value:\n\tdef __init__(self, data, _children=(), _op=''):\n\t\tself.data = data\n\t\tself.grad = 0\n\t\tself._backward = lambda: None\n\t\tself._prev = set(_children)\n\t\tself._op = _op\n\tdef __repr__(self):\n\t\treturn f\"Value(data={self.data}, grad={self.grad})\"\n\n\tdef __add__(self, other):\n\t\t # Implement addition here\n\t\tpass\n\n\tdef __mul__(self, other):\n\t\t# Implement multiplication here\n\t\tpass\n\n\tdef relu(self):\n\t\t# Implement ReLU here\n\t\tpass\n\n\tdef backward(self):\n\t\t# Implement backward pass here\n\t\tpass",
        "learn_section": "\n## Understanding Mathematical Concepts in Autograd Operations\n\n*First, watch the video in the Solution section.*\n\nThis task focuses on implementing basic automatic differentiation mechanisms for neural networks. The operations of addition, multiplication, and ReLU are fundamental to neural network computations and their training through backpropagation.\n\n### Mathematical Foundations\n\n**Addition (`__add__`)**  \n- **Forward Pass**: For two scalar values \\( a \\) and \\( b \\), their sum \\( s \\) is:\n  $$\n  s = a + b\n  $$\n- **Backward Pass**: The derivative of \\( s \\) with respect to both \\( a \\) and \\( b \\) is 1. During backpropagation, the gradient of the output is passed directly to both inputs.\n\n**Multiplication (`__mul__`)**  \n- **Forward Pass**: For two scalar values \\( a \\) and \\( b \\), their product \\( p \\) is:\n  $$\n  p = a \\times b\n  $$\n- **Backward Pass**: The gradient of \\( p \\) with respect to \\( a \\) is \\( b \\), and with respect to \\( b \\) is \\( a \\). During backpropagation, each input's gradient is the product of the other input and the output's gradient.\n\n**ReLU Activation (`relu`)**  \n- **Forward Pass**: The ReLU function is defined as:\n  $$\n  R(x) = \\max(0, x)\n  $$\n  This function outputs \\( x \\) if \\( x \\) is positive, and 0 otherwise.\n- **Backward Pass**: The derivative of the ReLU function is 1 for \\( x > 0 \\) and 0 for \\( x \\leq 0 \\). The gradient is propagated through the function only if the input is positive; otherwise, it stops.\n\n### Conceptual Application in Neural Networks\n- **Addition and Multiplication**: These operations are ubiquitous in neural networks, forming the basis for computing weighted sums of inputs in the neurons.\n- **ReLU Activation**: Commonly used as an activation function in neural networks due to its simplicity and effectiveness in introducing non-linearity, making learning complex patterns possible.\n\nUnderstanding these operations and their implications on gradient flow is crucial for designing and training effective neural network models. By implementing these from scratch, you gain deeper insights into the workings of more sophisticated deep learning libraries.\n\n",
        "title": "Implementing Basic Autograd Operations",
        "contributor": null,
        "pytorch_test_cases": [
            {
                "test": "a = Value(2); b = Value(3); c = Value(10); d = a + b * c; e = Value(7) * Value(2); f = e + d; g = f.relu(); g.backward(); print(a, b, c, d, e, f, g)",
                "expected_output": "Value(data=2, grad=1) Value(data=3, grad=10) Value(data=10, grad=3) Value(data=32, grad=1) Value(data=14, grad=1) Value(data=46, grad=1) Value(data=46, grad=1)"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "a = Value(2); b = Value(3); c = Value(10); d = a + b * c; e = Value(7) * Value(2); f = e + d; g = f.relu(); g.backward(); print(a, b, c, d, e, f, g)",
                "expected_output": "Value(data=2, grad=1) Value(data=3, grad=10) Value(data=10, grad=3) Value(data=32, grad=1) Value(data=14, grad=1) Value(data=46, grad=1) Value(data=46, grad=1)"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpjbGFzcyBWYWx1ZToKICAgICIiIlNjYWxhciBhdXRvZ3JhZCB2YWx1ZSBwb3dlcmVkIGJ5IFB5VG9yY2ggdGVuc29ycy4iIiIKCiAgICBkZWYgX19pbml0X18oc2VsZiwgZGF0YSwgX3RlbnNvcj1Ob25lKToKICAgICAgICBzZWxmLl90ID0gX3RlbnNvciBpZiBfdGVuc29yIGlzIG5vdCBOb25lIGVsc2UgdG9yY2gudGVuc29yKGZsb2F0KGRhdGEpLCByZXF1aXJlc19ncmFkPVRydWUpCiAgICAgICAgc2VsZi5fdC5yZXRhaW5fZ3JhZCgpCgogICAgIyAtLS0tLSBoZWxwZXJzIC0tLS0tCiAgICBAcHJvcGVydHkKICAgIGRlZiBkYXRhKHNlbGYpOgogICAgICAgIHJldHVybiBzZWxmLl90Lml0ZW0oKQoKICAgIEBwcm9wZXJ0eQogICAgZGVmIGdyYWQoc2VsZik6CiAgICAgICAgZyA9IHNlbGYuX3QuZ3JhZAogICAgICAgIHJldHVybiAwIGlmIGcgaXMgTm9uZSBlbHNlIGcuaXRlbSgpCgogICAgZGVmIF9fcmVwcl9fKHNlbGYpOgogICAgICAgIGRlZiBmbXQoeCk6CiAgICAgICAgICAgIHJldHVybiBpbnQoeCkgaWYgZmxvYXQoeCkuaXNfaW50ZWdlcigpIGVsc2Ugcm91bmQoeCwgNCkKICAgICAgICByZXR1cm4gZiJWYWx1ZShkYXRhPXtmbXQoc2VsZi5kYXRhKX0sIGdyYWQ9e2ZtdChzZWxmLmdyYWQpfSkiCgogICAgZGVmIF93cmFwKHNlbGYsIG90aGVyKToKICAgICAgICByZXR1cm4gb3RoZXIgaWYgaXNpbnN0YW5jZShvdGhlciwgVmFsdWUpIGVsc2UgVmFsdWUob3RoZXIpCgogICAgIyBhcml0aG1ldGljCiAgICBkZWYgX19hZGRfXyhzZWxmLCBvdGhlcik6CiAgICAgICAgb3RoZXIgPSBzZWxmLl93cmFwKG90aGVyKQogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXNlbGYuX3QgKyBvdGhlci5fdCkKCiAgICBfX3JhZGRfXyA9IF9fYWRkX18KCiAgICBkZWYgX19tdWxfXyhzZWxmLCBvdGhlcik6CiAgICAgICAgb3RoZXIgPSBzZWxmLl93cmFwKG90aGVyKQogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXNlbGYuX3QgKiBvdGhlci5fdCkKCiAgICBfX3JtdWxfXyA9IF9fbXVsX18KCiAgICAjIGFjdGl2YXRpb24KICAgIGRlZiByZWx1KHNlbGYpOgogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXRvcmNoLnJlbHUoc2VsZi5fdCkpCgogICAgIyBiYWNrLXByb3AKICAgIGRlZiBiYWNrd2FyZChzZWxmKToKICAgICAgICBzZWxmLl90LmJhY2t3YXJkKCkK",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpjbGFzcyBWYWx1ZToKICAgICIiIkEgdGlueSBzY2FsYXIgd3JhcHBlciB0aGF0IGRlbGVnYXRlcyBhbGwgZ3JhZGllbnQgd29yayB0byBQeVRvcmNoIGF1dG9ncmFkLiIiIgoKICAgIGRlZiBfX2luaXRfXyhzZWxmLCBkYXRhLCBfdGVuc29yPU5vbmUpOgogICAgICAgICMgbGVhZiBub2RlOiBjcmVhdGUgZnJlc2ggdGVuc29yIHdpdGggZ3JhZDsgaW50ZXJuYWwgbm9kZTogcmV1c2UgdGVuc29yCiAgICAgICAgc2VsZi5fdCA9IF90ZW5zb3IgaWYgX3RlbnNvciBpcyBub3QgTm9uZSBlbHNlIHRvcmNoLnRlbnNvcihmbG9hdChkYXRhKSwgcmVxdWlyZXNfZ3JhZD1UcnVlKQogICAgICAgICMgbWFrZSBzdXJlIGV2ZXJ5IFRlbnNvciAobGVhZiBvciBub3QpIGtlZXBzIGl0cyBncmFkIGZvciBwcmludGluZwogICAgICAgIHNlbGYuX3QucmV0YWluX2dyYWQoKQoKICAgICMgLS0tLS0tLSBjb252ZW5pZW5jZXMgLS0tLS0tLQogICAgQHByb3BlcnR5CiAgICBkZWYgZGF0YShzZWxmKToKICAgICAgICByZXR1cm4gc2VsZi5fdC5pdGVtKCkKCiAgICBAcHJvcGVydHkKICAgIGRlZiBncmFkKHNlbGYpOgogICAgICAgIGcgPSBzZWxmLl90LmdyYWQKICAgICAgICByZXR1cm4gMCBpZiBnIGlzIE5vbmUgZWxzZSBnLml0ZW0oKQoKICAgIGRlZiBfX3JlcHJfXyhzZWxmKToKICAgICAgICBkZWYgZm10KHgpOgogICAgICAgICAgICByZXR1cm4gaW50KHgpIGlmIGZsb2F0KHgpLmlzX2ludGVnZXIoKSBlbHNlIHJvdW5kKHgsIDQpCiAgICAgICAgcmV0dXJuIGYiVmFsdWUoZGF0YT17Zm10KHNlbGYuZGF0YSl9LCBncmFkPXtmbXQoc2VsZi5ncmFkKX0pIgoKICAgICMgZW5zdXJlIHJocyBpcyBWYWx1ZQogICAgZGVmIF93cmFwKHNlbGYsIG90aGVyKToKICAgICAgICByZXR1cm4gb3RoZXIgaWYgaXNpbnN0YW5jZShvdGhlciwgVmFsdWUpIGVsc2UgVmFsdWUob3RoZXIpCgogICAgIyAtLS0tLS0tIGFyaXRobWV0aWMgb3BzIC0tLS0tLS0KICAgIGRlZiBfX2FkZF9fKHNlbGYsIG90aGVyKToKICAgICAgICBvdGhlciA9IHNlbGYuX3dyYXAob3RoZXIpCiAgICAgICAgcmV0dXJuIFZhbHVlKDAsIF90ZW5zb3I9c2VsZi5fdCArIG90aGVyLl90KQoKICAgIF9fcmFkZF9fID0gX19hZGRfXwoKICAgIGRlZiBfX211bF9fKHNlbGYsIG90aGVyKToKICAgICAgICBvdGhlciA9IHNlbGYuX3dyYXAob3RoZXIpCiAgICAgICAgcmV0dXJuIFZhbHVlKDAsIF90ZW5zb3I9c2VsZi5fdCAqIG90aGVyLl90KQoKICAgIF9fcm11bF9fID0gX19tdWxfXwoKICAgICMgLS0tLS0tLSBhY3RpdmF0aW9uIC0tLS0tLS0KICAgIGRlZiByZWx1KHNlbGYpOgogICAgICAgIHJldHVybiBWYWx1ZSgwLCBfdGVuc29yPXRvcmNoLnJlbHUoc2VsZi5fdCkpCgogICAgIyAtLS0tLS0tIGJhY2stcHJvcCBlbnRyeSAtLS0tLS0tCiAgICBkZWYgYmFja3dhcmQoc2VsZik6CiAgICAgICAgc2VsZi5fdC5iYWNrd2FyZCgpCg==",
        "id": "26"
    },
    {
        "description": "Given basis vectors in two different bases B and C for R^3, write a Python function to compute the transformation matrix P from basis B to C.",
        "mdx_file": "635af2c4-1c05-4978-abff-538b14f56643.mdx",
        "test_cases": [
            {
                "test": "print(transform_basis([[1, 0, 0], [0, 1, 0], [0, 0, 1]], [[1, 2.3, 3], [4.4, 25, 6], [7.4, 8, 9]]))",
                "expected_output": "[[-0.6772, -0.0126, 0.2342], [-0.0184, 0.0505, -0.0275], [0.5732, -0.0345, -0.0569]]"
            },
            {
                "test": "print(transform_basis([[1,0],[0,1]],[[1,2],[9,2]]))",
                "expected_output": "[[-0.125, 0.125 ],[ 0.5625, -0.0625]]"
            }
        ],
        "solution": "import numpy as np\ndef transform_basis(B, C):\n    C = np.array(C)\n    B = np.array(B)\n    C_inv = np.linalg.inv(C)\n    P = np.dot(C_inv, B)\n    return P.tolist()",
        "difficulty": "easy",
        "video": "https://youtu.be/P2LTAUO1TdA?si=O8XAmMrfpZizOr81",
        "likes": "0",
        "example": {
            "input": "B = [[1, 0, 0], \n             [0, 1, 0], \n             [0, 0, 1]]\n        C = [[1, 2.3, 3], \n             [4.4, 25, 6], \n             [7.4, 8, 9]]",
            "output": "[[-0.6772, -0.0126, 0.2342],\n                [-0.0184, 0.0505, -0.0275],\n                [0.5732, -0.0345, -0.0569]]",
            "reasoning": "The transformation matrix P from basis B to C can be found using matrix operations involving the inverse of matrix C."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "def transform_basis(B: list[list[int]], C: list[list[int]]) -> list[list[float]]:\n\treturn P",
        "title": "Transformation Matrix from Basis B to C",
        "learn_section": "\n## Understanding Transformation Matrices\n\nA transformation matrix allows us to convert the coordinates of a vector in one basis to coordinates in another basis. For bases \\( B \\) and \\( C \\) of a vector space, the transformation matrix \\( P \\) from \\( B \\) to \\( C \\) is calculated as follows:\n\n### Steps to Calculate the Transformation Matrix\n1. **Inverse of Basis \\( C \\)**: First, find the inverse of the matrix representing basis \\( C \\), denoted \\( C^{-1} \\).\n2. **Matrix Multiplication**: Multiply \\( C^{-1} \\) by the matrix of basis \\( B \\). The result is the transformation matrix:\n   $$\n   P = C^{-1} \\cdot B\n   $$\n\nThis matrix \\( P \\) can be used to transform any vector coordinates from the \\( B \\) basis to the \\( C \\) basis.\n\n",
        "contributor": null,
        "id": "27"
    },
    {
        "description": "Given a 2x2 matrix, write a Python function to compute its Singular Value Decomposition (SVD). The function should return the matrices U, S, and V such that A = U * S * V, use the method described in this post https://metamerist.blogspot.com/2006/10/linear-algebra-for-graphics-geeks-svd.html",
        "mdx_file": "9ed3f67c-f01d-4d4d-b9a2-2e5fa7d61307.mdx",
        "test_cases": [
            {
                "test": "U,s,V = svd_2x2(np.array([[-10, 8], [10, -1]]))\nresult = U @ np.diag(s) @ V\nprint(result)",
                "expected_output": "[[-10, 8], [10, -1]]"
            },
            {
                "test": "U,s,V = svd_2x2(np.array([[1, 2], [3, 4]]))\nresult = U @ np.diag(s) @ V\nprint(result)",
                "expected_output": "[[1, 2], [3, 4]]"
            }
        ],
        "solution": "import numpy as np\n\ndef svd_2x2(A: np.ndarray) -> tuple:\n    y1, x1 = (A[1, 0] + A[0, 1]), (A[0, 0] - A[1, 1])\n    y2, x2 = (A[1, 0] - A[0, 1]), (A[0, 0] + A[1, 1])\n\n    h1 = np.sqrt(y1**2 + x1**2)\n    h2 = np.sqrt(y2**2 + x2**2)\n\n    t1 = x1 / h1\n    t2 = x2 / h2\n\n    cc = np.sqrt((1.0 + t1) * (1.0 + t2))\n    ss = np.sqrt((1.0 - t1) * (1.0 - t2))\n    cs = np.sqrt((1.0 + t1) * (1.0 - t2))\n    sc = np.sqrt((1.0 - t1) * (1.0 + t2))\n\n    c1, s1 = (cc - ss) / 2.0, (sc + cs) / 2.0\n    U = np.array([[-c1, -s1], [-s1, c1]])\n\n    s = np.array([(h1 + h2) / 2.0, abs(h1 - h2) / 2.0])\n\n    V = np.diag(1.0 / s) @ U.T @ A\n\n    return U, s, V\n    ",
        "difficulty": "hard",
        "likes": "0",
        "video": "",
        "example": {
            "input": "A = [[-10, 8], \n         [10, -1]]",
            "output": "(array([[  0.8, -0.6], [-0.6, -0.8]]), \n    array([15.65247584,  4.47213595]), \n    array([[ -0.89442719,  0.4472136], [ -0.4472136 , -0.89442719]]))",
            "reasoning": "The SVD of the matrix A is calculated using the eigenvalues and eigenvectors of A^T A and A A^T. The singular values are the square roots of the eigenvalues, and the eigenvectors form the columns of matrices U and V."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef svd_2x2(A: np.ndarray) -> tuple:\n\t# Your code here\n\tpass",
        "title": "SVD of a 2x2 Matrix using eigen values & vectors",
        "learn_section": "\n## Understanding Singular Value Decomposition (SVD)\n\nSingular Value Decomposition (SVD) is a method in linear algebra for decomposing a matrix into three other matrices. For a given matrix \\( A \\), SVD is represented as:\n$$\nA = U \\cdot S \\cdot V^T\n$$\n\n### Step-by-Step Method to Calculate the SVD of a 2x2 Matrix by Hand\n\n1. **Calculate \\( A^T A \\) and \\( A A^T \\)**  \n   Compute the product of the matrix with its transpose and the transpose of the matrix with itself. These matrices share the same eigenvalues.\n\n2. **Find the Eigenvalues**  \n   To find the eigenvalues of a 2x2 matrix, solve the characteristic equation:\n   $$\n   \\det(A - \\lambda I) = 0\n   $$\n   This results in a quadratic equation.\n\n3. **Compute the Singular Values**  \n   The singular values, which form the diagonal elements of the matrix \\( S \\), are the square roots of the eigenvalues.\n\n4. **Calculate the Eigenvectors**  \n   For each eigenvalue, solve the equation:\n   $$\n   (A - \\lambda I) \\mathbf{x} = 0\n   $$\n   to find the corresponding eigenvector. Normalize these eigenvectors to form the columns of \\( U \\) and \\( V \\).\n\n5. **Form the Matrices \\( U \\), \\( S \\), and \\( V \\)**  \n   Combine the singular values and eigenvectors to construct the matrices \\( U \\), \\( S \\), and \\( V \\) such that:\n   $$\n   A = U \\cdot S \\cdot V^T\n   $$\n\n### Additional Notes\n- This method involves solving quadratic equations to find eigenvalues and eigenvectors and normalizing these vectors to unit length.\n- **Resources**:  \n  - *Linear Algebra for Graphics Geeks (SVD-IX) by METAMERIST* [Google Search]  \n  - *Robust Algorithm for 2×2 SVD*\n\nThis explanation provides a clear and structured overview of how to calculate the SVD of a 2x2 matrix by hand.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/brentspell",
                "name": "brentspell"
            },
            {
                "profile_link": "https://github.com/EpsIotaPi",
                "name": "EpsIotaPi"
            }
        ],
        "id": "28"
    },
    {
        "description": "Write a Python function to perform a random shuffle of the samples in two numpy arrays, X and y, while maintaining the corresponding order between them. The function should have an optional seed parameter for reproducibility.",
        "mdx_file": "1184d513-541a-408b-a342-16f2a455f12d.mdx",
        "test_cases": [
            {
                "test": "print(shuffle_data(np.array([[1, 2], [3, 4], [5, 6], [7, 8]]), np.array([1, 2, 3, 4]), seed=42))",
                "expected_output": "(array([[3, 4], [7, 8], [1, 2], [5, 6]]), array([2, 4, 1, 3]))"
            },
            {
                "test": "print(shuffle_data(np.array([[1, 1], [2, 2], [3, 3], [4, 4]]), np.array([10, 20, 30, 40]), seed=24))",
                "expected_output": "(array([[4, 4],[2, 2],[1, 1],[3, 3]]), array([40, 20, 10, 30]))"
            }
        ],
        "solution": "import numpy as np\n\ndef shuffle_data(X, y, seed=None):\n    if seed:\n        np.random.seed(seed)\n    idx = np.arange(X.shape[0])\n    np.random.shuffle(idx)\n    return X[idx], y[idx]\n    ",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "X = np.array([[1, 2], \n                  [3, 4], \n                  [5, 6], \n                  [7, 8]])\n    y = np.array([1, 2, 3, 4])",
            "output": "(array([[5, 6],\n                    [1, 2],\n                    [7, 8],\n                    [3, 4]]), \n             array([3, 1, 4, 2]))",
            "reasoning": "The samples in X and y are shuffled randomly, maintaining the correspondence between the samples in both arrays."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef shuffle_data(X, y, seed=None):\n\t# Your code here\n\tpass",
        "title": "Random Shuffle of Dataset",
        "learn_section": "\n## Understanding Dataset Shuffling\n\nRandom shuffling of a dataset is a common preprocessing step in machine learning to ensure that the data is randomly distributed before training a model. This helps to avoid any potential biases that may arise from the order in which data is presented to the model.\n\n### Step-by-Step Method to Shuffle a Dataset\n\n1. **Generate a Random Index Array**  \n   Create an array of indices corresponding to the number of samples in the dataset.\n\n2. **Shuffle the Indices**  \n   Use a random number generator to shuffle the array of indices.\n\n3. **Reorder the Dataset**  \n   Use the shuffled indices to reorder the samples in both \\( X \\) and \\( y \\).\n\n### Key Point\nThis method ensures that the correspondence between \\( X \\) and \\( y \\) is maintained after shuffling, preserving the relationship between features and labels.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            }
        ],
        "id": "29"
    },
    {
        "description": "Write a Python function that reshapes a given matrix into a specified shape. if it cant be reshaped return back an empty list `[ ]`",
        "mdx_file": "6a908ce1-b2e5-4832-b9a7-10930acdb640.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHJlc2hhcGVfbWF0cml4X3RnKGEsIG5ld19zaGFwZSkgLT4gVGVuc29yOgogICAgIiIiCiAgICBSZXNoYXBlIGEgMkQgbWF0cml4IGBhYCB0byBzaGFwZSBgbmV3X3NoYXBlYCB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRpbnlncmFkIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgVGVuc29yIG9mIHNoYXBlIGBuZXdfc2hhcGVgLCBvciBhbiBlbXB0eSBUZW5zb3Igb24gbWlzbWF0Y2guCiAgICAiIiIKICAgICMgRGltZW5zaW9uIGNoZWNrCiAgICBpZiBsZW4oYSkgKiBsZW4oYVswXSkgIT0gbmV3X3NoYXBlWzBdICogbmV3X3NoYXBlWzFdOgogICAgICAgIHJldHVybiBUZW5zb3IoW10pCiAgICAjIENvbnZlcnQgdG8gVGVuc29yIGFuZCByZXNoYXBlCiAgICBhX3QgPSBUZW5zb3IoYSkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(reshape_matrix([[1,2,3,4],[5,6,7,8]], (4, 2)))",
                "expected_output": "[[1, 2], [3, 4], [5, 6], [7, 8]]"
            },
            {
                "test": "print(reshape_matrix([[1, 2, 3, 4], [5, 6, 7, 8]], (1, 4)))",
                "expected_output": "[]"
            },
            {
                "test": "print(reshape_matrix([[1,2,3],[4,5,6]], (3, 2)))",
                "expected_output": "[[1, 2], [3, 4], [5, 6]]"
            },
            {
                "test": "print(reshape_matrix([[1,2,3,4],[5,6,7,8]], (2, 4)))",
                "expected_output": "[[1, 2, 3, 4], [5, 6, 7, 8]]"
            }
        ],
        "code": "import numpy as np\n\ndef reshape_matrix(a: list[list[int|float]], new_shape: tuple[int, int]) -> list[list[int|float]]:\n\t#Write your code here and return a python list after reshaping by using numpy's tolist() method\n\treturn reshaped_matrix",
        "solution": "import numpy as np\n\ndef reshape_matrix(a: list[list[int|float]], new_shape: tuple[int|float]) -> list[list[int|float]]:\n    # Not compatible case\n    if len(a)*len(a[0]) != new_shape[0]*new_shape[1]:\n        return []\n    return np.array(a).reshape(new_shape).tolist()",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHJlc2hhcGVfbWF0cml4X3RnKGEsIG5ld19zaGFwZSkgLT4gVGVuc29yOgogICAgIiIiCiAgICBSZXNoYXBlIGEgMkQgbWF0cml4IGBhYCB0byBzaGFwZSBgbmV3X3NoYXBlYCB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRpbnlncmFkIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgVGVuc29yIG9mIHNoYXBlIGBuZXdfc2hhcGVgLCBvciBhbiBlbXB0eSBUZW5zb3Igb24gbWlzbWF0Y2guCiAgICAiIiIKICAgICMgRGltZW5zaW9uIGNoZWNrCiAgICBpZiBsZW4oYSkgKiBsZW4oYVswXSkgIT0gbmV3X3NoYXBlWzBdICogbmV3X3NoYXBlWzFdOgogICAgICAgIHJldHVybiBUZW5zb3IoW10pCiAgICBhX3QgPSBUZW5zb3IoYSkKICAgIHJldHVybiBhX3QucmVzaGFwZShuZXdfc2hhcGUpCg==",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/19FD49nPH6w?si=VrJh7RV27naO2V3o",
        "marimo_link": "",
        "difficulty": "easy",
        "dislikes": "0",
        "example": {
            "input": "a = [[1,2,3,4],[5,6,7,8]], new_shape = (4, 2)",
            "output": "[[1, 2], [3, 4], [5, 6], [7, 8]]",
            "reasoning": "The given matrix is reshaped from 2x4 to 4x2."
        },
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef reshape_matrix(a: list[list[int|float]], new_shape: tuple[int, int]) -> list[list[int|float]]:\n\t#Write your code here and return a python list after reshaping by using numpy's tolist() method\n\treturn reshaped_matrix",
        "title": "Reshape Matrix",
        "learn_section": "\n## Reshaping a Matrix\n\nMatrix reshaping involves changing the shape of a matrix without altering its data. This is essential in many machine learning tasks where the input data needs to be formatted in a specific way.\n\nFor example, consider a matrix $M$:\n\n**Original Matrix $M$:**\n$$\nM = \\begin{pmatrix} \n1 & 2 & 3 & 4 \\\\ \n5 & 6 & 7 & 8 \n\\end{pmatrix}\n$$\n\n**Reshaped Matrix $M'$ with shape (4, 2):**\n$$\nM' = \\begin{pmatrix} \n1 & 2 \\\\ \n3 & 4 \\\\ \n5 & 6 \\\\ \n7 & 8 \n\\end{pmatrix}\n$$\n\n### Important Note:\nEnsure the total number of elements remains constant during reshaping.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/mmujtabah",
                "name": "mmujtabah"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = reshape_matrix(\n    torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float),\n    (3, 2)\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]"
            },
            {
                "test": "import torch\nres = reshape_matrix(\n    torch.tensor([[1,2],[3,4]], dtype=torch.float),\n    (3, 2)\n)\nprint(res.numpy().tolist())",
                "expected_output": "[]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = reshape_matrix_tg(\n    [[1,2,3],[4,5,6]],\n    (3, 2)\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[1, 2], [3, 4], [5, 6]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = reshape_matrix_tg(\n    [[1,2],[3,4]],\n    (3, 2)\n)\nprint(res.numpy().tolist())",
                "expected_output": "[]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgcmVzaGFwZV9tYXRyaXgoYSwgbmV3X3NoYXBlKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFJlc2hhcGUgYSAyRCBtYXRyaXggYGFgIHRvIHNoYXBlIGBuZXdfc2hhcGVgIHVzaW5nIFB5VG9yY2guCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0b3JjaCBUZW5zb3JzLgogICAgUmV0dXJucyBhIHRlbnNvciBvZiBzaGFwZSBgbmV3X3NoYXBlYCwgb3IgYW4gZW1wdHkgdGVuc29yIG9uIG1pc21hdGNoLgogICAgIiIiCiAgICAjIERpbWVuc2lvbiBjaGVjawogICAgaWYgbGVuKGEpICogbGVuKGFbMF0pICE9IG5ld19zaGFwZVswXSAqIG5ld19zaGFwZVsxXToKICAgICAgICByZXR1cm4gdG9yY2gudGVuc29yKFtdKQogICAgYV90ID0gdG9yY2guYXNfdGVuc29yKGEsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgcmV0dXJuIGFfdC5yZXNoYXBlKG5ld19zaGFwZSkK",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgcmVzaGFwZV9tYXRyaXgoYSwgbmV3X3NoYXBlKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFJlc2hhcGUgYSAyRCBtYXRyaXggYGFgIHRvIHNoYXBlIGBuZXdfc2hhcGVgIHVzaW5nIFB5VG9yY2guCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0b3JjaCBUZW5zb3JzLgogICAgUmV0dXJucyBhIHRlbnNvciBvZiBzaGFwZSBgbmV3X3NoYXBlYCwgb3IgYW4gZW1wdHkgdGVuc29yIG9uIG1pc21hdGNoLgogICAgIiIiCiAgICAjIERpbWVuc2lvbiBjaGVjawogICAgaWYgbGVuKGEpICogbGVuKGFbMF0pICE9IG5ld19zaGFwZVswXSAqIG5ld19zaGFwZVsxXToKICAgICAgICByZXR1cm4gdG9yY2gudGVuc29yKFtdKQogICAgIyBDb252ZXJ0IHRvIHRlbnNvciBhbmQgcmVzaGFwZQogICAgYV90ID0gdG9yY2guYXNfdGVuc29yKGEsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "3"
    },
    {
        "description": "Implement a batch iterable function that samples in a numpy array X and an optional numpy array y. The function should return batches of a specified size. If y is provided, the function should return batches of (X, y) pairs; otherwise, it should return batches of X only.",
        "mdx_file": "22f2b530-bcba-49e0-965d-9d9416bd1057.mdx",
        "id": "30",
        "test_cases": [
            {
                "test": "print(batch_iterator(np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]), np.array([1, 2, 3, 4, 5]), batch_size=2))",
                "expected_output": "[[[[1, 2], [3, 4]], [1, 2]], [[[5, 6], [7, 8]], [3, 4]], [[[9, 10]], [5]]]"
            },
            {
                "test": "print(batch_iterator(np.array([[1, 1], [2, 2], [3, 3], [4, 4]]), batch_size=3))",
                "expected_output": "[[[1, 1], [2, 2], [3, 3]], [[4, 4]]]"
            }
        ],
        "solution": "import numpy as np\n\ndef batch_iterator(X, y=None, batch_size=64):\n    n_samples = X.shape[0]\n    batches = []\n    for i in np.arange(0, n_samples, batch_size):\n        begin, end = i, min(i+batch_size, n_samples)\n        if y is not None:\n            batches.append([X[begin:end], y[begin:end]])\n        else:\n            batches.append( X[begin:end])\n    return batches\n    ",
        "difficulty": "easy",
        "video": "https://youtu.be/_Ox2PUBpkMw?si=oiWBJezQQoREIHPU",
        "likes": "0",
        "example": {
            "input": "X = np.array([[1, 2], \n                  [3, 4], \n                  [5, 6], \n                  [7, 8], \n                  [9, 10]])\n    y = np.array([1, 2, 3, 4, 5])\n    batch_size = 2\n    batch_iterator(X, y, batch_size)",
            "output": "[[[[1, 2], [3, 4]], [1, 2]],\n     [[[5, 6], [7, 8]], [3, 4]],\n     [[[9, 10]], [5]]]",
            "reasoning": "The dataset X contains 5 samples, and we are using a batch size of 2. Therefore, the function will divide the dataset into 3 batches. The first two batches will contain 2 samples each, and the last batch will contain the remaining sample. The corresponding values from y are also included in each batch."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef batch_iterator(X, y=None, batch_size=64):\n\t# Your code here\n\tpass",
        "title": "Batch Iterator for Dataset",
        "learn_section": "\n## Understanding Batch Iteration\n\nBatch iteration is a common technique used in machine learning and data processing to handle large datasets more efficiently. Instead of processing the entire dataset at once, which can be memory-intensive, data is processed in smaller, more manageable batches.\n\n### Step-by-Step Method to Create a Batch Iterator\n\n1. **Determine the Number of Samples**  \n   Calculate the total number of samples in the dataset.\n\n2. **Iterate in Batches**  \n   Loop through the dataset in increments of the specified batch size.\n\n3. **Yield Batches**  \n   For each iteration, yield a batch of samples from \\( X \\) and, if provided, the corresponding samples from \\( y \\).\n\n### Key Point\nThis method ensures efficient processing and can be used for both the training and evaluation phases in machine learning workflows.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            }
        ]
    },
    {
        "description": "Write a Python function to divide a dataset based on whether the value of a specified feature is greater than or equal to a given threshold. The function should return two subsets of the dataset: one with samples that meet the condition and another with samples that do not.",
        "mdx_file": "51b61f99-17f2-4c4f-9883-7aa6a27bcab9.mdx",
        "test_cases": [
            {
                "test": "print(divide_on_feature(np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]), 0, 5))",
                "expected_output": "[array([[ 5,  6], [ 7,  8], [ 9, 10]]), array([[1, 2], [3, 4]])]"
            },
            {
                "test": "print(divide_on_feature(np.array([[1, 1], [2, 2], [3, 3], [4, 4]]), 1, 3))",
                "expected_output": "[array([[3, 3], [4, 4]]), array([[1, 1], [2, 2]])]"
            }
        ],
        "solution": "import numpy as np\n\ndef divide_on_feature(X, feature_i, threshold):\n    # Define the split function based on the threshold type\n    split_func = None\n    if isinstance(threshold, int) or isinstance(threshold, float):\n        # For numeric threshold, check if feature value is greater than or equal to the threshold\n        split_func = lambda sample: sample[feature_i] >= threshold\n    else:\n        # For non-numeric threshold, check if feature value is equal to the threshold\n        split_func = lambda sample: sample[feature_i] == threshold\n\n    # Create two subsets based on the split function\n    X_1 = np.array([sample for sample in X if split_func(sample)])\n    X_2 = np.array([sample for sample in X if not split_func(sample)])\n\n    # Return the two subsets\n    return [X_1, X_2]\n    ",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "X = np.array([[1, 2], \n                  [3, 4], \n                  [5, 6], \n                  [7, 8], \n                  [9, 10]])\n    feature_i = 0\n    threshold = 5",
            "output": "[array([[ 5,  6],\n                    [ 7,  8],\n                    [ 9, 10]]), \n             array([[1, 2],\n                    [3, 4]])]",
            "reasoning": "The dataset X is divided based on whether the value in the 0th feature (first column) is greater than or equal to 5. Samples with the first column value >= 5 are in the first subset, and the rest are in the second subset."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef divide_on_feature(X, feature_i, threshold):\n\t# Your code here\n\tpass",
        "title": "Divide Dataset Based on Feature Threshold",
        "learn_section": "\n## Understanding Dataset Division Based on Feature Threshold\n\nDividing a dataset based on a feature threshold is a common operation in machine learning, especially in decision tree algorithms. This technique helps in creating splits that can be used for further processing or model training.\n\n### Problem Overview\nIn this problem, you will write a function to split a dataset based on whether the value of a specified feature is greater than or equal to a given threshold. You'll need to create two subsets:\n- One for samples that meet the condition (values greater than or equal to the threshold).\n- Another for samples that do not meet the condition.\n\n### Importance\nThis method is crucial for algorithms that rely on data partitioning, such as decision trees and random forests. By splitting the data, the model can create rules to make predictions based on the threshold values of certain features.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            }
        ],
        "id": "31"
    },
    {
        "description": "Write a Python function that takes a 2-D NumPy array **X** and an integer **degree**, generates all polynomial feature combinations of the columns of **X** up to the given degree **inclusive**, **then sorts the resulting features for each sample from lowest to highest value**. The function should return a new 2-D NumPy array whose rows correspond to the input samples and whose columns are the **ascending-sorted** polynomial features.",
        "mdx_file": "1a78a74c-dffb-4e87-8e0a-1e9c05d7ec23.mdx",
        "id": "32",
        "test_cases": [
            {
                "test": "print(polynomial_features(np.array([[2, 3], [3, 4], [5, 6]]), 2))",
                "expected_output": "[[ 1.  2.  3.  4.  6.  9.]\n [ 1.  3.  4.  9. 12. 16.]\n [ 1.  5.  6. 25. 30. 36.]]"
            },
            {
                "test": "print(polynomial_features(np.array([[1, 2], [3, 4], [5, 6]]), 3))",
                "expected_output": "[[1., 1., 1., 1., 2., 2., 2., 4., 4., 8.], [ 1., 3., 4., 9., 12., 16., 27., 36., 48., 64.], [ 1., 5., 6., 25., 30., 36., 125., 150., 180., 216.]]"
            },
            {
                "test": "print(polynomial_features(np.array([[1, 2, 3], [3, 4, 5], [5, 6, 9]]), 3))",
                "expected_output": "[[ 1., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 6., 6., 8., 9., 9., 12., 18., 27.], [ 1., 3., 4., 5., 9., 12., 15., 16., 20., 25., 27., 36., 45., 48., 60., 64., 75., 80., 100., 125.], [ 1., 5., 6., 9., 25., 30., 36., 45., 54., 81., 125., 150., 180., 216., 225., 270., 324., 405., 486., 729.]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\nfrom itertools import combinations_with_replacement\n\ndef polynomial_features(X, degree):\n    n_samples, n_features = X.shape\n\n    # All index combinations for powers 0 … degree (constant term included)\n    combs = [c for d in range(degree + 1)\n             for c in combinations_with_replacement(range(n_features), d)]\n\n    # Compute raw polynomial terms\n    X_poly = np.empty((n_samples, len(combs)))\n    for i, idx in enumerate(combs):\n        X_poly[:, i] = 1 if len(idx) == 0 else np.prod(X[:, idx], axis=1)\n\n    # Sort each row from lowest → highest\n    X_sorted = np.sort(X_poly, axis=1)\n    return X_sorted",
        "likes": "0",
        "video": "",
        "dislikes": "0",
        "example": {
            "input": "X = np.array([[2, 3],\n              [3, 4],\n              [5, 6]])\ndegree = 2\noutput = polynomial_features(X, degree)\nprint(output)",
            "output": "[[ 1.  2.  3.  4.  6.  9.]\n [ 1.  3.  4.  9. 12. 16.]\n [ 1.  5.  6. 25. 30. 36.]]",
            "reasoning": "For **degree = 2**, the raw polynomial terms for the first sample are [1, 2, 3, 4, 6, 9].  Sorting them from smallest to largest yields [1, 2, 3, 4, 6, 9]. The same procedure is applied to every sample."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\nfrom itertools import combinations_with_replacement\n\ndef polynomial_features(X, degree):\n    # ✏️  Your code here\n    pass",
        "learn_section": "## Understanding Polynomial Features\n\nGenerating polynomial features is a method used to create new features for a machine-learning model by raising existing features to a specified power. This technique helps capture non-linear relationships between features.\n\n### Example\nGiven a dataset with two features $x_1$ and $x_2$, generating polynomial features up to degree 2 will create new features such as:\n- $x_1^2$\n- $x_2^2$\n- $x_1 x_2$\n\n### Problem Overview\nIn this problem you will write a function to **generate** polynomial features **and then sort each sample's features in ascending order**. Specifically:\n- Given a 2-D NumPy array **X** and an integer **degree**, create a new 2-D array with all polynomial combinations of the features up to the specified degree.\n- Finally, sort each row from the lowest value to the highest value.\n\n### Importance\nPolynomial expansion allows otherwise linear models to handle non-linear data. Sorting the expanded features can be useful for certain downstream tasks (e.g., histogram-based models or feature selection heuristics) and reinforces array-manipulation skills in NumPy.",
        "title": "Generate Sorted Polynomial Features",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            },
            {
                "profile_link": "https://github.com/peppermin-t",
                "name": "Yinjia Chen"
            }
        ]
    },
    {
        "description": "Write a Python function to generate random subsets of a given dataset. The function should take in a 2D numpy array X, a 1D numpy array y, an integer n_subsets, and a boolean replacements. It should return a list of n_subsets random subsets of the dataset, where each subset is a tuple of (X_subset, y_subset). If replacements is True, the subsets should be created with replacements; otherwise, without replacements.",
        "mdx_file": "73aa54af-8975-48b8-af14-ef158c256443.mdx",
        "test_cases": [
            {
                "test": " \nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\ny = np.array([1, 2, 3, 4, 5])\nprint(get_random_subsets(X,y, 3, False, seed=42))",
                "expected_output": "[[[3, 4], [9, 10]], [2, 5], [[7, 8], [3, 4]], [4, 2], [[3, 4], [1, 2]], [2, 1]]"
            },
            {
                "test": "\nX = np.array([[1, 1], [2, 2], [3, 3], [4, 4]])\ny = np.array([10, 20, 30, 40])\nprint(get_random_subsets(X, y, 1, True, seed=42))",
                "expected_output": "[([[3, 3], [4, 4], [1, 1], [3, 3]], [30, 40, 10, 30])]"
            }
        ],
        "solution": "import numpy as np\n\ndef get_random_subsets(X, y, n_subsets, replacements=True, seed=42):\n    np.random.seed(seed)\n\n    n, m = X.shape\n    \n    subset_size = n if replacements else n // 2\n    idx = np.array([np.random.choice(n, subset_size, replace=replacements) for _ in range(n_subsets)])\n    # convert all ndarrays to lists\n    return [(X[idx][i].tolist(), y[idx][i].tolist()) for i in range(n_subsets)]\n    ",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "X = np.array([[1, 2],\n                  [3, 4],\n                  [5, 6],\n                  [7, 8],\n                  [9, 10]])\n    y = np.array([1, 2, 3, 4, 5])\n    n_subsets = 3\n    replacements = False\n    get_random_subsets(X, y, n_subsets, replacements)",
            "output": "[array([[7, 8],\n            [1, 2]]), \n     array([4, 1])]\n     \n    [array([[9, 10],\n            [5, 6]]), \n     array([5, 3])]\n     \n    [array([[3, 4],\n            [5, 6]]), \n     array([2, 3])]",
            "reasoning": "The function generates three random subsets of the dataset without replacements.\n    Each subset includes 50% of the samples (since replacements=False). The samples\n    are randomly selected without duplication."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef get_random_subsets(X, y, n_subsets, replacements=True, seed=42):\n\t# Your code here\n\tpass",
        "title": "Generate Random Subsets of a Dataset",
        "learn_section": "\n## Understanding Random Subsets of a Dataset\n\nGenerating random subsets of a dataset is a useful technique in machine learning, particularly in ensemble methods like bagging and random forests. By creating random subsets, models can be trained on different parts of the data, which helps in reducing overfitting and improving generalization.\n\n### Problem Overview\nIn this problem, you will write a function to generate random subsets of a given dataset. Specifically:\n- Given a 2D numpy array $X$, a 1D numpy array $y$, an integer `n_subsets`, and a boolean `replacements`, the function will create a list of `n_subsets` random subsets.\n- Each subset will be a tuple of $(X_{\\text{subset}}, y_{\\text{subset}})$.\n\n### Parameters\n- **$X$**: A 2D numpy array representing the features.\n- **$y$**: A 1D numpy array representing the labels.\n- **$n_{\\text{subsets}}$**: The number of random subsets to generate.\n- **`replacements`**: A boolean indicating whether to sample with or without replacement.\n  - If `replacements` is **True**, subsets will be created *with* replacements, meaning samples can be repeated within a subset.\n  - If `replacements` is **False**, subsets will be created *without* replacements, meaning samples cannot be repeated within a subset.\n\n### Importance\nBy understanding and implementing this technique, you can enhance the performance of your models through methods like bootstrapping and ensemble learning.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/peppermin-t",
                "name": "Yinjia Chen"
            },
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            }
        ],
        "id": "33"
    },
    {
        "description": "Write a Python function to perform one-hot encoding of nominal values. The function should take in a 1D numpy array x of integer values and an optional integer n_col representing the number of columns for the one-hot encoded array. If n_col is not provided, it should be automatically determined from the input array.",
        "mdx_file": "62e9bd5d-ae0e-4c48-a5e2-0653437f196c.mdx",
        "test_cases": [
            {
                "test": "print(to_categorical(np.array([0, 1, 2, 1, 0])))",
                "expected_output": "[[1., 0., 0.], [0., 1., 0.], [0., 0., 1.], [0., 1., 0.], [1., 0., 0.]]"
            },
            {
                "test": "print(to_categorical(np.array([3, 1, 2, 1, 3]), 4))",
                "expected_output": "[[0., 0., 0., 1.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 1., 0., 0.], [0., 0., 0., 1.]]"
            }
        ],
        "solution": "import numpy as np\n\ndef to_categorical(x, n_col=None):\n    # One-hot encoding of nominal values\n    # If n_col is not provided, determine the number of columns from the input array\n    if not n_col:\n        n_col = np.amax(x) + 1\n    # Initialize a matrix of zeros with shape (number of samples, n_col)\n    one_hot = np.zeros((x.shape[0], n_col))\n    # Set the appropriate elements to 1\n    one_hot[np.arange(x.shape[0]), x] = 1\n    return one_hot\n    ",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "x = np.array([0, 1, 2, 1, 0])\n    output = to_categorical(x)\n    print(output)",
            "output": "# [[1. 0. 0.]\n    #  [0. 1. 0.]\n    #  [0. 0. 1.]\n    #  [0. 1. 0.]\n    #  [1. 0. 0.]]",
            "reasoning": "Each element in the input array is transformed into a one-hot encoded vector,\n    where the index corresponding to the value in the input array is set to 1, \n    and all other indices are set to 0."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef to_categorical(x, n_col=None):\n\t# Your code here\n\tpass",
        "title": "One-Hot Encoding of Nominal Values",
        "learn_section": "\n## Understanding One-Hot Encoding\n\nOne-hot encoding is a method used to represent categorical variables as binary vectors. This technique is useful in machine learning when dealing with categorical data that has no ordinal relationship.\n\n### Explanation\nIn one-hot encoding, each category is represented by a binary vector with a length equal to the number of categories. The vector has a value of 1 at the index corresponding to the category and 0 at all other indices.\n\n### Example\nFor instance, if you have three categories: 0, 1, and 2, the one-hot encoded vectors would be:\n- **0**: $[1, 0, 0]$\n- **1**: $[0, 1, 0]$\n- **2**: $[0, 0, 1]$\n\nThis method ensures that the model does not assume any ordinal relationship between categories, which is crucial for many machine learning algorithms.\n\n### Mathematical Representation\nThe one-hot encoding process can be mathematically represented as follows:\n\nGiven a category $x_i$ from a set of categories $\\{0, 1, \\ldots, n-1\\}$, the one-hot encoded vector $\\mathbf{v}$ is:\n$$\n\\mathbf{v}_i = \n\\begin{cases} \n1 & \\text{if } i = x_i \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\nThis vector $\\mathbf{v}$ will have a length equal to the number of unique categories.\n",
        "contributor": null,
        "id": "34"
    },
    {
        "description": "Write a Python function to convert a 1D numpy array into a diagonal matrix. The function should take in a 1D numpy array x and return a 2D numpy array representing the diagonal matrix.",
        "mdx_file": "735f1a71-6d1a-4cca-9a35-d812bfcd4d35.mdx",
        "test_cases": [
            {
                "test": "print(make_diagonal(np.array([1, 2, 3])))",
                "expected_output": "[[1., 0., 0.], [0., 2., 0.], [0., 0., 3.]]"
            },
            {
                "test": "print(make_diagonal(np.array([4, 5, 6, 7])))",
                "expected_output": "[[4., 0., 0., 0.], [0., 5., 0., 0.], [0., 0., 6., 0.], [0., 0., 0., 7.]]"
            }
        ],
        "solution": "import numpy as np\n\ndef make_diagonal(x):\n    identity_matrix = np.identity(np.size(x))\n    return (identity_matrix*x)\n    ",
        "difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/iT5dQ9hl-KQ",
        "example": {
            "input": "x = np.array([1, 2, 3])\n    output = make_diagonal(x)\n    print(output)",
            "output": "[[1. 0. 0.]\n    [0. 2. 0.]\n    [0. 0. 3.]]",
            "reasoning": "The input vector [1, 2, 3] is converted into a diagonal matrix where the elements of the vector form the diagonal of the matrix."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef make_diagonal(x):\n\t# Your code here\n\tpass",
        "title": "Convert Vector to Diagonal Matrix",
        "learn_section": "\n## Understanding Diagonal Matrices\n\nA diagonal matrix is a square matrix in which the entries outside the main diagonal are all zero. The main diagonal is the set of entries extending from the top left to the bottom right of the matrix.\n\n### Problem Overview\nIn this problem, you will write a function to convert a 1D numpy array (vector) into a diagonal matrix. The resulting matrix will have the elements of the input vector on its main diagonal, with zeros elsewhere.\n\n### Mathematical Representation\nGiven a vector $\\mathbf{x} = [x_1, x_2, \\ldots, x_n]$, the corresponding diagonal matrix $\\mathbf{D}$ is:\n$$\n\\mathbf{D} = \\begin{bmatrix}\nx_1 & 0 & 0 & \\cdots & 0 \\\\\n0 & x_2 & 0 & \\cdots & 0 \\\\\n0 & 0 & x_3 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & x_n\n\\end{bmatrix}\n$$\n\n### Importance\nDiagonal matrices are important in various mathematical and scientific computations due to their simple structure and useful properties.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/adarsh3690704",
                "name": "Adarsh R"
            }
        ],
        "id": "35"
    },
    {
        "description": "Write a Python function to calculate the accuracy score of a model's predictions. The function should take in two 1D numpy arrays: y_true, which contains the true labels, and y_pred, which contains the predicted labels. It should return the accuracy score as a float.",
        "mdx_file": "a103935a-4090-4163-b3ba-da46780bb37d.mdx",
        "test_cases": [
            {
                "test": "print(accuracy_score(np.array([1, 0, 1, 1, 0, 1]), np.array([1, 0, 0, 1, 0, 1])))",
                "expected_output": "0.8333333333333334"
            },
            {
                "test": "print(accuracy_score(np.array([1, 1, 1, 1]), np.array([1, 0, 1, 0])))",
                "expected_output": "0.5"
            }
        ],
        "solution": "import numpy as np\n\ndef accuracy_score(y_true, y_pred):\n    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n    return accuracy\n    ",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "y_true = np.array([1, 0, 1, 1, 0, 1])\n    y_pred = np.array([1, 0, 0, 1, 0, 1])\n    output = accuracy_score(y_true, y_pred)\n    print(output)",
            "output": "# 0.8333333333333334",
            "reasoning": "The function compares the true labels with the predicted labels and calculates the ratio of correct predictions to the total number of predictions. In this example, there are 5 correct predictions out of 6, resulting in an accuracy score of 0.8333333333333334."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef accuracy_score(y_true, y_pred):\n\t# Your code here\n\tpass",
        "title": "Calculate Accuracy Score",
        "learn_section": "\n## Understanding Accuracy Score\n\nAccuracy is a metric used to evaluate the performance of a classification model. It is defined as the ratio of the number of correct predictions to the total number of predictions made. Mathematically, accuracy is given by:\n$$\n\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n$$\n\n### Problem Overview\nIn this problem, you will write a function to calculate the accuracy score given the true labels and the predicted labels. The function will compare the two arrays and compute the accuracy as the proportion of matching elements.\n\n### Importance\nAccuracy is a straightforward and commonly used metric for classification tasks. It provides a quick way to understand how well a model is performing, but it may not always be the best metric, especially for imbalanced datasets.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            }
        ],
        "id": "36"
    },
    {
        "description": "Write a Python function to calculate the correlation matrix for a given dataset. The function should take in a 2D numpy array X and an optional 2D numpy array Y. If Y is not provided, the function should calculate the correlation matrix of X with itself. It should return the correlation matrix as a 2D numpy array.",
        "mdx_file": "ca6e06f5-43c2-413b-bc31-bc3d388c22c7.mdx",
        "test_cases": [
            {
                "test": "print(calculate_correlation_matrix(np.array([[1, 2], [3, 4], [5, 6]])))",
                "expected_output": "[[1., 1.], [1., 1.]]"
            },
            {
                "test": "print(calculate_correlation_matrix(np.array([[1, 2, 3], [7, 15, 6], [7, 8, 9]])))",
                "expected_output": "[[1.,0.84298868, 0.8660254 ],[0.84298868, 1., 0.46108397],[0.8660254,  0.46108397, 1.]]"
            },
            {
                "test": "print(calculate_correlation_matrix(np.array([[1, 0], [0, 1]]), np.array([[1, 2], [3, 4]])))",
                "expected_output": "[[ -1.,  -1.], [ 1.,  1.]]"
            }
        ],
        "solution": "import numpy as np\n\ndef calculate_correlation_matrix(X, Y=None):\n    # Helper function to calculate standard deviation\n    def calculate_std_dev(A):\n        return np.sqrt(np.mean((A - A.mean(0))**2, axis=0))\n    \n    if Y is None:\n        Y = X\n    n_samples = np.shape(X)[0]\n    # Calculate the covariance matrix\n    covariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\n    # Calculate the standard deviations\n    std_dev_X = np.expand_dims(calculate_std_dev(X), 1)\n    std_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\n    # Calculate the correlation matrix\n    correlation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n\n    return np.array(correlation_matrix, dtype=float)\n    ",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "X = np.array([[1, 2],\n                  [3, 4],\n                  [5, 6]])\n    output = calculate_correlation_matrix(X)\n    print(output)",
            "output": "# [[1. 1.]\n    #  [1. 1.]]",
            "reasoning": "The function calculates the correlation matrix for the dataset X. In this example, the correlation between the two features is 1, indicating a perfect linear relationship."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef calculate_correlation_matrix(X, Y=None):\n\t# Your code here\n\tpass",
        "title": "Calculate Correlation Matrix",
        "learn_section": "\n## Understanding Correlation Matrix\n\nA correlation matrix is a table showing the correlation coefficients between variables. Each cell in the table shows the correlation between two variables, with values ranging from -1 to 1. These values indicate the strength and direction of the linear relationship between the variables.\n\n### Mathematical Definition\nThe correlation coefficient between two variables \\( X \\) and \\( Y \\) is given by:\n$$\n\\text{corr}(X, Y) = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}\n$$\n\n#### Where:\n- \\( \\text{cov}(X, Y) \\) is the covariance between \\( X \\) and \\( Y \\).\n- \\( \\sigma_X \\) and \\( \\sigma_Y \\) are the standard deviations of \\( X \\) and \\( Y \\), respectively.\n\n### Problem Overview\nIn this problem, you will write a function to calculate the correlation matrix for a given dataset. The function will take in a 2D numpy array \\( X \\) and an optional 2D numpy array \\( Y \\). If \\( Y \\) is not provided, the function will calculate the correlation matrix of \\( X \\) with itself.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            }
        ],
        "id": "37"
    },
    {
        "description": "Write a Python function `adaboost_fit` that implements the fit method for an AdaBoost classifier. The function should take in a 2D numpy array `X` of shape `(n_samples, n_features)` representing the dataset, a 1D numpy array `y` of shape `(n_samples,)` representing the labels, and an integer `n_clf` representing the number of classifiers. The function should initialize sample weights, find the best thresholds for each feature, calculate the error, update weights, and return a list of classifiers with their parameters.",
        "mdx_file": "12dafded-0efd-4fa3-b7ed-ee6de40f4f1e.mdx",
        "id": "38",
        "test_cases": [
            {
                "test": "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\ny = np.array([1, 1, -1, -1])\nn_clf = 3\nclfs = adaboost_fit(X, y, n_clf)\nprint(clfs)",
                "expected_output": "[{'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}]"
            },
            {
                "test": "X = np.array([[8, 7], [3, 4], [5, 9], [4, 0], [1, 0], [0, 7], [3, 8], [4, 2], [6, 8], [0, 2]])\ny = np.array([1, -1, 1, -1, 1, -1, -1, -1, 1, 1])\nn_clf = 2\nclfs = adaboost_fit(X, y, n_clf)\nprint(clfs)",
                "expected_output": "[{'polarity': 1, 'threshold': 5, 'feature_index': 0, 'alpha': 0.6931471803099453}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 0.5493061439673882}]"
            }
        ],
        "difficulty": "hard",
        "solution": "import math\nimport numpy as np\ndef adaboost_fit(X, y, n_clf):\n    n_samples, n_features = np.shape(X)\n    w = np.full(n_samples, (1 / n_samples))\n    clfs = []\n    \n    for _ in range(n_clf):\n        clf = {}\n        min_error = float('inf')\n        \n        for feature_i in range(n_features):\n            feature_values = np.expand_dims(X[:, feature_i], axis=1)\n            unique_values = np.unique(feature_values)\n            \n            for threshold in unique_values:\n                p = 1\n                prediction = np.ones(np.shape(y))\n                prediction[X[:, feature_i] < threshold] = -1\n                error = sum(w[y != prediction])\n                \n                if error > 0.5:\n                    error = 1 - error\n                    p = -1\n                \n                if error < min_error:\n                    clf['polarity'] = p\n                    clf['threshold'] = threshold\n                    clf['feature_index'] = feature_i\n                    min_error = error\n        \n        clf['alpha'] = 0.5 * math.log((1.0 - min_error) / (min_error + 1e-10))\n        predictions = np.ones(np.shape(y))\n        negative_idx = (X[:, clf['feature_index']] < clf['threshold'])\n        if clf['polarity'] == -1:\n            negative_idx = np.logical_not(negative_idx)\n        predictions[negative_idx] = -1\n        w *= np.exp(-clf['alpha'] * y * predictions)\n        w /= np.sum(w)\n        clfs.append(clf)\n\n    return clfs",
        "video": "",
        "likes": "0",
        "example": {
            "input": "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n    y = np.array([1, 1, -1, -1])\n    n_clf = 3\n\n    clfs = adaboost_fit(X, y, n_clf)\n    print(clfs)",
            "output": "(example format, actual values may vary):\n    # [{'polarity': 1, 'threshold': 2, 'feature_index': 0, 'alpha': 0.5},\n    #  {'polarity': -1, 'threshold': 3, 'feature_index': 1, 'alpha': 0.3},\n    #  {'polarity': 1, 'threshold': 4, 'feature_index': 0, 'alpha': 0.2}]",
            "reasoning": "The function fits an AdaBoost classifier on the dataset X with the given labels y and number of classifiers n_clf. It returns a list of classifiers with their parameters, including the polarity, threshold, feature index, and alpha values"
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\nimport math\n\ndef adaboost_fit(X, y, n_clf):\n\tn_samples, n_features = np.shape(X)\n\tw = np.full(n_samples, (1 / n_samples))\n\tclfs = []\n\n\t# Your code here\n\n\treturn clfs\n    ",
        "title": "Implement AdaBoost Fit Method",
        "learn_section": "\n## Understanding AdaBoost\n\nAdaBoost, short for Adaptive Boosting, is an ensemble learning method that combines multiple weak classifiers to create a strong classifier. The basic idea is to fit a sequence of weak learners on weighted versions of the data.\n\n### Implementing the Fit Method for an AdaBoost Classifier\n\n1. **Initialize Weights**  \n   Start by initializing the sample weights uniformly:\n   $$\n   w_i = \\frac{1}{N}, \\text{ where } N \\text{ is the number of samples}\n   $$\n\n2. **Iterate Through Classifiers**  \n   For each classifier, determine the best threshold for each feature to minimize the error.\n\n3. **Calculate Error and Flip Polarity**  \n   If the error is greater than 0.5, flip the polarity:\n   $$\n   \\text{error} = \\sum_{i=1}^N w_i [y_i \\neq h(x_i)]\n   $$\n   $$\n   \\text{if error} > 0.5: \\text{error} = 1 - \\text{error}, \\text{ and flip the polarity}\n   $$\n\n4. **Calculate Alpha**  \n   Compute the weight (alpha) of the classifier based on its error rate:\n   $$\n   \\alpha = \\frac{1}{2} \\ln \\left( \\frac{1 - \\text{error}}{\\text{error} + 1e-10} \\right)\n   $$\n\n5. **Update Weights**  \n   Adjust the sample weights based on the classifier's performance and normalize them:\n   $$\n   w_i = w_i \\exp(-\\alpha y_i h(x_i))\n   $$\n   $$\n   w_i = \\frac{w_i}{\\sum_{j=1}^N w_j}\n   $$\n\n6. **Save Classifier**  \n   Store the classifier with its parameters.\n\n### Key Insight\nThis method helps in focusing more on the misclassified samples in subsequent rounds, thereby improving the overall performance.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
                "name": "Erik Linder-Norén"
            },
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "In machine learning and statistics, the softmax function is a generalization of the logistic function that converts a vector of scores into probabilities. The log-softmax function is the logarithm of the softmax function, and it is often used for numerical stability when computing the softmax of large numbers.\n\nGiven a 1D numpy array of scores, implement a Python function to compute the log-softmax of the array.",
        "mdx_file": "d8c6fd66-323e-4376-a240-5c161919b722.mdx",
        "test_cases": [
            {
                "test": "print(log_softmax([1, 2, 3]))",
                "expected_output": "[-2.4076, -1.4076, -0.4076]"
            },
            {
                "test": "print(log_softmax([1, 1, 1]))",
                "expected_output": "[-1.0986, -1.0986, -1.0986]"
            },
            {
                "test": "print(log_softmax([1, 1, .0000001]))",
                "expected_output": "[-0.862, -0.862, -1.862]"
            }
        ],
        "solution": "import numpy as np\n\ndef log_softmax(scores: list) -> np.ndarray:\n    # Subtract the maximum value for numerical stability\n    scores = scores - np.max(scores)\n    return scores - np.log(np.sum(np.exp(scores)))",
        "difficulty": "easy",
        "video": null,
        "likes": "0",
        "example": {
            "input": "A = np.array([1, 2, 3])\nprint(log_softmax(A))",
            "output": "array([-2.4076, -1.4076, -0.4076])",
            "reasoning": "The log-softmax function is applied to the input array [1, 2, 3]. The output array contains the log-softmax values for each element."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef log_softmax(scores: list) -> np.ndarray:\n\t# Your code here\n\tpass",
        "title": "Implementation of Log Softmax Function",
        "learn_section": "\n## Understanding Log Softmax Function\n\nThe log softmax function is a numerically stable way of calculating the logarithm of the softmax function. The softmax function converts a vector of arbitrary values (logits) into a vector of probabilities, where each value lies between 0 and 1, and the values sum to 1.\n\n### Softmax Function\nThe softmax function is given by:\n$$\n\\text{softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}\n$$\n\n### Log Softmax Function\nDirectly applying the logarithm to the softmax function can lead to numerical instability, especially when dealing with large numbers. To prevent this, we use the log-softmax function, which incorporates a shift by subtracting the maximum value from the input vector:\n$$\n\\text{log softmax}(x_i) = x_i - \\max(x) - \\log\\left(\\sum_{j=1}^n e^{x_j - \\max(x)}\\right)\n$$\n\nThis formulation helps to avoid overflow issues that can occur when exponentiating large numbers. The log-softmax function is particularly useful in machine learning for calculating probabilities in a stable manner, especially when used with cross-entropy loss functions.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/MKFMIKU",
                "name": "Kangfu MEI"
            }
        ],
        "id": "39"
    },
    {
        "description": "Write a Python function that calculates the mean of a matrix either by row or by column, based on a given mode. The function should take a matrix (list of lists) and a mode ('row' or 'column') as input and return a list of means according to the specified mode.",
        "mdx_file": "73c0a6e5-9590-45d9-8d54-19d02171f515.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGNhbGN1bGF0ZV9tYXRyaXhfbWVhbl90ZyhtYXRyaXgsIG1vZGU6IHN0cikgLT4gVGVuc29yOgogICAgIiIiCiAgICBDYWxjdWxhdGUgbWVhbiBvZiBhIDJEIG1hdHJpeCBwZXIgcm93IG9yIHBlciBjb2x1bW4gdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0aW55Z3JhZCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDEtRCBUZW5zb3Igb2YgbWVhbnMgb3IgcmFpc2VzIFZhbHVlRXJyb3Igb24gaW52YWxpZCBtb2RlLgogICAgIiIiCiAgICB2X3QgPSBUZW5zb3IobWF0cml4KS5mbG9hdCgpCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "test_cases": [
            {
                "test": "print(calculate_matrix_mean([[1, 2, 3], [4, 5, 6], [7, 8, 9]], 'column'))",
                "expected_output": "[4.0, 5.0, 6.0]"
            },
            {
                "test": "print(calculate_matrix_mean([[1, 2, 3], [4, 5, 6], [7, 8, 9]], 'row'))",
                "expected_output": "[2.0, 5.0, 8.0]"
            }
        ],
        "solution": "def calculate_matrix_mean(matrix: list[list[float]], mode: str) -> list[float]:\n    if mode == 'column':\n        return [sum(col) / len(matrix) for col in zip(*matrix)]\n    elif mode == 'row':\n        return [sum(row) / len(row) for row in matrix]\n    else:\n        raise ValueError(\"Mode must be 'row' or 'column'\")",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGNhbGN1bGF0ZV9tYXRyaXhfbWVhbl90ZyhtYXRyaXgsIG1vZGU6IHN0cikgLT4gVGVuc29yOgogICAgIiIiCiAgICBDYWxjdWxhdGUgbWVhbiBvZiBhIDJEIG1hdHJpeCBwZXIgcm93IG9yIHBlciBjb2x1bW4gdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0aW55Z3JhZCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDEtRCBUZW5zb3Igb2YgbWVhbnMgb3IgcmFpc2VzIFZhbHVlRXJyb3Igb24gaW52YWxpZCBtb2RlLgogICAgIiIiCiAgICB2X3QgPSBUZW5zb3IobWF0cml4KS5mbG9hdCgpCiAgICBuX29icyA9IHZfdC5zaGFwZVsxXQogICAgbl9mZWF0ID0gdl90LnNoYXBlWzBdCiAgICBpZiBtb2RlID09ICdjb2x1bW4nOgogICAgICAgIHJldHVybiB2X3Quc3VtKGF4aXM9MSkgLyBuX29icwogICAgZWxpZiBtb2RlID09ICdyb3cnOgogICAgICAgIHJldHVybiB2X3Quc3VtKGF4aXM9MCkgLyBuX2ZlYXQKICAgIGVsc2U6CiAgICAgICAgcmFpc2UgVmFsdWVFcnJvcigiTW9kZSBtdXN0IGJlICdyb3cnIG9yICdjb2x1bW4nIikK",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/l7kQALZvS_c",
        "marimo_link": "https://adityakhalkar.github.io/Deep-ML-x-Marimo/4",
        "difficulty": "easy",
        "dislikes": "0",
        "example": {
            "input": "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]], mode = 'column'",
            "output": "[4.0, 5.0, 6.0]",
            "reasoning": "Calculating the mean of each column results in [(1+4+7)/3, (2+5+8)/3, (3+6+9)/3]."
        },
        "category": "Linear Algebra",
        "starter_code": "def calculate_matrix_mean(matrix: list[list[float]], mode: str) -> list[float]:\n\treturn means",
        "title": "Calculate Mean by Row or Column",
        "learn_section": "\n## Calculate Mean by Row or Column\n\nCalculating the mean of a matrix by row or column involves averaging the elements across the specified dimension. This operation provides insights into the distribution of values within the dataset, useful for data normalization and scaling.\n\n### Row Mean\nThe mean of a row is computed by summing all elements in the row and dividing by the number of elements. For row $i$, the mean is:\n$$\n\\mu_{\\text{row } i} = \\frac{1}{n} \\sum_{j=1}^{n} a_{ij}\n$$\nwhere $a_{ij}$ is the matrix element in the $i^{\\text{th}}$ row and $j^{\\text{th}}$ column, and $n$ is the total number of columns.\n\n### Column Mean\nSimilarly, the mean of a column is found by summing all elements in the column and dividing by the number of elements. For column $j$, the mean is:\n$$\n\\mu_{\\text{column } j} = \\frac{1}{m} \\sum_{i=1}^{m} a_{ij}\n$$\nwhere $m$ is the total number of rows.\n\nThis mathematical formulation helps in understanding how data is aggregated across different dimensions, a critical step in various data preprocessing techniques.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nprint(calculate_matrix_mean([[1.0,2.0,3.0],[4.0,5.0,6.0]], 'column').numpy().tolist())",
                "expected_output": "[2.5, 3.5, 4.5]"
            },
            {
                "test": "import torch\nprint(calculate_matrix_mean([[1.0,2.0,3.0],[4.0,5.0,6.0]], 'row').numpy().tolist())",
                "expected_output": "[2.0, 5.0]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nprint(calculate_matrix_mean_tg([[1.0,2.0,3.0],[4.0,5.0,6.0]], 'column').numpy().tolist())",
                "expected_output": "[2.5, 3.5, 4.5]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nprint(calculate_matrix_mean_tg([[1.0,2.0,3.0],[4.0,5.0,6.0]], 'row').numpy().tolist())",
                "expected_output": "[2.0, 5.0]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgY2FsY3VsYXRlX21hdHJpeF9tZWFuKG1hdHJpeCwgbW9kZTogc3RyKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIENhbGN1bGF0ZSBtZWFuIG9mIGEgMkQgbWF0cml4IHBlciByb3cgb3IgcGVyIGNvbHVtbiB1c2luZyBQeVRvcmNoLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdG9yY2ggVGVuc29ycy4KICAgIFJldHVybnMgYSAxLUQgdGVuc29yIG9mIG1lYW5zIG9yIHJhaXNlcyBWYWx1ZUVycm9yIG9uIGludmFsaWQgbW9kZS4KICAgICIiIgogICAgYV90ID0gdG9yY2guYXNfdGVuc29yKG1hdHJpeCwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBpZiBtb2RlID09ICdjb2x1bW4nOgogICAgICAgIHJldHVybiBhX3QubWVhbihkaW09MCkKICAgIGVsaWYgbW9kZSA9PSAncm93JzoKICAgICAgICByZXR1cm4gYV90Lm1lYW4oZGltPTEpCiAgICBlbHNlOgogICAgICAgIHJhaXNlIFZhbHVlRXJyb3IoIk1vZGUgbXVzdCBiZSAncm93JyBvciAnY29sdW1uJyIpCg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgY2FsY3VsYXRlX21hdHJpeF9tZWFuKG1hdHJpeCwgbW9kZTogc3RyKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIENhbGN1bGF0ZSBtZWFuIG9mIGEgMkQgbWF0cml4IHBlciByb3cgb3IgcGVyIGNvbHVtbiB1c2luZyBQeVRvcmNoLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdG9yY2ggVGVuc29ycy4KICAgIFJldHVybnMgYSAxLUQgdGVuc29yIG9mIG1lYW5zIG9yIHJhaXNlcyBWYWx1ZUVycm9yIG9uIGludmFsaWQgbW9kZS4KICAgICIiIgogICAgYV90ID0gdG9yY2guYXNfdGVuc29yKG1hdHJpeCwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "id": "4"
    },
    {
        "description": "## Implementing a Custom Dense Layer in Python\n\nYou are provided with a base `Layer` class that defines the structure of a neural network layer. Your task is to implement a subclass called `Dense`, which represents a fully connected neural network layer. The `Dense` class should extend the `Layer` class and implement the following methods:\n\n1. **Initialization (`__init__`)**:\n   - Define the layer with a specified number of neurons (`n_units`) and an optional input shape (`input_shape`).\n   - Set up placeholders for the layer's weights (`W`), biases (`w0`), and optimizers.\n\n2. **Weight Initialization (`initialize`)**:\n   - Initialize the weights `W` using a uniform distribution with a limit of `1 / sqrt(input_shape[0])`, and bias `w0` should be set to zero.\n   - Initialize optimizers for `W` and `w0`.\n\n3. **Parameter Count (`parameters`)**:\n   - Return the total number of trainable parameters in the layer, which includes the parameters in `W` and `w0`.\n\n4. **Forward Pass (`forward_pass`)**:\n   - Compute the output of the layer by performing a dot product between the input `X` and the weight matrix `W`, and then adding the bias `w0`.\n\n5. **Backward Pass (`backward_pass`)**:\n   - Calculate and return the gradient with respect to the input.\n   - If the layer is trainable, update the weights and biases using the optimizer's update rule.\n\n6. **Output Shape (`output_shape`)**:\n   - Return the shape of the output produced by the forward pass, which should be `(self.n_units,)`.\n\n**Objective**:  \nExtend the `Layer` class by implementing the `Dense` class to ensure it functions correctly within a neural network framework.\n",
        "mdx_file": "e82ce44c-608a-44d8-822b-204102742e87.mdx",
        "test_cases": [
            {
                "test": "\ndense_layer = Dense(n_units=3, input_shape=(2,))\n\nclass MockOptimizer:\n    def update(self, weights, grad):\n        return weights - 0.01 * grad\n\noptimizer = MockOptimizer()\ndense_layer.initialize(optimizer)\n\nX = np.array([[1, 2]])\noutput = dense_layer.forward_pass(X)\n\naccum_grad = np.array([[0.1, 0.2, 0.3]])\nback_output = dense_layer.backward_pass(accum_grad)\nprint(back_output)",
                "expected_output": "[[ 0.20816524, -0.22928937]]"
            }
        ],
        "solution": "\nclass Dense(Layer):\n    def __init__(self, n_units, input_shape=None):\n        self.layer_input = None\n        self.input_shape = input_shape\n        self.n_units = n_units\n        self.trainable = True\n        self.W = None\n        self.w0 = None\n\n    def initialize(self, optimizer):\n        limit = 1 / math.sqrt(self.input_shape[0])\n        self.W  = np.random.uniform(-limit, limit, (self.input_shape[0], self.n_units))\n        self.w0 = np.zeros((1, self.n_units))\n        self.W_opt  = copy.copy(optimizer)\n        self.w0_opt = copy.copy(optimizer)\n\n    def parameters(self):\n        return np.prod(self.W.shape) + np.prod(self.w0.shape)\n\n    def forward_pass(self, X, training=True):\n        self.layer_input = X\n        return X.dot(self.W) + self.w0\n\n    def backward_pass(self, accum_grad):\n        W = self.W\n        if self.trainable:\n            grad_w = self.layer_input.T.dot(accum_grad)\n            grad_w0 = np.sum(accum_grad, axis=0, keepdims=True)\n            self.W = self.W_opt.update(self.W, grad_w)\n            self.w0 = self.w0_opt.update(self.w0, grad_w0)\n        accum_grad = accum_grad.dot(W.T)\n        return accum_grad\n\n    def output_shape(self):\n        return (self.n_units, )\n    ",
        "difficulty": "hard",
        "video": null,
        "likes": "0",
        "example": {
            "input": "# Initialize a Dense layer with 3 neurons and input shape (2,)\ndense_layer = Dense(n_units=3, input_shape=(2,))\n\n# Define a mock optimizer with a simple update rule\nclass MockOptimizer:\n    def update(self, weights, grad):\n        return weights - 0.01 * grad\n\noptimizer = MockOptimizer()\n\n# Initialize the Dense layer with the mock optimizer\ndense_layer.initialize(optimizer)\n\n# Perform a forward pass with sample input data\nX = np.array([[1, 2]])\noutput = dense_layer.forward_pass(X)\nprint(\"Forward pass output:\", output)\n\n# Perform a backward pass with sample gradient\naccum_grad = np.array([[0.1, 0.2, 0.3]])\nback_output = dense_layer.backward_pass(accum_grad)\nprint(\"Backward pass output:\", back_output)",
            "output": "Forward pass output: [[-0.00655782  0.01429615  0.00905812]]\nBackward pass output: [[ 0.00129588  0.00953634]]",
            "reasoning": "The code initializes a Dense layer with 3 neurons and input shape (2,). It then performs a forward pass with sample input data and a backward pass with sample gradients. The output demonstrates the forward and backward pass results."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "\nimport numpy as np\nimport copy\nimport math\n\n# DO NOT CHANGE SEED\nnp.random.seed(42)\n\n# DO NOT CHANGE LAYER CLASS\nclass Layer(object):\n\n\tdef set_input_shape(self, shape):\n    \n\t\tself.input_shape = shape\n\n\tdef layer_name(self):\n\t\treturn self.__class__.__name__\n\n\tdef parameters(self):\n\t\treturn 0\n\n\tdef forward_pass(self, X, training):\n\t\traise NotImplementedError()\n\n\tdef backward_pass(self, accum_grad):\n\t\traise NotImplementedError()\n\n\tdef output_shape(self):\n\t\traise NotImplementedError()\n\n# Your task is to implement the Dense class based on the above structure\nclass Dense(Layer):\n\tdef __init__(self, n_units, input_shape=None):\n\t\tself.layer_input = None\n\t\tself.input_shape = input_shape\n\t\tself.n_units = n_units\n\t\tself.trainable = True\n\t\tself.W = None\n\t\tself.w0 = None\n\n\tdef forward_pass():\n\n\n\tdef backward_pass(self, accum_grad):\n\n\n\tdef number_of_parameters():\n\n\n    ",
        "title": "Implementing a Custom Dense Layer in Python",
        "learn_section": "## Understanding the Dense Layer\n\nThe Dense layer, also known as a fully connected layer, is a fundamental building block in neural networks. It connects each input neuron to each output neuron, hence the term \"fully connected.\"\n\n### 1. Weight Initialization\nIn the `initialize` method, weights are typically initialized using a uniform distribution within a certain range. For a Dense layer, a common practice is to set this range as:\n$$\n\\text{limit} = \\frac{1}{\\sqrt{\\text{input\\_shape}}}\n$$\nThis initialization helps in maintaining a balance in the distribution of weights, preventing issues like vanishing or exploding gradients during training.\n\n### 2. Forward Pass\nDuring the forward pass, the input data \\( X \\) is multiplied by the weight matrix \\( W \\) and added to the bias \\( w_0 \\) to produce the output:\n$$\n\\text{output} = X \\cdot W + w_0\n$$\n\n### 3. Backward Pass\nThe backward pass computes the gradients of the loss function with respect to the input data, weights, and biases. If the layer is trainable, it updates the weights and biases using the optimizer's update rule:\n$$\nW = W - \\eta \\cdot \\text{grad}_W\n$$\n$$\nw_0 = w_0 - \\eta \\cdot \\text{grad}_{w_0}\n$$\nwhere \\( \\eta \\) is the learning rate and \\( \\text{grad}_W \\) and \\( \\text{grad}_{w_0} \\) are the gradients of the weights and biases, respectively.\n\n### 4. Output Shape\nThe shape of the output from a Dense layer is determined by the number of neurons in the layer. If a layer has `n_units` neurons, the output shape will be \\( (n\\_units,) \\).\n\n### Resources\n- [CS231n: Fully Connected Layer](https://cs231n.github.io/neural-networks-2/#fc)\n\n    ",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabor"
            }
        ],
        "id": "40"
    },
    {
        "description": "In this problem, you need to implement a 2D convolutional layer in Python. This function will process an input matrix using a specified convolutional kernel, padding, and stride.\n",
        "mdx_file": "78c5d6df-d000-4da1-a86d-633e13d2c4fa.mdx",
        "id": "41",
        "test_cases": [
            {
                "test": "input_matrix = np.array([\n    [1., 2., 3., 4., 5.],\n    [6., 7., 8., 9., 10.],\n    [11., 12., 13., 14., 15.],\n    [16., 17., 18., 19., 20.],\n    [21., 22., 23., 24., 25.],\n])\nkernel = np.array([\n    [1., 2.],\n    [3., -1.],\n])\npadding, stride = 0, 1\nexpected = np.array([\n    [ 16., 21., 26., 31.],\n    [ 41., 46., 51., 56.],\n    [ 66., 71., 76., 81.],\n    [ 91., 96., 101., 106.],\n])\noutput = simple_conv2d(input_matrix, kernel, padding, stride)\nprint(output)",
                "expected_output": "[[ 16.,  21.,  26.,  31.],\n [ 41.,  46.,  51.,  56.],\n [ 66.,  71.,  76.,  81.],\n [ 91.,  96., 101., 106.]]"
            },
            {
                "test": "input_matrix = np.array([\n    [1., 2., 3., 4., 5.],\n    [6., 7., 8., 9., 10.],\n    [11., 12., 13., 14., 15.],\n    [16., 17., 18., 19., 20.],\n    [21., 22., 23., 24., 25.],\n])\nkernel = np.array([\n    [.5, 3.2],\n    [1., -1.],\n])\npadding, stride = 2, 2\nexpected = np.array([\n        [ -1., 1., 3., 5., 7., 15.],\n        [ -4., 16., 21., 26., 31., 35.],\n        [  1., 41., 46., 51., 56., 55.],\n        [  6., 66., 71., 76., 81., 75.],\n        [ 11., 91., 96., 101., 106., 95.],\n        [ 42., 65., 68., 71., 74.,  25.],\n    ])\noutput = simple_conv2d(input_matrix, kernel, padding, stride)\nprint(output)",
                "expected_output": "[[ 0.,   0.,   0.,   0. ],\n [ 0.,   5.9, 13.3, 12.5],\n [ 0.,  42.9, 50.3, 27.5],\n [ 0.,  80.9, 88.3, 12.5],]"
            }
        ],
        "solution": "import numpy as np\n\ndef simple_conv2d(input_matrix: np.ndarray, kernel: np.ndarray, padding: int, stride: int):\n    input_height, input_width = input_matrix.shape\n    kernel_height, kernel_width = kernel.shape\n\n    padded_input = np.pad(input_matrix, ((padding, padding), (padding, padding)), mode='constant')\n    input_height_padded, input_width_padded = padded_input.shape\n\n    output_height = (input_height_padded - kernel_height) // stride + 1\n    output_width = (input_width_padded - kernel_width) // stride + 1\n\n    output_matrix = np.zeros((output_height, output_width))\n\n    for i in range(output_height):\n        for j in range(output_width):\n            region = padded_input[i*stride:i*stride + kernel_height, j*stride:j*stride + kernel_width]\n            output_matrix[i, j] = np.sum(region * kernel)\n\n    return output_matrix\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "import numpy as np\n\ninput_matrix = np.array([\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9, 10, 11, 12],\n    [13, 14, 15, 16]\n])\n\nkernel = np.array([\n    [1, 0],\n    [-1, 1]\n])\n\npadding = 1\nstride = 2\n\noutput = simple_conv2d(input_matrix, kernel, padding, stride)\nprint(output)",
            "reasoning": "The function performs a 2D convolution operation on the input matrix using the specified kernel, padding, and stride. The output matrix contains the results of the convolution operation.",
            "output": "[[ 1.  1. -4.],[ 9.  7. -4.],[ 0. 14. 16.]]"
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef simple_conv2d(input_matrix: np.ndarray, kernel: np.ndarray, padding: int, stride: int):\n\tinput_height, input_width = input_matrix.shape\n\tkernel_height, kernel_width = kernel.shape\n\n\t# Your code here\n    \n\treturn output_matrix\n",
        "title": "Simple Convolutional 2D Layer",
        "learn_section": "## Simple Convolutional 2D Layer\n\nThe Convolutional layer is a fundamental component used extensively in Computer Vision tasks. Here are the crucial parameters:\n\n### Parameters\n1. **input_matrix**:  \n   A 2D NumPy array representing the input data, such as an image. Each element in this array corresponds to a pixel or a feature value in the input space. The dimensions of the input matrix are typically represented as $ \\text{height} \\times \\text{width} $.\n\n2. **kernel**:  \n   Another 2D NumPy array representing the convolutional filter. The kernel is smaller than the input matrix and slides over it to perform the convolution operation. Each element in the kernel serves as a weight that modifies the input during convolution. The kernel size is denoted as $ \\text{kernel\\_height} \\times \\text{kernel\\_width} $.\n\n3. **padding**:  \n   An integer specifying the number of rows and columns of zeros added around the input matrix. Padding controls the spatial dimensions of the output, allowing the kernel to process edge elements effectively or to maintain the original input size.\n\n4. **stride**:  \n   An integer that represents the number of steps the kernel moves across the input matrix for each convolution. A stride greater than one reduces the output size, as the kernel skips over elements.\n\n### Implementation\n1. **Padding the Input**:  \n   The input matrix is padded with zeros based on the specified `padding` value. This increases the input size and enables the kernel to cover elements at the borders and corners.\n\n2. **Calculating Output Dimensions**:  \n   The height and width of the output matrix are calculated using the following formulas:\n   $$\n   \\text{output\\_height} = \\left( \\frac{\\text{input\\_height, padded} - \\text{kernel\\_height}}{\\text{stride}} \\right) + 1\n   $$\n   $$\n   \\text{output\\_width} = \\left( \\frac{\\text{input\\_width, padded} - \\text{kernel\\_width}}{\\text{stride}} \\right) + 1\n   $$\n\n3. **Performing Convolution**:\n   - A nested loop iterates over each position where the kernel can be applied to the padded input matrix.\n   - At each position, a region of the input matrix, matching the size of the kernel, is selected.\n   - Element-wise multiplication between the kernel and the input region is performed, followed by summing the results to produce a single value. This value is then stored in the corresponding position of the output matrix.\n\n4. **Output**:  \n   The function returns the output matrix, which contains the results of the convolution operation performed across the entire input.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/drogovozDP",
                "name": "Drogovoz Dima"
            }
        ]
    },
    {
        "description": "Write a Python function `relu` that implements the Rectified Linear Unit (ReLU) activation function. The function should take a single float as input and return the value after applying the ReLU function. The ReLU function returns the input if it's greater than 0, otherwise, it returns 0.",
        "mdx_file": "655e16ea-1159-42c0-b911-85573844c388.mdx",
        "test_cases": [
            {
                "test": "print(relu(0))",
                "expected_output": "0"
            },
            {
                "test": "print(relu(1))",
                "expected_output": "1"
            },
            {
                "test": "print(relu(-1))",
                "expected_output": "0"
            }
        ],
        "solution": "def relu(z: float) -> float:\n    return max(0, z)\n",
        "difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/1hq_bTksuOQ",
        "example": {
            "input": "print(relu(0)) \nprint(relu(1)) \nprint(relu(-1))",
            "output": "0\n1\n0",
            "reasoning": "The ReLU function is applied to the input values 0, 1, and -1. The output is 0 for negative values and the input value for non-negative values."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "def relu(z: float) -> float:\n\t# Your code here\n\tpass\n",
        "title": "Implement ReLU Activation Function",
        "learn_section": "\n## Understanding the ReLU Activation Function\n\nThe ReLU (Rectified Linear Unit) activation function is widely used in neural networks, particularly in hidden layers of deep learning models. It maps any real-valued number to the non-negative range $[0, \\infty)$, which helps introduce non-linearity into the model while maintaining computational efficiency.\n\n### Mathematical Definition\nThe ReLU function is mathematically defined as:\n$$\nf(z) = \\max(0, z)\n$$\nwhere $z$ is the input to the function.\n\n### Characteristics\n- **Output Range**: The output is always in the range $[0, \\infty)$. Values below 0 are mapped to 0, while positive values are retained.\n- **Shape**: The function has an \"L\" shaped curve with a horizontal axis at $y = 0$ and a linear increase for positive $z$.\n- **Gradient**: The gradient is 1 for positive values of $z$ and 0 for non-positive values. This means the function is linear for positive inputs and flat (zero gradient) for negative inputs.\n\nThis function is particularly useful in deep learning models as it introduces non-linearity while being computationally efficient, helping to capture complex patterns in the data.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/doshi-kevin",
                "name": "Kevin Doshi"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "marmo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-42/",
        "id": "42"
    },
    {
        "description": "Write a Python function `ridge_loss` that implements the Ridge Regression loss function. The function should take a 2D numpy array `X` representing the feature matrix, a 1D numpy array `w` representing the coefficients, a 1D numpy array `y_true` representing the true labels, and a float `alpha` representing the regularization parameter. The function should return the Ridge loss, which combines the Mean Squared Error (MSE) and a regularization term.",
        "mdx_file": "42621736-0bbf-47c8-b46e-2ba5edbc4f75.mdx",
        "test_cases": [
            {
                "test": "X = np.array([[1,1],[2,1],[3,1],[4,1]])\nW = np.array([.2,2])\ny = np.array([2,3,4,5])\nalpha = 0.1\noutput = ridge_loss(X, W, y, alpha)\nprint(output)",
                "expected_output": "2.204"
            },
            {
                "test": "X = np.array([[1,1,4],[2,1,2],[3,1,.1],[4,1,1.2],[1,2,3]])\nW = np.array([.2,2,5])\ny = np.array([2,3,4,5,2])\nalpha = 0.1\noutput = ridge_loss(X, W, y, alpha)\nprint(output)",
                "expected_output": "164.402"
            }
        ],
        "solution": "import numpy as np\n\ndef ridge_loss(X: np.ndarray, w: np.ndarray, y_true: np.ndarray, alpha: float) -> float:\n    loss = np.mean((y_true - X @ w)**2) + alpha * np.sum(w**2)\n    return loss\n",
        "difficulty": "easy",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-43/index.html",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n\nX = np.array([[1, 1], [2, 1], [3, 1], [4, 1]])\nw = np.array([0.2, 2])\ny_true = np.array([2, 3, 4, 5])\nalpha = 0.1\n\nloss = ridge_loss(X, w, y_true, alpha)\nprint(loss)",
            "output": "2.204",
            "reasoning": "The Ridge loss is calculated using the Mean Squared Error (MSE) and a regularization term. The output represents the combined loss value."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef ridge_loss(X: np.ndarray, w: np.ndarray, y_true: np.ndarray, alpha: float) -> float:\n\t# Your code here\n\tpass\n",
        "title": "Implement Ridge Regression Loss Function",
        "learn_section": "\n## Ridge Regression Loss\n\nRidge Regression is a linear regression method with a regularization term to prevent overfitting by controlling the size of the coefficients.\n\n### Key Concepts:\n1. **Regularization**:  \n   Adds a penalty to the loss function to discourage large coefficients, helping to generalize the model.\n\n2. **Mean Squared Error (MSE)**:  \n   Measures the average squared difference between actual and predicted values.\n\n3. **Penalty Term**:  \n   The sum of the squared coefficients, scaled by the regularization parameter $ \\lambda $, which controls the strength of the regularization.\n\n### Ridge Loss Function\nThe Ridge Loss function combines MSE and the penalty term:\n$$\nL(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n$$\n\n### Implementation Steps:\n1. **Calculate MSE**:  \n   Compute the average squared difference between actual and predicted values.\n\n2. **Add Regularization Term**:  \n   Compute the sum of squared coefficients multiplied by $ \\lambda $.\n\n3. **Combine and Minimize**:  \n   Sum MSE and the regularization term to form the Ridge loss, then minimize this loss to find the optimal coefficients.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "id": "43"
    },
    {
        "description": "Write a Python function `leaky_relu` that implements the Leaky Rectified Linear Unit (Leaky ReLU) activation function. The function should take a float `z` as input and an optional float `alpha`, with a default value of 0.01, as the slope for negative inputs. The function should return the value after applying the Leaky ReLU function.",
        "mdx_file": "b57b51bc-e9cc-473c-a7ad-1fd713a25c8b.mdx",
        "test_cases": [
            {
                "test": "print(leaky_relu(5))",
                "expected_output": "5"
            },
            {
                "test": "print(leaky_relu(1))",
                "expected_output": "1"
            },
            {
                "test": "print(leaky_relu(-1))",
                "expected_output": "-0.01"
            }
        ],
        "solution": "def leaky_relu(z: float, alpha: float = 0.01) -> float|int:\n    return z if z > 0 else alpha * z\n",
        "difficulty": "easy",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-4",
        "likes": "0",
        "video": "https://youtu.be/V817IRW07vs",
        "example": {
            "input": "print(leaky_relu(0)) \nprint(leaky_relu(1))\nprint(leaky_relu(-1)) \nprint(leaky_relu(-2, alpha=0.1))",
            "output": "0\n1\n-0.01\n-0.2",
            "reasoning": "- For z = 0, the output is 0.\n- For z = 1, the output is 1.\n- For z = -1, the output is -0.01 (0.01 * -1).\n- For z = -2 with alpha = 0.1, the output is -0.2 (0.1 * -2)."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "def leaky_relu(z: float, alpha: float = 0.01) -> float|int:\n\t# Your code here\n\tpass\n",
        "title": "Leaky ReLU Activation Function",
        "learn_section": "\n## Understanding the Leaky ReLU Activation Function\n\nThe Leaky ReLU (Leaky Rectified Linear Unit) activation function is a variant of the ReLU function used in neural networks. It addresses the \"dying ReLU\" problem by allowing a small, non-zero gradient when the input is negative. This small slope for negative inputs helps keep the function active and prevents neurons from becoming inactive.\n\n### Mathematical Definition\nThe Leaky ReLU function is mathematically defined as:\n$$\nf(z) = \\begin{cases} \nz & \\text{if } z > 0 \\\\ \n\\alpha z & \\text{if } z \\leq 0 \n\\end{cases}\n$$\nwhere $z$ is the input to the function and $\\alpha$ is a small positive constant, typically $\\alpha = 0.01$.\n\nIn this definition, the function returns $z$ for positive values, and for negative values, it returns $\\alpha z$, allowing a small gradient to pass through.\n\n### Characteristics\n- **Output Range**: The output is in the range $(-\\infty, \\infty)$. Positive values are retained, while negative values are scaled by the factor $\\alpha$, allowing them to be slightly negative.\n- **Shape**: The function has a similar \"L\" shaped curve as ReLU, but with a small negative slope on the left side for negative $z$, creating a small gradient for negative inputs.\n- **Gradient**: The gradient is 1 for positive values of $z$ and $\\alpha$ for non-positive values. This allows the function to remain active even for negative inputs, unlike ReLU, where the gradient is zero for negative inputs.\n\nThis function is particularly useful in deep learning models as it mitigates the issue of \"dead neurons\" in ReLU by ensuring that neurons can still propagate a gradient even when the input is negative, helping to improve learning dynamics in the network.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/atharva-gite",
                "name": "atharva-gite"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "id": "44"
    },
    {
        "description": "Write a Python function `kernel_function` that computes the linear kernel between two input vectors `x1` and `x2`. The linear kernel is defined as the dot product (inner product) of two vectors.",
        "mdx_file": "c57878a3-973a-41dc-84b3-758b24fb1fd7.mdx",
        "id": "45",
        "test_cases": [
            {
                "test": "import numpy as np\nx1 = np.array([1, 2, 3])\nx2 = np.array([4, 5, 6])\nresult = kernel_function(x1, x2)\nprint(result)",
                "expected_output": "32"
            },
            {
                "test": "import numpy as np\nx1 = np.array([0, 1, 2])\nx2 = np.array([3, 4, 5])\nresult = kernel_function(x1, x2)\nprint(result)",
                "expected_output": "14"
            }
        ],
        "solution": "import numpy as np\n\ndef kernel_function(x1, x2):\n    return np.inner(x1, x2)\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "import numpy as np\n\nx1 = np.array([1, 2, 3])\nx2 = np.array([4, 5, 6])\n\nresult = kernel_function(x1, x2)\nprint(result)",
            "output": "32",
            "reasoning": "The linear kernel between x1 and x2 is computed as:1\\*4 + 2\\*5 + 3\\*6 = 32"
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef kernel_function(x1, x2):\n\t# Your code here\n\tpass\n",
        "title": "Linear Kernel Function",
        "learn_section": "\n## Understanding the Linear Kernel\n\nA kernel function in machine learning is used to measure the similarity between two data points in a higher-dimensional space without having to compute the coordinates of the points in that space explicitly. The **linear kernel** is one of the simplest and most commonly used kernel functions. It computes the dot product (or inner product) of two vectors.\n\n### Mathematical Definition\nThe linear kernel between two vectors $ \\mathbf{x}_1 $ and $ \\mathbf{x}_2 $ is mathematically defined as:\n$$\nK(\\mathbf{x}_1, \\mathbf{x}_2) = \\mathbf{x}_1 \\cdot \\mathbf{x}_2 = \\sum_{i=1}^{n} x_{1,i} \\cdot x_{2,i}\n$$\nwhere $ n $ is the number of features, and $ x_{1,i} $ and $ x_{2,i} $ are the components of the vectors $ \\mathbf{x}_1 $ and $ \\mathbf{x}_2 $ respectively.\n\nThe linear kernel is widely used in support vector machines (SVMs) and other machine learning algorithms for linear classification and regression tasks. It is computationally efficient and works well when the data is linearly separable.\n\n### Characteristics\n- **Simplicity**: The linear kernel is straightforward to implement and compute.\n- **Efficiency**: It is computationally less expensive compared to other complex kernels like polynomial or RBF kernels.\n- **Interpretability**: The linear kernel is interpretable because it corresponds directly to the dot product, a well-understood operation in vector algebra.\n\nIn this problem, you will implement a function capable of computing the linear kernel between two vectors.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Write a Python function `precision` that calculates the precision metric given two numpy arrays: `y_true` and `y_pred`. The `y_true` array contains the true binary labels, and the `y_pred` array contains the predicted binary labels. Precision is defined as the ratio of true positives to the sum of true positives and false positives.",
        "mdx_file": "41c46d39-b6a0-4b90-b4a5-c8785639b533.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nresult = precision(y_true, y_pred)\nprint(result)",
                "expected_output": "1.0"
            },
            {
                "test": "import numpy as np\ny_true = np.array([1, 0, 1, 1, 0, 0])\ny_pred = np.array([1, 0, 0, 0, 0, 1])\nresult = precision(y_true, y_pred)\nprint(result)",
                "expected_output": "0.5"
            }
        ],
        "solution": "import numpy as np\n\ndef precision(y_true, y_pred):\n    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n    false_positives = np.sum((y_true == 0) & (y_pred == 1))\n    return true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/u99yBNF4vE0",
        "example": {
            "input": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\n\nresult = precision(y_true, y_pred)\nprint(result)",
            "output": "1.0",
            "reasoning": "- True Positives (TP) = 3\n- False Positives (FP) = 0\n- Precision = TP / (TP + FP) = 3 / (3 + 0) = 1.0"
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\ndef precision(y_true, y_pred):\n\t# Your code here\n\tpass\n",
        "title": "Implement Precision Metric",
        "learn_section": "\n## Understanding Precision in Classification\n\nPrecision is a key metric used in the evaluation of classification models, particularly in binary classification. It provides insight into the accuracy of the positive predictions made by the model.\n\n### Mathematical Definition\nPrecision is defined as the ratio of true positives (TP) to the sum of true positives and false positives (FP):\n$$\n\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n$$\n\nWhere:\n- **True Positives (TP)**: The number of positive samples that are correctly identified as positive.\n- **False Positives (FP)**: The number of negative samples that are incorrectly identified as positive.\n\n### Characteristics of Precision\n- **Range**: Precision ranges from 0 to 1, where 1 indicates perfect precision (no false positives) and 0 indicates no true positives.\n- **Interpretation**: High precision means that the model has a low false positive rate, meaning it rarely labels negative samples as positive.\n- **Use Case**: Precision is particularly useful when the cost of false positives is high, such as in medical diagnosis or fraud detection.\n\nIn this problem, you will implement a function to calculate precision given the true labels and predicted labels of a binary classification task.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "id": "46"
    },
    {
        "description": "In this problem, you need to implement a single function that can perform three variants of gradient descent Stochastic Gradient Descent (SGD), Batch Gradient Descent, and Mini Batch Gradient Descent using Mean Squared Error (MSE) as the loss function. The function will take an additional parameter to specify which variant to use. Note: Do not shuffle the data\n",
        "mdx_file": "5ee614fe-73ae-4474-b043-1c8a0ab82a47.mdx",
        "id": "47",
        "test_cases": [
            {
                "test": "import numpy as np\n\nX = np.array([[1, 1], [2, 1], [3, 1], [4, 1]])\ny = np.array([2, 3, 4, 5])\nweights = np.zeros(X.shape[1])\nlearning_rate = 0.01\nn_iterations = 100\n\n# Test Batch Gradient Descent\noutput = gradient_descent(X, y, weights, learning_rate, n_iterations, method='batch')\nprint(output)",
                "expected_output": "[1.14905239 0.56176776]"
            },
            {
                "test": "import numpy as np\n\nX = np.array([[1, 1], [2, 1], [3, 1], [4, 1]])\ny = np.array([2, 3, 4, 5])\nweights = np.zeros(X.shape[1])\nlearning_rate = 0.01\nn_iterations = 100\n\n# Test Stochastic Gradient Descent\noutput = gradient_descent(X, y, weights, learning_rate, n_iterations, method='stochastic')\nprint(output)",
                "expected_output": "[1.0507814  0.83659454]"
            },
            {
                "test": "import numpy as np\n\nX = np.array([[1, 1], [2, 1], [3, 1], [4, 1]])\ny = np.array([2, 3, 4, 5])\nweights = np.zeros(X.shape[1])\nlearning_rate = 0.01\nn_iterations = 100\nbatch_size = 2\n\n# Test Mini-Batch Gradient Descent\noutput = gradient_descent(X, y, weights, learning_rate, n_iterations, batch_size, method='mini_batch')\nprint(output)",
                "expected_output": "[1.10334065 0.68329431]"
            }
        ],
        "solution": "import numpy as np\n\ndef gradient_descent(X, y, weights, learning_rate, n_iterations, batch_size=1, method='batch'):\n    m = len(y)\n    \n    for _ in range(n_iterations):\n        if method == 'batch':\n            # Calculate the gradient using all data points\n            predictions = X.dot(weights)\n            errors = predictions - y\n            gradient = 2 * X.T.dot(errors) / m\n            weights = weights - learning_rate * gradient\n        \n        elif method == 'stochastic':\n            # Update weights for each data point individually\n            for i in range(m):\n                prediction = X[i].dot(weights)\n                error = prediction - y[i]\n                gradient = 2 * X[i].T.dot(error)\n                weights = weights - learning_rate * gradient\n        \n        elif method == 'mini_batch':\n            # Update weights using sequential batches of data points without shuffling\n            for i in range(0, m, batch_size):\n                X_batch = X[i:i+batch_size]\n                y_batch = y[i:i+batch_size]\n                predictions = X_batch.dot(weights)\n                errors = predictions - y_batch\n                gradient = 2 * X_batch.T.dot(errors) / batch_size\n                weights = weights - learning_rate * gradient\n                \n    return weights\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n\n# Sample data\nX = np.array([[1, 1], [2, 1], [3, 1], [4, 1]])\ny = np.array([2, 3, 4, 5])\n\n# Parameters\nlearning_rate = 0.01\nn_iterations = 1000\nbatch_size = 2\n\n# Initialize weights\nweights = np.zeros(X.shape[1])\n\n# Test Batch Gradient Descent\nfinal_weights = gradient_descent(X, y, weights, learning_rate, n_iterations, method='batch')\n# Test Stochastic Gradient Descent\nfinal_weights = gradient_descent(X, y, weights, learning_rate, n_iterations, method='stochastic')\n# Test Mini-Batch Gradient Descent\nfinal_weights = gradient_descent(X, y, weights, learning_rate, n_iterations, batch_size, method='mini_batch')",
            "output": "[float,float]\n[float, float]\n[float, float]",
            "reasoning": "The function should return the final weights after performing the specified variant of gradient descent."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef gradient_descent(X, y, weights, learning_rate, n_iterations, batch_size=1, method='batch'):\n\t# Your code here\n\tpass\n",
        "title": "Implement Gradient Descent Variants with MSE Loss",
        "learn_section": "\n## Understanding Gradient Descent Variants with MSE Loss\n\nGradient Descent is an optimization algorithm used to minimize the cost function in machine learning models, particularly in linear regression and neural networks. The Mean Squared Error (MSE) loss function is commonly used in regression tasks. There are three main types of gradient descent based on how much data is used to compute the gradient at each iteration:\n\n1. **Batch Gradient Descent**:  \n   Batch Gradient Descent computes the gradient of the MSE loss function with respect to the parameters for the entire training dataset. It updates the parameters after processing the entire dataset:\n   $$\n   \\theta = \\theta - \\alpha \\cdot \\frac{2}{m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)}\n   $$\n   where $ \\alpha $ is the learning rate, $ m $ is the number of samples, and $ \\nabla_{\\theta} J(\\theta) $ is the gradient of the MSE loss function.\n\n2. **Stochastic Gradient Descent (SGD)**:  \n   Stochastic Gradient Descent updates the parameters for each training example individually, making it faster but more noisy:\n   $$\n   \\theta = \\theta - \\alpha \\cdot 2 \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)}\n   $$\n   where $ x^{(i)}, y^{(i)} $ are individual training examples.\n\n3. **Mini-Batch Gradient Descent**:  \n   Mini-Batch Gradient Descent is a compromise between Batch and Stochastic Gradient Descent. It updates the parameters after processing a small batch of training examples, without shuffling the data:\n   $$\n   \\theta = \\theta - \\alpha \\cdot \\frac{2}{b} \\sum_{i=1}^{b} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x^{(i)}\n   $$\n   where $ b $ is the batch size, a subset of the training dataset.\n\nEach method has its advantages: Batch Gradient Descent is more stable but slower, Stochastic Gradient Descent is faster but noisy, and Mini-Batch Gradient Descent strikes a balance between the two.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "In this problem, your task is to implement a function that converts a given matrix into its Reduced Row Echelon Form (RREF). The RREF of a matrix is a special form where each leading entry in a row is 1, and all other elements in the column containing the leading 1 are zeros, except for the leading 1 itself.\n\nHowever, there are some additional details to keep in mind:\n\n- Diagonal entries can be 0 if the matrix is reducible (i.e., the row corresponding to that position can be eliminated entirely).\n- Some rows may consist entirely of zeros.\n- If a column contains a pivot (a leading 1), all other entries in that column should be zero.\n\nYour task is to implement the RREF algorithm, which must handle these cases and convert any given matrix into its RREF.\n\n",
        "mdx_file": "15fb34f8-1b48-4558-9f5d-807148d4381e.mdx",
        "id": "48",
        "test_cases": [
            {
                "test": "import numpy as np\n\nmatrix = np.array([\n    [1, 2, -1, -4],\n    [2, 3, -1, -11],\n    [-2, 0, -3, 22]\n])\n\noutput = rref(matrix)\nprint(output)",
                "expected_output": "[[ 1.,  0.,  0., -8.], [ 0.,  1.,  0.,  1.], [-0., -0.,  1., -2.]]"
            },
            {
                "test": "import numpy as np\n\nmatrix = np.array([\n    [2, 4, -2],\n    [4, 9, -3],\n    [-2, -3, 7]\n])\n\noutput = rref(matrix)\nprint(output)",
                "expected_output": "[[ 1.,  0.,  0.], [ 0.,  1.,  0.], [ 0.,  0.,  1.]]"
            },
            {
                "test": "import numpy as np\n\nmatrix = np.array([\n    [0, 2, -1, -4],\n    [2, 0, -1, -11],\n    [-2, 0, 0, 22]\n])\n\noutput = rref(matrix)\nprint(output)",
                "expected_output": "[[ 1.,  0.,  0., -11.],[-0.,  1.,  0., -7.5],[-0., -0.,  1., -11.]]"
            },
            {
                "test": "import numpy as np\n\nmatrix = np.array([\n        [1, 2, -1],\n        [2, 4, -1],\n        [-2, -4, -3]])\n\noutput = rref(matrix)\nprint(output)",
                "expected_output": "[[ 1.,  2.,  0.],[ 0.,  0.,  1.],[0., 0.,  0.]]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef rref(matrix):\n    # Convert to float for division operations\n    A = matrix.astype(np.float32)\n    n, m = A.shape\n    row = 0  # Current row index for pivot placement\n    \n    # Iterate over columns, up to the number of columns m\n    for col in range(m):\n        if row >= n:  # No more rows to process\n            break\n        \n        # Find a row with a non-zero entry in the current column\n        nonzero_rel_id = np.nonzero(A[row:, col])[0]\n        if len(nonzero_rel_id) == 0:  # No pivot in this column\n            continue\n        \n        # Swap the current row with the row containing the non-zero entry\n        k = nonzero_rel_id[0] + row\n        A[[row, k]] = A[[k, row]]\n        \n        # Normalize the pivot row to make the pivot 1\n        A[row] = A[row] / A[row, col]\n        \n        # Eliminate all other entries in this column\n        for j in range(n):\n            if j != row:\n                A[j] -= A[j, col] * A[row]\n        \n        row += 1  # Move to the next row for the next pivot\n    \n    return A",
        "likes": "0",
        "video": "https://youtu.be/mpimdNG9XsA?si=kWFw8hhbGTy2ujX3",
        "example": {
            "input": "import numpy as np\n\nmatrix = np.array([\n    [1, 2, -1, -4],\n    [2, 3, -1, -11],\n    [-2, 0, -3, 22]\n])\n\nrref_matrix = rref(matrix)\nprint(rref_matrix)",
            "output": "# array([\n#    [ 1.  0.  0. -8.],\n#    [ 0.  1.  0.  1.],\n#    [-0. -0.  1. -2.]\n# ])",
            "reasoning": "The given matrix is converted to its Reduced Row Echelon Form (RREF) where each leading entry is 1, and all other entries in the leading columns are zero."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef rref(matrix):\n\tYour code here\n\tpass\n",
        "title": "Implement Reduced Row Echelon Form (RREF) Function",
        "learn_section": "## Understanding the RREF Algorithm\n\nThe Reduced Row Echelon Form (RREF) of a matrix is a specific form achieved through a sequence of elementary row operations. This algorithm will convert any matrix into its RREF, which is useful for solving linear equations and understanding the properties of the matrix.\n\nHere’s a step-by-step guide to implementing the RREF algorithm:\n\n1. **Start with the leftmost column**:  \n   Set the initial leading column to the first column of the matrix. Move this \"lead\" to the right as you progress through the algorithm.\n\n2. **Select the pivot row**:  \n   Identify the first non-zero entry in the current leading column. This entry is the pivot. If necessary, swap rows to bring the pivot into position to avoid having a zero in the pivot position.\n\n3. **Scale the pivot row**:  \n   Divide the entire pivot row by the pivot value to make the leading entry equal to 1.\n   $$\n   \\text{Row}_r = \\frac{\\text{Row}_r}{\\text{pivot}}\n   $$\n   For example, if the pivot is 3, divide the entire row by 3 to make the leading entry 1.\n\n4. **Eliminate above and below the pivot**:  \n   Subtract multiples of the pivot row from all the other rows to create zeros in the rest of the pivot column. This ensures the pivot is the only non-zero entry in its column.\n   $$\n   \\text{Row}_i = \\text{Row}_i - (\\text{Row}_r \\times \\text{lead coefficient})\n   $$\n   Repeat this step for each row $ i $ where $ i \\neq r $, ensuring all entries above and below the pivot are zero.\n\n5. **Move to the next column**:  \n   Move the lead one column to the right and repeat the process from step 2. Continue until there are no more columns to process or the remaining submatrix is all zeros.\n\nBy following these steps, the matrix will be converted into its Reduced Row Echelon Form, where each leading entry is 1, and all other entries in the leading columns are zero.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://github.com/peppermin-t",
                "name": "Yinjia Chen"
            }
        ]
    },
    {
        "description": "Implement the Adam (Adaptive Moment Estimation) optimization algorithm in Python. Adam is an optimization algorithm that adapts the learning rate for each parameter. Your task is to write a function `adam_optimizer` that updates the parameters of a given function using the Adam algorithm.\n\nThe function should take the following parameters:\n\n- `f`: The objective function to be optimized\n- `grad`: A function that computes the gradient of `f`\n- `x0`: Initial parameter values\n- `learning_rate`: The step size (default: 0.001)\n- `beta1`: Exponential decay rate for the first moment estimates (default: 0.9)\n- `beta2`: Exponential decay rate for the second moment estimates (default: 0.999)\n- `epsilon`: A small constant for numerical stability (default: 1e-8)\n- `num_iterations`: Number of iterations to run the optimizer (default: 1000)\n\nThe function should return the optimized parameters.\n\n",
        "mdx_file": "2916c64a-c0d7-41a2-956e-b5961e023d6d.mdx",
        "test_cases": [
            {
                "test": "\nimport numpy as np\n\ndef objective_function(x):\n    return x[0]**2 + x[1]**2\n\ndef gradient(x):\n    return np.array([2*x[0], 2*x[1]])\n\nx0 = np.array([1.0, 1.0])\nx_opt = adam_optimizer(objective_function, gradient, x0)\n\nprint(x_opt)\n",
                "expected_output": "[0.99000325 0.99000325]"
            },
            {
                "test": "\nimport numpy as np\n\ndef objective_function(x):\n    return x[0]**2 + x[1]**2\n\ndef gradient(x):\n    return np.array([2*x[0], 2*x[1]])\n\nx0 = np.array([0.2, 12.3])\nx_opt = adam_optimizer(objective_function, gradient, x0)\n\nprint(x_opt)\n",
                "expected_output": "[ 0.19001678 12.29000026]"
            }
        ],
        "solution": "import numpy as np\n\ndef adam_optimizer(f, grad, x0, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, num_iterations=10):\n    x = x0\n    m = np.zeros_like(x)\n    v = np.zeros_like(x)\n\n    for t in range(1, num_iterations + 1):\n        g = grad(x)\n        m = beta1 * m + (1 - beta1) * g\n        v = beta2 * v + (1 - beta2) * g**2\n        m_hat = m / (1 - beta1**t)\n        v_hat = v / (1 - beta2**t)\n        x = x - learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n\n    return x\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n\ndef objective_function(x):\n    return x[0]**2 + x[1]**2\n\ndef gradient(x):\n    return np.array([2*x[0], 2*x[1]])\n\nx0 = np.array([1.0, 1.0])\nx_opt = adam_optimizer(objective_function, gradient, x0)\n\nprint(\"Optimized parameters:\", x_opt)",
            "output": "# Optimized parameters: [0.99000325 0.99000325]",
            "reasoning": "The Adam optimizer updates the parameters to minimize the objective function. In this case, the objective function is the sum of squares of the parameters, and the optimizer finds the optimal values for the parameters."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef adam_optimizer(f, grad, x0, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, num_iterations=10):\n\t# Your code here\n\tpass\n",
        "title": "Implement Adam Optimization Algorithm",
        "learn_section": "\n## Understanding the Adam Optimization Algorithm\n\nAdam (Adaptive Moment Estimation) is an optimization algorithm commonly used in training deep neural networks. It combines ideas from two other optimization algorithms: RMSprop and Momentum.\n\n### Key Concepts\n1. **Adaptive Learning Rates**:  \n   Adam computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients.\n2. **Momentum**:  \n   It keeps track of an exponentially decaying average of past gradients, similar to momentum.\n3. **RMSprop**:  \n   It also keeps track of an exponentially decaying average of past squared gradients.\n4. **Bias Correction**:  \n   Adam includes bias correction terms to account for the initialization of the first and second moment estimates.\n\n### The Adam Algorithm\nGiven parameters $ \\theta $, objective function $ f(\\theta) $, and its gradient $ \\nabla_\\theta f(\\theta) $:\n1. **Initialize**:\n   - Time step $ t = 0 $\n   - Parameters $ \\theta_0 $\n   - First moment vector $ m_0 = 0 $\n   - Second moment vector $ v_0 = 0 $\n   - Hyperparameters $ \\alpha $ (learning rate), $ \\beta_1 $, $ \\beta_2 $, and $ \\epsilon $\n2. **While not converged, do**:\n   1. Increment time step: $ t = t + 1 $\n   2. Compute gradient: $ g_t = \\nabla_\\theta f_t(\\theta_{t-1}) $\n   3. Update biased first moment estimate: $ m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t $\n   4. Update biased second raw moment estimate: $ v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2 $\n   5. Compute bias-corrected first moment estimate: $ \\hat{m}_t = m_t / (1 - \\beta_1^t) $\n   6. Compute bias-corrected second raw moment estimate: $ \\hat{v}_t = v_t / (1 - \\beta_2^t) $\n   7. Update parameters: $ \\theta_t = \\theta_{t-1} - \\alpha \\cdot \\hat{m}_t / (\\sqrt{\\hat{v}_t} + \\epsilon) $\n\nAdam combines the advantages of AdaGrad, which works well with sparse gradients, and RMSProp, which works well in online and non-stationary settings. Adam is generally regarded as being fairly robust to the choice of hyperparameters, though the learning rate may sometimes need to be changed from the suggested default.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "id": "49"
    },
    {
        "description": "Write a Python function that multiplies a matrix by a scalar and returns the result.",
        "mdx_file": "2a723046-cee1-4d03-8d5e-ec8ce111e8f2.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNjYWxhcl9tdWx0aXBseV90ZyhtYXRyaXgsIHNjYWxhcikgLT4gVGVuc29yOgogICAgIiIiCiAgICBNdWx0aXBseSBlYWNoIGVsZW1lbnQgb2YgYSAyRCBtYXRyaXggYnkgYSBzY2FsYXIgdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0aW55Z3JhZCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDJEIFRlbnNvciBvZiB0aGUgc2FtZSBzaGFwZS4KICAgICIiIgogICAgIyBDb252ZXJ0IGlucHV0IHRvIFRlbnNvcgogICAgbV90ID0gVGVuc29yKG1hdHJpeCkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
        "test_cases": [
            {
                "test": "print(scalar_multiply([[1,2],[3,4]], 2))",
                "expected_output": "[[2, 4], [6, 8]]"
            },
            {
                "test": "print(scalar_multiply([[0,-1],[1,0]], -1))",
                "expected_output": "[[0, 1], [-1, 0]]"
            }
        ],
        "solution": "def scalar_multiply(matrix: list[list[int|float]], scalar: int|float) -> list[list[int|float]]:\n    return [[element * scalar for element in row] for row in matrix]",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHNjYWxhcl9tdWx0aXBseV90ZyhtYXRyaXgsIHNjYWxhcikgLT4gVGVuc29yOgogICAgIiIiCiAgICBNdWx0aXBseSBlYWNoIGVsZW1lbnQgb2YgYSAyRCBtYXRyaXggYnkgYSBzY2FsYXIgdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0aW55Z3JhZCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDJEIFRlbnNvciBvZiB0aGUgc2FtZSBzaGFwZS4KICAgICIiIgogICAgbV90ID0gVGVuc29yKG1hdHJpeCkKICAgIHJldHVybiBtX3QgKiBzY2FsYXIK",
        "pytorch_difficulty": "easy",
        "video": "https://youtu.be/iE2NvpvZRBk",
        "likes": "0",
        "difficulty": "easy",
        "example": {
            "input": "matrix = [[1, 2], [3, 4]], scalar = 2",
            "output": "[[2, 4], [6, 8]]",
            "reasoning": "Each element of the matrix is multiplied by the scalar."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "def scalar_multiply(matrix: list[list[int|float]], scalar: int|float) -> list[list[int|float]]:\n\treturn result",
        "title": "Scalar Multiplication of a Matrix",
        "learn_section": "\n## Scalar Multiplication of a Matrix\n\nWhen a matrix $A$ is multiplied by a scalar $k$, the operation is defined as multiplying each element of $A$ by $k$.\n\nGiven a matrix $A$:\n$$\nA = \\begin{pmatrix} \na_{11} & a_{12} \\\\ \na_{21} & a_{22} \n\\end{pmatrix}\n$$\n\nAnd a scalar $k$, the result of the scalar multiplication $kA$ is:\n$$\nkA = \\begin{pmatrix} \nka_{11} & ka_{12} \\\\ \nka_{21} & ka_{22} \n\\end{pmatrix}\n$$\n\nThis operation scales the matrix by $k$ without changing its dimension or the relative proportion of its elements.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = scalar_multiply(\n    torch.tensor([[1, 2], [3, 4]], dtype=torch.float),\n    3\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[3.0, 6.0], [9.0, 12.0]]"
            },
            {
                "test": "import torch\nres = scalar_multiply(\n    torch.tensor([[1.5, 2.5], [3.0, 4.0]], dtype=torch.float),\n    2.0\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[3.0, 5.0], [6.0, 8.0]]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = scalar_multiply_tg(\n    [[1, 2], [3, 4]],\n    3\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[3, 6], [9, 12]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = scalar_multiply_tg(\n    [[1.5, 2.5], [3.0, 4.0]],\n    2.0\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[3.0, 5.0], [6.0, 8.0]]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgc2NhbGFyX211bHRpcGx5KG1hdHJpeCwgc2NhbGFyKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIE11bHRpcGx5IGVhY2ggZWxlbWVudCBvZiBhIDJEIG1hdHJpeCBieSBhIHNjYWxhciB1c2luZyBQeVRvcmNoLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdG9yY2ggVGVuc29ycy4KICAgIFJldHVybnMgYSAyRCB0ZW5zb3Igb2YgdGhlIHNhbWUgc2hhcGUuCiAgICAiIiIKICAgIG1fdCA9IHRvcmNoLmFzX3RlbnNvcihtYXRyaXgsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgcmV0dXJuIG1fdCAqIHNjYWxhcgo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgc2NhbGFyX211bHRpcGx5KG1hdHJpeCwgc2NhbGFyKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIE11bHRpcGx5IGVhY2ggZWxlbWVudCBvZiBhIDJEIG1hdHJpeCBieSBhIHNjYWxhciB1c2luZyBQeVRvcmNoLgogICAgSW5wdXRzIGNhbiBiZSBQeXRob24gbGlzdHMsIE51bVB5IGFycmF5cywgb3IgdG9yY2ggVGVuc29ycy4KICAgIFJldHVybnMgYSAyRCB0ZW5zb3Igb2YgdGhlIHNhbWUgc2hhcGUuCiAgICAiIiIKICAgICMgQ29udmVydCBpbnB1dCB0byB0ZW5zb3IKICAgIG1fdCA9IHRvcmNoLmFzX3RlbnNvcihtYXRyaXgsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "5"
    },
    {
        "description": "In this problem, you need to implement the Lasso Regression algorithm using Gradient Descent. Lasso Regression (L1 Regularization) adds a penalty equal to the absolute value of the coefficients to the loss function. Your task is to update the weights and bias iteratively using the gradient of the loss function and the L1 penalty.\n\nThe objective function of Lasso Regression is:\n$$\nJ(w, b) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left( y_i - \\left( \\sum_{j=1}^{p} X_{ij} w_j + b \\right) \\right)^2 + \\alpha \\sum_{j=1}^{p} | w_j |\n$$\n\nWhere:\n- $ y_i $ is the actual value for the $ i $-th sample\n- $ \\hat{y}_i = \\sum_{j=1}^{p} X_{ij} w_j + b $ is the predicted value for the $ i $-th sample\n- $ w_j $ is the weight associated with the $ j $-th feature\n- $ \\alpha $ is the regularization parameter\n- $ b $ is the bias\n\nYour task is to use the L1 penalty to shrink some of the feature coefficients to zero during gradient descent, thereby helping with feature selection.\n\n",
        "mdx_file": "ae0bf0f7-0349-4ca1-85e3-8316c8faa74b.mdx",
        "id": "50",
        "test_cases": [
            {
                "test": "import numpy as np\n\nX = np.array([[0, 0], [1, 1], [2, 2]])\ny = np.array([0, 1, 2])\n\nalpha = 0.1\noutput = l1_regularization_gradient_descent(X, y, alpha=alpha, learning_rate=0.01, max_iter=1000)\nprint(output)",
                "expected_output": "(array([0.42371644, 0.42371644]), 0.15385068459377865)"
            },
            {
                "test": "import numpy as np\n\nX = np.array([[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]])\ny = np.array([1, 2, 3, 4, 5])\n\nalpha = 0.1\noutput = l1_regularization_gradient_descent(X, y, alpha=alpha, learning_rate=0.01, max_iter=1000)\nprint(output)",
                "expected_output": "(array([0.27280148, 0.68108784]), 0.4082863608718005)"
            }
        ],
        "solution": "import numpy as np\n\ndef l1_regularization_gradient_descent(X: np.array, y: np.array, alpha: float = 0.1, learning_rate: float = 0.01, max_iter: int = 1000, tol: float = 1e-4) -> tuple:\n    n_samples, n_features = X.shape\n    # Zero out weights and bias\n    weights = np.zeros(n_features)\n    bias = 0\n    \n    for iteration in range(max_iter):\n        # Predict values\n        y_pred = np.dot(X, weights) + bias\n        # Calculate error\n        error = y_pred - y\n        # Gradient for weights with L1 penalty\n        grad_w = (1 / n_samples) * np.dot(X.T, error) + alpha * np.sign(weights)\n        # Gradient for bias (no penalty for bias)\n        grad_b = (1 / n_samples) * np.sum(error)\n        \n        # Update weights and bias\n        weights -= learning_rate * grad_w\n        bias -= learning_rate * grad_b\n        \n        # Check for convergence\n        if np.linalg.norm(grad_w, ord=1) < tol:\n            break\n    \n    return weights, bias\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n\nX = np.array([[0, 0], [1, 1], [2, 2]])\ny = np.array([0, 1, 2])\n\nalpha = 0.1\nweights, bias = l1_regularization_gradient_descent(X, y, alpha=alpha, learning_rate=0.01, max_iter=1000)",
            "output": "(weights,bias)\n(array([float, float]), float)",
            "reasoning": "The Lasso Regression algorithm is used to optimize the weights and bias for the given data. The weights are adjusted to minimize the loss function with the L1 penalty."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef l1_regularization_gradient_descent(X: np.array, y: np.array, alpha: float = 0.1, learning_rate: float = 0.01, max_iter: int = 1000, tol: float = 1e-4) -> tuple:\n\tn_samples, n_features = X.shape\n\n\tweights = np.zeros(n_features)\n\tbias = 0\n\t# Your code here\n\tpass\n",
        "title": "Implement Lasso Regression using Gradient Descent",
        "learn_section": "## Understanding Lasso Regression and L1 Regularization\n\nLasso Regression is a type of linear regression that applies L1 regularization to the model. It adds a penalty equal to the sum of the absolute values of the coefficients, encouraging some of them to be exactly zero. This makes Lasso Regression particularly useful for feature selection, as it can shrink the coefficients of less important features to zero, effectively removing them from the model.\n\n### Steps to Implement Lasso Regression using Gradient Descent\n\n1. **Initialize Weights and Bias**:  \n   Start with the weights and bias set to zero.\n\n2. **Make Predictions**:  \n   Use the formula:\n   $$\n   \\hat{y}_i = \\sum_{j=1}^{p} X_{ij} w_j + b\n   $$\n   where $ \\hat{y}_i $ is the predicted value for the $ i $-th sample.\n\n3. **Compute Residuals**:  \n   Find the difference between the predicted values $ \\hat{y}_i $ and the actual values $ y_i $. These residuals are the errors in the model.\n\n4. **Update the Weights and Bias**:  \n   Update the weights and bias using the gradient of the loss function with respect to the weights and bias:\n\n   1. For weights $ w_j $:\n      $$\n      \\frac{\\partial J}{\\partial w_j} = \\frac{1}{n} \\sum_{i=1}^{n} X_{ij}(\\hat{y}_i - y_i) + \\alpha \\cdot \\text{sign}(w_j)\n      $$\n\n   2. For bias $ b $ (without the regularization term):\n      $$\n      \\frac{\\partial J}{\\partial b} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)\n      $$\n\n   3. Update the weights and bias:\n      $$\n      w_j = w_j - \\eta \\cdot \\frac{\\partial J}{\\partial w_j}\n      $$\n      $$\n      b = b - \\eta \\cdot \\frac{\\partial J}{\\partial b}\n      $$\n\n5. **Check for Convergence**:  \n   The algorithm stops when the L1 norm of the gradient with respect to the weights becomes smaller than a predefined threshold $ \\text{tol} $:\n   $$\n   ||\\nabla w ||_1 = \\sum_{j=1}^{p} \\left| \\frac{\\partial J}{\\partial w_j} \\right|\n   $$\n\n6. **Return the Weights and Bias**:  \n   Once the algorithm converges, return the optimized weights and bias.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/afrenkai",
                "name": "Artem Frenk"
            },
            {
                "profile_link": "https://github.com/JerryWu-code",
                "name": "JerryWu-code"
            }
        ]
    },
    {
        "description": "In this problem, you need to implement a function that calculates the [Optimal String Alignment (OSA)](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance) distance between two given strings. The OSA distance represents the minimum number of edits required to transform one string into another. The allowed edit operations are:\n\n- Insert a character\n- Delete a character\n- Substitute a character\n- Transpose two adjacent characters\n\nEach of these operations costs 1 unit.\n\nYour task is to find the minimum number of edits needed to convert the first string (s1) into the second string (s2).\n\nFor example, the OSA distance between the strings `caper` and `acer` is 2: one deletion (removing \"p\") and one transposition (swapping \"a\" and \"c\").\n\n",
        "mdx_file": "4dad11b6-d762-4c60-a1a9-b67af638f9f7.mdx",
        "test_cases": [
            {
                "test": "source = \"butterfly\"\ntarget = \"dragonfly\"\noutput = OSA(source, target)\nprint(output)",
                "expected_output": "6"
            },
            {
                "test": "source = \"caper\"\ntarget = \"acer\"\noutput = OSA(source, target)\nprint(output)",
                "expected_output": "2"
            },
            {
                "test": "source = \"telescope\"\ntarget = \"microscope\"\noutput = OSA(source, target)\nprint(output)",
                "expected_output": "5"
            },
            {
                "test": "source = \"london\"\ntarget = \"paris\"\noutput = OSA(source, target)\nprint(output)",
                "expected_output": "6"
            }
        ],
        "solution": "import numpy as np\n\ndef OSA(source: str, target: str) -> int:\n    source_len, target_len = len(source), len(target)\n\n    # Initialize matrix with zeros\n    osa_matrix = [[0] * (target_len + 1) for _ in range(source_len + 1)]\n\n    # Fill the first row and first column with index values\n    for j in range(1, target_len + 1):\n        osa_matrix[0][j] = j\n    for i in range(1, source_len + 1):\n        osa_matrix[i][0] = i\n\n    # Compute the OSA distance\n    for i in range(1, source_len + 1):\n        for j in range(1, target_len + 1):\n            osa_matrix[i][j] = min(\n                osa_matrix[i - 1][j] + 1,  # Deletion\n                osa_matrix[i][j - 1] + 1,  # Insertion\n                osa_matrix[i - 1][j - 1] + (1 if source[i - 1] != target[j - 1] else 0)  # Substitution\n            )\n            if i > 1 and j > 1 and source[i - 1] == target[j - 2] and source[i - 2] == target[j - 1]:\n                osa_matrix[i][j] = min(osa_matrix[i][j], osa_matrix[i - 2][j - 2] + 1)  # Transposition\n\n    return osa_matrix[-1][-1]\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "source = \"butterfly\"\ntarget = \"dragonfly\"\n\ndistance = OSA(source, target)\nprint(distance)",
            "output": "6",
            "reasoning": "The OSA distance between the strings \"butterfly\" and \"dragonfly\" is 6. The minimum number of edits required to transform the source string into the target string is 6."
        },
        "dislikes": "0",
        "category": "NLP",
        "starter_code": "def OSA(source: str, target: str) -> int:\n\t# Your code here\n\tpass\n",
        "title": "Optimal String Alignment Distance",
        "learn_section": "\n## Optimal String Alignment Distance\n\nGiven two strings \\( s_1 \\) and \\( s_2 \\), find the Optimal String Alignment (OSA) distance between them.\n\nThe OSA distance gives the minimum number of edits needed to transform string \\( s_1 \\) into \\( s_2 \\). Here are the allowed edit operations:\n\n1. **Insert a character**\n2. **Delete a character**\n3. **Substitute a character**\n4. **Transpose two adjacent characters**\n\nEach operation has a cost of 1 unit.\n\nFor example, the OSA distance between the strings \"caper\" and \"acer\" is 2:\n- One deletion (removing the letter 'p')\n- One transposition (swapping the letters 'a' and 'c')\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/12345pnp",
                "name": "Biplab P."
            }
        ],
        "id": "51"
    },
    {
        "description": "## Task: Implement Recall in Binary Classification\n\nYour task is to implement the **recall** metric in a binary classification setting. Recall is a performance measure that evaluates how effectively a machine learning model identifies positive instances from all the actual positive cases in a dataset.\n\nYou need to write a function `recall(y_true, y_pred)` that calculates the recall metric. The function should accept two inputs:\n\n- `y_true`: A list of true binary labels (0 or 1) for the dataset.\n- `y_pred`: A list of predicted binary labels (0 or 1) from the model.\n\nYour function should return the recall value rounded to three decimal places. If the denominator (TP + FN) is zero, the recall should be 0.0 to avoid division by zero.\n\n    ",
        "mdx_file": "e37c4904-e6c8-499d-bfba-1ef47a8e7235.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nprint(recall(y_true, y_pred))",
                "expected_output": "0.75"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 0])\ny_pred = np.array([1, 0, 0, 0, 0, 1])\nprint(recall(y_true, y_pred))",
                "expected_output": "0.333"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 0])\ny_pred = np.array([1, 0, 1, 1, 0, 0])\nprint(recall(y_true, y_pred))",
                "expected_output": "1.0"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([0, 0, 0, 1, 0, 1])\nprint(recall(y_true, y_pred))",
                "expected_output": "0.5"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([0, 1, 0, 0, 1, 0])\nprint(recall(y_true, y_pred))",
                "expected_output": "0.0"
            }
        ],
        "solution": "import numpy as np\n\ndef recall(y_true, y_pred):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n\n    try:\n        return round(tp / (tp + fn), 3)\n    except ZeroDivisionError:\n        return 0.0\n\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\n\nprint(recall(y_true, y_pred))",
            "output": "# 0.75",
            "reasoning": "The recall value for the given true labels and predicted labels is 0.75. The model correctly identified 3 out of 4 positive instances in the dataset."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\ndef recall(y_true, y_pred):\n    \n",
        "title": "Implement Recall Metric in Binary Classification",
        "learn_section": "\n## Understanding Recall in Classification\n\nRecall is a metric that measures how often a machine learning model correctly identifies positive instances, also known as true positives, from all the actual positive samples in the dataset.\n\n### Mathematical Definition\n\nRecall, also known as sensitivity, is the fraction of relevant instances that were retrieved. It is calculated using the following equation:\n$$\n\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n$$\n\nWhere:\n1. **True Positives (TP)**: The number of positive samples that are correctly identified as positive.\n2. **False Negatives (FN)**: The number of positive samples that are incorrectly identified as negative.\n\n### Task\n\nIn this problem, you will implement a function to calculate recall given the true labels and predicted labels of a binary classification task. The results should be rounded to three decimal places.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/rafaelgreca",
                "name": "Rafael Greca"
            }
        ],
        "id": "52"
    },
    {
        "description": "## Task: Implement the Self-Attention Mechanism\n\nYour task is to implement the **self-attention** mechanism, which is a fundamental component of transformer models, widely used in natural language processing and computer vision tasks. The self-attention mechanism allows a model to dynamically focus on different parts of the input sequence when generating a contextualized representation.\n\nYour function should return the self-attention output as a numpy array.\n\n    ",
        "mdx_file": "dafb6e03-b5e6-4710-9608-81b0f5bc1249.mdx",
        "id": "53",
        "test_cases": [
            {
                "test": "import numpy as np\n\nX = np.array([[1, 0], [0, 1]])\nW_q = np.array([[1, 0], [0, 1]])\nW_k = np.array([[1, 0], [0, 1]])\nW_v = np.array([[1, 2], [3, 4]])\n\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\noutput = self_attention(Q, K, V)\nprint(output)",
                "expected_output": "[[1.660477, 2.660477], [2.339523, 3.339523]]"
            },
            {
                "test": "import numpy as np\n\nX = np.array([[1, 1], [1, 0]])\nW_q = np.array([[1, 0], [0, 1]])\nW_k = np.array([[1, 0], [0, 1]])\nW_v = np.array([[1, 2], [3, 4]])\n\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\noutput = self_attention(Q, K, V)\nprint(output)",
                "expected_output": "[[3.00928465, 4.6790462], [2.5, 4.0]]"
            },
            {
                "test": "import numpy as np\n\nX = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 0]])\nW_q = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nW_k = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]])\nW_v = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\noutput = self_attention(Q, K, V)\nprint(output)",
                "expected_output": "[[8.0, 10.0, 12.0], [8.61987385, 10.61987385, 12.61987385], [7.38012615, 9.38012615, 11.38012615]]"
            }
        ],
        "solution": "import numpy as np\n\ndef compute_qkv(X, W_q, W_k, W_v):\n    Q = np.dot(X, W_q)\n    K = np.dot(X, W_k)\n    V = np.dot(X, W_v)\n    return Q, K, V\n\ndef self_attention(Q, K, V):\n    d_k = Q.shape[1]\n    scores = np.matmul(Q, K.T) / np.sqrt(d_k)\n    attention_weights = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n    attention_output = np.matmul(attention_weights, V)\n    return attention_output\n\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n\nX = np.array([[1, 0], [0, 1]])\nW_q = np.array([[1, 0], [0, 1]])\nW_k = np.array([[1, 0], [0, 1]])\nW_v = np.array([[1, 2], [3, 4]])\n\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\noutput = self_attention(Q, K, V)\n\nprint(output)",
            "output": "# [[1.660477 2.660477]\n#  [2.339523 3.339523]]",
            "reasoning": "The self-attention mechanism calculates the attention scores for each input, determining how much focus to put on other inputs when generating a contextualized representation. The output is the weighted sum of the values based on the attention scores."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef self_attention(Q, K, V):\n    \n\treturn attention_output\n",
        "title": "Implement Self-Attention Mechanism",
        "learn_section": "## Self-Attention Mechanism\n\nThe **self-attention mechanism** is a fundamental concept in **transformer models** and is widely used in **natural language processing (NLP)** and **computer vision (CV)**. It allows models to dynamically weigh different parts of the input sequence, enabling them to capture **long-range dependencies** effectively.\n\n---\n\n### **Understanding Self-Attention**\n\nSelf-attention helps a model determine **which parts of an input sequence are relevant to each other**. Instead of treating every word or token equally, self-attention assigns different weights to different parts of the sequence, allowing the model to capture contextual relationships.\n\nFor example, in machine translation, self-attention allows the model to **focus on relevant words** from the input sentence when generating each word in the output.\n\n---\n\n### **Mathematical Formulation of Self-Attention**\n\nGiven an input sequence $X$, self-attention computes three key components:\n\n1. **Query ($Q$)**: Represents the current token we are processing.\n2. **Key ($K$)**: Represents each token in the sequence.\n3. **Value ($V$)**: Contains the actual token embeddings.\n\nThe Query, Key, and Value matrices are computed as:\n\n$$\nQ = X W_Q, \\quad K = X W_K, \\quad V = X W_V\n$$\n\nwhere $W_Q$, $W_K$, and $W_V$ are learned weight matrices.\n\nThe attention scores are computed using the **scaled dot-product attention**:\n\n$$\n\\text{Attention}(Q, K, V) = \\text{softmax} \\left( \\frac{Q K^T}{\\sqrt{d_k}} \\right) V\n$$\n\nwhere $d_k$ is the dimensionality of the key vectors.\n\n---\n\n### **Why Self-Attention is Powerful?**\n\n- **Captures long-range dependencies**: Unlike RNNs, which process input sequentially, self-attention can relate any word in the sequence to any other word, regardless of distance.\n- **Parallelization**: Since self-attention is computed **simultaneously** across the entire sequence, it is much faster than sequential models like LSTMs.\n- **Contextual Understanding**: Each token is **contextually enriched** by attending to relevant tokens in the sequence.\n\n---\n\n### **Example Calculation**\n\nConsider an input sequence of three tokens:\n\n$$\nX = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix}\n$$\n\nWe compute $Q$, $K$, and $V$ as:\n\n$$\nQ = X W_Q, \\quad K = X W_K, \\quad V = X W_V\n$$\n\nNext, we compute the attention scores:\n\n$$\nS = \\frac{Q K^T}{\\sqrt{d_k}}\n$$\n\nApplying the softmax function:\n\n$$\nA = \\text{softmax}(S)\n$$\n\nFinally, the weighted sum of values:\n\n$$\n\\text{Output} = A V\n$$\n\n---\n\n### **Applications of Self-Attention**\n\nSelf-attention is widely used in:\n- **Transformer models (e.g., BERT, GPT-3)** for language modeling.\n- **Speech processing models** for transcribing audio.\n- **Vision Transformers (ViTs)** for computer vision tasks.\n- **Recommender systems** for learning item-user relationships.\n\nMastering self-attention is essential for understanding modern deep learning architectures, especially in NLP and computer vision.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/Jayanth-vardhan",
                "name": "Jayanth-vardhan"
            }
        ]
    },
    {
        "description": "Write a Python function that implements a simple Recurrent Neural Network (RNN) cell. The function should process a sequence of input vectors and produce the final hidden state. Use the tanh activation function for the hidden state updates. The function should take as inputs the sequence of input vectors, the initial hidden state, the weight matrices for input-to-hidden and hidden-to-hidden connections, and the bias vector. The function should return the final hidden state after processing the entire sequence, rounded to four decimal places.",
        "mdx_file": "7604323a-8320-49b8-b327-d85fa7fbbf3a.mdx",
        "test_cases": [
            {
                "test": "print(rnn_forward([[1.0], [2.0], [3.0]], [0.0], [[0.5]], [[0.8]], [0.0]))",
                "expected_output": "[0.9759]"
            },
            {
                "test": "print(rnn_forward([[0.5], [0.1], [-0.2]], [0.0], [[1.0]], [[0.5]], [0.1]))",
                "expected_output": "[0.118]"
            },
            {
                "test": "print(rnn_forward(\n    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n    [0.0, 0.0],\n    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n    [[0.7, 0.8], [0.9, 1.0]],\n    [0.1, 0.2]\n))",
                "expected_output": "[0.7474, 0.9302]"
            }
        ],
        "solution": "\nimport numpy as np\n\ndef rnn_forward(input_sequence, initial_hidden_state, Wx, Wh, b):\n    h = np.array(initial_hidden_state)\n    Wx = np.array(Wx)\n    Wh = np.array(Wh)\n    b = np.array(b)\n    for x in input_sequence:\n        x = np.array(x)\n        h = np.tanh(np.dot(Wx, x) + np.dot(Wh, h) + b)\n    final_hidden_state = np.round(h, 4)\n    return final_hidden_state.tolist()\n",
        "difficulty": "medium",
        "video": null,
        "likes": "0",
        "example": {
            "input": "input_sequence = [[1.0], [2.0], [3.0]]\n    initial_hidden_state = [0.0]\n    Wx = [[0.5]]  # Input to hidden weights\n    Wh = [[0.8]]  # Hidden to hidden weights\n    b = [0.0]     # Bias",
            "output": "final_hidden_state = [0.9993]",
            "reasoning": "The RNN processes each input in the sequence, updating the hidden state at each step using the tanh activation function."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef rnn_forward(input_sequence: list[list[float]], initial_hidden_state: list[float], Wx: list[list[float]], Wh: list[list[float]], b: list[float]) -> list[float]:\n\t# Your code here\n\treturn final_hidden_state",
        "title": "Implementing a Simple RNN",
        "learn_section": "\n## Understanding Recurrent Neural Networks (RNNs)\n\nRecurrent Neural Networks (RNNs) are a class of neural networks designed to handle sequential data by maintaining a hidden state that captures information from previous inputs.\n\n### Mathematical Formulation\n\nFor each time step $t$, the RNN updates its hidden state $h_t$ using the current input $x_t$ and the previous hidden state $h_{t-1}$:\n\n$$\nh_t = \\tanh(W_x x_t + W_h h_{t-1} + b)\n$$\n\nWhere:\n1. $W_x$ is the weight matrix for the input-to-hidden connections.\n2. $W_h$ is the weight matrix for the hidden-to-hidden connections.\n3. $b$ is the bias vector.\n4. $\\tanh$ is the hyperbolic tangent activation function applied element-wise.\n\n### Implementation Steps\n\n1. **Initialization**: Start with the initial hidden state $h_0$.\n\n2. **Sequence Processing**: For each input $x_t$ in the sequence:\n\n   $$\n   h_t = \\tanh(W_x x_t + W_h h_{t-1} + b)\n   $$\n\n3. **Final Output**: After processing all inputs, the final hidden state $h_T$ (where $T$ is the length of the sequence) contains information from the entire sequence.\n\n### Example Calculation\n\nGiven:\n1. Inputs: $x_1 = 1.0$, $x_2 = 2.0$, $x_3 = 3.0$\n2. Initial hidden state: $h_0 = 0.0$\n3. Weights:\n   - $W_x = 0.5$\n   - $W_h = 0.8$\n4. Bias: $b = 0.0$\n\n**Compute**:\n\n1. First time step ($t = 1$):\n\n   $$\n   h_1 = \\tanh(0.5 \\times 1.0 + 0.8 \\times 0.0 + 0.0) = \\tanh(0.5) \\approx 0.4621\n   $$\n\n2. Second time step ($t = 2$):\n\n   $$\n   h_2 = \\tanh(0.5 \\times 2.0 + 0.8 \\times 0.4621 + 0.0) = \\tanh(1.0 + 0.3697) = \\tanh(1.3697) \\approx 0.8781\n   $$\n\n3. Third time step ($t = 3$):\n\n   $$\n   h_3 = \\tanh(0.5 \\times 3.0 + 0.8 \\times 0.8781 + 0.0) = \\tanh(1.5 + 0.7025) = \\tanh(2.2025) \\approx 0.9750\n   $$\n\nThe final hidden state $h_3$ is approximately 0.9750.\n\n### Applications\n\nRNNs are widely used in natural language processing, time-series prediction, and any task involving sequential data.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "id": "54"
    },
    {
        "description": "## Task: Implement a 2D Translation Matrix\n\nYour task is to implement a function that applies a 2D translation matrix to a set of points. A translation matrix is used to move points in 2D space by a specified distance in the x and y directions.\n\nWrite a function `translate_object(points, tx, ty)` where `points` is a list of [x, y] coordinates and `tx` and `ty` are the translation distances in the x and y directions, respectively.\n\nThe function should return a new list of points after applying the translation matrix.\n\n    ",
        "mdx_file": "04e991cf-c5d4-4526-bdd7-194c665b9ac9.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\ntriangle = [[0, 0], [1, 0], [0.5, 1]]\ntx, ty = 2, 3\nprint(translate_object(triangle, tx, ty))",
                "expected_output": "[[2.0, 3.0], [3.0, 3.0], [2.5, 4.0]]"
            },
            {
                "test": "import numpy as np\n\nsquare = [[0, 0], [1, 0], [1, 1], [0, 1]]\ntx, ty = -1, 2\nprint(translate_object(square, tx, ty))",
                "expected_output": "[[-1.0, 2.0], [0.0, 2.0], [0.0, 3.0], [-1.0, 3.0]]"
            }
        ],
        "solution": "import numpy as np\n\ndef translate_object(points, tx, ty):\n    translation_matrix = np.array([\n        [1, 0, tx],\n        [0, 1, ty],\n        [0, 0, 1]\n    ])\n    \n    homogeneous_points = np.hstack([np.array(points), np.ones((len(points), 1))])\n    \n    translated_points = np.dot(homogeneous_points, translation_matrix.T)\n    \n    return translated_points[:, :2].tolist()\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "points = [[0, 0], [1, 0], [0.5, 1]]\ntx, ty = 2, 3\n\nprint(translate_object(points, tx, ty))",
            "output": "[[2.0, 3.0], [3.0, 3.0], [2.5, 4.0]]",
            "reasoning": "The translation matrix moves the points by 2 units in the x-direction and 3 units in the y-direction. The resulting points are [[2.0, 3.0], [3.0, 3.0], [2.5, 4.0]]."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\ndef translate_object(points, tx, ty):\n\treturn translated_points\n",
        "title": "2D Translation Matrix Implementation",
        "learn_section": "\n## 2D Translation Matrix Implementation\n\nThe translation matrix is a fundamental concept in linear algebra and computer graphics, used to move points or objects in a 2D space.\n\n### Concept Overview\n\nFor a 2D translation, we use a 3x3 matrix to move a point \\( (x, y) \\) by \\( x_t \\) units in the x-direction and \\( y_t \\) units in the y-direction.\n\nAny point \\( P \\) in 2D Cartesian space with coordinates \\( (x, y) \\) can be represented in homogeneous coordinates as \\( (x, y, 1) \\):\n\n$$\nP_{\\text{Cartesian}} = (x, y) \\rightarrow P_{\\text{Homogeneous}} = (x, y, 1)\n$$\n\nMore generally, any scalar multiple of \\( (x, y, 1) \\) represents the same point in 2D space. Thus, \\( (kx, ky, k) \\) for any non-zero \\( k \\) also represents the same point \\( (x, y) \\).\n\nThe addition of this third coordinate allows us to represent translation as a linear transformation.\n\n### Translation Matrix\n\nThe translation matrix \\( T \\) is defined as:\n\n$$\nT = \\begin{bmatrix}\n1 & 0 & x_t \\\\\n0 & 1 & y_t \\\\\n0 & 0 & 1\n\\end{bmatrix}\n$$\n\n### Applying the Translation\n\nTo translate a point \\( (x, y) \\), we first convert it to homogeneous coordinates: \\( (x, y, 1) \\). The transformation is then performed using matrix multiplication:\n\n$$\n\\begin{bmatrix}\n1 & 0 & x_t \\\\\n0 & 1 & y_t \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny \\\\\n1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nx + x_t \\\\\ny + y_t \\\\\n1\n\\end{bmatrix}\n$$\n\n### Explanation of Parameters\n\n1. **Original Point**: \\( (x, y) \\)  \n2. **Translation in x-direction**: \\( x_t \\)  \n3. **Translation in y-direction**: \\( y_t \\)  \n4. **Translated Point**: \\( (x + x_t, y + y_t) \\)\n\nThis process effectively shifts the original point \\( (x, y) \\) by \\( x_t \\) and \\( y_t \\), resulting in the new coordinates \\( (x + x_t, y + y_t) \\).\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/Mohamad-Abdulkadir",
                "name": "Mohamad Abdulkadir"
            }
        ],
        "id": "55"
    },
    {
        "description": "## Task: Implement KL Divergence Between Two Normal Distributions\n\nYour task is to compute the Kullback Leibler (KL) divergence between two normal distributions. KL divergence measures how one probability distribution differs from a second, reference probability distribution.\n\nWrite a function kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q) that calculates the KL divergence between two normal distributions.\n\nThe function should return the KL divergence as a floating point number.\n\n    ",
        "mdx_file": "e7a03d3b-e527-4457-92c8-4d1a5268cdec.mdx",
        "id": "56",
        "test_cases": [
            {
                "test": "import numpy as np\n\nmu_p = 0.0\nsigma_p = 1.0\nmu_q = 0.0\nsigma_q = 1.0\nprint(kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q))",
                "expected_output": "0.0"
            },
            {
                "test": "import numpy as np\n\nmu_p = 0.0\nsigma_p = 1.0\nmu_q = 1.0\nsigma_q = 1.0\nprint(kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q))",
                "expected_output": "0.5"
            },
            {
                "test": "import numpy as np\n\nmu_p = 0.0\nsigma_p = 1.0\nmu_q = 0.0\nsigma_q = 2.0\nprint(kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q))",
                "expected_output": "0.3181471805599453"
            },
            {
                "test": "import numpy as np\n\nmu_p = 1.0\nsigma_p = 1.0\nmu_q = 0.0\nsigma_q = 2.0\nprint(kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q))",
                "expected_output": "0.4431471805599453"
            }
        ],
        "solution": "import numpy as np\n\ndef kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q):\n    term1 = np.log(sigma_q / sigma_p)\n    term2 = (sigma_p ** 2 + (mu_p - mu_q) ** 2) / (2 * sigma_q ** 2)\n    kl_div = term1 + term2 - 0.5\n    return kl_div\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "mu_p = 0.0\nsigma_p = 1.0\nmu_q = 1.0\nsigma_q = 1.0\n\nprint(kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q))",
            "output": "0.5",
            "reasoning": "The KL divergence between the normal distributions \\( P \\) and \\( Q \\) with parameters \\( \\mu_P = 0.0 \\), \\( \\sigma_P = 1.0 \\) and \\( \\mu_Q = 1.0 \\), \\( \\sigma_Q = 1.0 \\) is 0.5."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef kl_divergence_normal(mu_p, sigma_p, mu_q, sigma_q):\n\treturn 0.0\n",
        "learn_section": "## Understanding Kullback-Leibler Divergence (KL Divergence)\n\nThe **Kullback-Leibler (KL) divergence**, also known as relative entropy, measures the difference between two probability distributions. It quantifies how much information is lost when approximating one distribution with another.\n\n---\n\n### Definition of KL Divergence\n\nFor continuous variables, the KL divergence is defined as:\n\n$$\nKL(P \\parallel Q) = \\int p(x) \\log \\frac{p(x)}{q(x)} \\, dx\n$$\n\nwhere:\n- $p(x)$ is the probability density function of the **reference** distribution $P$.\n- $q(x)$ is the probability density function of the **comparison** distribution $Q$.\n\n---\n\n### KL Divergence Between Two Normal Distributions\n\nConsider two normal distributions $P$ and $Q$:\n\n- $P \\sim N(\\mu_P, \\sigma_P^2)$  \n- $Q \\sim N(\\mu_Q, \\sigma_Q^2)$\n\nFor these, the KL divergence simplifies to:\n\n$$\nKL(P \\parallel Q) = \\int p(x) \\left[\n\\log \\frac{\\sigma_Q}{\\sigma_P}\n+ \\frac{\\sigma_P^2 + (\\mu_P - \\mu_Q)^2}{2\\sigma_Q^2}\n- \\frac{1}{2}\n\\right] dx\n$$\n\nSince $p(x)$ is the PDF of $x$ under $P$, the integral over $p(x)$ just multiplies by 1 for each constant term. Thus, the final closed form is:\n\n$$\nKL(P \\parallel Q) =\n\\log \\frac{\\sigma_Q}{\\sigma_P}\n+ \\frac{\\sigma_P^2 + (\\mu_P - \\mu_Q)^2}{2\\sigma_Q^2}\n- \\frac{1}{2}\n$$\n\n---\n\n### Interpretation\n\nThis expression quantifies how one normal distribution $P$ **diverges** from another normal distribution $Q$. A KL divergence of zero indicates the two distributions are identical. As the divergence grows, it signals that $Q$ is a poorer approximation of $P$.\n\nThe KL divergence is **asymmetric**:\n\n$$\nKL(P \\parallel Q) \\neq KL(Q \\parallel P)\n$$\n\nmaking it sensitive to the **direction** of comparison.\n",
        "title": "KL Divergence Between Two Normal Distributions",
        "contributor": [
            {
                "profile_link": "https://github.com/Hui-cd",
                "name": "Hui"
            }
        ]
    },
    {
        "description": "## Task: Implement the Gauss-Seidel Method\n\nYour task is to implement the Gauss-Seidel method, an iterative technique for solving a system of linear equations \\(Ax = b\\).\n\nThe function should iteratively update the solution vector \\(x\\) by using the most recent values available during the iteration process.\n\nWrite a function `gauss_seidel(A, b, n, x_ini=None)` where:\n\n- `A` is a square matrix of coefficients,\n- `b` is the right-hand side vector,\n- `n` is the number of iterations,\n- `x_ini` is an optional initial guess for \\(x\\) (if not provided, assume a vector of zeros).\n\nThe function should return the approximated solution vector \\(x\\) after performing the specified number of iterations.\n\n    ",
        "mdx_file": "2d39fde8-a09b-4045-88bf-5b339fd387fc.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\nA = np.array([[4, 1, 2], [3, 5, 1], [1, 1, 3]], dtype=float)\nb = np.array([4, 7, 3], dtype=float)\nn = 5\nprint(gauss_seidel(A, b, n))",
                "expected_output": "[0.5008, 0.99968, 0.49984]"
            },
            {
                "test": "import numpy as np\n\nA = np.array([[4, -1, 0, 1], [-1, 4, -1, 0], [0, -1, 4, -1], [1, 0, -1, 4]], dtype=float)\nb = np.array([15, 10, 10, 15], dtype=float)\nn = 1\nprint(gauss_seidel(A, b, n))",
                "expected_output": "[3.75, 3.4375, 3.359375, 3.65234375]"
            },
            {
                "test": "import numpy as np\n\nA = np.array([[10, -1, 2], [-1, 11, -1], [2, -1, 10]], dtype=float)\nb = np.array([6, 25, -11], dtype=float)\nn = 100\nprint(gauss_seidel(A, b, n))",
                "expected_output": "[1.04326923, 2.26923077, -1.08173077]"
            }
        ],
        "solution": "import numpy as np\n\ndef gauss_seidel_it(A, b, x):\n    rows, cols = A.shape\n    for i in range(rows):\n        x_new = b[i]\n        for j in range(cols):\n            if i != j:\n                x_new -= A[i, j] * x[j]\n        x[i] = x_new / A[i, i]\n    return x\n\ndef gauss_seidel(A, b, n, x_ini=None):\n    x = x_ini or np.zeros_like(b)\n    for _ in range(n):\n        x = gauss_seidel_it(A, b, x)\n    return x\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "A = np.array([[4, 1, 2], [3, 5, 1], [1, 1, 3]], dtype=float)\nb = np.array([4, 7, 3], dtype=float)\n\nn = 100\nprint(gauss_seidel(A, b, n))",
            "output": "# [0.2, 1.4, 0.8]  (Approximate, values may vary depending on iterations)",
            "reasoning": "The Gauss-Seidel method iteratively updates the solution vector \\(x\\) until convergence. The output is an approximate solution to the linear system."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef gauss_seidel(A, b, n, x_ini=None):\n\treturn np.zeros_like(b)\n",
        "title": "Gauss-Seidel Method for Solving Linear Systems",
        "learn_section": "\n## Understanding the Gauss-Seidel Method\n\nThe Gauss-Seidel method is a technique for solving linear systems of equations $Ax = b$. Unlike fixed-point Jacobi, Gauss-Seidel uses previously computed results as soon as they are available. This increases convergence, resulting in fewer iterations, but it is not as easily parallelizable as fixed-point Jacobi.\n\n### Mathematical Formulation\n\n1. **Initialization**: Start with an initial guess for $x$.\n\n2. **Iteration**: For each equation $i$, update $x[i]$ using:\n\n$$\nx_{i}^{(k+1)} = \\frac{1}{a_{ii}} \\left( b[i] - \\sum_{j < i} a_{ij} x_{j}^{(k+1)} - \\sum_{j > i} a_{ij} x_{j}^{(k)} \\right)\n$$\n\nwhere $a_{ii}$ represents the diagonal elements of $A$, and $a_{ij}$ represents the off-diagonal elements.\n\n3. **Convergence**: Repeat the iteration until the changes in $x$ are below a set tolerance or until a maximum number of iterations is reached.\n\n### Matrix Form\n\nThe Gauss-Seidel method can also be expressed in matrix form using the diagonal matrix $D$, lower triangle $L$, and upper triangle $U$:\n\n$$\nx^{(k+1)} = D^{-1} \\left( b - Lx^{(k+1)} - Ux^{(k)} \\right)\n$$\n\n### Example Calculation\n\nLet’s solve the system of equations:\n\n$$\n3x_1 + x_2 = 5 \\quad x_1 + 2x_2 = 5\n$$\n\n1. Initialize $ x_1^{(0)} = 0 $ and $ x_2^{(0)} = 0 $.\n\n2. **First iteration**:\n\nFor $ x_1^{(1)} $:\n\n$$\nx_1^{(1)} = \\frac{1}{3} \\left( 5 - 1 \\cdot x_2^{(0)} \\right) = \\frac{5}{3} \\approx 1.6667\n$$\n\nFor $ x_2^{(1)} $:\n\n$$\nx_2^{(1)} = \\frac{1}{2} \\left( 5 - 1 \\cdot x_1^{(1)} \\right) = \\frac{1}{2} \\left( 5 - 1.6667 \\right) \\approx 1.6667\n$$\n\nAfter the first iteration, the values are $ x_1^{(1)} = 1.6667 $ and $ x_2^{(1)} = 1.6667 $.\n\nContinue iterating until the results converge to a desired tolerance.\n\n### Applications\n\nThe Gauss-Seidel method and other iterative solvers are commonly used in data science, computational fluid dynamics, and 3D graphics.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "57"
    },
    {
        "description": "## Task: Implement the Gaussian Elimination Method\n\nYour task is to implement the Gaussian Elimination method, which transforms a system of linear equations into an upper triangular matrix. This method can then be used to solve for the variables using backward substitution.\n\nWrite a function `gaussian_elimination(A, b)` that performs Gaussian Elimination with partial pivoting to solve the system \\(Ax = b\\).\n\nThe function should return the solution vector \\(x\\).\n\n    ",
        "mdx_file": "9c862443-4811-4ff8-b29f-38c581f7b52d.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\nA = np.array([[2,8,4], [2,5,1], [4,10,-1]], dtype=float)\nb = np.array([2,5,1], dtype=float)\nprint(gaussian_elimination(A, b))",
                "expected_output": "[11.0, -4.0, 3.0]"
            },
            {
                "test": "import numpy as np\n\nA = np.array([\n    [0, 2, 1, 0, 0, 0, 0],\n    [2, 6, 2, 1, 0, 0, 0],\n    [1, 2, 7, 2, 1, 0, 0],\n    [0, 1, 2, 8, 2, 1, 0],\n    [0, 0, 1, 2, 9, 2, 1],\n    [0, 0, 0, 1, 2, 10, 2],\n    [0, 0, 0, 0, 1, 2, 11]\n], dtype=float)\nb = np.array([1, 2, 3, 4, 5, 6, 7], dtype=float)\nprint(gaussian_elimination(A, b))",
                "expected_output": "[-0.4894027,   0.36169985,  0.2766003,   0.25540569,  0.31898951,  0.40387497, 0.53393278]"
            },
            {
                "test": "import numpy as np\n\nA = np.array([[2, 1, -1], [-3, -1, 2], [-2, 1, 2]], dtype=float)\nb = np.array([8, -11, -3], dtype=float)\nprint(gaussian_elimination(A, b))",
                "expected_output": "[2.0, 3.0, -1.0]"
            }
        ],
        "solution": "import numpy as np\n\ndef partial_pivoting(A_aug, row_num, col_num):\n    rows, cols = A_aug.shape\n    max_row = row_num\n    max_val = abs(A_aug[row_num, col_num])\n    for i in range(row_num, rows):\n        current_val = abs(A_aug[i, col_num])\n        if current_val > max_val:\n            max_val = current_val\n            max_row = i\n    if max_row != row_num:\n        A_aug[[row_num, max_row]] = A_aug[[max_row, row_num]]\n    return A_aug\n\ndef gaussian_elimination(A, b):\n    rows, cols = A.shape\n    A_aug = np.hstack((A, b.reshape(-1, 1)))\n\n    for i in range(rows-1):\n        A_aug = partial_pivoting(A_aug, i, i)\n        for j in range(i+1, rows):\n            A_aug[j, i:] -= (A_aug[j, i] / A_aug[i, i]) * A_aug[i, i:]\n\n    x = np.zeros_like(b, dtype=float)\n    for i in range(rows-1, -1, -1):\n        x[i] = (A_aug[i, -1] - np.dot(A_aug[i, i+1:cols], x[i+1:])) / A_aug[i, i]\n    return x\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "A = np.array([[2,8,4], [2,5,1], [4,10,-1]], dtype=float)\nb = np.array([2,5,1], dtype=float)\n\nprint(gaussian_elimination(A, b))",
            "output": "[11.0, -4.0, 3.0]",
            "reasoning": "The Gaussian Elimination method transforms the system of equations into an upper triangular matrix and then uses backward substitution to solve for the variables."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef gaussian_elimination(A, b):\n\t\"\"\"\n\tSolves the system Ax = b using Gaussian Elimination with partial pivoting.\n    \n\t:param A: Coefficient matrix\n\t:param b: Right-hand side vector\n\t:return: Solution vector x\n\t\"\"\"\n\treturn np.zeros_like(b)\n",
        "title": "Gaussian Elimination for Solving Linear Systems",
        "learn_section": "\n## Understanding Gaussian Elimination\n\nGaussian Elimination is used to replace matrix coefficients with a row-echelon form matrix, which can be more easily solved via backwards substitution.\n\n### Row-Echelon Form Criteria\n\n- **Non-zero rows** are above any rows of all zeros.\n- The **leading entry** of each non-zero row is to the right of the leading entry of the previous row.\n- The **leading entry** in any non-zero row is 1, and all entries below it in the same column are zeros.\n\n### Augmented Matrix\n\nFor a linear system $Ax = b$, an augmented matrix is a way of displaying all the numerical information in a linear system in a single matrix. This combines the coefficient matrix $A$ and vector source $b$ as follows:\n\n$$\n\\begin{pmatrix} \na_{11} & a_{21} & a_{31} & b_1\\\\ \na_{12} & a_{22} & a_{32} & b_2\\\\ \na_{31} & a_{32} & a_{33} & b_3 \n\\end{pmatrix}\n$$\n\n### Partial Pivoting\n\nIn linear algebra, diagonal elements of a matrix are referred to as the \"pivot\". To solve a linear system, the diagonal is used as a divisor for other elements within the matrix. This means that Gaussian Elimination will fail if there is a zero pivot.\n\nIn this case, pivoting is used to interchange rows, ensuring a non-zero pivot. Specifically, **partial pivoting** looks at all other rows in the current column to find the row with the highest absolute value. This row is then interchanged with the current row. This not only increases the numerical stability of the solution, but also reduces round-off errors caused by dividing by small entries.\n\n### Gaussian Elimination Mathematical Formulation\n\n**Gaussian Elimination:**\n\n- For $k = 1$ to $ \\text{number of rows} - 1$:\n  - Apply partial pivoting to the current row.\n  - For $i = k + 1$ to $ \\text{number of rows}$:\n    - $ m_{ik} = \\frac{a_{ik}}{a_{kk}} $\n    - For $j = k$ to $ \\text{number of columns}$:\n      - $ a_{ij} = a_{ij} - m_{ik} \\times a_{kj} $\n    - $ b_i = b_i - m_{ik} \\times b_k $\n\n**Backwards Substitution:**\n\n- For $k = \\text{number of rows}$ to $1$:\n  - For $i = \\text{number of columns} - 1$ to $1$:\n    - $ b_k = b_k - a_{ki} \\times b_i $\n  - $ b_k = \\frac{b_k}{a_{kk}} $\n\n### Example Calculation\n\nLet’s solve the system of equations:\n\n$$\nA = \\begin{pmatrix} \n2 & 8 & 4\\\\ \n5 & 5 & 1 \\\\ \n4 & 10 & -1 \n\\end{pmatrix} \n\\quad \\text{and} \\quad \nb = \\begin{pmatrix} \n2 \\\\ 5 \\\\ 1 \n\\end{pmatrix} \n$$\n\n1. Apply **partial pivoting** to increase the magnitude of the pivot. For $A_{11}$, calculate the factor for the elimination of $A_{12}$: \n\n$$ \nm_{12} = \\frac{A_{12}}{A_{11}} = \\frac{2}{5} = 0.4 \n$$\n\n2. Apply this scaling to row 1 and subtract this from row 2, eliminating $A_{12}$:\n\n$$\nA = \\begin{pmatrix} \n5 & 5 & 1 \\\\ \n0 & 6 & 3.6 \\\\ \n4 & 10 & -1 \n\\end{pmatrix} \n\\quad \\text{and} \\quad \nb = \\begin{pmatrix} \n5 \\\\ 0 \\\\ 1 \n\\end{pmatrix} \n$$\n\nAfter the full **Gaussian Elimination** process has been applied to $A$ and $b$, we get the following:\n\n$$\nA = \\begin{pmatrix} \n5 & 5 & 1\\\\ \n0 & 6 & 3.6 \\\\ \n0 & 0 & -5.4 \n\\end{pmatrix} \n\\quad \\text{and} \\quad \nb = \\begin{pmatrix} \n5 \\\\ 0 \\\\ 3 \n\\end{pmatrix} \n$$\n\nTo calculate $x$, we apply **backward substitution** by substituting in the currently solved values and dividing by the pivot. This gives the following for the first iteration:\n\n$$ \nx_3 = \\frac{b_3}{A_{33}} = \\frac{3}{-5.4} = -0.56 \n$$\n\nThis process can be repeated iteratively for all rows to solve the linear system, substituting in the solved values for the rows below.\n\n### Applications\n\nGaussian Elimination and linear solvers have a wide range of real-world applications, including their use in:\n\n- Machine learning\n- Computational fluid dynamics\n- 3D graphics\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "58"
    },
    {
        "description": "## Task: Implement Long Short-Term Memory (LSTM) Network\n\nYour task is to implement an LSTM network that processes a sequence of inputs and produces the final hidden state and cell state after processing all inputs.\n\nWrite a class `LSTM` with the following methods:\n\n- `__init__(self, input_size, hidden_size)`: Initializes the LSTM with random weights and zero biases.\n- `forward(self, x, initial_hidden_state, initial_cell_state)`: Processes a sequence of inputs and returns the hidden states at each time step, as well as the final hidden state and cell state.\n\nThe LSTM should compute the forget gate, input gate, candidate cell state, and output gate at each time step to update the hidden state and cell state.\n\n    ",
        "mdx_file": "d50ffd7a-1e79-4324-90cc-cc1f81d17e08.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\ninput_sequence = np.array([[1.0], [2.0], [3.0]])\ninitial_hidden_state = np.zeros((1, 1))\ninitial_cell_state = np.zeros((1, 1))\n\nlstm = LSTM(input_size=1, hidden_size=1)\n# Set weights and biases for reproducibility\nlstm.Wf = np.array([[0.5, 0.5]])\nlstm.Wi = np.array([[0.5, 0.5]])\nlstm.Wc = np.array([[0.3, 0.3]])\nlstm.Wo = np.array([[0.5, 0.5]])\nlstm.bf = np.array([[0.1]])\nlstm.bi = np.array([[0.1]])\nlstm.bc = np.array([[0.1]])\nlstm.bo = np.array([[0.1]])\n\noutputs, final_h, final_c = lstm.forward(input_sequence, initial_hidden_state, initial_cell_state)\n\nprint(final_h)",
                "expected_output": "[[0.73698596]]"
            },
            {
                "test": "import numpy as np\n\ninput_sequence = np.array([[0.1, 0.2], [0.3, 0.4]])\ninitial_hidden_state = np.zeros((2, 1))\ninitial_cell_state = np.zeros((2, 1))\n\nlstm = LSTM(input_size=2, hidden_size=2)\n# Set weights and biases for reproducibility\nlstm.Wf = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]])\nlstm.Wi = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]])\nlstm.Wc = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]])\nlstm.Wo = np.array([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8]])\nlstm.bf = np.array([[0.1], [0.2]])\nlstm.bi = np.array([[0.1], [0.2]])\nlstm.bc = np.array([[0.1], [0.2]])\nlstm.bo = np.array([[0.1], [0.2]])\n\noutputs, final_h, final_c = lstm.forward(input_sequence, initial_hidden_state, initial_cell_state)\n\nprint(final_h)",
                "expected_output": "[[0.16613133], [0.40299449]]"
            }
        ],
        "solution": "import numpy as np\n\nclass LSTM:\n    def __init__(self, input_size, hidden_size):\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n\n        # Initialize weights and biases\n        self.Wf = np.random.randn(hidden_size, input_size + hidden_size)\n        self.Wi = np.random.randn(hidden_size, input_size + hidden_size)\n        self.Wc = np.random.randn(hidden_size, input_size + hidden_size)\n        self.Wo = np.random.randn(hidden_size, input_size + hidden_size)\n\n        self.bf = np.zeros((hidden_size, 1))\n        self.bi = np.zeros((hidden_size, 1))\n        self.bc = np.zeros((hidden_size, 1))\n        self.bo = np.zeros((hidden_size, 1))\n\n    def forward(self, x, initial_hidden_state, initial_cell_state):\n        h = initial_hidden_state\n        c = initial_cell_state\n        outputs = []\n\n        for t in range(len(x)):\n            xt = x[t].reshape(-1, 1)\n            concat = np.vstack((h, xt))\n\n            # Forget gate\n            ft = self.sigmoid(np.dot(self.Wf, concat) + self.bf)\n\n            # Input gate\n            it = self.sigmoid(np.dot(self.Wi, concat) + self.bi)\n            c_tilde = np.tanh(np.dot(self.Wc, concat) + self.bc)\n\n            # Cell state update\n            c = ft * c + it * c_tilde\n\n            # Output gate\n            ot = self.sigmoid(np.dot(self.Wo, concat) + self.bo)\n\n            # Hidden state update\n            h = ot * np.tanh(c)\n\n            outputs.append(h)\n\n        return np.array(outputs), h, c\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "input_sequence = np.array([[1.0], [2.0], [3.0]])\ninitial_hidden_state = np.zeros((1, 1))\ninitial_cell_state = np.zeros((1, 1))\n\nlstm = LSTM(input_size=1, hidden_size=1)\noutputs, final_h, final_c = lstm.forward(input_sequence, initial_hidden_state, initial_cell_state)\n\nprint(final_h)",
            "output": "[[0.73698596]] (approximate)",
            "reasoning": "The LSTM processes the input sequence [1.0, 2.0, 3.0] and produces the final hidden state [0.73698596]."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\nclass LSTM:\n\tdef __init__(self, input_size, hidden_size):\n\t\tself.input_size = input_size\n\t\tself.hidden_size = hidden_size\n\n\t\t# Initialize weights and biases\n\t\tself.Wf = np.random.randn(hidden_size, input_size + hidden_size)\n\t\tself.Wi = np.random.randn(hidden_size, input_size + hidden_size)\n\t\tself.Wc = np.random.randn(hidden_size, input_size + hidden_size)\n\t\tself.Wo = np.random.randn(hidden_size, input_size + hidden_size)\n\n\t\tself.bf = np.zeros((hidden_size, 1))\n\t\tself.bi = np.zeros((hidden_size, 1))\n\t\tself.bc = np.zeros((hidden_size, 1))\n\t\tself.bo = np.zeros((hidden_size, 1))\n\n\tdef forward(self, x, initial_hidden_state, initial_cell_state):\n\t\t\"\"\"\n\t\tProcesses a sequence of inputs and returns the hidden states, final hidden state, and final cell state.\n\t\t\"\"\"\n\t\tpass\n",
        "title": "Implement Long Short-Term Memory (LSTM) Network",
        "learn_section": "\n## Understanding Long Short-Term Memory Networks (LSTMs)\n\nLong Short-Term Memory Networks are a special type of RNN designed to capture long-term dependencies in sequential data by using a more complex hidden state structure.\n\n### LSTM Gates and Their Functions\n\nFor each time step $t$, the LSTM updates its cell state $c_t$ and hidden state $h_t$ using the current input $x_t$, the previous cell state $c_{t-1}$, and the previous hidden state $h_{t-1}$. The LSTM architecture consists of several gates that control the flow of information:\n\n#### Forget Gate $f_t$:\n\nThis gate decides what information to discard from the cell state. It looks at the previous hidden state $h_{t-1}$ and the current input $x_t$, and outputs a number between 0 and 1 for each number in the cell state. A 1 represents \"keep this\" while a 0 represents \"forget this\".\n\n$$\nf_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n$$\n\n#### Input Gate $i_t$:\n\nThis gate decides which new information will be stored in the cell state. It consists of two parts:\n- A sigmoid layer that decides which values we'll update.\n- A tanh layer that creates a vector of new candidate values $\\tilde{c}_t$ that could be added to the state.\n\n$$\ni_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n$$\n\n$$\n\\tilde{c}_t = \\tanh(W_c \\cdot [h_{t-1}, x_t] + b_c)\n$$\n\n#### Cell State Update $c_t$:\n\nThis step updates the old cell state $c_{t-1}$ into the new cell state $c_t$. It multiplies the old state by the forget gate output, then adds the product of the input gate and the new candidate values.\n\n$$\nc_t = f_t \\circ c_{t-1} + i_t \\circ \\tilde{c}_t\n$$\n\n#### Output Gate $o_t$:\n\nThis gate decides what parts of the cell state we're going to output. It uses a sigmoid function to determine which parts of the cell state to output, and then multiplies it by a tanh of the cell state to get the final output.\n\n$$\no_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n$$\n\n$$\nh_t = o_t \\circ \\tanh(c_t)\n$$\n\nWhere:\n- $(W_f, W_i, W_c, W_o)$ are weight matrices for the forget gate, input gate, cell state, and output gate respectively.\n- $(b_f, b_i, b_c, b_o)$ are bias vectors.\n- $\\sigma$ is the sigmoid activation function.\n- $\\circ$ denotes element-wise multiplication.\n\n### Implementation Steps\n\n1. **Initialization**: Start with the initial cell state $c_0$ and hidden state $h_0$.\n2. **Sequence Processing**: For each input $x_t$ in the sequence:\n   - Compute forget gate $f_t$, input gate $i_t$, candidate cell state $\\tilde{c}_t$, and output gate $o_t$.\n   - Update cell state $c_t$ and hidden state $h_t$.\n3. **Final Output**: After processing all inputs, the final hidden state $h_T$ (where $T$ is the length of the sequence) contains information from the entire sequence.\n\n### Example Calculation\n\nGiven:\n- Inputs: $x_1 = 1.0$, $x_2 = 2.0$, $x_3 = 3.0$\n- Initial states: $c_0 = 0.0$, $h_0 = 0.0$\n- Simplified weights (for demonstration): $W_f = W_i = W_c = W_o = 0.5$\n- All biases: $b_f = b_i = b_c = b_o = 0.1$\n\n#### Compute:\n\n**First time step $t = 1$:**\n\n$$\nf_1 = \\sigma(0.5 \\times 1.0 + 0.1) = 0.6487\n$$\n\n$$\ni_1 = \\sigma(0.5 \\times 1.0 + 0.1) = 0.6487\n$$\n\n$$\n\\tilde{c}_1 = \\tanh(0.5 \\times 1.0 + 0.1) = 0.5370\n$$\n\n$$\nc_1 = f_1 \\times 0.0 + i_1 \\times \\tilde{c}_1 = 0.6487 \\times 0.0 + 0.6487 \\times 0.5370 = 0.3484\n$$\n\n$$\no_1 = \\sigma(0.5 \\times 1.0 + 0.1) = 0.6487\n$$\n\n$$\nh_1 = o_1 \\times \\tanh(c_1) = 0.6487 \\times \\tanh(0.3484) = 0.2169\n$$\n\n**Second time step $t = 2$:**\n(Calculations omitted for brevity, but follow the same pattern using $x_2 = 2.0$ and the previous states)\n\n**Third time step $t = 3$:**\n(Calculations omitted for brevity, but follow the same pattern using $x_3 = 3.0$ and the previous states)\n\nThe final hidden state $h_3$ would be the result after these calculations.\n\n### Applications\n\nLSTMs are extensively used in various sequence modeling tasks, including machine translation, speech recognition, and time series forecasting, where capturing long-term dependencies is crucial.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/Hui-cd",
                "name": "Hui"
            }
        ],
        "id": "59"
    },
    {
        "description": "Write a Python function that calculates the eigenvalues of a 2x2 matrix. The function should return a list containing the eigenvalues, sort values from highest to lowest.",
        "mdx_file": "4164928f-cf75-47a9-869f-6024de454d76.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGNhbGN1bGF0ZV9laWdlbnZhbHVlc190ZyhtYXRyaXgpIC0+IFRlbnNvcjoKICAgICIiIgogICAgQ29tcHV0ZSBlaWdlbnZhbHVlcyBvZiBhIDLDlzIgbWF0cml4IHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXQ6IDLDlzIgbGlzdCwgTnVtUHkgYXJyYXksIG9yIFRlbnNvcjsgT3V0cHV0OiAxLUQgVGVuc29yIHdpdGggZWlnZW52YWx1ZXMgaW4gYXNjZW5kaW5nIG9yZGVyLgogICAgIiIiCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "test_cases": [
            {
                "test": "print(calculate_eigenvalues([[2, 1], [1, 2]]))",
                "expected_output": "[3.0, 1.0]"
            },
            {
                "test": "print(calculate_eigenvalues([[4, -2], [1, 1]]))",
                "expected_output": "[3.0, 2.0]"
            }
        ],
        "code": "def calculate_eigenvalues(matrix: list[list[float|int]]) -> list[float]:\n\treturn eigenvalues",
        "solution": "def calculate_eigenvalues(matrix: list[list[float]]) -> list[float]:\n    a, b, c, d = matrix[0][0], matrix[0][1], matrix[1][0], matrix[1][1]\n    trace = a + d\n    determinant = a * d - b * c\n    # Calculate the discriminant of the quadratic equation\n    discriminant = trace**2 - 4 * determinant\n    # Solve for eigenvalues\n    lambda_1 = (trace + discriminant**0.5) / 2\n    lambda_2 = (trace - discriminant**0.5) / 2\n    return [lambda_1, lambda_2]",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGNhbGN1bGF0ZV9laWdlbnZhbHVlc190ZyhtYXRyaXgpIC0+IFRlbnNvcjoKICAgICIiIgogICAgQ29tcHV0ZSBlaWdlbnZhbHVlcyBvZiBhIDLDlzIgbWF0cml4IHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXQ6IDLDlzIgbGlzdCwgTnVtUHkgYXJyYXksIG9yIFRlbnNvcjsgT3V0cHV0OiAxLUQgVGVuc29yIHdpdGggZWlnZW52YWx1ZXMgaW4gYXNjZW5kaW5nIG9yZGVyLgogICAgIiIiCiAgICBtID0gVGVuc29yKG1hdHJpeCkuZmxvYXQoKQogICAgYSA9IG1bMCwwXTsgYiA9IG1bMCwxXQogICAgYyA9IG1bMSwwXTsgZCA9IG1bMSwxXQogICAgdHJhY2UgPSBhICsgZAogICAgZGV0ID0gYSAqIGQgLSBiICogYwogICAgZGlzYyA9IHRyYWNlICogdHJhY2UgLSA0ICogZGV0CiAgICBzcXJ0X2Rpc2MgPSBkaXNjLnBvdygwLjUpCiAgICBsYW1iZGExID0gKHRyYWNlICsgc3FydF9kaXNjKSAvIDIKICAgIGxhbWJkYTIgPSAodHJhY2UgLSBzcXJ0X2Rpc2MpIC8gMgogICAgdmFscyA9IHNvcnRlZChbbGFtYmRhMS5udW1weSgpLCBsYW1iZGEyLm51bXB5KCldKQogICAgcmV0dXJuIFRlbnNvcih2YWxzKQo=",
        "pytorch_difficulty": "easy",
        "video": "https://youtu.be/AMCFzIaHc4Y",
        "likes": "0",
        "marimo_link": "",
        "difficulty": "medium",
        "dislikes": "0",
        "example": {
            "input": "matrix = [[2, 1], [1, 2]]",
            "output": "[3.0, 1.0]",
            "reasoning": "The eigenvalues of the matrix are calculated using the characteristic equation of the matrix, which for a 2x2 matrix is $\\lambda^2 - \ttrace(A)\\lambda + \tdet(A) = 0$, where $\\lambda$ are the eigenvalues."
        },
        "category": "Linear Algebra",
        "starter_code": "def calculate_eigenvalues(matrix: list[list[float|int]]) -> list[float]:\n\treturn eigenvalues",
        "title": "Calculate Eigenvalues of a Matrix",
        "learn_section": "\n## Calculate Eigenvalues\n\nEigenvalues of a matrix offer significant insight into the matrix's behavior, particularly in the context of linear transformations and systems of linear equations.\n\n### Definition\nFor a square matrix $A$, eigenvalues are scalars $\\lambda$ that satisfy the equation for some non-zero vector $v$ (eigenvector):\n$$\nAv = \\lambda v\n$$\n\n### Calculation for a 2x2 Matrix\nThe eigenvalues of a 2x2 matrix $A$, given by:\n$$\nA = \\begin{pmatrix} \na & b \\\\ \nc & d \n\\end{pmatrix}\n$$\nare determined by solving the characteristic equation:\n$$\n\\det(A - \\lambda I) = 0\n$$\n\nThis simplifies to a quadratic equation:\n$$\n\\lambda^2 - \\text{tr}(A) \\lambda + \\det(A) = 0\n$$\n\nHere, the trace of $A$, denoted as $\\text{tr}(A)$, is $a + d$, and the determinant of $A$, denoted as $\\det(A)$, is $ad - bc$. Solving this equation yields the eigenvalues, $\\lambda$.\n\n### Significance\nUnderstanding eigenvalues is essential for analyzing the effects of linear transformations represented by the matrix. They are crucial in various applications, including stability analysis, vibration analysis, and Principal Component Analysis (PCA) in machine learning.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = calculate_eigenvalues(torch.tensor([[2.0,0.0],[0.0,3.0]]))\nprint(res.detach().numpy().tolist())",
                "expected_output": "[2.0, 3.0]"
            },
            {
                "test": "import torch\nres = calculate_eigenvalues(torch.tensor([[0.0,1.0],[1.0,0.0]]))\nprint(res.detach().numpy().tolist())",
                "expected_output": "[-1.0, 1.0]"
            },
            {
                "test": "import torch\nres = calculate_eigenvalues(torch.tensor([[4.0,2.0],[1.0,3.0]]))\nprint(res.detach().numpy().tolist())",
                "expected_output": "[2.0, 5.0]"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = calculate_eigenvalues_tg([[2.0,0.0],[0.0,3.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[2.0, 3.0]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = calculate_eigenvalues_tg([[0.0,1.0],[1.0,0.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[-1.0, 1.0]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = calculate_eigenvalues_tg([[4.0,2.0],[1.0,3.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[2.0, 5.0]"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgY2FsY3VsYXRlX2VpZ2VudmFsdWVzKG1hdHJpeDogdG9yY2guVGVuc29yKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIENvbXB1dGUgZWlnZW52YWx1ZXMgb2YgYSAyw5cyIG1hdHJpeCB1c2luZyBQeVRvcmNoLgogICAgSW5wdXQ6IDLDlzIgdGVuc29yOyBPdXRwdXQ6IDEtRCB0ZW5zb3Igd2l0aCB0aGUgdHdvIGVpZ2VudmFsdWVzIGluIGFzY2VuZGluZyBvcmRlci4KICAgICIiIgogICAgYSA9IG1hdHJpeFswLDBdOyBiID0gbWF0cml4WzAsMV0KICAgIGMgPSBtYXRyaXhbMSwwXTsgZCA9IG1hdHJpeFsxLDFdCiAgICB0cmFjZSA9IGEgKyBkCiAgICBkZXQgPSBhICogZCAtIGIgKiBjCiAgICBkaXNjID0gdHJhY2UgKiB0cmFjZSAtIDQgKiBkZXQKICAgIHNxcnRfZGlzYyA9IHRvcmNoLnNxcnQoZGlzYykKICAgIGxhbWJkYTEgPSAodHJhY2UgKyBzcXJ0X2Rpc2MpIC8gMgogICAgbGFtYmRhMiA9ICh0cmFjZSAtIHNxcnRfZGlzYykgLyAyCiAgICBlaWcgPSB0b3JjaC5zdGFjayhbbGFtYmRhMSwgbGFtYmRhMl0pCiAgICByZXR1cm4gdG9yY2guc29ydChlaWcpLnZhbHVlcwo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgY2FsY3VsYXRlX2VpZ2VudmFsdWVzKG1hdHJpeDogdG9yY2guVGVuc29yKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIENvbXB1dGUgZWlnZW52YWx1ZXMgb2YgYSAyw5cyIG1hdHJpeCB1c2luZyBQeVRvcmNoLgogICAgSW5wdXQ6IDLDlzIgdGVuc29yOyBPdXRwdXQ6IDEtRCB0ZW5zb3Igd2l0aCB0aGUgdHdvIGVpZ2VudmFsdWVzIGluIGFzY2VuZGluZyBvcmRlci4KICAgICIiIgogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "6"
    },
    {
        "description": "## Task: Implement TF-IDF (Term Frequency-Inverse Document Frequency)\n\nYour task is to implement a function that computes the TF-IDF scores for a query against a given corpus of documents.\n\n### Function Signature\n\nWrite a function `compute_tf_idf(corpus, query)` that takes the following inputs:\n\n- `corpus`: A list of documents, where each document is a list of words.\n- `query`: A list of words for which you want to compute the TF-IDF scores.\n\n### Output\n\nThe function should return a list of lists containing the TF-IDF scores for the query words in each document, rounded to five decimal places.\n\n### Important Considerations\n\n1. **Handling Division by Zero:**  \n   When implementing the Inverse Document Frequency (IDF) calculation, you must account for cases where a term does not appear in any document (`df = 0`). This can lead to division by zero in the standard IDF formula. Add smoothing (e.g., adding 1 to both numerator and denominator) to avoid such errors.\n\n2. **Empty Corpus:**  \n   Ensure your implementation gracefully handles the case of an empty corpus. If no documents are provided, your function should either raise an appropriate error or return an empty result. This will ensure the program remains robust and predictable.\n\n3. **Edge Cases:**  \n   - Query terms not present in the corpus.  \n   - Documents with no words.  \n   - Extremely large or small values for term frequencies or document frequencies.\n\nBy addressing these considerations, your implementation will be robust and handle real-world scenarios effectively.\n",
        "mdx_file": "a93ff8be-9c7a-40dd-825f-5eb88e36a6be.mdx",
        "id": "60",
        "test_cases": [
            {
                "test": "import numpy as np\n\ncorpus = [\n    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n]\nquery = [\"cat\"]\n\nprint(compute_tf_idf(corpus, query))",
                "expected_output": "[[0.21461], [0.25754], [0.0]]"
            },
            {
                "test": "import numpy as np\n\ncorpus = [\n    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n]\nquery = [\"cat\", \"mat\"]\n\nprint(compute_tf_idf(corpus, query))",
                "expected_output": "[[0.21461, 0.21461], [0.25754, 0.0], [0.0, 0.21461]]"
            },
            {
                "test": "import numpy as np\n\ncorpus = [\n    [\"this\", \"is\", \"a\", \"sample\"],\n    [\"this\", \"is\", \"another\", \"example\"],\n    [\"yet\", \"another\", \"sample\", \"document\"],\n    [\"one\", \"more\", \"document\", \"for\", \"testing\"]\n]\nquery = [\"sample\", \"document\", \"test\"]\n\nprint(compute_tf_idf(corpus, query))",
                "expected_output": "[[0.37771, 0.0, 0.0], [0.0, 0.0, 0.0], [0.37771, 0.37771, 0.0], [0.0, 0.30217, 0.0]]"
            }
        ],
        "solution": "import numpy as np\n\ndef compute_tf_idf(corpus, query):\n    \"\"\"\n    Compute TF-IDF scores for a query against a corpus of documents using only NumPy.\n    The output TF-IDF scores retain five decimal places.\n    \"\"\"\n    vocab = sorted(set(word for document in corpus for word in document).union(query))\n    word_to_index = {word: idx for idx, word in enumerate(vocab)}\n\n    tf = np.zeros((len(corpus), len(vocab)))\n\n    for doc_idx, document in enumerate(corpus):\n        for word in document:\n            word_idx = word_to_index[word]\n            tf[doc_idx, word_idx] += 1\n        tf[doc_idx, :] /= len(document)\n\n    df = np.count_nonzero(tf > 0, axis=0)\n\n    num_docs = len(corpus)\n    idf = np.log((num_docs + 1) / (df + 1)) + 1\n\n    tf_idf = tf * idf\n\n    query_indices = [word_to_index[word] for word in query]\n    tf_idf_scores = tf_idf[:, query_indices]\n\n    tf_idf_scores = np.round(tf_idf_scores, 5)\n\n    return tf_idf_scores.tolist()\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "corpus = [\n    [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"],\n    [\"the\", \"dog\", \"chased\", \"the\", \"cat\"],\n    [\"the\", \"bird\", \"flew\", \"over\", \"the\", \"mat\"]\n]\nquery = [\"cat\"]\n\nprint(compute_tf_idf(corpus, query))",
            "output": "[[0.21461], [0.25754], [0.0]]",
            "reasoning": "The TF-IDF scores for the word \"cat\" in each document are computed and rounded to five decimal places."
        },
        "dislikes": "0",
        "category": "NLP",
        "starter_code": "import numpy as np\n\ndef compute_tf_idf(corpus, query):\n\t\"\"\"\n\tCompute TF-IDF scores for a query against a corpus of documents.\n    \n\t:param corpus: List of documents, where each document is a list of words\n\t:param query: List of words in the query\n\t:return: List of lists containing TF-IDF scores for the query words in each document\n\t\"\"\"\n\tpass\n",
        "learn_section": "# Understanding TF-IDF (Term Frequency-Inverse Document Frequency)\n\nTF-IDF is a numerical statistic that reflects how important a word is in a document relative to a collection (or corpus). It is widely used in information retrieval, text mining, and natural language processing tasks.\n\n## Mathematical Formulation\n\nTF-IDF is the product of two key statistics: **Term Frequency (TF)** and **Inverse Document Frequency (IDF)**.\n\n### 1. Term Frequency (TF)\n\nThe term frequency is defined as:\n\n$TF(t, d) = \\frac{\\text{Number of times term } t \\text{ appears in document } d}{\\text{Total number of terms in document } d}$\n\n- $t$: A specific term (word).\n- $d$: A specific document in the corpus.\n\n### 2. Inverse Document Frequency (IDF)\n\nTo account for how common or rare a term is across all documents in the corpus, we calculate:\n\n$IDF(t) = \\log\\Bigl(\\frac{N + 1}{\\text{df}(t) + 1}\\Bigr) + 1$\n\nWhere:\n\n- $N$: Total number of documents in the corpus.\n- $\\text{df}(t)$: Number of documents containing the term $t$.\n- Adding $+1$ inside the fraction prevents division by zero if a term never appears.\n- Adding $+1$ outside the log ensures IDF remains nonzero.\n\n### 3. TF-IDF\n\nCombining TF and IDF:\n\n$TFIDF(t, d) = TF(t, d) \\times IDF(t)$\n\n## Implementation Steps\n\n1. **Compute TF**  \n   For each document, count how often each term appears and divide by the document’s total word count.\n\n2. **Compute IDF**  \n   For each term, calculate its document frequency across all documents and apply the IDF formula.\n\n3. **Calculate TF-IDF**  \n   For every term in every document, multiply the term’s TF by its IDF.\n\n4. **Normalization (Optional)**  \n   Normalize TF-IDF vectors (e.g., using $L2$ norm) if comparing documents in a vector space model.\n\n## Example Calculation\n\nSuppose we have a small corpus of 3 documents:\n\n- **Doc1**: \"The cat sat on the mat\"  \n- **Doc2**: \"The dog chased the cat\"  \n- **Doc3**: \"The bird flew over the mat\"\n\nWe want to calculate the TF-IDF for the word **\"cat\"** in **Doc1**.\n\n### Step 1: Compute $TF(\"cat\", \\text{Doc1})$\n\n$TF(\"cat\", \\text{Doc1}) = \\frac{1}{6} \\approx 0.1667$\n\n- \"cat\" appears once.\n- Total words in Doc1 (counting each occurrence of “the”) = 6.\n\n### Step 2: Compute $IDF(\"cat\")$\n\n- \"cat\" appears in 2 out of 3 documents, so $\\text{df}(\"cat\") = 2$.\n- $N = 3$.\n\nUsing the formula with smoothing and an added constant:\n\n$IDF(\"cat\") = \\log\\Bigl(\\frac{N + 1}{\\text{df}(\"cat\") + 1}\\Bigr) + 1 = \\log\\Bigl(\\frac{3 + 1}{2 + 1}\\Bigr) + 1 = \\log\\Bigl(\\frac{4}{3}\\Bigr) + 1 \\approx 0.2877 + 1 = 1.2877$\n\n### Step 3: Calculate $TFIDF(\"cat\", \\text{Doc1})$\n\n$TFIDF(\"cat\", \\text{Doc1}) = TF(\"cat\", \\text{Doc1}) \\times IDF(\"cat\") = 0.1667 \\times 1.2877 \\approx 0.2147$\n\n## Applications of TF-IDF\n\n1. **Information Retrieval**  \n   TF-IDF is often used in search engines to rank how relevant a document is to a given query.\n2. **Text Mining**  \n   Helps identify key terms and topics in large volumes of text.\n3. **Document Classification**  \n   Useful for weighting important words in classification tasks.\n4. **Search Engines**  \n   Refines document ranking by emphasizing distinctive terms.\n5. **Recommendation Systems**  \n   Evaluates text-based similarity (e.g., for content-based filtering).\n\nTF-IDF remains a foundational technique in natural language processing, widely used for feature extraction and analysis across numerous text-based applications.\n",
        "title": "Implement TF-IDF (Term Frequency-Inverse Document Frequency)",
        "contributor": [
            {
                "profile_link": "https://github.com/Hui-cd",
                "name": "Hui"
            }
        ]
    },
    {
        "description": "## Task: Implement F-Score Calculation for Binary Classification\n\nYour task is to implement a function that calculates the F-Score for a binary classification task. The F-Score combines both Precision and Recall into a single metric, providing a balanced measure of a model's performance.\n\nWrite a function `f_score(y_true, y_pred, beta)` where:\n\n- `y_true`: A numpy array of true labels (binary).\n- `y_pred`: A numpy array of predicted labels (binary).\n- `beta`: A float value that adjusts the importance of Precision and Recall. When `beta=1`, it computes the F1-Score, a balanced measure of both Precision and Recall.\n\nThe function should return the F-Score rounded to three decimal places.\n\n    ",
        "mdx_file": "49dceca1-f08c-4b8f-a6f8-fcdbbb9499ff.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nbeta = 1\nprint(f_score(y_true, y_pred, beta))",
                "expected_output": "0.857"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 0])\ny_pred = np.array([1, 0, 0, 0, 0, 1])\nbeta = 1\nprint(f_score(y_true, y_pred, beta))",
                "expected_output": "0.4"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 0])\ny_pred = np.array([1, 0, 1, 1, 0, 0])\nbeta = 2\nprint(f_score(y_true, y_pred, beta))",
                "expected_output": "1.0"
            },
            {
                "test": "import numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([0, 0, 0, 1, 0, 1])\nbeta = 2\nprint(f_score(y_true, y_pred, beta))",
                "expected_output": "0.556"
            }
        ],
        "solution": "import numpy as np\n\ndef f_score(y_true, y_pred, beta):\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n\n    op = precision * recall\n    div = ((beta**2) * precision) + recall\n\n    if div == 0 or op == 0:\n        return 0.0\n\n    score = (1 + (beta ** 2)) * op / div\n    return round(score, 3)\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "y_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nbeta = 1\n\nprint(f_score(y_true, y_pred, beta))",
            "output": "0.857",
            "reasoning": "The F-Score for the binary classification task is calculated using the true labels, predicted labels, and beta value."
        },
        "dislikes": "0",
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef f_score(y_true, y_pred, beta):\n\t\"\"\"\n\tCalculate F-Score for a binary classification task.\n\n\t:param y_true: Numpy array of true labels\n\t:param y_pred: Numpy array of predicted labels\n\t:param beta: The weight of precision in the harmonic mean\n\t:return: F-Score rounded to three decimal places\n\t\"\"\"\n\tpass\n",
        "title": "Implement F-Score Calculation for Binary Classification",
        "learn_section": "\n## Understanding F-Score in Classification\n\nF-Score, also called F-measure, is a measure of predictive performance that's calculated from the Precision and Recall metrics.\n\n### Mathematical Definition\n\nThe $F_{\\beta}$ score applies additional weights, valuing one of precision or recall more than the other. When $\\beta$ equals 1, also known as the **F1-Score**, it symmetrically represents both precision and recall in one metric. The F-Score can be calculated using the following formula:\n\n$$\nF_{\\beta} = (1 + \\beta^2) \\times \\frac{\\text{precision} \\times \\text{recall}}{(\\beta^2 \\times \\text{precision}) + \\text{recall}}\n$$\n\nWhere:\n\n- **Recall**: The number of true positive results divided by the number of all samples that should have been identified as positive.\n- **Precision**: The number of true positive results divided by the number of all samples predicted to be positive, including those not identified correctly.\n\n### Implementation Instructions\n\nIn this problem, you will implement a function to calculate the **F-Score** given the true labels, predicted labels, and the Beta value of a binary classification task. The results should be rounded to three decimal places.\n\n#### Special Case:\nIf the denominator is zero, the F-Score should be set to **0.0** to avoid division by zero.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/rafaelgreca",
                "name": "Rafael Greca"
            }
        ],
        "id": "61"
    },
    {
        "description": "## Task: Implement a Simple RNN with Backpropagation Through Time (BPTT)\n\nYour task is to implement a simple Recurrent Neural Network (RNN) and backpropagation through time (BPTT) to learn from sequential data. The RNN will process input sequences, update hidden states, and perform backpropagation to adjust weights based on the error gradient.\n\nWrite a class `SimpleRNN` with the following methods:\n\n- `__init__(self, input_size, hidden_size, output_size)`: Initializes the RNN with random weights and zero biases.\n- `forward(self, x)`: Processes a sequence of inputs and returns the hidden states and output.\n- `backward(self, x, y, learning_rate)`: Performs backpropagation through time (BPTT) to adjust the weights based on the loss.\n\nIn this task, the RNN will be trained on sequence prediction, where the network will learn to predict the next item in a sequence. You should use 1/2 * Mean Squared Error (MSE) as the loss function and make sure to aggregate the losses at each time step by summing.\n",
        "mdx_file": "57bad012-a481-4993-8d9b-a6c839ca8395.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\nnp.random.seed(42) \n\ninput_sequence = np.array([[1.0], [2.0], [3.0], [4.0]])\nexpected_output = np.array([[2.0], [3.0], [4.0], [5.0]])\n\nrnn = SimpleRNN(input_size=1, hidden_size=5, output_size=1)\n\n# Train the RNN over multiple epochs\nfor epoch in range(100):\n    output = rnn.forward(input_sequence)\n    rnn.backward(input_sequence, expected_output, learning_rate=0.01)\n\nprint(output)",
                "expected_output": "[[[2.24143915]],[[3.18450265]],[[4.04305928]],[[4.57419398]]]"
            },
            {
                "test": "import numpy as np\n\nnp.random.seed(42) \n\ninput_sequence = np.array([[1.0,2.0], [7.0,2.0], [1.0,3.0], [12.0,4.0]])\nexpected_output = np.array([[2.0], [3.0], [4.0], [5.0]])\n\nrnn = SimpleRNN(input_size=2, hidden_size=3, output_size=1)\n\n# Train the RNN over multiple epochs\nfor epoch in range(100):\n    output = rnn.forward(input_sequence)\n    rnn.backward(input_sequence, expected_output, learning_rate=0.01)\n\nprint(output)",
                "expected_output": "[[[2.42201379]],[[3.44167595]],[[3.6129965 ]],[[4.50660152]]]"
            },
            {
                "test": "import numpy as np\n\nnp.random.seed(42) \n\ninput_sequence = np.array([[1.0,2.0], [7.0,2.0], [1.0,3.0], [12.0,4.0]])\nexpected_output = np.array([[2.0,1.0], [3.0,7.0], [4.0,8.0], [5.0,10.0]])\n\nrnn = SimpleRNN(input_size=2, hidden_size=10, output_size=2)\n\n# Train the RNN over multiple epochs\nfor epoch in range(50):\n    output = rnn.forward(input_sequence)\n    rnn.backward(input_sequence, expected_output, learning_rate=0.01)\n\nprint(output)",
                "expected_output": "[[[3.28424506],[5.93532247]],[[3.60393582],[6.82013468]],[[3.52586543],[6.58278163]],[[3.61336207],[6.84916339]]]"
            }
        ],
        "solution": "import numpy as np\n\nclass SimpleRNN:\n    def __init__(self, input_size, hidden_size, output_size):\n        self.hidden_size = hidden_size\n        self.W_xh = np.random.randn(hidden_size, input_size) * 0.01\n        self.W_hh = np.random.randn(hidden_size, hidden_size) * 0.01\n        self.W_hy = np.random.randn(output_size, hidden_size) * 0.01\n        self.b_h = np.zeros((hidden_size, 1))\n        self.b_y = np.zeros((output_size, 1))\n\n    def forward(self, x):\n        h = np.zeros((self.hidden_size, 1))  # Initialize hidden state\n        outputs = []\n        self.last_inputs = []\n        self.last_hiddens = [h]\n        \n        for t in range(len(x)):\n            self.last_inputs.append(x[t].reshape(-1, 1))\n            h = np.tanh(np.dot(self.W_xh, self.last_inputs[t]) + np.dot(self.W_hh, h) + self.b_h)\n            y = np.dot(self.W_hy, h) + self.b_y\n            outputs.append(y)\n            self.last_hiddens.append(h)\n        \n        self.last_outputs = outputs\n        return np.array(outputs)\n\n    def backward(self, x, y, learning_rate):\n        dW_xh = np.zeros_like(self.W_xh)\n        dW_hh = np.zeros_like(self.W_hh)\n        dW_hy = np.zeros_like(self.W_hy)\n        db_h = np.zeros_like(self.b_h)\n        db_y = np.zeros_like(self.b_y)\n\n        dh_next = np.zeros((self.hidden_size, 1))\n\n        for t in reversed(range(len(x))):\n            dy = self.last_outputs[t] - y[t].reshape(-1, 1)  # (Predicted - Actual)\n            dW_hy += np.dot(dy, self.last_hiddens[t+1].T)\n            db_y += dy\n\n            dh = np.dot(self.W_hy.T, dy) + dh_next\n            dh_raw = (1 - self.last_hiddens[t+1] ** 2) * dh  # Derivative of tanh\n\n            dW_xh += np.dot(dh_raw, self.last_inputs[t].T)\n            dW_hh += np.dot(dh_raw, self.last_hiddens[t].T)\n            db_h += dh_raw\n\n            dh_next = np.dot(self.W_hh.T, dh_raw)\n\n        # Update weights and biases\n        self.W_xh -= learning_rate * dW_xh\n        self.W_hh -= learning_rate * dW_hh\n        self.W_hy -= learning_rate * dW_hy\n        self.b_h -= learning_rate * db_h\n        self.b_y -= learning_rate * db_y\n",
        "difficulty": "hard",
        "video": "",
        "likes": "0",
        "example": {
            "input": "import numpy as np\n    input_sequence = np.array([[1.0], [2.0], [3.0], [4.0]])\n    expected_output = np.array([[2.0], [3.0], [4.0], [5.0]])\n    # Initialize RNN\n    rnn = SimpleRNN(input_size=1, hidden_size=5, output_size=1)\n    \n    # Forward pass\n    output = rnn.forward(input_sequence)\n    \n    # Backward pass\n    rnn.backward(input_sequence, expected_output, learning_rate=0.01)\n    \n    print(output)\n    \n    # The output should show the RNN predictions for each step of the input sequence.",
            "output": "[[x1], [x2], [x3], [x4]]",
            "reasoning": "The RNN processes the input sequence [1.0, 2.0, 3.0, 4.0] and predicts the next item in the sequence at each step."
        },
        "dislikes": "0",
        "category": "Deep Learning",
        "starter_code": "\nimport numpy as np\nclass SimpleRNN:\n    def __init__(self, input_size, hidden_size, output_size):\n\t\t\"\"\"\n\t\tInitializes the RNN with random weights and zero biases.\n\t\t\"\"\"\n        self.hidden_size = hidden_size\n        self.W_xh = np.random.randn(hidden_size, input_size)*0.01\n        self.W_hh = np.random.randn(hidden_size, hidden_size)*0.01\n        self.W_hy = np.random.randn(output_size, hidden_size)*0.01\n        self.b_h = np.zeros((hidden_size, 1))\n        self.b_y = np.zeros((output_size, 1))\n    def forward(self, x):\n\t\t\"\"\"\n\t\tForward pass through the RNN for a given sequence of inputs.\n\t\t\"\"\"\n\t\tpass\n\n\tdef backward(self, x, y, learning_rate):\n\t\t\"\"\"\n\t\tBackpropagation through time to adjust weights based on error gradient.\n\t\t\"\"\"\n\t\tpass\n",
        "title": "Implement a Simple RNN with Backpropagation Through Time (BPTT)",
        "learn_section": "# Understanding Recurrent Neural Networks (RNNs) and Backpropagation Through Time (BPTT)\n\nRecurrent Neural Networks (RNNs) are designed to handle sequential data by maintaining a hidden state that captures information from previous inputs. They are particularly useful for tasks where context or sequential order is important, such as language modeling, time series forecasting, and sequence prediction.\n\n## RNN Architecture\n\nAn RNN processes inputs one at a time while maintaining a hidden state that gets updated at each time step. The core equations governing the forward pass of an RNN are:\n\n### 1) Hidden State Update\n\n$$\nh_t = \\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)\n$$\n\n### 2) Output Computation\n\n$$\ny_t = W_{hy} h_t + b_y\n$$\n\nWhere:\n\n1. $x_t$ is the input at time step $t$.\n2. $h_t$ is the hidden state at time step $t$.\n3. $W_{xh}$ is the weight matrix for input to hidden state.\n4. $W_{hh}$ is the weight matrix for hidden state to hidden state.\n5. $W_{hy}$ is the weight matrix for hidden state to output.\n6. $b_h$ and $b_y$ are the bias terms for the hidden state and output, respectively.\n7. $\\tanh$ is the hyperbolic tangent activation function applied element-wise.\n\n## Forward Pass Implementation\n\nIn the forward pass, we iterate over each element in the input sequence, updating the hidden state and computing the output:\n\n1. **Initialize the hidden state** $h_0$ to zeros.\n2. For each time step $t$:\n   - Compute $h_t = \\tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)$.\n   - Compute $y_t = W_{hy} h_t + b_y$.\n   - Store $h_t$ and $y_t$ for use in backpropagation.\n\n## Loss Function\n\nThe loss function measures the discrepancy between the predicted outputs and the actual target values. For sequence prediction tasks, we often use the **Mean Squared Error (MSE)** loss:\n\n$$\n\\text{Loss} = \\frac{1}{T} \\sum_{t=1}^{T} (\\hat{y}_t - y_t)^2\n$$\n\nWhere $T$ is the length of the sequence, $\\hat{y}_t$ is the predicted output, and $y_t$ is the actual target at time step $t$.\n\n## Backpropagation Through Time (BPTT)\n\nBPTT is the process of training RNNs by unrolling them through time and applying backpropagation to compute gradients for each time step. The key steps in BPTT are:\n\n1. Compute the gradient of the loss with respect to the outputs:\n\n$$\n\\frac{dL}{dy_t} = \\hat{y}_t - y_t\n$$\n\n2. Compute the gradients for the output layer weights and biases:\n\n$$\ndW_{hy} += \\frac{dL}{dy_t} \\cdot h_t^T\n$$\n\n$$\ndb_y += \\frac{dL}{dy_t}\n$$\n\n3. Backpropagate the gradients through the hidden layers:\n\n$$\ndh_t = W_{hy}^T \\cdot \\frac{dL}{dy_t} + dh_{t+1}\n$$\n\n$$\ndh_{\\text{raw}} = dh_t \\circ (1 - h_t^2)\n$$\n\nHere, $\\circ$ denotes element-wise multiplication, and $(1 - h_t^2)$ is the derivative of the $\\tanh$ activation function.\n\n4. Compute the gradients for the hidden layer weights and biases:\n\n$$\ndW_{xh} += dh_{\\text{raw}} \\cdot x_t^T\n$$\n\n$$\ndW_{hh} += dh_{\\text{raw}} \\cdot h_{t-1}^T\n$$\n\n$$\ndb_h += dh_{\\text{raw}}\n$$\n\nWe repeat steps 1-4 for each time step $t$ in reverse order (from $T$ to 1), accumulating the gradients. The term $dh_{t+1}$ represents the gradient flowing from the next time step, initialized to zeros at the last time step.\n\n## Updating Weights\n\nAfter computing the gradients, we update the weights and biases using gradient descent:\n\n$$\nW_{xh} -= \\text{learning\\_rate} \\times dW_{xh}\n$$\n\n$$\nW_{hh} -= \\text{learning\\_rate} \\times dW_{hh}\n$$\n\n$$\nW_{hy} -= \\text{learning\\_rate} \\times dW_{hy}\n$$\n\n$$\nb_h -= \\text{learning\\_rate} \\times db_h\n$$\n\n$$\nb_y -= \\text{learning\\_rate} \\times db_y\n$$\n\n## Implementing the RNN\n\nTo implement the RNN with BPTT, follow these steps:\n\n1. **Initialization**: Initialize the weight matrices $W_{xh}, W_{hh}, W_{hy}$ with small random values and biases $b_h, b_y$ with zeros.\n2. **Forward Pass**: Implement the forward method to process the input sequence, updating the hidden states and computing the outputs at each time step. Store the inputs, hidden states, and outputs for use in backpropagation.\n3. **Backward Pass**: Implement the backward method to perform BPTT. Compute the gradients at each time step in reverse order, accumulate them, and update the weights and biases.\n4. **Training Loop**: Train the RNN over multiple epochs by repeatedly performing forward and backward passes and updating the weights.\n\n## Tips for Implementation\n\n1. **Gradient Clipping**: To prevent exploding gradients, consider applying gradient clipping, which scales down gradients if they exceed a certain threshold.\n2. **Learning Rate**: Choose an appropriate learning rate. If the learning rate is too high, the training may become unstable.\n3. **Debugging**: Check the dimensions of all matrices and vectors to ensure they align correctly during matrix multiplication.\n4. **Testing**: Start with small sequences and hidden sizes to test your implementation before scaling up.\n\n## Example Calculation\n\nSuppose we have an input sequence $x = [x_1, x_2]$ and target sequence $y = [y_1, y_2]$. Here's how you would compute the forward and backward passes:\n\n### 1) Forward Pass\n\n- At $t = 1$:\n  - Compute $h_1 = \\tanh(W_{xh} x_1 + W_{hh} h_0 + b_h)$.\n  - Compute $\\hat{y}_1 = W_{hy} h_1 + b_y$.\n\n- At $t = 2$:\n  - Compute $h_2 = \\tanh(W_{xh} x_2 + W_{hh} h_1 + b_h)$.\n  - Compute $\\hat{y}_2 = W_{hy} h_2 + b_y$.\n\n### 2) Compute Loss\n\n$$\nL = \\frac{1}{2} \\left[ (\\hat{y}_1 - y_1)^2 + (\\hat{y}_2 - y_2)^2 \\right]\n$$\n\n### 3) Backward Pass\n\nStarting from $t = 2$ to $t = 1$:\n\n- At $t = 2$:\n  - Compute $\\frac{dL}{d\\hat{y}_2} = \\hat{y}_2 - y_2$.\n  - Backpropagate to find $dh_2$, $dW_{hy}$, $db_y$.\n\n- At $t = 1$:\n  - Use the chain rule to compute gradients with respect to inputs and weights.\n\n## Conclusion\n\nRNNs with BPTT are powerful for modeling sequences, but they come with challenges such as vanishing and exploding gradients. Techniques like gradient clipping, long short-term memory (LSTM) cells, or gated recurrent units (GRUs) can help mitigate these issues. Implementing an RNN from scratch provides a deeper understanding of the underlying mechanisms and prepares you for working with more complex architectures.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "id": "62"
    },
    {
        "description": "## Task: Implement the Conjugate Gradient Method for Solving Linear Systems\n\nYour task is to implement the Conjugate Gradient (CG) method, an efficient iterative algorithm for solving large, sparse, symmetric, positive-definite linear systems. Given a matrix `A` and a vector `b`, the algorithm will solve for `x` in the system \\( Ax = b \\).\n\nWrite a function `conjugate_gradient(A, b, n, x0=None, tol=1e-8)` that performs the Conjugate Gradient method as follows:\n\n- `A`: A symmetric, positive-definite matrix representing the linear system.\n- `b`: The vector on the right side of the equation.\n- `n`: Maximum number of iterations.\n- `x0`: Initial guess for the solution vector.\n- `tol`: Tolerance for stopping criteria.\n\nThe function should return the solution vector `x`.\n\n    ",
        "mdx_file": "77b7596f-5d73-4065-aa45-24a56d8281eb.mdx",
        "test_cases": [
            {
                "test": "import numpy as np\n\nA = np.array([[4, 1], [1, 3]])\nb = np.array([1, 2])\nn = 5\nprint(conjugate_gradient(A, b, n))",
                "expected_output": "[0.09090909, 0.63636364]"
            },
            {
                "test": "import numpy as np\n\nA = np.array([[4, 1, 2], [1, 3, 0], [2, 0, 5]])\nb = np.array([7, 8, 5])\nn = 1\nprint(conjugate_gradient(A, b, n))",
                "expected_output": "[1.2627451, 1.44313725, 0.90196078]"
            },
            {
                "test": "import numpy as np\n\nA = np.array([[6, 2, 1, 1, 0],\n              [2, 5, 2, 1, 1],\n              [1, 2, 6, 1, 2],\n              [1, 1, 1, 7, 1],\n              [0, 1, 2, 1, 8]])\nb = np.array([1, 2, 3, 4, 5])\nn = 100\nprint(conjugate_gradient(A, b, n))",
                "expected_output": "[0.01666667, 0.11666667, 0.21666667, 0.45, 0.5]"
            }
        ],
        "solution": "import numpy as np\n\ndef conjugate_gradient(A: np.array, b: np.array, n: int, x0: np.array=None, tol=1e-8) -> np.array:\n\n    # calculate initial residual vector\n    x = np.zeros_like(b)\n    r = residual(A, b, x) # residual vector\n    rPlus1 = r\n    p = r # search direction vector\n\n    for i in range(n):\n\n        # line search step value - this minimizes the error along the current search direction\n        alp = alpha(A, r, p)\n\n        # new x and r based on current p (the search direction vector)\n        x = x + alp * p\n        rPlus1 = r - alp * (A@p)\n\n        # calculate beta - this ensures that all vectors are A-orthogonal to each other\n        bet = beta(r, rPlus1)\n\n        # update x and r\n        # using a othogonal search direction ensures we get all the information we need in more direction and then don't have to search in that direction again\n        p = rPlus1 + bet * p\n\n        # update residual vector\n        r = rPlus1\n\n        # break if less than tolerance\n        if np.linalg.norm(residual(A,b,x)) < tol:\n            break\n\n    return x\n\ndef residual(A: np.array, b: np.array, x: np.array) -> np.array:\n    # calculate linear system residuals\n    return b - A @ x\n\ndef alpha(A: np.array, r: np.array, p: np.array) -> float:\n\n    # calculate step size\n    alpha_num = np.dot(r, r)\n    alpha_den = np.dot(p @ A, p)\n\n    return alpha_num/alpha_den\n\ndef beta(r: np.array, r_plus1: np.array) -> float:\n\n    # calculate direction scaling\n    beta_num = np.dot(r_plus1, r_plus1)\n    beta_den = np.dot(r, r)\n\n    return beta_num/beta_den\n",
        "difficulty": "hard",
        "video": "",
        "likes": "0",
        "example": {
            "input": "A = np.array([[4, 1], [1, 3]])\nb = np.array([1, 2])\nn = 5\n\nprint(conjugate_gradient(A, b, n))",
            "output": "[0.09090909, 0.63636364]",
            "reasoning": "The Conjugate Gradient method is applied to the linear system Ax = b with the given matrix A and vector b. The algorithm iteratively refines the solution to converge to the exact solution."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef conjugate_gradient(A, b, n, x0=None, tol=1e-8):\n\t\"\"\"\n\tSolve the system Ax = b using the Conjugate Gradient method.\n\n\t:param A: Symmetric positive-definite matrix\n\t:param b: Right-hand side vector\n\t:param n: Maximum number of iterations\n\t:param x0: Initial guess for solution (default is zero vector)\n\t:param tol: Convergence tolerance\n\t:return: Solution vector x\n\t\"\"\"\n\t# calculate initial residual vector\n\tx = np.zeros_like(b)\n",
        "title": "Implement the Conjugate Gradient Method for Solving Linear Systems",
        "learn_section": "\n## Understanding The Conjugate Gradient Method\n\nThe Conjugate Gradient (CG) method is an iterative algorithm used to solve large systems of linear equations, particularly those that are symmetric and positive-definite.\n\n### Concepts\n\nThe CG gradient method is often applied to the quadratic form of a linear system, $Ax = b$:\n\n$$\nf(x) = \\frac{1}{2} x^T A x - b^T x\n$$\n\nThe quadratic form is used due to its differential reducing to the following for a symmetric $A$. Therefore, $x$ satisfies $Ax = b$ at the optimum:\n\n$$\nf'(x) = Ax - b\n$$\n\nThe conjugate gradient method uses search directions that are conjugate to all the previous search directions. This is satisfied when search directions are $A$-orthogonal, i.e.\n\n$$\np_i^T A p_j = 0 \\quad \\text{for } i \\neq j\n$$\n\nThis results in a more efficient algorithm, as it ensures that the algorithm gathers all information in a search direction at once and then doesn't need to search in that direction again. This is opposed to steepest descent, where the algorithm steps a bit in one direction and then may search in that direction again later.\n\n### Algorithm Steps\n\n1) **Initialization**:\n   - $ x_0 $: Initial guess for the variable vector.\n   - $ r_0 = b - A x_0 $: Initial residual vector.\n   - $ p_0 = r_0 $: Initial search direction.\n\n2) **Iteration $k$**:\n   - $ \\alpha_k = \\frac{r_k^T r_k}{p_k^T A p_k} $: Step size.\n   - $ x_{k+1} = x_k + \\alpha_k p_k $: Update solution.\n   - $ r_{k+1} = r_k - \\alpha_k A p_k $: Update residual.\n   - Check convergence: $ \\| r_{k+1} \\| < \\text{tolerance} $.\n   - $ \\beta_k = \\frac{r_{k+1}^T r_{k+1}}{r_k^T r_k} $: New direction scaling. This ensures search directions are $A$-orthogonal.\n   - $ p_{k+1} = r_{k+1} + \\beta_k p_k $: Update search direction.\n\n3) **Termination**:\n   - Stop when $ \\| r_{k+1} \\| < \\text{tolerance} $ or after a set number of iterations.\n\n### Example Calculation\n\nLet's solve the system of equations:\n\n$$\n4x_1 + x_2 = 6 \\quad x_1 + 3x_2 = 6\n$$\n\n1) **Initialize**: $ x_0 = [0, 0]^T $, $ r_0 = b - A x_0 = [6, 6]^T $, and $ p_0 = r_0 = [6, 6]^T $.\n\n2) **First iteration**:\n   - Compute $ \\alpha_0 $:\n\n   $$\n   \\alpha_0 = \\frac{r_0^T r_0}{p_0^T A p_0} = \\frac{72}{324} = 0.2222\n   $$\n\n   - Update solution $ x_1 $:\n\n   $$\n   x_1 = x_0 + \\alpha_0 p_0 = [0, 0]^T + 0.2222 \\cdot [6, 6]^T = [1.3333, 1.3333]^T\n   $$\n\n   - Update residual $ r_1 $:\n\n   $$\n   r_1 = r_0 - \\alpha_0 A p_0 = [6, 6]^T - 0.2222 \\cdot \\begin{bmatrix} 4 & 1 \\\\ 1 & 3 \\end{bmatrix} \\cdot [6, 6]^T = [6.67, 5.33]^T\n   $$\n\n   - Compute $ \\beta_0 $:\n\n   $$\n   \\beta_0 = \\frac{r_1^T r_1}{r_0^T r_0} = \\frac{6.67^2 + 5.33^2}{6^2 + 6^2} \\approx 0.99\n   $$\n\n   - Update search direction $ p_1 $:\n\n   $$\n   p_1 = r_1 + \\beta_0 p_0 = [6.67, 5.33]^T + 0.99 \\cdot [6, 6]^T = [12.60, 11.26]^T\n   $$\n\n3) **Second iteration**:\n   - Compute $ \\alpha_1 $, $ x_2 $, $ r_2 $, and repeat until convergence.\n\n### Applications\n\nThe conjugate gradient method is often used because it's more efficient than other iterative solvers, such as steepest descent, and direct solvers, such as Gaussian Elimination. Iterative linear solvers are commonly used in:\n\n- Optimization\n- Machine Learning\n- Computational Fluid Dynamics\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "63"
    },
    {
        "description": "## Task: Implement Gini Impurity Calculation\n\nYour task is to implement a function that calculates the Gini Impurity for a set of classes. Gini impurity is commonly used in decision tree algorithms to measure the impurity or disorder within a node.\n",
        "mdx_file": "dcb1f8cf-c91d-4b6f-a3c2-b387a2bab6cf.mdx",
        "id": "64",
        "test_cases": [
            {
                "test": "y = [0, 0, 0, 0, 1, 1, 1, 1]\nprint(gini_impurity(y))",
                "expected_output": "0.5"
            },
            {
                "test": "y = [0, 0, 0, 0, 0, 1]\nprint(gini_impurity(y))",
                "expected_output": "0.278"
            },
            {
                "test": "y = [0, 1, 2, 2, 2, 1, 2]\nprint(gini_impurity(y))",
                "expected_output": "0.571"
            }
        ],
        "solution": "import numpy as np\n\ndef gini_impurity(y: list[int]) -> float:\n\n    classes = set(y)\n    n = len(y)\n\n    gini_impurity = 0\n\n    for cls in classes:\n        gini_impurity += (y.count(cls)/n)**2\n\n    return round(1-gini_impurity,3)\n",
        "difficulty": "easy",
        "likes": "0",
        "video": "",
        "dislikes": "0",
        "example": {
            "input": "y = [0, 1, 1, 1, 0]\nprint(gini_impurity(y))",
            "output": "0.48",
            "reasoning": "The Gini Impurity is calculated as 1 - (p_0^2 + p_1^2), where p_0 and p_1 are the probabilities of each class. In this case, p_0 = 2/5 and p_1 = 3/5, resulting in a Gini Impurity of 0.48."
        },
        "category": "Machine Learning",
        "starter_code": "\nimport numpy as np\n\ndef gini_impurity(y):\n\t\"\"\"\n\tCalculate Gini Impurity for a list of class labels.\n\n\t:param y: List of class labels\n\t:return: Gini Impurity rounded to three decimal places\n\t\"\"\"\n\tpass\n\treturn round(val,3)",
        "title": "Implement Gini Impurity Calculation for a Set of Classes",
        "learn_section": "\n## Understanding Gini Impurity\n\nGini impurity is a statistical measurement of the impurity or disorder in a list of elements. It is commonly used in decision tree algorithms to decide the optimal split at tree nodes. It is calculated as follows, where $ p_i $ is the probability of each class, $ \\frac{n_i}{n} $:\n\n$$\n\\text{Gini Impurity} = 1 - \\sum_{i=1}^{C} p_i^2\n$$\n\nA Gini impurity of 0 indicates a node where all elements belong to the same class, whereas a Gini impurity of 1-1/C indicates maximum impurity, where elements are evenly distributed among each class. This means that a lower impurity implies a less homogeneous distribution of elements, suggesting a good split, as decision trees aim to minimize it at each node.\n\n### Advantages and Limitations\n\n#### Advantages:\n- Computationally efficient\n- Works for binary and multi-class classification\n\n#### Limitations:\n- Biased toward larger classes\n- May cause overfitting in deep decision trees\n\n### Example Calculation\n\nSuppose we have the set: $[0, 1, 1, 1, 0]$. The probability of each class is calculated as follows:\n\n$$\np_{0} = \\frac{2}{5} \\quad p_{1} = \\frac{3}{5}\n$$\n\nThe Gini Impurity is then calculated as follows:\n\n$$\n\\text{Gini Impurity} = 1 - (p_0^2 + p_1^2) = 1 - \\left(\\left(\\frac{2}{5}\\right)^2 + \\left(\\frac{3}{5}\\right)^2\\right) = 0.48\n$$\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            },
            {
                "profile_link": "https://github.com/ianxek",
                "name": "ianxek"
            }
        ]
    },
    {
        "description": "## Task: Convert a Dense Matrix to Compressed Row Sparse (CSR) Format\n\nYour task is to implement a function that converts a given dense matrix into the Compressed Row Sparse (CSR) format, an efficient storage representation for sparse matrices. The CSR format only stores non-zero elements and their positions, significantly reducing memory usage for matrices with a large number of zeros.\n\nWrite a function `compressed_row_sparse_matrix(dense_matrix)` that takes a 2D list `dense_matrix` as input and returns a tuple containing three lists:\n\n- **Values array**: List of all non-zero elements in row-major order.\n- **Column indices array**: Column index for each non-zero element in the values array.\n- **Row pointer array**: Cumulative number of non-zero elements per row, indicating the start of each row in the values array.\n\n    ",
        "mdx_file": "1a2857ff-1cba-4509-9d66-8fdee280132e.mdx",
        "test_cases": [
            {
                "test": "dense_matrix = [\n    [1, 0, 0, 0],\n    [0, 2, 0, 0],\n    [3, 0, 4, 0],\n    [1, 0, 0, 5]\n]\nvals, col_idx, row_ptr = compressed_row_sparse_matrix(dense_matrix)\nprint(\"Values array:\", vals)\nprint(\"Column indices array:\", col_idx)\nprint(\"Row pointer array:\", row_ptr)",
                "expected_output": "Values array: [1, 2, 3, 4, 1, 5]\nColumn indices array: [0, 1, 0, 2, 0, 3]\nRow pointer array: [0, 1, 2, 4, 6]"
            },
            {
                "test": "dense_matrix = [\n    [0, 0, 0],\n    [1, 2, 0],\n    [0, 3, 4]\n]\nvals, col_idx, row_ptr = compressed_row_sparse_matrix(dense_matrix)\nprint(\"Values array:\", vals)\nprint(\"Column indices array:\", col_idx)\nprint(\"Row pointer array:\", row_ptr)",
                "expected_output": "Values array: [1, 2, 3, 4]\nColumn indices array: [0, 1, 1, 2]\nRow pointer array: [0, 0, 2, 4]"
            },
            {
                "test": "dense_matrix = [\n    [0, 0, 3, 0, 0],\n    [0, 4, 0, 0, 0],\n    [5, 0, 0, 6, 0],\n    [0, 0, 0, 0, 0],\n    [0, 7, 0, 0, 8]\n]\nvals, col_idx, row_ptr = compressed_row_sparse_matrix(dense_matrix)\nprint(\"Values array:\", vals)\nprint(\"Column indices array:\", col_idx)\nprint(\"Row pointer array:\", row_ptr)",
                "expected_output": "Values array: [3, 4, 5, 6, 7, 8]\nColumn indices array: [2, 1, 0, 3, 1, 4]\nRow pointer array: [0, 1, 2, 4, 4, 6]"
            }
        ],
        "solution": "import numpy as np\n\ndef compressed_row_sparse_matrix(dense_matrix):\n    vals = []\n    col_idx = []\n    row_ptr = [0]\n\n    for row in dense_matrix:\n        for j, val in enumerate(row):\n            if val != 0:\n                vals.append(val)\n                col_idx.append(j)\n        row_ptr.append(len(vals))\n\n    return vals, col_idx, row_ptr\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "dense_matrix = [\n    [1, 0, 0, 0],\n    [0, 2, 0, 0],\n    [3, 0, 4, 0],\n    [1, 0, 0, 5]\n]\n\nvals, col_idx, row_ptr = compressed_row_sparse_matrix(dense_matrix)\nprint(\"Values array:\", vals)\nprint(\"Column indices array:\", col_idx)\nprint(\"Row pointer array:\", row_ptr)",
            "output": "Values array: [1, 2, 3, 4, 1, 5]\nColumn indices array: [0, 1, 0, 2, 0, 3]\nRow pointer array: [0, 1, 2, 4, 6]",
            "reasoning": "The dense matrix is converted to CSR format with the values array containing non-zero elements, column indices array storing the corresponding column index, and row pointer array indicating the start of each row in the values array."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef compressed_row_sparse_matrix(dense_matrix):\n\t\"\"\"\n\tConvert a dense matrix to its Compressed Row Sparse (CSR) representation.\n\n\t:param dense_matrix: 2D list representing a dense matrix\n\t:return: A tuple containing (values array, column indices array, row pointer array)\n\t\"\"\"\n\tpass\n",
        "title": "Implement Compressed Row Sparse Matrix (CSR) Format Conversion",
        "learn_section": "\n## Understanding the Compressed Row Sparse Matrix Format\n\nThe Compressed Row Sparse (CSR) format is a data-efficient representation of sparse matrices, where most of the elements are zero. This format is particularly useful in large-scale scientific computing and machine learning applications, where memory efficiency is critical.\n\n### Concepts\n\nA sparse matrix is a matrix that contains a large number of zero elements. Storing such matrices in their full form can be inefficient, both in terms of memory and computational resources. The CSR format addresses this problem by storing only the non-zero elements and their positions in the matrix. In the CSR format, a matrix is represented by three one-dimensional arrays:\n\n- **Values array**: Contains all the non-zero elements of the matrix, stored row by row.\n- **Column indices array**: Stores the column index corresponding to each value in the values array.\n- **Row pointer array**: Stores the cumulative number of non-zero elements in each row, allowing quick access to each row's data.\n\n### Structure\n\nGiven a matrix:\n\n$$\n\\begin{bmatrix} \n1 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n3 & 0 & 4 & 0 \\\\\n1 & 0 & 0 & 5 \n\\end{bmatrix}\n$$\n\nThe CSR representation would be:\n\n- **Values array**: [1, 2, 3, 4, 1, 5]\n- **Column indices array**: [0, 1, 0, 2, 0, 3]\n- **Row pointer array**: [0, 1, 2, 4, 6]\n\n### Explanation:\n\n- The **values array** holds the non-zero elements in the matrix, in row-major order.\n- The **column indices array** stores the corresponding column index of each non-zero element.\n- The **row pointer array** keeps track of where each row starts in the values array. For example, row 1 starts at index 0, row 2 starts at index 1, row 3 starts at index 2, and so on.\n\n### Applications\n\nThe CSR format is widely used in high-performance computing applications such as:\n\n- Finite element analysis (FEA)\n- Solving large sparse linear systems (e.g., in numerical simulations)\n- Machine learning algorithms (e.g., support vector machines with sparse input)\n- Graph-based algorithms where adjacency matrices are often sparse\n\nThe CSR format improves both memory efficiency and the speed of matrix operations by focusing only on non-zero elements.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "65"
    },
    {
        "description": "## Task: Compute the Orthogonal Projection of a Vector\n\nYour task is to implement a function that calculates the orthogonal projection of a vector **v** onto another vector **L**. This projection results in the vector on **L** that is closest to **v**.\n\nWrite a function `orthogonal_projection(v, L)` that takes in two lists, `v` (the vector to be projected) and `L` (the line vector), and returns the orthogonal projection of `v` onto `L`. The function should output a list representing the projection vector rounded to three decimal places.\n\n    ",
        "mdx_file": "8862283b-f3be-4371-a516-6c7b433e0b85.mdx",
        "test_cases": [
            {
                "test": "v = [3, 4]\nL = [1, 0]\nprint(orthogonal_projection(v, L))",
                "expected_output": "[3.0, 0.0]"
            },
            {
                "test": "v = [1, 2, 3]\nL = [0, 0, 1]\nprint(orthogonal_projection(v, L))",
                "expected_output": "[0.0, 0.0, 3.0]"
            },
            {
                "test": "v = [5, 6, 7]\nL = [2, 0, 0]\nprint(orthogonal_projection(v, L))",
                "expected_output": "[5.0, 0.0, 0.0]"
            }
        ],
        "solution": "def dot(v1, v2):\n    return sum([ax1 * ax2 for ax1, ax2 in zip(v1, v2)])\n\ndef scalar_mult(scalar, v):\n    return [scalar * ax for ax in v]\n\ndef orthogonal_projection(v, L):\n    L_mag_sq = dot(L, L)\n    proj_scalar = dot(v, L) / L_mag_sq\n    proj_v = scalar_mult(proj_scalar, L)\n    return [round(x, 3) for x in proj_v]\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "v = [3, 4]\nL = [1, 0]\nprint(orthogonal_projection(v, L))",
            "output": "[3.0, 0.0]",
            "reasoning": "The orthogonal projection of vector [3, 4] onto the line defined by [1, 0] results in the projection vector [3, 0], which lies on the line [1, 0]."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "\ndef orthogonal_projection(v, L):\n\t\"\"\"\n\tCompute the orthogonal projection of vector v onto line L.\n\n\t:param v: The vector to be projected\n\t:param L: The line vector defining the direction of projection\n\t:return: List representing the projection of v onto L\n\t\"\"\"\n\tpass\n",
        "title": "Implement Orthogonal Projection of a Vector onto a Line",
        "learn_section": "\n## Understanding Orthogonal Projection in Vector Spaces\n\nOrthogonal projection is a fundamental concept in linear algebra, used to project one vector onto another. The projection of vector $v$ onto a line defined by vector $L$ results in a new vector that lies on $L$, representing the closest point to $v$ on that line. This can be thought of as $v$'s shadow on $L$ if a light was shown directly down on $v$.\n\nTo project a vector $v$ onto a non-zero vector $L$ in space, we calculate the scalar projection of $v$ onto the unit vector of $L$, which represents the magnitude of the projection. The resulting projection vector lies along the direction of $L$.\n\nFor any vector $v$ in Cartesian space, the orthogonal projection onto $L$ is calculated using the formula:\n\n$$\n\\text{proj}_{L} (v) = \\frac{v \\cdot L}{L \\cdot L} L\n$$\n\nWhere:\n\n1) $v$ is the vector being projected,  \n2) $L$ is the vector defining the line of projection,  \n3) $v \\cdot L$ is the dot product of $v$ and $L$,  \n4) $L \\cdot L$ is the dot product of $L$ with itself, which gives the magnitude squared of $L$.\n\nThe resulting projection vector lies along the direction of $L$ and represents the component of $v$ that is parallel to $L$.\n\nMore generally, the projection of $v$ onto a unit vector $ \\hat{L} $ (the normalized version of $L$) simplifies to:\n\n$$\n\\text{proj}_{L} (v) = (v \\cdot \\hat{L}) \\hat{L}\n$$\n\n### Applications of Orthogonal Projection\n\nOrthogonal projection has a wide range of applications across various fields in mathematics, physics, computer science, and engineering. Some of the most common applications include:\n\n1) **Computer Graphics**: In 3D rendering, orthogonal projections are used to create 2D views of 3D objects. This projection helps in reducing dimensional complexity and displaying models from different angles.\n2) **Data Science and Machine Learning**: In high-dimensional data, projection methods are used to reduce dimensions (e.g., Principal Component Analysis) by projecting data onto lower-dimensional subspaces, helping with data visualization and reducing computational complexity.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "66"
    },
    {
        "description": "## Task: Create a Compressed Column Sparse Matrix Representation\n\nYour task is to implement a function that converts a dense matrix into its Compressed Column Sparse (CSC) representation. The CSC format stores only non-zero elements of the matrix and is efficient for matrices with a high number of zero elements.\n\nWrite a function `compressed_col_sparse_matrix(dense_matrix)` that takes in a two-dimensional list `dense_matrix` and returns a tuple of three lists:\n\n- `values`: List of non-zero elements, stored in column-major order.\n- `row indices`: List of row indices corresponding to each value in the values array.\n- `column pointer`: List that indicates the starting index of each column in the values array.\n\n    ",
        "mdx_file": "9b047a80-6f07-4ce2-9cb7-82946011f320.mdx",
        "test_cases": [
            {
                "test": "dense_matrix = [\n    [0, 0, 0],\n    [0, 0, 0],\n    [0, 0, 0]\n]\nvals, row_idx, col_ptr = compressed_col_sparse_matrix(dense_matrix)\nprint(vals)",
                "expected_output": "[]"
            },
            {
                "test": "dense_matrix = [\n    [0, 0, 0],\n    [1, 2, 0],\n    [0, 3, 4]\n]\nvals, row_idx, col_ptr = compressed_col_sparse_matrix(dense_matrix)\nprint(vals)",
                "expected_output": "[1, 2, 3, 4]"
            },
            {
                "test": "dense_matrix = [\n    [0, 0, 3, 0, 0],\n    [0, 4, 0, 0, 0],\n    [5, 0, 0, 6, 0],\n    [0, 0, 0, 0, 0],\n    [0, 7, 0, 0, 8]\n]\nvals, row_idx, col_ptr = compressed_col_sparse_matrix(dense_matrix)\nprint(vals)",
                "expected_output": "[5, 4, 7, 3, 6, 8]"
            }
        ],
        "solution": "def compressed_col_sparse_matrix(dense_matrix):\n    vals = []\n    row_idx = []\n    col_ptr = [0]\n\n    rows, cols = len(dense_matrix), len(dense_matrix[0])\n\n    for i in range(cols):\n        for j in range(rows):\n            val = dense_matrix[j][i]\n            if val != 0:\n                vals.append(val)\n                row_idx.append(j)\n        col_ptr.append(len(vals))\n\n    return vals, row_idx, col_ptr\n",
        "difficulty": "easy",
        "video": "",
        "likes": "0",
        "example": {
            "input": "dense_matrix = [\n    [0, 0, 3, 0],\n    [1, 0, 0, 4],\n    [0, 2, 0, 0]\n]\n\nvals, row_idx, col_ptr = compressed_col_sparse_matrix(dense_matrix)",
            "output": "[1, 2, 3, 4] [1, 2, 0, 1] [0, 1, 2, 3, 4]",
            "reasoning": "The dense matrix is converted to CSC format with the values array containing non-zero elements, row indices array storing the corresponding row index, and column pointer array indicating the start of each column in the values array."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "def compressed_col_sparse_matrix(dense_matrix):\n\t\"\"\"\n\tConvert a dense matrix into its Compressed Column Sparse (CSC) representation.\n\n\t:param dense_matrix: List of lists representing the dense matrix\n\t:return: Tuple of (values, row indices, column pointer)\n\t\"\"\"\n\tpass\n",
        "title": "Implement Compressed Column Sparse Matrix Format (CSC)",
        "learn_section": "\n## Understanding the Compressed Row Sparse Matrix Format\n\nThe Compressed Row Sparse (CSR) format is a data-efficient representation of sparse matrices, where most of the elements are zero. This format is particularly useful in large-scale scientific computing and machine learning applications, where memory efficiency is critical.\n\n### Concepts\n\nA sparse matrix is a matrix that contains a large number of zero elements. Storing such matrices in their full form can be inefficient, both in terms of memory and computational resources. The CSR format addresses this problem by storing only the non-zero elements and their positions in the matrix. In the CSR format, a matrix is represented by three one-dimensional arrays:\n\n1) **Values array**: Contains all the non-zero elements of the matrix, stored row by row.  \n2) **Column indices array**: Stores the column index corresponding to each value in the values array.  \n3) **Row pointer array**: Stores the cumulative number of non-zero elements in each row, allowing quick access to each row's data. This means that it points to the position within the column indices array at which the row starts.\n\n### Structure\n\nGiven a matrix:\n\n$$\n\\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 2 & 0 & 0 \\\\\n3 & 0 & 4 & 0 \\\\\n1 & 0 & 0 & 5\n\\end{bmatrix}\n$$\n\nThe CSR representation would be:\n\n1) **Values array**: [1, 2, 3, 4, 1, 5]  \n2) **Column indices array**: [0, 1, 0, 2, 0, 3]  \n3) **Row pointer array**: [0, 1, 2, 4, 6]\n\n### Explanation:\n\n1) The **values array** holds the non-zero elements in the matrix, in row-major order.\n2) The **column indices array** stores the corresponding column index of each non-zero element.\n3) The **row pointer array** keeps track of where each row starts in the values array. For example, row 1 starts at index 0, row 2 starts at index 1, row 3 starts at index 2, within the columns indices array, and so on.\n\n### Applications\n\nThe CSR format is widely used in high-performance computing applications such as:\n\n1) **Finite element analysis (FEA)**\n2) **Solving large sparse linear systems** (e.g., in numerical simulations)\n3) **Machine learning algorithms** (e.g., support vector machines with sparse input)\n4) **Graph-based algorithms** where adjacency matrices are often sparse\n\nThe CSR format improves both memory efficiency and the speed of matrix operations by focusing only on non-zero elements.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "67"
    },
    {
        "description": "\n## Task: Compute the Column Space of a Matrix\n\nIn this task, you are required to implement a function `matrix_image(A)` that calculates the column space of a given matrix `A`. The column space, also known as the image or span, consists of all linear combinations of the columns of `A`. To find this, you'll use concepts from linear algebra, focusing on identifying independent columns that span the matrix's image.\n**Your task:** Implement the function `matrix_image(A)` to return the basis vectors that span the column space of `A`. These vectors should be extracted from the original matrix and correspond to the independent columns.\n\n",
        "mdx_file": "abde6b54-0fc0-4b03-aeb3-e21148f2fe66.mdx",
        "test_cases": [
            {
                "test": "\nimport numpy as np\nmatrix = np.array([[1, 0], [0, 1]])\nprint(matrix_image(matrix))\n",
                "expected_output": "[[1, 0], [0, 1]]"
            },
            {
                "test": "\nimport numpy as np\nmatrix = np.array([[1, 2], [2, 4]])\nprint(matrix_image(matrix))\n",
                "expected_output": "[[1], [2]]"
            },
            {
                "test": "\nimport numpy as np\nmatrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(matrix_image(matrix))\n",
                "expected_output": "[[1, 2], [4, 5], [7, 8]]"
            }
        ],
        "solution": "\nimport numpy as np\n\ndef rref(A):\n    # Convert to float for division operations\n    A = A.astype(np.float32)\n    n, m = A.shape\n\n    for i in range(n):\n        if A[i, i] == 0:\n            nonzero_current_row = np.nonzero(A[i:, i])[0] + i\n            if len(nonzero_current_row) == 0:\n                continue\n            A[[i, nonzero_current_row[0]]] = A[[nonzero_current_row[0], i]]\n\n        A[i] = A[i] / A[i, i]\n\n        for j in range(n):\n            if i != j:\n                A[j] -= A[i] * A[j, i]\n    return A\n\ndef find_pivot_columns(A):\n    n, m = A.shape\n    pivot_columns = []\n    for i in range(n):\n        nonzero = np.nonzero(A[i, :])[0]\n        if len(nonzero) != 0:\n            pivot_columns.append(nonzero[0])\n    return pivot_columns\n\ndef matrix_image(A):\n    # Find the RREF of the matrix\n    Arref = rref(A)\n    # Find the pivot columns\n    pivot_columns = find_pivot_columns(Arref)\n    # Extract the pivot columns from the original matrix\n    image_basis = A[:, pivot_columns]\n    return image_basis\n",
        "difficulty": "medium",
        "video": "",
        "likes": "0",
        "example": {
            "input": "matrix = np.array([\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]\n])\nprint(matrix_image(matrix))",
            "output": "# [[1, 2],\n#  [4, 5],\n#  [7, 8]]",
            "reasoning": "The column space of the matrix is spanned by the independent columns [1, 2], [4, 5], and [7, 8]. These columns form the basis vectors that represent the image of the matrix."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "\nimport numpy as np\n\ndef matrix_image(A):\n\t# Write your code here\n\tpass\n",
        "title": "Find the Image of a Matrix Using Row Echelon Form",
        "learn_section": "\n## Matrix Image, Spans, and How to Calculate It\n\nIn linear algebra, the column space, also called the **image** or **span**, of a matrix is the set of all possible linear combinations of its columns. The column space gives important information about the matrix, such as the dimensions and dependencies between columns. It is useful for solving linear systems and understanding the structure of the data in the matrix. The image of a function can also be thought of as all the values the function takes in its codomain. The image of a matrix is the span of its columns - all linear combinations of its columns.\n\nConsider the following matrix $ A $:\n\n$$\nA = \\begin{bmatrix} \n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{bmatrix}\n$$\n\nThe column space of $ A $ is the set of all linear combinations of its columns. In other words, any vector in the column space of $ A $ can be written as:\n\n$$\n\\text{span}(A) = c_1 \\begin{bmatrix} \n1 \\\\\n4 \\\\\n7\n\\end{bmatrix} + c_2 \\begin{bmatrix} \n2 \\\\\n5 \\\\\n8\n\\end{bmatrix} + c_3 \\begin{bmatrix} \n3 \\\\\n6 \\\\\n9\n\\end{bmatrix}\n$$\n\nWhere $ c_1 $, $ c_2 $, and $ c_3 $ are scalars representing the linear combination of the columns of matrix $ A $.\n\n### The Image of a Matrix\n\nThe image of a matrix is spanned by its pivot columns. To find the image of a matrix, you can use the following steps:\n\n1) **Convert to Row Echelon Form (RREF)**\n\nThe first step is to convert the matrix to its RREF using **Gauss-Jordan Elimination**. This finds the independent equations within the matrix. In RREF form:\n- Each non-zero row begins with a leading 1, called a pivot\n- Rows of all zeros are at the bottom of the matrix\n- Each leading 1 is to the right of the leading 1 in the row above\n\n2) **Identify Pivot Columns**\n\nOnce the matrix is in RREF, the pivot columns are the columns that contain the leading 1s in each non-zero row. These columns represent the independent directions that span the column space of the matrix.\n\n3) **Extract Pivot Columns from the Original Matrix**\n\nFinally, to find the column space of the original matrix, you take the columns from the original matrix corresponding to the pivot columns in RREF.\n\n### Applications of Matrix Image\n\nThe matrix image has important applications in:\n\n- **Solving systems of linear equations**\n- **Determining the rank of a matrix**\n- **Understanding linear transformations**\n\nIt is also used in areas such as **data compression**, **computer graphics**, and **signal processing** to analyze and manipulate data effectively.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ],
        "id": "68"
    },
    {
        "video": "",
        "description": "\n## Task: Compute the R-squared Value in Regression Analysis\n\n- R-squared, also known as the coefficient of determination, is a measure that indicates how well the independent variables explain the variability of the dependent variable in a regression model. \n\n- **Your Task**: \n    To implement the function `r_squared(y_true, y_pred)` that calculates the R-squared value, given arrays of true values `y_true` and predicted values `y_pred`.\n",
        "example": {
            "input": "import numpy as np\n\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([1.1, 2.1, 2.9, 4.2, 4.8])\nprint(r_squared(y_true, y_pred))",
            "output": "0.989",
            "reasoning": "The R-squared value is calculated to be 0.989, indicating that the regression model explains 98.9% of the variance in the dependent variable."
        },
        "dislikes": 0,
        "test_cases": [
            {
                "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([1, 2, 3, 4, 5])\nprint(r_squared(y_true, y_pred))\n",
                "expected_output": "1.0"
            },
            {
                "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([1.1, 2.1, 2.9, 4.2, 4.8])\nprint(r_squared(y_true, y_pred))\n",
                "expected_output": "0.989"
            },
            {
                "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([2, 1, 4, 3, 5])\nprint(r_squared(y_true, y_pred))\n",
                "expected_output": "0.6"
            },
            {
                "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([3, 3, 3, 3, 3])\nprint(r_squared(y_true, y_pred))\n",
                "expected_output": "0.0"
            },
            {
                "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([5, 4, 3, 2, 1])\nprint(r_squared(y_true, y_pred))\n",
                "expected_output": "-3.0"
            }
        ],
        "starter_code": "\nimport numpy as np\n\ndef r_squared(y_true, y_pred):\n\t# Write your code here\n\tpass\n",
        "title": "Calculate R-squared for Regression Analysis",
        "learn_section": "\n# Understanding R-squared (R²) in Regression Analysis\n\nR-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. It provides insight into how well the model fits the data.\n\n### Mathematical Definition\n\nThe R-squared value is calculated using the following formula:  \n$$\nR^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}\n$$\nWhere:  \n\n1) $ \\text{SSR} $ (Sum of Squared Residuals): The sum of the squares of the differences between the actual values and the predicted values.  \n2) $ \\text{SST} $ (Total Sum of Squares): The sum of the squares of the differences between the actual values and the mean of the actual values.\n\n### Equations for SSR and SST\n\nTo calculate SSR and SST, we use the following formulas:  \n\n1) SSR:  \n$$\n\\text{SSR} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n$$  \n\n2) SST:  \n$$\n\\text{SST} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n$$  \n\nWhere:  \n\n1) $ y_i $: Actual value  \n2) $ \\hat{y}_i $: Predicted value  \n3) $ \\bar{y} $: Mean of the actual values  \n\n### Significance of R-squared\n\nR-squared is a key metric for evaluating how well a regression model performs. A higher R-squared value indicates a better fit for the model, meaning it can explain more variability in the data. However, it's important to note:  \n\n- A high R-squared does not always imply that the model is good; it can sometimes be misleading if overfitting occurs.  \n- It should be used in conjunction with other metrics for comprehensive model evaluation.\n\n### Implementing R-squared Calculation\n\nIn this problem, you will implement a function to calculate R-squared given arrays of true and predicted values from a regression task. The results should be rounded to three decimal places.  \n\nIn the solution, the implemented $ r\\_squared() $ function calculates R-squared by first determining SSR and SST, then applying them to compute $ R^2 $. It handles edge cases such as perfect predictions and situations where all true values are identical.\n\n### Reference\n\nYou can refer to this resource for more information:  \n[Coefficient of Determination](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html)\n",
        "solution": "\nimport numpy as np\n\ndef r_squared(y_true, y_pred):\n    \"\"\"\n    Calculate the R-squared (R²) coefficient of determination.\n    \n    Args:\n        y_true (numpy.ndarray): Array of true values\n        y_pred (numpy.ndarray): Array of predicted values\n    \n    Returns:\n        float: R-squared value rounded to 3 decimal places\n    \"\"\"\n    if np.array_equal(y_true, y_pred):\n        return 1.0\n\n    # Calculate mean of true values\n    y_mean = np.mean(y_true)\n\n    # Calculate Sum of Squared Residuals (SSR)\n    ssr = np.sum((y_true - y_pred) ** 2)\n\n    # Calculate Total Sum of Squares (SST)\n    sst = np.sum((y_true - y_mean) ** 2)\n\n    try:\n        # Calculate R-squared\n        r2 = 1 - (ssr / sst)\n        if np.isinf(r2):\n            return 0.0\n        return round(r2, 3)\n    except ZeroDivisionError:\n        return 0.0\n",
        "difficulty": "easy",
        "contributor": [
            {
                "profile_link": "https://github.com/rittik9",
                "name": "rittik9"
            }
        ],
        "likes": 0,
        "category": "Machine Learning",
        "id": "69"
    },
    {
        "description": "Write a Python function that transforms a given matrix A using the operation  $T^{-1} A S$, where T and S are invertible matrices. The function should first validate if the matrices T and S are invertible, and then perform the transformation. In cases where there is no solution return -1",
        "mdx_file": "935e3734-a356-47b6-8947-128d22898970.mdx",
        "tinygrad_difficulty": "medium",
        "id": "7",
        "test_cases": [
            {
                "test": "print(transform_matrix([[1, 2], [3, 4]], [[2, 0], [0, 2]], [[1, 1], [0, 1]]))",
                "expected_output": "[[0.5, 1.5], [1.5, 3.5]]"
            },
            {
                "test": "print(transform_matrix([[1, 0], [0, 1]], [[1, 2], [3, 4]], [[2, 0], [0, 2]]))",
                "expected_output": "[[-4.0, 2.0], [3.0, -1.0]]"
            },
            {
                "test": "print(transform_matrix([[2, 3], [1, 4]], [[3, 0], [0, 3]], [[1, 1], [0, 1]]))",
                "expected_output": "[[0.66666667,1.66666667],[0.33333333, 1.66666667]]"
            },
            {
                "test": "print(transform_matrix([[2, 3], [1, 4]], [[3, 0], [0, 3]], [[1, 1], [1, 1]]))",
                "expected_output": "-1"
            },
            {
                "test": "print(transform_matrix([[1, 2, 3],[0, 1, 4],[5, 6, 0]], [[2, 0, 0],[0, 2, 0],[0, 0, 2]], [[0, 1, 0],[0, 0, 1],[1, 0, 0]]))",
                "expected_output": "[[1.5, 0.5, 1.0], [2.0, 0.0, 0.5], [0.0, 2.5, 3.0]]"
            }
        ],
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHRyYW5zZm9ybV9tYXRyaXhfdGcoQSwgVCwgUykgLT4gVGVuc29yOgogICAgIiIiCiAgICBQZXJmb3JtIHRoZSBjaGFuZ2Utb2YtYmFzaXMgdHJhbnNmb3JtIFTigbvCuSBBIFMgZm9yIDLDlzIgbWF0cmljZXMgdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dHMgQSwgVCwgUyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRpbnlncmFkIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMsOXMiBUZW5zb3Igb3IgVGVuc29yKC0xLikgaWYgVCBvciBTIGlzIHNpbmd1bGFyLgogICAgIiIiCiAgICBBX3QgPSBUZW5zb3IoQSkuZmxvYXQoKQogICAgVF90ID0gVGVuc29yKFQpLmZsb2F0KCkKICAgIFNfdCA9IFRlbnNvcihTKS5mbG9hdCgpCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
        "solution": "import numpy as np\n\ndef transform_matrix(A: list[list[int|float]], T: list[list[int|float]], S: list[list[int|float]]) -> list[list[int|float]]:\n    # Convert to numpy arrays for easier manipulation\n    A = np.array(A, dtype=float)\n    T = np.array(T, dtype=float)\n    S = np.array(S, dtype=float)\n    \n    # Check if the matrices T and S are invertible\n    if np.linalg.det(T) == 0 or np.linalg.det(S) == 0:\n        # raise ValueError(\"The matrices T and/or S are not invertible.\")\n        return -1\n    \n    # Compute the inverse of T\n    T_inv = np.linalg.inv(T)\n\n    # Perform the matrix transformation; use @ for better readability\n    transformed_matrix = np.round(T_inv @ A @ S, 3)\n    \n    return transformed_matrix.tolist()",
        "tinygrad_solution": "aW1wb3J0IG51bXB5IGFzIG5wCmZyb20gdGlueWdyYWQudGVuc29yIGltcG9ydCBUZW5zb3IKCmRlZiB0cmFuc2Zvcm1fbWF0cml4X3RnKEEsIFQsIFMpIC0+IFRlbnNvcjoKICAgICIiIgogICAgUGVyZm9ybSB0aGUgY2hhbmdlLW9mLWJhc2lzIHRyYW5zZm9ybSBU4oG7wrkgQSBTIGZvciAyw5cyIG1hdHJpY2VzIHVzaW5nIHRpbnlncmFkLgogICAgSW5wdXRzIEEsIFQsIFMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0aW55Z3JhZCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDLDlzIgVGVuc29yIG9yIFRlbnNvcigtMS4pIGlmIFQgb3IgUyBpcyBzaW5ndWxhci4KICAgICIiIgogICAgQV90ID0gVGVuc29yKEEpLmZsb2F0KCkKICAgIFRfdCA9IFRlbnNvcihUKS5mbG9hdCgpCiAgICBTX3QgPSBUZW5zb3IoUykuZmxvYXQoKQogICAgIyBtYW51YWwgMsOXMiBkZXRlcm1pbmFudAogICAgZGV0VCA9IFRfdFswLDBdKlRfdFsxLDFdIC0gVF90WzAsMV0qVF90WzEsMF0KICAgIGRldFMgPSBTX3RbMCwwXSpTX3RbMSwxXSAtIFNfdFswLDFdKlNfdFsxLDBdCiAgICBpZiBkZXRULm51bXB5KCkgPT0gMCBvciBkZXRTLm51bXB5KCkgPT0gMDoKICAgICAgICByZXR1cm4gVGVuc29yKC0xLikKICAgICMgaW52ZXJzZSBvZiAyw5cyCiAgICBhLGIsYyxkID0gVF90WzAsMF0sIFRfdFswLDFdLCBUX3RbMSwwXSwgVF90WzEsMV0KICAgIFRfaW52ID0gVGVuc29yKFtbZCwgLWJdLCBbLWMsIGFdXSkgLyBkZXRUCiAgICBvdXQgPSBUX2ludi5tYXRtdWwoQV90KS5tYXRtdWwoU190KQogICAgIyByb3VuZCB2aWEgTnVtUHkgdGhlbiB3cmFwIGJhY2sKICAgIHJvdW5kZWQgPSBucC5yb3VuZChvdXQubnVtcHkoKSwgMykKICAgIHJldHVybiBUZW5zb3Iocm91bmRlZCkK",
        "pytorch_difficulty": "medium",
        "likes": "0",
        "video": "https://youtu.be/20zaxoO1mDg?si=oLCfMB59ilnG7-Sq",
        "difficulty": "medium",
        "example": {
            "input": "A = [[1, 2], [3, 4]], T = [[2, 0], [0, 2]], S = [[1, 1], [0, 1]]",
            "output": "[[0.5,1.5],[1.5,3.5]]",
            "reasoning": "The matrices T and S are used to transform matrix A by computing $T^{-1}AS$."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef transform_matrix(A: list[list[int|float]], T: list[list[int|float]], S: list[list[int|float]]) -> list[list[int|float]]:\n\treturn transformed_matrix",
        "title": "Matrix Transformation ",
        "learn_section": "### Matrix Transformation using $T^{-1} A S$\n\nTransforming a matrix $A$ using the operation $T^{-1} A S$ involves several steps. This operation changes the basis of matrix $A$ using two matrices $T$ and $S$, with $T$  being invertible.\n\n### Steps for Transformation\n\nGiven matrices $A$, $T$, and $S$:\n\n1. **Check Invertibility**: Verify that $T$ is invertible by ensuring its determinant is non-zero; otherwise, return $-1$.\n2. **Compute Inverses**: Find the invers of $T$, denoted as $T^{-1}$.\n3. **Perform Matrix Multiplication**: Calculate the transformed matrix:\n\n   $$\n   A' = T^{-1} A S\n   $$\n\n### Example\n\nIf:\n\n$$\nA =\n\\begin{pmatrix} \n1 & 2 \\\\ \n3 & 4 \n\\end{pmatrix}\n$$\n\n$$\nT =\n\\begin{pmatrix} \n2 & 0 \\\\ \n0 & 2 \n\\end{pmatrix}\n$$\n\n$$\nS =\n\\begin{pmatrix} \n1 & 1 \\\\ \n0 & 1 \n\\end{pmatrix}\n$$\n\n#### Check Invertibility:\n\n- $\\det(T) = 4 \\neq 0$\n\n#### Compute Inverses:\n\n$$\nT^{-1} =\n\\begin{pmatrix} \n\\frac{1}{2} & 0 \\\\ \n0 & \\frac{1}{2} \n\\end{pmatrix}\n$$\n\n#### Perform the Transformation:\n\n$$\nA' = T^{-1} A S\n$$\n\n$$\nA' =\n\\begin{pmatrix} \n\\frac{1}{2} & 0 \\\\ \n0 & \\frac{1}{2} \n\\end{pmatrix}\n\\begin{pmatrix} \n1 & 2 \\\\ \n3 & 4 \n\\end{pmatrix}\n\\begin{pmatrix} \n1 & 1 \\\\ \n0 & 1 \n\\end{pmatrix}\n$$\n\n$$\nA' =\n\\begin{pmatrix} \n0.5 & 1.5 \\\\ \n1.5 & 3.5 \n\\end{pmatrix}\n$$\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Srihari Thyagarajan"
            },
            {
                "profile_link": "https://github.com/sai-samarth",
                "name": "sai-samarth"
            },
            {
                "profile_link": "https://github.com/836hardik-agrawal",
                "name": "836hardik-agrawal"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = transform_matrix(\n    torch.tensor([[1,2],[3,4]], dtype=torch.float),\n    torch.eye(2),\n    torch.eye(2)\n)\nprint(res.detach().numpy().tolist())",
                "expected_output": "[[1.0, 2.0], [3.0, 4.0]]"
            },
            {
                "test": "import torch\nres = transform_matrix(\n    torch.tensor([[1,2],[3,4]], dtype=torch.float),\n    torch.tensor([[2,0],[0,3]], dtype=torch.float),\n    torch.eye(2)\n)\nprint(res.detach().numpy().tolist())",
                "expected_output": "[[0.5, 1.0], [1.0, 1.333]]"
            },
            {
                "test": "import torch\nres = transform_matrix(\n    torch.tensor([[1,2],[3,4]], dtype=torch.float),\n    torch.eye(2),\n    torch.tensor([[1,0],[0,0]], dtype=torch.float)\n)\nprint(res.detach().numpy().tolist())",
                "expected_output": "-1.0"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = transform_matrix_tg(\n    [[1,2],[3,4]],\n    [[1,0],[0,1]],\n    [[1,0],[0,1]]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 2.0], [3.0, 4.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = transform_matrix_tg(\n    [[1,2],[3,4]],\n    [[2,0],[0,3]],\n    [[1,0],[0,1]]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[0.5, 1.0], [1.0, 1.333]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = transform_matrix_tg(\n    [[1,2],[3,4]],\n    [[1,0],[0,1]],\n    [[1,0],[0,0]]\n)\nprint(res.numpy().tolist())",
                "expected_output": "-1.0"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgdHJhbnNmb3JtX21hdHJpeChBLCBULCBTKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFBlcmZvcm0gdGhlIGNoYW5nZS1vZi1iYXNpcyB0cmFuc2Zvcm0gVOKBu8K5IEEgUyBhbmQgcm91bmQgdG8gMyBkZWNpbWFscyB1c2luZyBQeVRvcmNoLgogICAgSW5wdXRzIEEsIFQsIFMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0b3JjaCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDLDlzIgdGVuc29yIG9yIHRlbnNvcigtMS4pIGlmIFQgb3IgUyBpcyBzaW5ndWxhci4KICAgICIiIgogICAgQV90ID0gdG9yY2guYXNfdGVuc29yKEEsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgVF90ID0gdG9yY2guYXNfdGVuc29yKFQsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgU190ID0gdG9yY2guYXNfdGVuc29yKFMsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgaWYgdG9yY2guZGV0KFRfdCkgPT0gMCBvciB0b3JjaC5kZXQoU190KSA9PSAwOgogICAgICAgIHJldHVybiB0b3JjaC50ZW5zb3IoLTEuKQogICAgVF9pbnYgPSB0b3JjaC5pbnZlcnNlKFRfdCkKICAgIG91dCA9IFRfaW52IEAgQV90IEAgU190CiAgICByZXR1cm4gdG9yY2gucm91bmQob3V0ICogMTAwMCkgLyAxMDAwCg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgdHJhbnNmb3JtX21hdHJpeChBLCBULCBTKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFBlcmZvcm0gdGhlIGNoYW5nZS1vZi1iYXNpcyB0cmFuc2Zvcm0gVOKBu8K5IEEgUyBhbmQgcm91bmQgdG8gMyBkZWNpbWFscyB1c2luZyBQeVRvcmNoLgogICAgSW5wdXRzIEEsIFQsIFMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0b3JjaCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDLDlzIgdGVuc29yIG9yIHRlbnNvcigtMS4pIGlmIFQgb3IgUyBpcyBzaW5ndWxhci4KICAgICIiIgogICAgQV90ID0gdG9yY2guYXNfdGVuc29yKEEsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgVF90ID0gdG9yY2guYXNfdGVuc29yKFQsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgU190ID0gdG9yY2guYXNfdGVuc29yKFMsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK"
    },
    {
        "video": "",
        "description": "\n## Task: Image Brightness Calculator\n\nIn this task, you will implement a function `calculate_brightness(img)` that calculates the average brightness of a grayscale image. The image is represented as a 2D matrix, where each element represents a pixel value between 0 (black) and 255 (white).\n\n### **Your Task**:\nImplement the function `calculate_brightness(img)` to:\n1. Return the average brightness of the image rounded to two decimal places.\n2. Handle edge cases:\n   - If the image matrix is empty.\n   - If the rows in the matrix have inconsistent lengths.\n   - If any pixel values are outside the valid range (0-255).\n\nFor any of these edge cases, the function should return `-1`.\n\n",
        "example": {
            "input": "img = [\n    [100, 200],\n    [50, 150]\n]\nprint(calculate_brightness(img))",
            "output": "125.0",
            "reasoning": "The average brightness is calculated as (100 + 200 + 50 + 150) / 4 = 125.0"
        },
        "dislikes": 0,
        "test_cases": [
            {
                "test": "\n# Test empty image\nprint(calculate_brightness([]))\n",
                "expected_output": "-1"
            },
            {
                "test": "\n# Test invalid dimensions\nprint(calculate_brightness([[100, 200], [150]]))\n",
                "expected_output": "-1"
            },
            {
                "test": "\n# Test invalid pixel values\nprint(calculate_brightness([[100, 300]]))\n",
                "expected_output": "-1"
            },
            {
                "test": "\n# Test valid cases\nprint(calculate_brightness([[128]]))\n",
                "expected_output": "128.0"
            },
            {
                "test": "\n# Another valid case\nprint(calculate_brightness([[100, 200], [50, 150]]))\n",
                "expected_output": "125.0"
            }
        ],
        "starter_code": "\ndef calculate_brightness(img):\n\t# Write your code here\n\tpass\n",
        "title": "Calculate Image Brightness",
        "learn_section": "\n# Image Brightness Calculator\n\nConsider a grayscale image represented as a 2D matrix where each element represents a pixel value between 0 (black) and 255 (white):\n\n$$\nImage = \\begin{pmatrix}\np_{11} & p_{12} \\\\\np_{21} & p_{22}\n\\end{pmatrix}\n$$\n\nThe average brightness is calculated as:\n\n$$\nBrightness = \\frac{\\sum_{i=1}^{m} \\sum_{j=1}^{n} p_{ij}}{m \\times n}\n$$\n\nWhere:\n\n1) $p_{ij}$ is the pixel value at position $(i,j)$  \n2) $m$ is the number of rows  \n3) $n$ is the number of columns  \n\n### Things to Note:\n\n1) All pixel values must be between 0 and 255  \n2) The image matrix must be well-formed (all rows same length)  \n3) Empty or invalid images return -1  \n",
        "solution": "\ndef calculate_brightness(img):\n    # Check if image is empty or has no columns\n    if not img or not img[0]:\n        return -1\n\n    rows, cols = len(img), len(img[0])\n\n    # Check if all rows have same length and values are valid\n    for row in img:\n        if len(row) != cols:\n            return -1\n        for pixel in row:\n            if not 0 <= pixel <= 255:\n                return -1\n\n    # Calculate average brightness\n    total = sum(sum(row) for row in img)\n    return round(total / (rows * cols), 2)\n",
        "difficulty": "easy",
        "contributor": [
            {
                "profile_link": "https://github.com/NiharP31",
                "name": "NiharP31"
            }
        ],
        "likes": 0,
        "category": "Computer Vision",
        "id": "70"
    },
    {
        "video": "",
        "description": "\n## Task: Compute Root Mean Square Error (RMSE)\n\nIn this task, you are required to implement a function `rmse(y_true, y_pred)` that calculates the Root Mean Square Error (RMSE) between the actual values and the predicted values. RMSE is a commonly used metric for evaluating the accuracy of regression models, providing insight into the standard deviation of residuals.\n\n### Your Task:\nImplement the function `rmse(y_true, y_pred)` to:\n1. Calculate the RMSE between the arrays `y_true` and `y_pred`.\n2. Return the RMSE value rounded to three decimal places.\n3. Ensure the function handles edge cases such as:\n   - Mismatched array shapes.\n   - Empty arrays.\n   - Invalid input types.\n\nThe RMSE is defined as:\n\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}, i} - y_{\\text{pred}, i})^2}\n$$\n\nWhere:\n- $ n $ is the number of observations.\n- $ y_{\\text{true}, i} $ and $ y_{\\text{pred}, i} $ are the actual and predicted values for the $ i $-th observation.\n",
        "example": {
            "input": "y_true = np.array([3, -0.5, 2, 7])\ny_pred = np.array([2.5, 0.0, 2, 8])\nprint(rmse(y_true, y_pred))",
            "output": "0.612",
            "reasoning": "The RMSE is calculated as sqrt((0.5^2 + 0.5^2 + 0^2 + 1^2) / 4) = 0.612"
        },
        "dislikes": 0,
        "test_cases": [
            {
                "test": "\n# Test Case 1: Normal Case  \ny_true1 = np.array([3, -0.5, 2, 7])\ny_pred1 = np.array([2.5, 0.0, 2, 8])\nprint(rmse(y_true1, y_pred1))\n",
                "expected_output": "0.612"
            },
            {
                "test": "\n# Test Case 2: 2D Array \ny_true2 = np.array([[0.5, 1], [-1, 1], [7, -6]])\ny_pred2 = np.array([[0, 2], [-1, 2], [8, -5]])\nprint(rmse(y_true2, y_pred2))\n",
                "expected_output": "0.842"
            },
            {
                "test": "\n# Test Case 3: Perfect predictions\ny_true3 = np.array([[1, 2], [3, 4]])\ny_pred3 = np.array([[1, 2], [3, 4]])\nprint(rmse(y_true3, y_pred3))\n",
                "expected_output": "0.0"
            }
        ],
        "starter_code": "\nimport numpy as np\n\ndef rmse(y_true, y_pred):\n\t# Write your code here\n\treturn round(rmse_res,3)\n",
        "title": "Calculate Root Mean Square Error (RMSE)",
        "learn_section": "\n## Root Mean Square Error (RMSE)\n\nRMSE is used to measure the accuracy of predictions in regression models. It represents the difference between the predictions and the actual values. In other words, it is the standard deviation of the residuals or prediction errors.\n\n### **Theory**\nThe RMSE is defined as:\n\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}_i} - y_{\\text{pred}_i})^2}\n$$\n\nwhere:\n- $ n $: The number of observations.\n- $ y_{\\text{true}_i} $: The actual values.\n- $ y_{\\text{pred}_i} $: The predicted values.\n\n### **Steps for Calculation**\n1. For each pair of actual and predicted values, calculate the difference $ y_{\\text{true}_i} - y_{\\text{pred}_i} $.\n2. Square each of these differences and find their mean.\n3. Take the square root of the mean value.\n\n### **When to Use RMSE vs. MAE**\n- **RMSE**: Used when large deviations/errors are more problematic and should be penalized more heavily.\n- **MAE**: Used when errors should be treated equally, regardless of their size.\n",
        "solution": "\nimport numpy as np\n\ndef rmse(y_true, y_pred):\n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"Arrays must have the same shape\")\n    if y_true.size == 0:\n        raise ValueError(\"Arrays cannot be empty\")\n    return round(np.sqrt(np.mean((y_true - y_pred) ** 2)), 3)\n",
        "difficulty": "easy",
        "contributor": [
            {
                "profile_link": "https://github.com/saitiger",
                "name": "Sai Tiger Raina"
            }
        ],
        "likes": 0,
        "category": "Machine Learning",
        "id": "71"
    },
    {
        "video": "",
        "description": "\n## Task: Implement the Jaccard Index\n\nYour task is to implement a function `jaccard_index(y_true, y_pred)` that calculates the Jaccard Index, a measure of similarity between two binary sets. The Jaccard Index is widely used in binary classification tasks to evaluate the overlap between predicted and true labels.\n\n### Your Task:\nImplement the function `jaccard_index(y_true, y_pred)` to:\n1. Calculate the Jaccard Index between the arrays `y_true` and `y_pred`.\n2. Return the Jaccard Index as a float value.\n3. Ensure the function handles cases where:\n   - There is no overlap between `y_true` and `y_pred`.\n   - Both arrays contain only zeros (edge cases).\n\nThe Jaccard Index is defined as:\n\n$$\n\\scriptsize\n\\text{Jaccard Index} = \\frac{\\text{Number of elements in the intersection of } y_{\\text{true}} \\text{ and } y_{\\text{pred}}}{\\text{Number of elements in the union of } y_{\\text{true}} \\text{ and } y_{\\text{pred}}}\n$$\n\n\nWhere:\n- $ y_{\\text{true}} $ and $ y_{\\text{pred}} $ are binary arrays of the same length, representing true and predicted labels.\n- The result ranges from 0 (no overlap) to 1 (perfect overlap).\n",
        "example": {
            "input": "y_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nprint(jaccard_index(y_true, y_pred))",
            "output": "0.75",
            "reasoning": "The Jaccard Index is calculated as 3 / 4 = 0.75, indicating a 75% overlap between the true and predicted labels."
        },
        "dislikes": 0,
        "test_cases": [
            {
                "test": "\n# Test case 1: Perfect match\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 1, 0, 1])\nprint(jaccard_index(y_true, y_pred))\n",
                "expected_output": "1.0"
            },
            {
                "test": "\n# Test case 2: No overlap\ny_true = np.array([1, 0, 1, 1, 0, 0])\ny_pred = np.array([0, 1, 0, 0, 1, 1])\nprint(jaccard_index(y_true, y_pred))\n",
                "expected_output": "0.0"
            },
            {
                "test": "\n# Test case 3: Partial overlap\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 0])\nprint(jaccard_index(y_true, y_pred))\n",
                "expected_output": "0.5"
            },
            {
                "test": "\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([0, 1, 0, 1, 1, 0])\nprint(jaccard_index(y_true, y_pred))\n",
                "expected_output": "0.167"
            }
        ],
        "starter_code": "\nimport numpy as np\n\ndef jaccard_index(y_true, y_pred):\n\t# Write your code here\n\treturn round(result, 3)\n",
        "title": "Calculate Jaccard Index for Binary Classification",
        "learn_section": "\n## Understanding Jaccard Index in Classification\n\nThe Jaccard Index, also known as the Jaccard Similarity Coefficient, is a statistic used to measure the similarity between sets. In the context of binary classification, it measures the overlap between predicted and actual positive labels.\n\n### Mathematical Definition\n\nThe Jaccard Index is defined as the size of the intersection divided by the size of the union of two sets:\n\n$$\n\\text{Jaccard Index} = \\frac{|A \\cap B|}{|A \\cup B|} = \\frac{|A \\cap B|}{|A| + |B| - |A \\cap B|}\n$$\n\n### In the Context of Binary Classification\n1. **Intersection ($A \\cap B$):** The number of positions where both the predicted and true labels are 1 (True Positives).  \n2. **Union ($A \\cup B$):** The number of positions where either the predicted or true labels (or both) are 1.  \n\n### Key Properties\n1. **Range:** The Jaccard Index always falls between 0 and 1 (inclusive).  \n2. **Perfect Match:** A value of 1 indicates identical sets.  \n3. **No Overlap:** A value of 0 indicates disjoint sets.  \n4. **Symmetry:** The index is symmetric, meaning $J(A, B) = J(B, A)$.  \n\n### Example\nConsider two binary vectors:  \n- **True labels:** [1, 0, 1, 1, 0, 1]  \n- **Predicted labels:** [1, 0, 1, 0, 0, 1]  \n\nIn this case:  \n1. **Intersection** (positions where both are 1): 3.  \n2. **Union** (positions where either is 1): 4.  \n3. **Jaccard Index**: $3 / 4 = 0.75$.\n\n### Usage in Machine Learning\nThe Jaccard Index is particularly useful in:  \n1. Evaluating clustering algorithms.  \n2. Comparing binary classification results.  \n3. Document similarity analysis.  \n4. Image segmentation evaluation.  \n\nWhen implementing the Jaccard Index, it's important to handle edge cases, such as when both sets are empty (in which case the index is typically defined as 0).\n",
        "solution": "\nimport numpy as np\n\ndef jaccard_index(y_true, y_pred):\n    intersection = np.sum((y_true == 1) & (y_pred == 1))\n    union = np.sum((y_true == 1) | (y_pred == 1))\n    result = intersection / union\n    if np.isnan(result):\n        return 0.0\n    return round(result, 3)\n",
        "difficulty": "easy",
        "contributor": [
            {
                "profile_link": "https://github.com/rittik9",
                "name": "rittik9"
            }
        ],
        "likes": 0,
        "category": "Machine Learning",
        "id": "72"
    },
    {
        "video": "",
        "description": "\n## Task: Compute the Dice Score\n\nYour task is to implement a function `dice_score(y_true, y_pred)` that calculates the Dice Score, also known as the Sørensen-Dice coefficient or F1-score, for binary classification. The Dice Score is used to measure the similarity between two sets and is particularly useful in tasks like image segmentation and binary classification.\n\n### Your Task:\nImplement the function `dice_score(y_true, y_pred)` to:\n1. Calculate the Dice Score between the arrays `y_true` and `y_pred`.\n2. Return the Dice Score as a float value rounded to 3 decimal places.\n3. Handle edge cases appropriately, such as when there are no true or predicted positives.\n\nThe Dice Score is defined as:\n\n$$\n\\scriptsize\n\\text{Dice Score} =\n\\frac{2 \\times (\\text{Number of elements in the intersection of } y_{\\text{true}} \\text{ and } y_{\\text{pred}})}{\\text{Number of elements in } y_{\\text{true}} + \\text{Number of elements in } y_{\\text{pred}}}\n$$\n\nWhere:\n- $ y_{\\text{true}} $ and $ y_{\\text{pred}} $ are binary arrays of the same length, representing true and predicted labels.\n- The result ranges from 0 (no overlap) to 1 (perfect overlap).\n",
        "example": {
            "input": "y_true = np.array([1, 1, 0, 1, 0, 1])\ny_pred = np.array([1, 1, 0, 0, 0, 1])\nprint(dice_score(y_true, y_pred))",
            "output": "0.857",
            "reasoning": "The Dice Score is calculated as (2 * 3) / (2 * 3 + 0 + 1) = 0.857, indicating an 85.7% overlap between the true and predicted labels."
        },
        "dislikes": 0,
        "test_cases": [
            {
                "test": "\ny_true = np.array([1, 1, 0, 0])\ny_pred = np.array([1, 1, 0, 0])\nprint(dice_score(y_true, y_pred))\n",
                "expected_output": "1.0"
            },
            {
                "test": "\ny_true = np.array([1, 1, 0, 0])\ny_pred = np.array([0, 0, 1, 1])\nprint(dice_score(y_true, y_pred))\n",
                "expected_output": "0.0"
            },
            {
                "test": "\ny_true = np.array([1, 1, 0, 0])\ny_pred = np.array([1, 0, 0, 0])\nprint(dice_score(y_true, y_pred))\n",
                "expected_output": "0.667"
            },
            {
                "test": "\ny_true = np.array([0, 0, 0, 0])\ny_pred = np.array([0, 0, 0, 0])\nprint(dice_score(y_true, y_pred))\n",
                "expected_output": "0.0"
            },
            {
                "test": "\ny_true = np.array([1, 1, 1, 1])\ny_pred = np.array([1, 1, 1, 1])\nprint(dice_score(y_true, y_pred))\n",
                "expected_output": "1.0"
            }
        ],
        "starter_code": "\nimport numpy as np\n\ndef dice_score(y_true, y_pred):\n\t# Write your code here\n\treturn round(res, 3)\n",
        "title": "Calculate Dice Score for Classification",
        "learn_section": "\n # Understanding Dice Score in Classification\n\nThe Dice Score, also known as the Sørensen-Dice coefficient or F1-score, is a statistical measure used to gauge the similarity between two samples. It is particularly popular in image segmentation tasks and binary classification problems.\n\n## Mathematical Definition\n\nThe Dice coefficient is defined as twice the intersection divided by the sum of the cardinalities of both sets:\n\n$$\n\\text{Dice Score} = \\frac{2|X \\cap Y|}{|X| + |Y|} = \\frac{2TP}{2TP + FP + FN}\n$$\n\n### In terms of binary classification:\n1. **TP (True Positives):** Number of positions where both predicted and true labels are 1.  \n2. **FP (False Positives):** Number of positions where the prediction is 1 but the true label is 0.  \n3. **FN (False Negatives):** Number of positions where the prediction is 0 but the true label is 1.\n\n## Relationship with F1-Score\n\nThe Dice coefficient is identical to the F1-score, which is the harmonic mean of precision and recall:\n\n$$\n\\text{F1-score} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}} = \\text{Dice Score}\n$$\n\n## Key Properties\n1. **Range:** The Dice score always falls between 0 and 1 (inclusive).  \n2. **Perfect Score:** A value of 1 indicates perfect overlap.  \n3. **No Overlap:** A value of 0 indicates no overlap.  \n4. **Sensitivity:** More sensitive to overlap than the Jaccard Index.  \n5. **Symmetry:** The score is symmetric, meaning DSC(A,B) = DSC(B,A).\n\n## Example\n\nConsider two binary vectors:  \n- **True labels:** [1, 1, 0, 1, 0, 1]  \n- **Predicted labels:** [1, 1, 0, 0, 0, 1]  \n\nIn this case:  \n- **True Positives (TP):** 3  \n- **False Positives (FP):** 0  \n- **False Negatives (FN):** 1  \n\n$$\n\\text{Dice Score} = \\frac{2 \\times 3}{2 \\times 3 + 0 + 1} = 0.857\n$$\n\n## Advantages Over Jaccard Index\n\nThe Dice score offers several advantages:  \n1. **Higher Sensitivity to Overlap:** Due to the doubled intersection term.  \n2. **Weight on Agreement:** Gives more weight to instances where labels agree.  \n3. **Preferred in Medical Imaging:** Often used in medical image segmentation due to its sensitivity to overlap.  \n4. **Intuitive Interpretation:** As the harmonic mean of precision and recall.\n\n## Common Applications\n\nThe Dice score is widely used in:  \n1. **Medical image segmentation evaluation.**  \n2. **Binary classification tasks.**  \n3. **Object detection overlap assessment.**  \n4. **Text similarity measurement.**  \n5. **Semantic segmentation evaluation.**\n\nWhen implementing the Dice score, it is important to handle edge cases properly, such as when both sets are empty. In such cases, the score is typically defined as 0.0 (as per scikit-learn).\n",
        "solution": "\nimport numpy as np\n\ndef dice_score(y_true, y_pred):\n    intersection = np.logical_and(y_true, y_pred).sum()\n    true_sum = y_true.sum()\n    pred_sum = y_pred.sum()\n\n    # Handle edge cases\n    if true_sum == 0 or pred_sum == 0:\n        return 0.0\n\n    dice = (2.0 * intersection) / (true_sum + pred_sum)\n    return round(float(dice), 3)\n",
        "difficulty": "easy",
        "contributor": [
            {
                "profile_link": "https://github.com/rittik9",
                "name": "rittik9"
            }
        ],
        "likes": 0,
        "category": "Machine Learning",
        "id": "73"
    },
    {
        "description": "## Task: Generate a Composite Hypervector Using Hyperdimensional Computing\n\nYour task is to implement the function `create_row_hv(row, dim, random_seeds)` to generate a composite hypervector for a given dataset row using Hyperdimensional Computing (HDC). Each feature in the row is represented by binding hypervectors for the feature name and its value. The hypervectors for the values are created using the same feature seed provided in the `random_seeds` dictionary to ensure reproducibility. All feature hypervectors are then bundled to create a composite hypervector for the row.\n\n### Input:\n- `row`: A dictionary representing a dataset row, where keys are feature names and values are their corresponding values.\n- `dim`: The dimensionality of the hypervectors.\n- `random_seeds`: A dictionary where keys are feature names and values are seeds to ensure reproducibility of hypervectors.\n\n### Output:\n- A composite hypervector representing the entire row.\n",
        "id": "74",
        "test_cases": [
            {
                "test": "\nrow = {\"FeatureA\": \"value1\", \"FeatureB\": \"value2\"}\ndim = 5\nrandom_seeds = {\"FeatureA\": 42, \"FeatureB\": 7}\nprint(create_row_hv(row, dim, random_seeds))\n",
                "expected_output": "[1, -1, 1, 1, 1]"
            },
            {
                "test": "\nrow = {\"FeatureA\": \"value1\", \"FeatureB\": \"value2\"}\ndim = 10\nrandom_seeds = {\"FeatureA\": 42, \"FeatureB\": 7}\nprint(create_row_hv(row, dim, random_seeds))\n",
                "expected_output": "[1, -1, 1, 1, -1, -1, -1, -1, -1, -1]"
            },
            {
                "test": "\nrow = {\"FeatureA\": \"value1\", \"FeatureB\": \"value2\"}\ndim = 15\nrandom_seeds = {\"FeatureA\": 42, \"FeatureB\": 7}\nprint(create_row_hv(row, dim, random_seeds))\n",
                "expected_output": "[1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1]"
            }
        ],
        "solution": "\nimport numpy as np\n\ndef create_hv(dim):\n    return np.random.choice([-1, 1], dim)\n\ndef create_col_hvs(dim, seed):\n    np.random.seed(seed)\n    return create_hv(dim), create_hv(dim)\n\ndef bind(hv1, hv2):\n    return hv1 * hv2\n\ndef bundle(hvs, dim):\n    bundled = np.sum(list(hvs.values()), axis=0)\n    return sign(bundled)\n\ndef sign(vector, threshold=0.01):\n    return np.array([1 if v >= 0 else -1 for v in vector])\n\ndef create_row_hv(row, dim, random_seeds):\n    row_hvs = {col: bind(*create_col_hvs(dim, random_seeds[col])) for col in row.keys()}\n    return bundle(row_hvs, dim)\n",
        "difficulty": "medium",
        "video": "",
        "likes": 0,
        "example": {
            "input": "row = {\"FeatureA\": \"value1\", \"FeatureB\": \"value2\"}\ndim = 5\nrandom_seeds = {\"FeatureA\": 42, \"FeatureB\": 7}\nprint(create_row_hv(row, dim, random_seeds))",
            "output": "[ 1, -1,  1,  1,  1]",
            "reasoning": "The composite hypervector is created by binding hypervectors for each feature and bundling them together."
        },
        "dislikes": 0,
        "category": "Linear Algebra",
        "starter_code": "\nimport numpy as np\n\ndef create_row_hv(row, dim, random_seeds):\n\t# Write your code here\n\tpass\n",
        "title": "Create Composite Hypervector for a Dataset Row",
        "learn_section": "\n## Hyperdimensional Computing\nHyperdimensional Computing (HDC) is a computational model inspired by the brain's ability to represent and process information using high-dimensional vectors, based on hypervectors being quasi-orthogonal. It uses vectors with a large number of dimensions to represent data, where each vector is typically filled with binary (1 or 0) or bipolar values (1 or -1). To represent complex data patterns, binding and bundling operations are used. \n\nIn HDC, different data types such as numeric and categorical variables are projected into high-dimensional space through specific encoding processes. Categorical variables are assigned unique hypervectors, often randomly generated binary or bipolar vectors, that serve as representations for each category. Numeric variables are encoded by discretizing the continuous values and mapping discrete bins to hypervectors. These projections allow HDC models to integrate various data types into a unified high-dimensional representation, preserving information across complex, multi-feature datasets.\n\n---\n\n## Binding Operation\nThe binding operation between two hypervectors is performed element-wise using multiplication. This operation is used to represent associations between different pieces of information:\n\n$$\n\\text{bind}(\\text{hv1}, \\text{hv2}) = \\text{hv1} \\times \\text{hv2}\n$$\n\nWhere $ \\text{hv1} $ and $ \\text{hv2} $ are bipolar vectors, and their element-wise multiplication results in a new vector where each element is either 1 or -1.\n\n---\n\n## Bundling Operation\nThe bundling operation sums multiple hypervectors to combine information, typically using element-wise addition for bipolar vectors and XOR operations for binary vectors. This operation aggregates information and creates a composite hypervector that represents the overall data or concept. For example, for a set of $ n $ hypervectors $ \\text{hv1}, \\text{hv2}, \\dots, \\text{hvn} $, the bundled vector is:\n\n$$\n\\text{bundle}(\\text{hv1}, \\text{hv2}, \\dots, \\text{hvn}) = \\sum_{i=1}^{n} \\text{hvi}\n$$\n\nThis bundled vector is then normalized to ensure it remains bipolar.\n\n---\n\n## Normalization\nNormalization ensures that the final bundled vector contains only bipolar or binary values. The normalization function typically applies a thresholding process that transforms any value greater than zero to +1 and any value less than zero to -1. Zero values are then typically assigned to either +1 or -1.\n\n---\n\n## Operations in Practice: Example\nConsider a scenario where we want to represent and combine information from each feature in a row of a dataset. Each feature, whether numeric or categorical, is represented by a hypervector, and these hypervectors are combined to form a composite vector that represents the entire row of data.\n\nFor instance, if we have a dataset row with features Feature A and Feature B, we would:\n1. Create a hypervector for the column Feature A and another for its specific feature value.\n2. Create a hypervector for the column Feature B and another for its specific feature value.\n3. Bind each feature’s column hypervector with the hypervector representing its value to form a unique vector for each feature.\n4. Bundle all the feature hypervectors for this row to create a single composite vector representing the entire row.\n5. Normalize the bundled vector to maintain bipolar values.\n\n---\n\n## Applications of HDC\nHyperdimensional computing has a variety of applications, including:\n1. **Data Classification**: Using high-dimensional vectors to represent data points and classifying them based on their properties.\n2. **Pattern Recognition**: Recognizing complex patterns in data through binding and bundling operations.\n3. **Natural Language Processing**: Representing words and phrases as high-dimensional vectors to analyze and process text data.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/paddywardle",
                "name": "paddywardle"
            }
        ]
    },
    {
        "description": "\n## Task: Generate a Confusion Matrix\n\nYour task is to implement the function `confusion_matrix(data)` that generates a confusion matrix for a binary classification problem. The confusion matrix provides a summary of the prediction results on a classification problem, allowing you to visualize how many data points were correctly or incorrectly labeled.\n\n### Input:\n- A list of lists, where each inner list represents a pair \n- `[y_true, y_pred]` for one observation. `y_true` is the actual label, and `y_pred` is the predicted label.\n\n### Output:\n- A $2 \\times 2$ confusion matrix represented as a list of lists.\n",
        "test_cases": [
            {
                "test": "\ndata = [[1, 1], [1, 0], [0, 1], [0, 0], [0, 1]]\nprint(confusion_matrix(data))\n",
                "expected_output": "[[1, 1], [2, 1]]"
            },
            {
                "test": "\ndata = [[0, 1], [1, 0], [1, 1], [0, 1], [0, 0], [1, 0], [0, 1], [1, 1], [0, 0], [1, 0], [1, 1], [0, 0], [1, 0], [0, 1], [1, 1], [1, 1], [1, 0]]\nprint(confusion_matrix(data))\n",
                "expected_output": "[[5, 5], [4, 3]]"
            },
            {
                "test": "\ndata = [[0, 1], [0, 1], [0, 0], [0, 1], [0, 0], [0, 1], [0, 1], [0, 0], [1, 0], [0, 1], [1, 0], [0, 0], [0, 1], [0, 1], [0, 1], [1, 0]]\nprint(confusion_matrix(data))\n",
                "expected_output": "[[0, 3], [9, 4]]"
            }
        ],
        "solution": "\nfrom collections import Counter\n\ndef confusion_matrix(data):\n    # Count all occurrences\n    counts = Counter(tuple(pair) for pair in data)\n    # Get metrics\n    TP, FN, FP, TN = counts[(1, 1)], counts[(1, 0)], counts[(0, 1)], counts[(0, 0)]\n    # Define matrix and return\n    confusion_matrix = [[TP, FN], [FP, TN]]\n    return confusion_matrix\n",
        "difficulty": "easy",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-75",
        "likes": 0,
        "video": "https://youtu.be/0n7dGmp0xUE",
        "example": {
            "input": "data = [[1, 1], [1, 0], [0, 1], [0, 0], [0, 1]]\nprint(confusion_matrix(data))",
            "output": "[[1, 1], [2, 1]]",
            "reasoning": "The confusion matrix shows the counts of true positives, false negatives, false positives, and true negatives."
        },
        "dislikes": 0,
        "category": "Machine Learning",
        "starter_code": "\nfrom collections import Counter\n\ndef confusion_matrix(data):\n\t# Implement the function here\n\tpass\n",
        "title": "Generate a Confusion Matrix for Binary Classification",
        "learn_section": "\n## Generate Confusion Matrix\n\nThe confusion matrix is a very useful tool to get a better understanding of the performance of a classification model. In it, you can visualize how many data points were labeled according to their correct categories.\n\nFor a binary classification problem of a dataset with $ n $ observations, the confusion matrix is a $ 2 \\times 2 $ matrix with the following structure:\n\n$$\nM = \\begin{pmatrix} \nTP & FN \\\\\nFP & TN\n\\end{pmatrix}\n$$\n\nWhere:\n\n- **TP**: True positives, the number of observations from the positive label that were correctly labeled as positive.\n- **FN**: False negatives, the number of observations from the positive label that were incorrectly labeled as negative.\n- **FP**: False positives, the number of observations from the negative label that were incorrectly labeled as positive.\n- **TN**: True negatives, the number of observations from the negative label that were correctly labeled as negative.\n\nA confusion matrix is a great starting point for computing more advanced metrics such as precision and recall that capture the model's performance.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "id": "75"
    },
    {
        "video": "https://youtu.be/QMdvVDhc6f0?si=ST33rc73BjHY3pij",
        "description": "\n## Task: Implement Cosine Similarity\n\nIn this task, you need to implement a function `cosine_similarity(v1, v2)` that calculates the cosine similarity between two vectors. Cosine similarity measures the cosine of the angle between two vectors, indicating their directional similarity.\n\n### Input:\n- `v1` and `v2`: Numpy arrays representing the input vectors.\n\n### Output:\n- A float representing the cosine similarity, rounded to three decimal places.\n\n### Constraints:\n- Both input vectors must have the same shape.\n- Input vectors cannot be empty or have zero magnitude.\n",
        "example": {
            "input": "import numpy as np\n\nv1 = np.array([1, 2, 3])\nv2 = np.array([2, 4, 6])\nprint(cosine_similarity(v1, v2))",
            "output": "1.0",
            "reasoning": "The cosine similarity between v1 and v2 is 1.0, indicating perfect similarity."
        },
        "dislikes": 0,
        "test_cases": [
            {
                "test": "\nimport numpy as np\n\nv1 = np.array([1, 2, 3])\nv2 = np.array([2, 4, 6])\nprint(cosine_similarity(v1, v2))\n",
                "expected_output": "1.0"
            },
            {
                "test": "\nimport numpy as np\n\nv1 = np.array([1, 2, 3])\nv2 = np.array([-1, -2, -3])\nprint(cosine_similarity(v1, v2))\n",
                "expected_output": "-1.0"
            },
            {
                "test": "\nimport numpy as np\n\nv1 = np.array([1, 0, 7])\nv2 = np.array([0, 1, 3])\nprint(cosine_similarity(v1, v2))\n",
                "expected_output": "0.939"
            }
        ],
        "starter_code": "\nimport numpy as np\n\ndef cosine_similarity(v1, v2):\n\t# Implement your code here\n\tpass\n",
        "title": "Calculate Cosine Similarity Between Vectors",
        "learn_section": "\n## Cosine Similarity\n\nCosine similarity measures the cosine of the angle between two vectors. It doesn't consider the magnitude of the vectors but focuses on the angle between them.\n\n### Cosine Similarity Formula\n$$\n\\cos(\\theta) = \\frac{\\sum_{i=1}^{p} A_i B_i}{\\sqrt{\\sum_{i=1}^{p} A_i^2} \\sqrt{\\sum_{i=1}^{p} B_i^2}}\n$$\n\n### Implementation Steps for Cosine Similarity\n1. **Handle Input**: Ensure input vectors have the same dimensions and handle edge cases (e.g., zero vectors).\n2. **Dot Product**: Compute $\\sum_{i=1}^{p} A_i B_i $ for the two vectors.\n3. **Magnitudes**: Compute the L2 norms $ \\sqrt{\\sum_{i=1}^{p} A_i^2} $ and $ \\sqrt{\\sum_{i=1}^{p} B_i^2} $.\n4. **Final Result**: Divide the dot product by the product of the magnitudes.\n\n### Use Cases\n1. **Text and Image Similarity**\n2. **Recommendation Systems**\n3. **Query Matching**\n\n### Pitfalls\n1. **Magnitude Blindness**:\n   - Example:\n     - $ \\text{vector1} = (1, 1) $\n     - $ \\text{vector2} = (1000, 1000) $\n     - Cosine similarity $ = 1 $, despite the vastly different magnitudes.\n2. **Sparse Data Issues**:\n   - In high-dimensional spaces, where data is often sparse, cosine similarity may become less reliable.\n3. **Non-Negative Data Limitation**:\n   - If all values are positive, cosine similarity cannot capture negative relationships or inverse trends.\n\n",
        "solution": "\nimport numpy as np\n\ndef cosine_similarity(v1, v2):\n    if v1.shape != v2.shape:\n        raise ValueError(\"Arrays must have the same shape\")\n\n    if v1.size == 0:\n        raise ValueError(\"Arrays cannot be empty\")\n\n    # Flatten arrays in case of 2D\n    v1_flat = v1.flatten()\n    v2_flat = v2.flatten()\n\n    dot_product = np.dot(v1_flat, v2_flat)\n    magnitude1 = np.sqrt(np.sum(v1_flat**2))\n    magnitude2 = np.sqrt(np.sum(v2_flat**2))\n\n    if magnitude1 == 0 or magnitude2 == 0:\n        raise ValueError(\"Vectors cannot have zero magnitude\")\n\n    return round(dot_product / (magnitude1 * magnitude2), 3)\n",
        "contributor": [
            {
                "profile_link": "https://github.com/saitiger",
                "name": "saitiger"
            }
        ],
        "category": "Linear Algebra",
        "likes": 0,
        "difficulty": "easy",
        "id": "76"
    },
    {
        "description": "\n### Task: Implement Performance Metrics Calculation\n\nIn this task, you are required to implement a function `performance_metrics(actual, predicted)` that computes various performance metrics for a binary classification problem. These metrics include:\n\n- Confusion Matrix\n- Accuracy\n- F1 Score\n- Specificity\n- Negative Predictive Value\n\nThe function should take in two lists:\n\n- `actual`: The actual class labels (1 for positive, 0 for negative).\n- `predicted`: The predicted class labels from the model.\n\n### Output\n\nThe function should return a tuple containing:\n\n1. `confusion_matrix`: A 2x2 matrix.\n2. `accuracy`: A float representing the accuracy of the model.\n3. `f1_score`: A float representing the F1 score of the model.\n4. `specificity`: A float representing the specificity of the model.\n5. `negative_predictive_value`: A float representing the negative predictive value.\n\n### Constraints\n\n- All elements in the `actual` and `predicted` lists must be either 0 or 1.\n- Both lists must have the same length.\n",
        "id": "77",
        "test_cases": [
            {
                "test": "\nactual = [1, 0, 1, 0, 1]\npredicted = [1, 0, 0, 1, 1]\nprint(performance_metrics(actual, predicted))\n",
                "expected_output": "([[2, 1], [1, 1]], 0.6, 0.667, 0.5, 0.5)"
            },
            {
                "test": "actual = [1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]\npredicted = [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0]\nprint(performance_metrics(actual, predicted))",
                "expected_output": "([[6, 4], [2, 7]], 0.684, 0.667, 0.778, 0.636)"
            },
            {
                "test": "actual = [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0]\npredicted = [1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]\nprint(performance_metrics(actual, predicted))",
                "expected_output": "([[4, 4], [5, 2]], 0.4, 0.471, 0.286, 0.333)"
            }
        ],
        "difficulty": "medium",
        "solution": "\nfrom collections import Counter\n\ndef performance_metrics(actual: list[int], predicted: list[int]) -> tuple:\n    data = list(zip(actual, predicted))\n    counts = Counter(tuple(pair) for pair in data)\n    TP, FN, FP, TN = counts[(1, 1)], counts[(1, 0)], counts[(0, 1)], counts[(0, 0)]\n    confusion_matrix = [[TP, FN], [FP, TN]]\n    accuracy = (TP + TN) / (TP + TN + FP + FN)\n    precision = TP / (TP + FP)\n    recall = TP / (TP + FN)\n    f1 = 2 * precision * recall / (precision + recall)\n    negativePredictive = TN / (TN + FN)\n    specificity = TN / (TN + FP)\n    return confusion_matrix, round(accuracy, 3), round(f1, 3), round(specificity, 3), round(negativePredictive, 3)\n",
        "likes": 0,
        "video": "https://youtu.be/W9YoUBZApcA?si=I8FTWXfH3EugaZhc",
        "dislikes": 0,
        "example": {
            "input": "actual = [1, 0, 1, 0, 1]\npredicted = [1, 0, 0, 1, 1]\nprint(performance_metrics(actual, predicted))",
            "output": "([[2, 1], [1, 1]], 0.6, 0.667, 0.5, 0.5)",
            "reasoning": "The function calculates the confusion matrix, accuracy, F1 score, specificity, and negative predictive value based on the input labels. The resulting values are rounded to three decimal places as required."
        },
        "category": "Machine Learning",
        "starter_code": "\ndef performance_metrics(actual: list[int], predicted: list[int]) -> tuple:\n\t# Implement your code here\n\treturn confusion_matrix, round(accuracy, 3), round(f1, 3), round(specificity, 3), round(negativePredictive, 3)\n",
        "title": "Calculate Performance Metrics for a Classification Model",
        "learn_section": "\n## Performance Metrics\n\nPerformance metrics such as accuracy, F1 score, specificity, negative predictive value, precision, and recall are vital to understanding how a model is performing.\n\nHow many observations are correctly labeled? Are we mislabeling one category more than the other? Performance metrics can answer these questions and provide an idea of where to focus to improve a model's performance.\n\nFor this problem, starting with the confusion matrix is a helpful first step, as all the elements of the confusion matrix can help with calculating other performance metrics.\n\nFor a binary classification problem of a dataset with $n$ observations, the confusion matrix is a $2 \\times 2$ matrix with the following structure:\n\n$$\nM = \\begin{pmatrix} \nTP & FN \\\\\nFP & TN\n\\end{pmatrix}\n$$\n\nWhere:\n- **TP**: True positives, the number of observations from the positive label that were correctly labeled as positive.\n- **FN**: False negatives, the number of observations from the positive label that were incorrectly labeled as negative.\n- **FP**: False positives, the number of observations from the negative label that were incorrectly labeled as positive.\n- **TN**: True negatives, the number of observations from the negative label that were correctly labeled as negative.\n\n### Metrics\n\n#### Accuracy\nHow many observations are labeled as the actual category they belong to?\n\n$$\n\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n$$\n\n#### Precision\nHow many elements labeled as positive are actually positive?\n\n$$\n\\text{Precision} = \\frac{TP}{TP + FP}\n$$\n\n#### Negative Predictive Value\nHow many elements labeled as negative are actually negative?\n\n$$\n\\text{Negative Predictive Value} = \\frac{TN}{TN + FN}\n$$\n\n#### Recall\nOut of all positive elements, how many were correctly labeled?\n\n$$\n\\text{Recall} = \\frac{TP}{TP + FN}\n$$\n\n#### Specificity\nHow well are we labeling the negative elements correctly?\n\n$$\n\\text{Specificity} = \\frac{TN}{TN + FP}\n$$\n\n#### F1 Score\nHow to account for the trade-off of false negatives and positives? The F1 score is the harmonic mean of precision and recall.\n\n$$\n\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n$$\n",
        "contributor": [
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ]
    },
    {
        "description": "Write a Python function to calculate various descriptive statistics metrics for a given dataset. The function should take a list or NumPy array of numerical values and return a dictionary containing mean, median, mode, variance, standard deviation, percentiles (25th, 50th, 75th), and interquartile range (IQR).",
        "id": "78",
        "test_cases": [
            {
                "test": "print(descriptive_statistics([10, 20, 30, 40, 50]))",
                "expected_output": "{'mean': 30.0, 'median': 30.0, 'mode': 10, 'variance': 200.0, 'standard_deviation': 14.1421, '25th_percentile': 20.0, '50th_percentile': 30.0, '75th_percentile': 40.0, 'interquartile_range': 20.0}"
            },
            {
                "test": "print(descriptive_statistics([1, 2, 2, 3, 4, 4, 4, 5]))",
                "expected_output": "{'mean': 3.125, 'median': 3.5, 'mode': 4, 'variance': 1.6094, 'standard_deviation': 1.2686, '25th_percentile': 2.0, '50th_percentile': 3.5, '75th_percentile': 4.0, 'interquartile_range': 2.0}"
            },
            {
                "test": "print(descriptive_statistics([100]))",
                "expected_output": "{'mean': 100.0, 'median': 100.0, 'mode': 100, 'variance': 0.0, 'standard_deviation': 0.0, '25th_percentile': 100.0, '50th_percentile': 100.0, '75th_percentile': 100.0, 'interquartile_range': 0.0}"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef descriptive_statistics(data):\n    \"\"\"\n    Calculate various descriptive statistics metrics for a given dataset.\n    :param data: List or numpy array of numerical values\n    :return: Dictionary containing mean, median, mode, variance, standard deviation,\n             percentiles (25th, 50th, 75th), and interquartile range (IQR)\n    \"\"\"\n    # Ensure data is a numpy array for easier calculations\n    data = np.array(data)\n\n    # Mean\n    mean = np.mean(data)\n\n    # Median\n    median = np.median(data)\n\n    # Mode\n    unique, counts = np.unique(data, return_counts=True)\n    mode = unique[np.argmax(counts)] if len(data) > 0 else None\n\n    # Variance\n    variance = np.var(data)\n\n    # Standard Deviation\n    std_dev = np.sqrt(variance)\n\n    # Percentiles (25th, 50th, 75th)\n    percentiles = np.percentile(data, [25, 50, 75])\n\n    # Interquartile Range (IQR)\n    iqr = percentiles[2] - percentiles[0]\n\n    # Compile results into a dictionary\n    stats_dict = {\n        \"mean\": mean,\n        \"median\": median,\n        \"mode\": mode,\n        \"variance\": np.round(variance,4),\n        \"standard_deviation\": np.round(std_dev,4),\n        \"25th_percentile\": percentiles[0],\n        \"50th_percentile\": percentiles[1],\n        \"75th_percentile\": percentiles[2],\n        \"interquartile_range\": iqr\n    }\n\n    return stats_dict",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "[10, 20, 30, 40, 50]",
            "output": "{'mean': 30.0, 'median': 30.0, 'mode': 10, 'variance': 200.0, 'standard_deviation': 14.142135623730951, '25th_percentile': 20.0, '50th_percentile': 30.0, '75th_percentile': 40.0, 'interquartile_range': 20.0}",
            "reasoning": "The dataset is processed to calculate all descriptive statistics. The mean is the average value, the median is the central value, the mode is the most frequent value, and variance and standard deviation measure the spread of data. Percentiles and IQR describe data distribution."
        },
        "category": "Statistics",
        "starter_code": "import numpy as np \ndef descriptive_statistics(data):\n\t# Your code here\n\tstats_dict = {\n        \"mean\": mean,\n        \"median\": median,\n        \"mode\": mode,\n        \"variance\": np.round(variance,4),\n        \"standard_deviation\": np.round(std_dev,4),\n        \"25th_percentile\": percentiles[0],\n        \"50th_percentile\": percentiles[1],\n        \"75th_percentile\": percentiles[2],\n        \"interquartile_range\": iqr\n    }\n\treturn {}",
        "title": "Descriptive Statistics Calculator",
        "learn_section": "## Understanding Descriptive Statistics\n\nDescriptive statistics provide a summary of data through various measures and help understand the basic structure and distribution of data.\n\n### Key Metrics\n\nDescriptive statistics cover several key metrics, including mean, median, mode, variance, standard deviation, percentiles, quartiles, and interquartile range.\n\n- **Mean**: The average of all values in the dataset, calculated by summing all the values and dividing by the count of values.\n- **Median**: The middle value when the data is sorted. If there is an even number of values, the median is the average of the two middle values.\n- **Mode**: The value that occurs most frequently in the dataset.\n- **Variance**: A measure of how much the values in the dataset deviate from the mean, calculated as:\n  $$\n  \\text{Variance} = \\frac{\\sum (x_i - \\bar{x})^2}{N}\n  $$\n  where \\(x_i\\) are the data points, \\(\\bar{x}\\) is the mean, and \\(N\\) is the number of data points.\n- **Standard Deviation**: The square root of the variance, calculated as:\n  $$\n  \\text{Standard Deviation} = \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{N}}\n  $$\n- **Percentiles and Quartiles**: Percentiles divide the data into 100 equal parts, while quartiles divide the data into four equal parts. The 25th, 50th (median), and 75th percentiles are the common quartiles.\n- **Interquartile Range (IQR)**: The difference between the 75th and 25th percentiles, calculated as:\n  $$\n  \\text{IQR} = Q_3 - Q_1\n  $$\n  where \\(Q_3\\) is the 75th percentile and \\(Q_1\\) is the 25th percentile.\n\n### Example Calculation\n\nGiven data:\n\nData set: \\([12, 15, 12, 18, 19, 17, 15, 14, 16, 18]\\)\n\n- **Mean**:\n  $$\n  \\text{Mean} = \\frac{\\sum x_i}{N} = \\frac{156}{10} = 15.6\n  $$\n- **Median**:\n  $$\n  \\text{Median} = 15.5\n  $$\n- **Mode**:\n  $$\n  \\text{Mode} = 12, 15, 18\n  $$\n- **Variance**:\n  $$\n  \\text{Variance} = \\frac{\\sum (x_i - 15.6)^2}{9} \\approx 6.93\n  $$\n- **Standard Deviation**:\n  $$\n  \\text{Standard Deviation} = \\sqrt{6.93} \\approx 2.63\n  $$\n- **Percentiles**:\n  $$\n  25\\% \\text{ Percentile} = 13.5, \\quad 50\\% \\text{ Percentile} = 15.5 ,\\quad 75\\% \\text{ Percentile} = 17.5\n  $$\n- **Interquartile Range**:\n  $$\n  \\text{IQR} = 17.5 - 13.5 = 4\n  $$\n\n### Applications\n\nDescriptive statistics are widely used in:\n\n- Data Analysis\n- Exploratory Data Analysis (EDA)\n- Understanding Data Distributions\n- Feature Engineering\n- Identifying Outliers\n\nThese metrics are foundational in data science, helping to interpret data and prepare it for further analysis in machine learning.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/BhardwajArjit",
                "name": "Arjit Bhardwaj"
            }
        ]
    },
    {
        "description": "Write a Python function to calculate the probability of achieving exactly k successes in n independent Bernoulli trials, each with probability p of success, using the Binomial distribution formula.",
        "id": "79",
        "test_cases": [
            {
                "test": "print(binomial_probability(6, 2, 0.5))",
                "expected_output": "0.23438"
            },
            {
                "test": "print(binomial_probability(6, 4, 0.7))",
                "expected_output": "0.32414"
            },
            {
                "test": "print(binomial_probability(3, 3, 0.9))",
                "expected_output": "0.729"
            },
            {
                "test": "print(binomial_probability(5, 0, 0.3))",
                "expected_output": "0.16807"
            },
            {
                "test": "print(binomial_probability(7, 2, 0.1))",
                "expected_output": "0.124"
            }
        ],
        "difficulty": "medium",
        "solution": "import math\n\ndef binomial_probability(n, k, p):\n    \"\"\"\n    Calculate the probability of achieving exactly k successes in n independent Bernoulli trials,\n    each with probability p of success, using the Binomial distribution formula.\n    :param n: Total number of trials\n    :param k: Number of successes\n    :param p: Probability of success on each trial\n    :return: Probability of k successes in n trials\n    \"\"\"\n    # Calculate binomial coefficient (n choose k)\n    binomial_coeff = math.comb(n, k)\n    # Calculate the probability using the binomial formula\n    probability = binomial_coeff * (p ** k) * ((1 - p) ** (n - k))\n    # Return the probability, rounded to five decimal places\n    return round(probability, 5)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "n = 6, k = 2, p = 0.5",
            "output": "0.23438",
            "reasoning": "The function calculates the Binomial probability, the intermediate steps include calculating the binomial coefficient, raising p and (1-p) to the appropriate powers, and multiplying the results."
        },
        "category": "Probability",
        "starter_code": "import math\n\ndef binomial_probability(n, k, p):\n\t\"\"\"\n    Calculate the probability of achieving exactly k successes in n independent Bernoulli trials,\n    each with probability p of success, using the Binomial distribution formula.\n    \"\"\"\n\t# Your code here\n\treturn round(probability, 5)",
        "learn_section": "## Understanding the Binomial Distribution\n\nThe Binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success.\n\n### Mathematical Formulation\n\nThe probability of achieving exactly $k$ successes in $n$ trials is given by the formula:\n\n$$\nP(X = k) = \\binom{n}{k} \\cdot p^k \\cdot (1-p)^{n-k}\n$$\n\n- **$n$**: Total number of trials  \n- **$k$**: Number of successes  \n- **$p$**: Probability of success on each trial  \n- $\\binom{n}{k}$: The number of ways to choose $k$ successes from $n$ trials, calculated as:\n\n$$\n\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n$$\n\n### Implementation Steps\n\n1. Calculate $\\binom{n}{k}$ using factorials.  \n2. Raise $p$ to the power of $k$ and $(1-p)$ to the power of $(n-k)$.  \n3. Multiply these results to get the probability.\n\n### Example Calculation\n\nGiven:\n\n- $n = 5$  \n- $k = 2$  \n- $p = 0.4$  \n\nStep-by-step:\n\n1. Calculate $\\binom{n}{k}$:\n\n$$\n\\binom{5}{2} = \\frac{5!}{2!(5-2)!} = \\frac{5 \\cdot 4}{2 \\cdot 1} = 10\n$$\n\n2. Calculate $p^k \\cdot (1-p)^{n-k}$:\n\n$$\n0.4^2 \\cdot (1-0.4)^3 = 0.16 \\cdot 0.216 = 0.03456\n$$\n\n3. Multiply results:\n\n$$\nP(X = 2) = 10 \\cdot 0.03456 = 0.3456\n$$\n\nThe probability of exactly 2 successes is $0.3456$.\n\n### Applications\n\nThe Binomial distribution is widely used in:\n\n- Quality control and defect analysis  \n- Survey analysis  \n- Medical trials  \n- Modeling success/failure experiments  \n\nIt provides insights into the likelihood of various outcomes in scenarios with two possible results (e.g., success or failure).\n",
        "title": "Binomial Distribution Probability",
        "contributor": [
            {
                "profile_link": "https://github.com/BhardwajArjit",
                "name": "Arjit Bhardwaj"
            }
        ]
    },
    {
        "description": "Write a Python function that calculates the inverse of a 2x2 matrix. Return 'None' if the matrix is not invertible.",
        "mdx_file": "ed6c921e-d77d-4e74-a02e-47626e690722.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGludmVyc2VfMngyX3RnKG1hdHJpeCkgLT4gVGVuc29yIHwgTm9uZToKICAgICIiIgogICAgQ29tcHV0ZSBpbnZlcnNlIG9mIGEgMsOXMiBtYXRyaXggdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dCBjYW4gYmUgUHl0aG9uIGxpc3QsIE51bVB5IGFycmF5LCBvciB0aW55Z3JhZCBUZW5zb3IuCiAgICBSZXR1cm5zIGEgMsOXMiBUZW5zb3Igb3IgTm9uZSBpZiB0aGUgbWF0cml4IGlzIHNpbmd1bGFyLgogICAgIiIiCiAgICBtID0gVGVuc29yKG1hdHJpeCkuZmxvYXQoKQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "test_cases": [
            {
                "test": "print(inverse_2x2([[4, 7], [2, 6]]))",
                "expected_output": "[[0.6, -0.7], [-0.2, 0.4]]"
            },
            {
                "test": "print(inverse_2x2([[2, 1], [6, 2]]))",
                "expected_output": "[[-1.0, 0.5], [3.0, -1.0]]"
            }
        ],
        "solution": "def inverse_2x2(matrix: list[list[float]]) -> list[list[float]]:\n    a, b, c, d = matrix[0][0], matrix[0][1], matrix[1][0], matrix[1][1]\n    determinant = a * d - b * c\n    if determinant == 0:\n        return None\n    inverse = [[d/determinant, -b/determinant], [-c/determinant, a/determinant]]\n    return inverse",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIGludmVyc2VfMngyX3RnKG1hdHJpeCkgLT4gVGVuc29yIHwgTm9uZToKICAgICIiIgogICAgQ29tcHV0ZSBpbnZlcnNlIG9mIGEgMsOXMiBtYXRyaXggdXNpbmcgdGlueWdyYWQuCiAgICBJbnB1dCBjYW4gYmUgUHl0aG9uIGxpc3QsIE51bVB5IGFycmF5LCBvciB0aW55Z3JhZCBUZW5zb3IuCiAgICBSZXR1cm5zIGEgMsOXMiBUZW5zb3Igb3IgTm9uZSBpZiB0aGUgbWF0cml4IGlzIHNpbmd1bGFyLgogICAgIiIiCiAgICBtID0gVGVuc29yKG1hdHJpeCkuZmxvYXQoKQogICAgYSwgYiA9IG1bMCwwXSwgbVswLDFdCiAgICBjLCBkID0gbVsxLDBdLCBtWzEsMV0KICAgIGRldCA9IGEgKiBkIC0gYiAqIGMKICAgIGlmIGRldC5udW1weSgpID09IDA6CiAgICAgICAgcmV0dXJuIE5vbmUKICAgIGludiA9IFRlbnNvcihbWyBkLCAtYl0sIFstYywgIGFdXSkgLyBkZXQKICAgIHJldHVybiBpbnYK",
        "pytorch_difficulty": "easy",
        "likes": "0",
        "video": "https://youtu.be/-fhFySMHPZk",
        "difficulty": "medium",
        "example": {
            "input": "matrix = [[4, 7], [2, 6]]",
            "output": "[[0.6, -0.7], [-0.2, 0.4]]",
            "reasoning": "The inverse of a 2x2 matrix [a, b], [c, d] is given by (1/(ad-bc)) * [d, -b], [-c, a], provided ad-bc is not zero."
        },
        "dislikes": "0",
        "category": "Linear Algebra",
        "starter_code": "def inverse_2x2(matrix: list[list[float]]) -> list[list[float]]:\n\treturn inverse",
        "learn_section": "\n## Calculating the Inverse of a 2x2 Matrix\n\nThe inverse of a matrix \\( A \\) is another matrix, often denoted \\( A^{-1} \\), such that:\n$$\nAA^{-1} = A^{-1}A = I\n$$\nwhere \\( I \\) is the identity matrix. For a 2x2 matrix:\n$$\nA = \\begin{pmatrix} \na & b \\\\ \nc & d \n\\end{pmatrix}\n$$\n\nThe inverse is given by:\n$$\nA^{-1} = \\frac{1}{\\det(A)} \\begin{pmatrix} \nd & -b \\\\ \n-c & a \n\\end{pmatrix}\n$$\n\nprovided that the determinant \\( \\det(A) = ad - bc \\) is non-zero. If \\( \\det(A) = 0 \\), the matrix does not have an inverse.\n\n### Importance\nCalculating the inverse of a matrix is essential in various applications, such as solving systems of linear equations, where the inverse is used to find solutions efficiently.\n",
        "title": "Calculate 2x2 Matrix Inverse",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            },
            {
                "profile_link": "https://www.youtube.com/@StoatScript/videos",
                "name": "StoatScript"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = inverse_2x2(torch.tensor([[1.0, 0.0], [0.0, 1.0]]))\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 1.0]]"
            },
            {
                "test": "import torch\nres = inverse_2x2(torch.tensor([[1.0, 2.0], [3.0, 4.0]]))\nprint(res.numpy().tolist())",
                "expected_output": "[[-2.0, 1.0], [1.5, -0.5]]"
            },
            {
                "test": "import torch\nres = inverse_2x2(torch.tensor([[1.0, 2.0], [2.0, 4.0]]))\nprint(res)",
                "expected_output": "None"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = inverse_2x2_tg([[1.0, 0.0], [0.0, 1.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 0.0], [0.0, 1.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = inverse_2x2_tg([[1.0, 2.0], [3.0, 4.0]])\nprint(res.numpy().tolist())",
                "expected_output": "[[-2.0, 1.0], [1.5, -0.5]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = inverse_2x2_tg([[1.0, 2.0], [2.0, 4.0]])\nprint(res)",
                "expected_output": "None"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgaW52ZXJzZV8yeDIobWF0cml4KSAtPiB0b3JjaC5UZW5zb3IgfCBOb25lOgogICAgIiIiCiAgICBDb21wdXRlIGludmVyc2Ugb2YgYSAyw5cyIG1hdHJpeCB1c2luZyBQeVRvcmNoLgogICAgSW5wdXQgY2FuIGJlIFB5dGhvbiBsaXN0LCBOdW1QeSBhcnJheSwgb3IgdG9yY2ggVGVuc29yLgogICAgUmV0dXJucyBhIDLDlzIgdGVuc29yIG9yIE5vbmUgaWYgdGhlIG1hdHJpeCBpcyBzaW5ndWxhci4KICAgICIiIgogICAgbSA9IHRvcmNoLmFzX3RlbnNvcihtYXRyaXgsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgYSwgYiA9IG1bMCwwXSwgbVswLDFdCiAgICBjLCBkID0gbVsxLDBdLCBtWzEsMV0KICAgIGRldCA9IGEgKiBkIC0gYiAqIGMKICAgIGlmIGRldCA9PSAwOgogICAgICAgIHJldHVybiBOb25lCiAgICBpbnYgPSB0b3JjaC5zdGFjayhbCiAgICAgICAgdG9yY2guc3RhY2soWyBkL2RldCwgLWIvZGV0XSksCiAgICAgICAgdG9yY2guc3RhY2soWy1jL2RldCwgIGEvZGV0XSkKICAgIF0pCiAgICByZXR1cm4gaW52Cg==",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgaW52ZXJzZV8yeDIobWF0cml4KSAtPiB0b3JjaC5UZW5zb3IgfCBOb25lOgogICAgIiIiCiAgICBDb21wdXRlIGludmVyc2Ugb2YgYSAyw5cyIG1hdHJpeCB1c2luZyBQeVRvcmNoLgogICAgSW5wdXQgY2FuIGJlIFB5dGhvbiBsaXN0LCBOdW1QeSBhcnJheSwgb3IgdG9yY2ggVGVuc29yLgogICAgUmV0dXJucyBhIDLDlzIgdGVuc29yIG9yIE5vbmUgaWYgdGhlIG1hdHJpeCBpcyBzaW5ndWxhci4KICAgICIiIgogICAgbSA9IHRvcmNoLmFzX3RlbnNvcihtYXRyaXgsIGR0eXBlPXRvcmNoLmZsb2F0KQogICAgIyBZb3VyIGltcGxlbWVudGF0aW9uIGhlcmUKICAgIHBhc3MK",
        "id": "8"
    },
    {
        "description": "Write a Python function to calculate the probability density function (PDF) of the normal distribution for a given value, mean, and standard deviation. The function should use the mathematical formula of the normal distribution to return the PDF value rounded to 5 decimal places.",
        "id": "80",
        "test_cases": [
            {
                "test": "print(normal_pdf(0, 0, 1))",
                "expected_output": "0.39894"
            },
            {
                "test": "print(normal_pdf(16, 15, 2.04))",
                "expected_output": "0.17342"
            },
            {
                "test": "print(normal_pdf(1, 0, 0.5))",
                "expected_output": "0.10798"
            }
        ],
        "difficulty": "medium",
        "solution": "import math\n\ndef normal_pdf(x, mean, std_dev):\n    \"\"\"\n    Calculate the probability density function (PDF) of the normal distribution.\n    :param x: The value at which the PDF is evaluated.\n    :param mean: The mean (μ) of the distribution.\n    :param std_dev: The standard deviation (σ) of the distribution.\n    :return: The PDF value for the given x.\n    \"\"\"\n    coefficient = 1 / (math.sqrt(2 * math.pi) * std_dev)\n    exponent = math.exp(-((x - mean) ** 2) / (2 * std_dev ** 2))\n    return round(coefficient * exponent, 5)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "x = 16, mean = 15, std_dev = 2.04",
            "output": "0.17342",
            "reasoning": "The function computes the PDF using x = 16, mean = 15, and std_dev = 2.04."
        },
        "category": "Probability",
        "starter_code": "import math\n\ndef normal_pdf(x, mean, std_dev):\n\t\"\"\"\n\tCalculate the probability density function (PDF) of the normal distribution.\n\t:param x: The value at which the PDF is evaluated.\n\t:param mean: The mean (μ) of the distribution.\n\t:param std_dev: The standard deviation (σ) of the distribution.\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,5)",
        "title": "Normal Distribution PDF Calculator",
        "learn_section": "## Understanding Normal Distribution\n\nThe Normal Distribution, also known as the Gaussian Distribution, is a continuous probability distribution that is symmetrical and bell-shaped, representing the distribution of data around the mean.\n\n### Key Characteristics\n\n- **Symmetry**: The distribution is symmetric around the mean, which means the left and right halves of the graph are mirror images.\n- **Mean, Median, and Mode**: In a perfectly normal distribution, the mean, median, and mode are all equal.\n- **Shape**: The bell-shaped curve is defined by its mean ($\\mu$) and standard deviation ($\\sigma$).\n- **Empirical Rule**: Approximately:\n  - $68\\%$ of data falls within 1 standard deviation ($\\mu \\pm \\sigma$).\n  - $95\\%$ of data falls within 2 standard deviations ($\\mu \\pm 2\\sigma$).\n  - $99.7\\%$ of data falls within 3 standard deviations ($\\mu \\pm 3\\sigma$).\n\n### Mathematical Formula\n\nThe probability density function (PDF) of a normal distribution is given by:\n\n$$\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n$$\n\n- **$x$**: Random variable\n- **$\\mu$**: Mean of the distribution\n- **$\\sigma$**: Standard deviation of the distribution\n\n### Implementation Steps\n\n1. **Calculate the mean ($\\mu$) and standard deviation ($\\sigma$):**\n   - $\\mu = \\frac{\\sum x_i}{N}$\n   - $\\sigma = \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{N}}$\n\n2. **Use the normal distribution formula to calculate the probability density for each value:**\n   - $\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n\n3. **Visualize the curve**:\n   - Plot the calculated PDF values for a range of $x$ to visualize the bell-shaped curve.\n\n### Example Calculation\n\nGiven:\n\n- Data: [10, 12, 14, 16, 18, 20]\n\n1. **Mean ($\\mu$):**\n   $$\n   \\mu = \\frac{10 + 12 + 14 + 16 + 18 + 20}{6} = 15\n   $$\n\n2. **Standard Deviation ($\\sigma$):**\n   $$\n   \\sigma = \\sqrt{\\frac{(10-15)^2 + \\dots + (20-15)^2}{6}} = \\sqrt{\\frac{25}{6}} \\approx 2.04\n   $$\n\n3. **PDF for $x = 16$:**\n   $$\n   f(16) = \\frac{1}{\\sqrt{2\\pi(2.04)^2}} e^{-\\frac{(16-15)^2}{2(2.04)^2}} \\approx 0.176\n   $$\n\n### Applications\n\nThe Normal Distribution is widely used in:\n\n- Data Analysis\n- Statistical Inference\n- Machine Learning Algorithms\n- Quality Control\n- Risk Management\n\nThis distribution is crucial in fields like economics, biology, psychology, and engineering to model natural phenomena and make predictions.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/BhardwajArjit",
                "name": "Arjit Bhardwaj"
            }
        ]
    },
    {
        "description": "Write a Python function to calculate the probability of observing exactly k events in a fixed interval using the Poisson distribution formula. The function should take k (number of events) and lam (mean rate of occurrences) as inputs and return the probability rounded to 5 decimal places.",
        "id": "81",
        "test_cases": [
            {
                "test": "print(poisson_probability(3, 5))",
                "expected_output": "0.14037"
            },
            {
                "test": "print(poisson_probability(0, 5))",
                "expected_output": "0.00674"
            },
            {
                "test": "print(poisson_probability(2, 10))",
                "expected_output": "0.00227"
            },
            {
                "test": "print(poisson_probability(1, 1))",
                "expected_output": "0.36788"
            },
            {
                "test": "print(poisson_probability(20, 20))",
                "expected_output": "0.08884"
            }
        ],
        "difficulty": "easy",
        "solution": "import math\n\ndef poisson_probability(k, lam):\n    \"\"\"\n    Calculate the probability of observing exactly k events in a fixed interval,\n    given the mean rate of events lam, using the Poisson distribution formula.\n    :param k: Number of events (non-negative integer)\n    :param lam: The average rate (mean) of occurrences in a fixed interval\n    :return: Probability of k events occurring\n    \"\"\"\n    # Calculate the Poisson probability using the formula\n    probability = (lam ** k) * math.exp(-lam) / math.factorial(k)\n    # Return the probability, rounded to five decimal places\n    return round(probability, 5)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "k = 3, lam = 5",
            "output": "0.14037",
            "reasoning": "The function calculates the probability for a given number of events occurring in a fixed interval, based on the mean rate of occurrences."
        },
        "category": "Probability",
        "starter_code": "import math\n\ndef poisson_probability(k, lam):\n\t\"\"\"\n\tCalculate the probability of observing exactly k events in a fixed interval,\n\tgiven the mean rate of events lam, using the Poisson distribution formula.\n\t:param k: Number of events (non-negative integer)\n\t:param lam: The average rate (mean) of occurrences in a fixed interval\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,5)",
        "title": "Poisson Distribution Probability Calculator",
        "learn_section": "## Understanding Poisson Distribution\n\nThe Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space, provided these events occur with a known constant mean rate and independently of the time since the last event.\n\n### Mathematical Definition\n\nThe probability of observing \\( k \\) events in a given interval is defined as:\n\n$$\nP(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n$$\n\n- **\\( k \\)**: Number of events (non-negative integer)\n- **\\( \\lambda \\)**: The mean number of events in the given interval (rate parameter)\n- **\\( e \\)**: Euler's number, approximately 2.718\n\n### Key Properties\n\n- **Mean**: \\( \\lambda \\)\n- **Variance**: \\( \\lambda \\)\n- The Poisson distribution is used for modeling rare or random events.\n\n### Example Calculation\n\nSuppose the mean number of calls received in an hour (\\( \\lambda \\)) is 5. Calculate the probability of receiving exactly 3 calls in an hour:\n\n1. **Substitute into the formula**:\n   $$\n   P(3; 5) = \\frac{5^3 e^{-5}}{3!}\n   $$\n\n2. **Calculate step-by-step**:\n   $$\n   P(3; 5) = \\frac{125 \\cdot e^{-5}}{6} \\approx 0.14037\n   $$\n\n### Applications\n\nThe Poisson distribution is widely used in:\n\n- Modeling the number of arrivals at a queue (e.g., calls at a call center)\n- Counting occurrences over time (e.g., number of emails received per hour)\n- Biology (e.g., distribution of mutations in a DNA strand)\n- Traffic flow analysis (e.g., number of cars passing through an intersection)\n\nThis distribution is essential for understanding and predicting rare events in real-world scenarios.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/BhardwajArjit",
                "name": "Arjit Bhardwaj"
            }
        ]
    },
    {
        "description": "Write a Python function to calculate the contrast of a grayscale image using the difference between the maximum and minimum pixel values.",
        "id": "82",
        "test_cases": [
            {
                "test": "print(calculate_contrast(np.array([[0, 50], [200, 255]])))",
                "expected_output": "255"
            },
            {
                "test": "print(calculate_contrast(np.array([[128, 128], [128, 128]])))",
                "expected_output": "0"
            },
            {
                "test": "print(calculate_contrast(np.zeros((10, 10), dtype=np.uint8)))",
                "expected_output": "0"
            },
            {
                "test": "print(calculate_contrast(np.ones((10, 10), dtype=np.uint8) * 255))",
                "expected_output": "0"
            },
            {
                "test": "print(calculate_contrast(np.array([[10, 20, 30], [40, 50, 60]])))",
                "expected_output": "50"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef calculate_contrast(img):\n    \"\"\"\n    Calculate the contrast of a grayscale image.\n    Args:\n        img (numpy.ndarray): 2D array representing a grayscale image with pixel values between 0 and 255.\n    Returns:\n        float: Contrast value rounded to 3 decimal places.\n    \"\"\"\n    # Find the maximum and minimum pixel values\n    max_pixel = np.max(img)\n    min_pixel = np.min(img)\n\n    # Calculate contrast\n    contrast = max_pixel - min_pixel\n\n    return round(float(contrast), 3)",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-82",
        "likes": "0",
        "video": "https://youtu.be/-IW2yzulQqI?si=gbdhQ5pRkwuDzaDB",
        "dislikes": "0",
        "example": {
            "input": "img = np.array([[0, 50], [200, 255]])",
            "output": "255",
            "reasoning": "The function calculates contrast by finding the difference between the maximum (255) and minimum (0) pixel values in the image, resulting in a contrast of 255."
        },
        "category": "Computer Vision",
        "starter_code": "import numpy as np\n\ndef calculate_contrast(img) -> int:\n\t\"\"\"\n\tCalculate the contrast of a grayscale image.\n\tArgs:\n\t\timg (numpy.ndarray): 2D array representing a grayscale image with pixel values between 0 and 255.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Grayscale Image Contrast Calculator",
        "learn_section": "## Calculating Contrast of a Grayscale Image\n\nContrast in a grayscale image refers to the difference in luminance or color that makes an object distinguishable. Here are methods to calculate contrast:\n\n### 1. Basic Contrast Calculation\n\nThe simplest way to define the contrast of a grayscale image is by using the difference between the maximum and minimum pixel values:\n\n$$\n\\text{Contrast} = \\max(I) - \\min(I)\n$$\n\n### 2. RMS Contrast\n\nRoot Mean Square (RMS) contrast considers the standard deviation of pixel intensities:\n\n$$\n\\text{RMS Contrast} = \\frac{\\sigma}{\\mu}\n$$\n\n### 3. Michelson Contrast\n\nMichelson contrast is defined as:\n\n$$\nC = \\frac{I_{\\text{max}} - I_{\\text{min}}}{I_{\\text{max}} + I_{\\text{min}}}\n$$\n\n### Example Calculation\n\nFor a grayscale image with pixel values ranging from 50 to 200:\n\n1. **Maximum Pixel Value**: 200  \n2. **Minimum Pixel Value**: 50  \n3. **Contrast Calculation**:\n\n$$\n\\text{Contrast} = 200 - 50 = 150\n$$\n\n### Applications\n\nCalculating contrast is crucial in:\n\n- Image quality assessment\n- Preprocessing in computer vision\n- Enhancing visibility in images\n- Object detection and analysis\n",
        "contributor": [
            {
                "profile_link": "https://github.com/rittik9",
                "name": "rittik9"
            }
        ]
    },
    {
        "description": "Write a Python function to calculate the dot product of two vectors. The function should take two 1D NumPy arrays as input and return the dot product as a single number.",
        "id": "83",
        "test_cases": [
            {
                "test": "print(calculate_dot_product(np.array([1, 2, 3]), np.array([4, 5, 6])))",
                "expected_output": "32"
            },
            {
                "test": "print(calculate_dot_product(np.array([-1, 2, 3]), np.array([4, -5, 6])))",
                "expected_output": "4"
            },
            {
                "test": "print(calculate_dot_product(np.array([1, 0]), np.array([0, 1])))",
                "expected_output": "0"
            },
            {
                "test": "print(calculate_dot_product(np.array([0, 0, 0]), np.array([0, 0, 0])))",
                "expected_output": "0"
            },
            {
                "test": "print(calculate_dot_product(np.array([7]), np.array([3])))",
                "expected_output": "21"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef calculate_dot_product(vec1, vec2):\n    \"\"\"\n    Calculate the dot product of two vectors.\n    Args:\n        vec1 (numpy.ndarray): 1D array representing the first vector.\n        vec2 (numpy.ndarray): 1D array representing the second vector.\n    Returns:\n        float: Dot product of the two vectors.\n    \"\"\"\n    return np.dot(vec1, vec2)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "vec1 = np.array([1, 2, 3]), vec2 = np.array([4, 5, 6])",
            "output": "32",
            "reasoning": "The function calculates the dot product by multiplying corresponding elements of the two vectors and summing the results. For vec1 = [1, 2, 3] and vec2 = [4, 5, 6], the result is (1 * 4) + (2 * 5) + (3 * 6) = 32."
        },
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef calculate_dot_product(vec1, vec2) -> float:\n\t\"\"\"\n\tCalculate the dot product of two vectors.\n\tArgs:\n\t\tvec1 (numpy.ndarray): 1D array representing the first vector.\n\t\tvec2 (numpy.ndarray): 1D array representing the second vector.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Dot Product Calculator",
        "learn_section": "## Calculating the Dot Product of Two Vectors\n\nThe dot product, also known as the scalar product, is a mathematical operation that takes two equal-length vectors and returns a single number. It is widely used in physics, geometry, and linear algebra.\n\n### 1. Formula for the Dot Product\n\nThe dot product of two vectors $\\mathbf{a}$ and $\\mathbf{b}$, each of length $n$, is calculated as follows:\n\n$$\n\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_i b_i\n$$\n\nThis means multiplying corresponding elements of the two vectors and summing up the results.\n\n### 2. Geometric Interpretation\n\nIn geometric terms, the dot product can also be expressed as:\n\n$$\n\\mathbf{a} \\cdot \\mathbf{b} = |\\mathbf{a}| |\\mathbf{b}| \\cos \\theta\n$$\n\nWhere:\n\n- $|\\mathbf{a}|$ and $|\\mathbf{b}|$ are the magnitudes of the vectors.\n- $\\theta$ is the angle between the two vectors.\n\n### 3. Properties of the Dot Product\n\n1. **Commutative**:  \n   $$\n   \\mathbf{a} \\cdot \\mathbf{b} = \\mathbf{b} \\cdot \\mathbf{a}\n   $$\n\n2. **Distributive**:  \n   $$\n   \\mathbf{a} \\cdot (\\mathbf{b} + \\mathbf{c}) = \\mathbf{a} \\cdot \\mathbf{b} + \\mathbf{a} \\cdot \\mathbf{c}\n   $$\n\n3. **Orthogonal Vectors**:  \n   If:  \n   $$\n   \\mathbf{a} \\cdot \\mathbf{b} = 0\n   $$  \n   Then $\\mathbf{a}$ and $\\mathbf{b}$ are perpendicular.\n\n### 4. Example Calculation\n\nGiven two vectors:\n\n- $\\mathbf{a} = [1, 2, 3]$\n- $\\mathbf{b} = [4, 5, 6]$\n\nThe dot product is calculated as:\n\n$$\n\\mathbf{a} \\cdot \\mathbf{b} = (1 \\cdot 4) + (2 \\cdot 5) + (3 \\cdot 6) = 4 + 10 + 18 = 32\n$$\n\n### Conclusion\n\nThe dot product is a fundamental operation in vector algebra, useful in determining angles between vectors, projections, and in many applications across physics and engineering.\n\n",
        "contributor": [
            {
                "profile_link": "https://github.com/rittik9",
                "name": "rittik9"
            }
        ]
    },
    {
        "description": "Write a Python function to perform a Phi Transformation that maps input features into a higher-dimensional space by generating polynomial features. The transformation allows models like linear regression to fit nonlinear data by introducing new feature dimensions that represent polynomial combinations of the original input features. The function should take a list of numerical data and a degree as inputs, and return a nested list where each inner list represents the transformed features of a data point. If the degree is less than 0, the function should return an empty list.",
        "id": "84",
        "test_cases": [
            {
                "test": "print(phi_transform([], 2))",
                "expected_output": "[]"
            },
            {
                "test": "print(phi_transform([1.0, 2.0], -1))",
                "expected_output": "[]"
            },
            {
                "test": "print(phi_transform([1.0, 2.0], 2))",
                "expected_output": "[[1.0, 1.0, 1.0], [1.0, 2.0, 4.0]]"
            },
            {
                "test": "print(phi_transform([1.0, 3.0], 3))",
                "expected_output": "[[1.0, 1.0, 1.0, 1.0], [1.0, 3.0, 9.0, 27.0]]"
            },
            {
                "test": "print(phi_transform([2.0], 4))",
                "expected_output": "[[1.0, 2.0, 4.0, 8.0, 16.0]]"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef phi_transform(data: list[float], degree: int) -> list[list[float]]:\n\t\"\"\"\n\tPerform a Phi Transformation to map input features into a higher-dimensional space by generating polynomial features.\n\n\tArgs:\n\t\tdata (list[float]): A list of numerical values to transform.\n\t\tdegree (int): The degree of the polynomial expansion.\n\n\tReturns:\n\t\tlist[list[float]]: A nested list where each inner list represents the transformed features of a data point.\n\t\"\"\"\n\tif degree < 0 or not data:\n\t\treturn []\n\treturn np.array([[x ** i for i in range(degree + 1)] for x in data]).tolist()",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "data = [1.0, 2.0], degree = 2",
            "output": "[[1.0, 1.0, 1.0], [1.0, 2.0, 4.0]]",
            "reasoning": "The Phi Transformation generates polynomial features for each data point up to the specified degree. For data = [1.0, 2.0] and degree = 2, the transformation creates a nested list where each row contains powers of the data point from 0 to 2."
        },
        "category": "Linear Algebra",
        "starter_code": "import numpy as np\n\ndef phi_transform(data: list[float], degree: int) -> list[list[float]]:\n\t\"\"\"\n\tPerform a Phi Transformation to map input features into a higher-dimensional space by generating polynomial features.\n\n\tArgs:\n\t\tdata (list[float]): A list of numerical values to transform.\n\t\tdegree (int): The degree of the polynomial expansion.\n\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Phi Transformation for Polynomial Features",
        "learn_section": "## Phi Transformation\n\nThe Phi Transformation maps input features into a higher-dimensional space by generating polynomial features. This allows models like linear regression to fit nonlinear data by introducing new feature dimensions that represent polynomial combinations of the original input features.\n\n### Why Use Phi Transformation?\n\n- To increase the expressive power of simple models such as linear models.\n- To enable better fitting of nonlinear relationships in the data.\n\n### Equations\n\nFor an input value $x$, the Phi Transformation expands it as:\n\n$$\n\\Phi(x) = [1, x, x^2, x^3, \\dots, x^d]\n$$\n\nWhere $d$ is the specified degree, and $\\Phi(x)$ represents the transformed feature vector.\n\n### Example 1: Polynomial Expansion for One Value\n\nGiven $x = 3$ and $d = 3$, the Phi Transformation is:\n\n$$\n\\Phi(3) = [1, 3, 9, 27]\n$$\n\n### Example 2: Transformation for Multiple Values\n\nFor $\\text{data} = [1, 2]$ and $d = 2$, the Phi Transformation is:\n\n$$\n\\Phi([1, 2]) = \\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 2 & 4 \\end{bmatrix}\n$$\n",
        "contributor": [
            {
                "profile_link": "https://github.com/changyy06",
                "name": "changyy06"
            }
        ]
    },
    {
        "description": "Write a Python function to implement the Positional Encoding layer for Transformers.\n      The function should calculate positional encodings for a sequence length (`position`) and model dimensionality (`d_model`) using sine and cosine functions as specified in the Transformer architecture.\n      The function should return -1 if `position` is 0, or if `d_model` is less than or equal to 0. The output should be a numpy array of type `float16`.",
        "id": "85",
        "test_cases": [
            {
                "test": "print(pos_encoding(2, 8))",
                "expected_output": "[[0.     , 1.     , 0.     , 1.     , 0.     , 1.     , 0.     ,\n        1.     ],\n       [0.8413 , 0.5405 , 0.09985, 0.995  , 0.01   , 1.     , 0.001  ,\n        1.     ]]"
            },
            {
                "test": "print(pos_encoding(5, 16))",
                "expected_output": "[[ 0.000e+00,  1.000e+00,  0.000e+00,  1.000e+00,  0.000e+00,\n         1.000e+00,  0.000e+00,  1.000e+00,  0.000e+00,  1.000e+00,\n         0.000e+00,  1.000e+00,  0.000e+00,  1.000e+00,  0.000e+00,\n         1.000e+00],\n       [ 8.413e-01,  5.405e-01,  3.110e-01,  9.502e-01,  9.985e-02,\n         9.951e-01,  3.162e-02,  9.995e-01,  1.000e-02,  1.000e+00,\n         3.162e-03,  1.000e+00,  1.000e-03,  1.000e+00,  3.161e-04,\n         1.000e+00],\n       [ 9.092e-01, -4.163e-01,  5.913e-01,  8.066e-01,  1.986e-01,\n         9.800e-01,  6.323e-02,  9.980e-01,  2.000e-02,  1.000e+00,\n         6.325e-03,  1.000e+00,  2.001e-03,  1.000e+00,  6.323e-04,\n         1.000e+00],\n       [ 1.411e-01, -9.902e-01,  8.125e-01,  5.825e-01,  2.954e-01,\n         9.556e-01,  9.473e-02,  9.956e-01,  3.000e-02,  9.995e-01,\n         9.483e-03,  1.000e+00,  3.000e-03,  1.000e+00,  9.489e-04,\n         1.000e+00],\n       [-7.568e-01, -6.538e-01,  9.536e-01,  3.010e-01,  3.894e-01,\n         9.209e-01,  1.261e-01,  9.922e-01,  3.998e-02,  9.990e-01,\n         1.265e-02,  1.000e+00,  4.002e-03,  1.000e+00,  1.265e-03,\n         1.000e+00]]"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef pos_encoding(position: int, d_model: int):\n    \n    if position == 0 or d_model <= 0:\n        return -1\n\n    # Create position and dimension indices\n    pos = np.arange(position, dtype=np.float32).reshape(position, 1)\n    ind = np.arange(d_model, dtype=np.float32).reshape(1, d_model)\n\n    # Compute the angles\n    angle_rads = pos / np.power(10000, (2 * (ind // 2)) / d_model)\n\n    # Apply sine to even indices, cosine to odd indices\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # Even indices (0, 2, 4...)\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # Odd indices (1, 3, 5...)\n\n    # Convert to float16 as required\n    return angle_rads.astype(np.float16)\n",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "position = 2, d_model = 8",
            "reasoning": "The function computes the positional encoding by calculating sine values for even indices and cosine values for odd indices, ensuring that the encoding provides the required positional information.",
            "output": "[[[ 0.,0.,0.,0.,1.,1.,1.,1.,]\n  [ 0.8413,0.0998,0.01,0.001,0.5405,0.995,1.,1.]]]"
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef pos_encoding(position: int, d_model: int):\n\t# Your code here\n\tpos_encoding = np.float16(pos_encoding)\n\treturn pos_encoding",
        "title": "Positional Encoding Calculator",
        "learn_section": "## **The Positional Encoding Layer in Transformers**\n\nThe Positional Encoding layer in Transformers plays a critical role by providing necessary positional information to the model. \nThis is particularly important because the Transformer architecture, unlike RNNs or LSTMs, processes input sequences in parallel\nand lacks inherent mechanisms to account for the sequential order of tokens.\n\nThe mathematical intuition behind the Positional Encoding layer in Transformers is centered on enabling the model to incorporate\ninformation about the order of tokens in a sequence.\n\n---\n\n### **Function Parameters**\n\n- **`position`**: Total positions or length of the sequence.\n- **`d_model`**: Dimensionality of the model's output.\n\n---\n\n### **Generating the Base Matrix**\n\n- **`angle_rads`**: Creates a matrix where rows represent sequence positions and columns represent feature dimensions.\n Values are scaled by dividing each position index by:  \n  $10000^{\\frac{2 \\cdot i}{d_{model}}}$\n\n---\n\n### **Applying Sine and Cosine Functions**\n\n- For even indices: Apply the sine function to encode positions.  \n  $PE(\\text{pos}, 2i) = \\sin\\left(\\frac{\\text{pos}}{10000^{\\frac{2i}{d_{model}}}}\\right)$\n\n- For odd indices: Apply the cosine function for a phase-shifted encoding.  \n  $PE(\\text{pos}, 2i+1) = \\cos\\left(\\frac{\\text{pos}}{10000^{\\frac{2i}{d_{model}}}}\\right)$\n\n---\n\n### **Creating the Positional Encoding Tensor**\n\n- The matrix is expanded to match input shape expectations of models like Transformers and cast to `float32`.\n\n---\n\n### **Output**\n\nReturns a TensorFlow tensor of shape $(1, \\text{position}, \\text{d\\_model})$, ready to be added to input embeddings\nto incorporate positional information.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/dsaha21",
                "name": "Dripto Saha"
            }
        ]
    },
    {
        "description": "Write a Python function to determine whether a machine learning model is overfitting, underfitting, or performing well based on training and test accuracy values. The function should take two inputs: `training_accuracy` and `test_accuracy`. It should return one of three values: 1 if Overfitting, -1 if Underfitting, or 0 if a Good fit. The rules for determination are as follows: \n- **Overfitting**: The training accuracy is significantly higher than the test accuracy (difference > 0.2).\n- **Underfitting**: Both training and test accuracy are below 0.7.\n- **Good fit**: Neither of the above conditions is true.",
        "id": "86",
        "test_cases": [
            {
                "test": "print(model_fit_quality(0.95, 0.65))",
                "expected_output": "1"
            },
            {
                "test": "print(model_fit_quality(0.6, 0.5))",
                "expected_output": "-1"
            },
            {
                "test": "print(model_fit_quality(0.85, 0.8))",
                "expected_output": "0"
            },
            {
                "test": "print(model_fit_quality(0.5, 0.6))",
                "expected_output": "-1"
            },
            {
                "test": "print(model_fit_quality(0.75, 0.74))",
                "expected_output": "0"
            }
        ],
        "difficulty": "easy",
        "solution": "def model_fit_quality(training_accuracy, test_accuracy):\n    \"\"\"\n    Determine if the model is overfitting, underfitting, or a good fit based on training and test accuracy.\n    :param training_accuracy: float, training accuracy of the model (0 <= training_accuracy <= 1)\n    :param test_accuracy: float, test accuracy of the model (0 <= test_accuracy <= 1)\n    :return: int, one of '1', '-1', or '0'.\n    \"\"\"\n    if training_accuracy - test_accuracy > 0.2:\n        return 1\n    elif training_accuracy < 0.7 and test_accuracy < 0.7:\n        return -1\n    else:\n        return 0",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "training_accuracy = 0.95, test_accuracy = 0.65",
            "output": "'1'",
            "reasoning": "The training accuracy is much higher than the test accuracy (difference = 0.30 > 0.2). This indicates that the model is overfitting to the training data and generalizes poorly to unseen data."
        },
        "category": "Machine Learning",
        "starter_code": "def model_fit_quality(training_accuracy, test_accuracy):\n\t\"\"\"\n\tDetermine if the model is overfitting, underfitting, or a good fit based on training and test accuracy.\n\t:param training_accuracy: float, training accuracy of the model (0 <= training_accuracy <= 1)\n\t:param test_accuracy: float, test accuracy of the model (0 <= test_accuracy <= 1)\n\t:return: int, one of '1', '-1', or '0'.\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Detect Overfitting or Underfitting",
        "learn_section": "## Understanding Overfitting and Underfitting\n\nOverfitting and underfitting are two common problems in machine learning models that affect their performance and generalization ability.\n\n### Overfitting\nOverfitting occurs when a model learns the training data too well, including noise and irrelevant patterns. This results in high training accuracy but poor performance on unseen data (low test accuracy).\n\n- **Indicators**: Training accuracy >> Test accuracy (large gap).\n\n### Underfitting\nUnderfitting occurs when a model is too simple to capture the underlying patterns in the data. This leads to poor performance on both training and test datasets.\n\n- **Indicators**: Both training and test accuracy are low.\n\n### Good Fit\nA good fit occurs when the model generalizes well to unseen data, with training and test accuracy being close and both reasonably high.\n\n### Remedies\n- **For Overfitting**:\n  - Use regularization techniques (e.g., L1, L2 regularization).\n  - Reduce model complexity by pruning unnecessary features.\n  - Add more training data to improve generalization.\n- **For Underfitting**:\n  - Increase model complexity (e.g., add layers or features).\n  - Train the model for more epochs.\n  - Enhance feature engineering or input data quality.\n\n### Mathematical Representation\n1. Overfitting:\n   $$ \\text{Training Accuracy} - \\text{Test Accuracy} > 0.2 $$\n\n2. Underfitting:\n   $$ \\text{Training Accuracy} < 0.7 \\, \\text{and} \\, \\text{Test Accuracy} < 0.7 $$\n\n3. Good Fit:\n   $$ \\text{Neither overfitting nor underfitting is true.} $$\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Implement the Adam optimizer update step function. Your function should take the current parameter value, gradient, and moving averages as inputs, and return the updated parameter value and new moving averages. The function should also handle scalar and array inputs and include bias correction for the moving averages.",
        "id": "87",
        "test_cases": [
            {
                "test": "print(adam_optimizer(1.0, 0.1, 0.0, 0.0, 1))",
                "expected_output": "(0.999, 0.01, 0.0001)"
            },
            {
                "test": "print(adam_optimizer(np.array([1.0, 2.0]), np.array([0.1, 0.2]), np.zeros(2), np.zeros(2), 1))",
                "expected_output": "(array([0.999, 1.999]), array([0.01, 0.02]), array([1.e-05, 4.e-05]))"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef adam_optimizer(parameter, grad, m, v, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n    \"\"\"\n    Update parameters using the Adam optimizer.\n    Adjusts the learning rate based on the moving averages of the gradient and squared gradient.\n    :param parameter: Current parameter value\n    :param grad: Current gradient\n    :param m: First moment estimate\n    :param v: Second moment estimate\n    :param t: Current timestep\n    :param learning_rate: Learning rate (default=0.001)\n    :param beta1: First moment decay rate (default=0.9)\n    :param beta2: Second moment decay rate (default=0.999)\n    :param epsilon: Small constant for numerical stability (default=1e-8)\n    :return: tuple: (updated_parameter, updated_m, updated_v)\n    \"\"\"\n    # Update biased first moment estimate\n    m = beta1 * m + (1 - beta1) * grad\n\n    # Update biased second raw moment estimate\n    v = beta2 * v + (1 - beta2) * (grad**2)\n\n    # Compute bias-corrected first moment estimate\n    m_hat = m / (1 - beta1**t)\n\n    # Compute bias-corrected second raw moment estimate\n    v_hat = v / (1 - beta2**t)\n\n    # Update parameters\n    update = learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n    parameter = parameter - update\n\n    return np.round(parameter,5), np.round(m,5), np.round(v,5)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "parameter = 1.0, grad = 0.1, m = 0.0, v = 0.0, t = 1",
            "output": "(0.999, 0.01, 0.0001)",
            "reasoning": "The Adam optimizer computes updated values for the parameter, first moment (m), and second moment (v) using bias-corrected estimates of gradients. With input values parameter=1.0, grad=0.1, m=0.0, v=0.0, and t=1, the updated parameter becomes 0.999."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef adam_optimizer(parameter, grad, m, v, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n\t\"\"\"\n\tUpdate parameters using the Adam optimizer.\n\tAdjusts the learning rate based on the moving averages of the gradient and squared gradient.\n\t:param parameter: Current parameter value\n\t:param grad: Current gradient\n\t:param m: First moment estimate\n\t:param v: Second moment estimate\n\t:param t: Current timestep\n\t:param learning_rate: Learning rate (default=0.001)\n\t:param beta1: First moment decay rate (default=0.9)\n\t:param beta2: Second moment decay rate (default=0.999)\n\t:param epsilon: Small constant for numerical stability (default=1e-8)\n\t:return: tuple: (updated_parameter, updated_m, updated_v)\n\t\"\"\"\n\t# Your code here\n\treturn np.round(parameter,5), np.round(m,5), np.round(v,5)",
        "title": "Adam Optimizer",
        "learn_section": "# Implementing Adam Optimizer\n\n## Introduction\nAdam (Adaptive Moment Estimation) is a popular optimization algorithm used in training deep learning models. It combines the benefits of two other optimization algorithms: RMSprop and momentum optimization.\n\n## Learning Objectives\n- Understand how Adam optimizer works\n- Learn to implement adaptive learning rates\n- Understand bias correction in optimization algorithms\n- Gain practical experience with gradient-based optimization\n\n## Theory\nAdam maintains moving averages of both gradients (first moment) and squared gradients (second moment) to adapt the learning rate for each parameter. The key equations are:\n\n$m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t$ (First moment)\n$v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2$ (Second moment)\n\nBias correction:\n$\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}$\n$\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$\n\nParameter update:\n$\\theta_t = \\theta_{t-1} - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$\n\n## Problem Statement\nImplement the Adam optimizer update step function. Your function should take the current parameter value, gradient, and moving averages as inputs, and return the updated parameter value and new moving averages.\n\n### Input Format\nThe function should accept:\n- parameter: Current parameter value\n- grad: Current gradient\n- m: First moment estimate\n- v: Second moment estimate\n- t: Current timestep\n- learning_rate: Learning rate (default=0.001)\n- beta1: First moment decay rate (default=0.9)\n- beta2: Second moment decay rate (default=0.999)\n- epsilon: Small constant for numerical stability (default=1e-8)\n\n### Output Format\nReturn tuple: (updated_parameter, updated_m, updated_v)\n\n## Example\n# Example usage:\nparameter = 1.0\ngrad = 0.1\nm = 0.0\nv = 0.0\nt = 1\n\nnew_param, new_m, new_v = adam_optimizer(parameter, grad, m, v, t)\n## Tips\n- Initialize m and v as zeros\n- Keep track of timestep t for bias correction\n- Use numpy for numerical operations\n- Test with both scalar and array inputs",
        "contributor": [
            {
                "profile_link": "https://github.com/kapardhi03",
                "name": "Kapardhi"
            }
        ]
    },
    {
        "description": "### Implement a Simplified GPT-2-like Text Generation Function\n\nYou are tasked with implementing a simplified GPT-2-like text generation function in Python. This function will incorporate the following components of a minimal GPT-2 architecture:\n\n- **Token Embeddings**: Map input tokens to dense vector representations.\n- **Positional Embeddings**: Add positional information to token embeddings.\n- **Multi-head Attention**: Attend to various parts of the sequence.\n- **Feed-Forward Network**: Process attention outputs through a dense layer.\n- **Layer Normalization**: Stabilize the training process.\n\nThe function must take in the following parameters:\n\n1. **Prompt**: The initial text to guide the generation process.\n2. **Number of Tokens to Generate**: Specify how many tokens to output.\n\nYour function should output the generated text.\n\nAdditionally, utilize the helper function `load_encoder_hparams_and_params` to retrieve:\n\n- A dummy encoder.\n- Model hyperparameters.\n- Model parameters.\n\nBuild your text generation logic around these components. This exercise is designed to help you understand the core concepts behind GPT-2's autoregressive text generation.",
        "id": "88",
        "test_cases": [
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(gen_text(\"hello\", n_tokens_to_generate=5))",
                "expected_output": "hello hello hello <UNK> <UNK>"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(gen_text(\"hello world\", n_tokens_to_generate=10))",
                "expected_output": "world world world world world world world world world world"
            },
            {
                "test": "import numpy as np\nnp.random.seed(42)\nprint(gen_text(\"world\", n_tokens_to_generate=3))",
                "expected_output": "world world world"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\n\ndef gelu(x):\n    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n\ndef softmax(x):\n    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n\ndef layer_norm(x, g, b, eps=1e-5):\n    mean = np.mean(x, axis=-1, keepdims=True)\n    variance = np.var(x, axis=-1, keepdims=True)\n    return g * (x - mean) / np.sqrt(variance + eps) + b\n\ndef linear(x, w, b):\n    return x @ w + b\n\ndef ffn(x, c_fc, c_proj):\n    return linear(gelu(linear(x, **c_fc)), **c_proj)\n\ndef attention(q, k, v, mask):\n    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v\n\ndef mha(x, c_attn, c_proj, n_head):\n    x = linear(x, **c_attn)\n    qkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), np.split(x, 3, axis=-1)))\n    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10\n    out_heads = [attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)]\n    x = linear(np.hstack(out_heads), **c_proj)\n    return x\n\ndef transformer_block(x, mlp, attn, ln_1, ln_2, n_head):\n    x = x + mha(layer_norm(x, **ln_1), **attn, n_head=n_head)\n    x = x + ffn(layer_norm(x, **ln_2), **mlp)\n    return x\n\ndef gpt2(inputs, wte, wpe, blocks, ln_f, n_head):\n    x = wte[inputs] + wpe[range(len(inputs))]\n    for block in blocks:\n        x = transformer_block(x, **block, n_head=n_head)\n    return layer_norm(x, **ln_f) @ wte.T\n\ndef generate(inputs, params, n_head, n_tokens_to_generate):\n    for _ in range(n_tokens_to_generate):\n        logits = gpt2(inputs, **params, n_head=n_head)\n        next_id = np.argmax(logits[-1])\n        inputs.append(int(next_id))\n    return inputs[len(inputs) - n_tokens_to_generate:]\n\ndef gen_text(prompt: str, n_tokens_to_generate: int = 40):\n    np.random.seed(42)  # Set the random seed for reproducibility\n    encoder, hparams, params = load_encoder_hparams_and_params()\n    input_ids = encoder.encode(prompt)\n    assert len(input_ids) + n_tokens_to_generate < hparams[\"n_ctx\"]\n    output_ids = generate(input_ids, params, hparams[\"n_head\"], n_tokens_to_generate)\n    output_text = encoder.decode(output_ids)\n    return output_text",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "prompt=\"hello\", n_tokens_to_generate=5",
            "output": "world <UNK> <UNK> <UNK> <UNK>",
            "reasoning": "The function encodes the input \"hello\" into tokens using the dummy encoder, then runs a simplified GPT-2 forward pass to generate 5 tokens. Finally, it decodes the generated tokens back into text."
        },
        "category": "NLP",
        "starter_code": "def gen_text(prompt: str, n_tokens_to_generate: int = 40):\n\t####your code goes here####\n\tpass\n\ndef load_encoder_hparams_and_params(model_size: str = \"124M\", models_dir: str = \"models\"):\n\tclass DummyBPE:\n\t\tdef __init__(self):\n\t\t\tself.encoder_dict = {\"hello\": 1, \"world\": 2, \"<UNK>\": 0}\n\n\t\tdef encode(self, text: str):\n\t\t\ttokens = text.strip().split()\n\t\t\treturn [self.encoder_dict.get(token, self.encoder_dict[\"<UNK>\"]) for token in tokens]\n\n\t\tdef decode(self, token_ids: list):\n\t\t\treversed_dict = {v: k for k, v in self.encoder_dict.items()}\n\t\t\treturn \" \".join([reversed_dict.get(tok_id, \"<UNK>\") for tok_id in token_ids])\n\n\thparams = {\n\t\t\"n_ctx\": 1024,\n\t\t\"n_head\": 12\n\t}\n\n\tparams = {\n\t\t\"wte\": np.random.rand(3, 10),\n\t\t\"wpe\": np.random.rand(1024, 10),\n\t\t\"blocks\": [],\n\t\t\"ln_f\": {\n\t\t\t\"g\": np.ones(10),\n\t\t\t\"b\": np.zeros(10),\n\t\t}\n\t}\n\n\tencoder = DummyBPE()\n\treturn encoder, hparams, params",
        "title": "GPT-2 Text Generation",
        "learn_section": "# Understanding Transformer Architecture and Text Generation\n\nTransformers have revolutionized the field of Natural Language Processing (NLP) with their efficient and scalable architecture. This guide provides an in-depth look into the core components of transformers and how they facilitate advanced text generation.\n\n## 1. Introduction to Transformers\n\nTransformers are a groundbreaking neural network architecture that has significantly advanced NLP. Introduced in the seminal paper *\"Attention is All You Need\"* by Vaswani et al. (2017), transformers have outperformed traditional models like Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks (LSTMs) in various NLP tasks.\n\n### Key Advantages of Transformers\n\n- **Parallel Processing**:  \n  Unlike RNNs, which process input sequences sequentially, transformers handle entire sequences simultaneously. This parallelism leads to substantial improvements in training speed and efficiency.\n\n- **Scalability**:  \n  Transformers can effectively scale to handle large datasets and complex tasks, making them ideal for applications like language translation, text generation, and summarization.\n\n- **Self-Attention Mechanism**:  \n  The core innovation of transformers is the self-attention mechanism, which allows the model to weigh the importance of different words in a sequence relative to each other. This capability enables the model to capture long-range dependencies and contextual relationships within the text.\n\n### Applications of Transformers\n\n- **Text Generation**: Creating coherent and contextually relevant text based on a given prompt.\n- **Machine Translation**: Translating text from one language to another with high accuracy.\n- **Text Summarization**: Condensing long documents into concise summaries while retaining key information.\n- **Question Answering**: Providing accurate answers to user queries based on contextual understanding.\n\n---\n\n## 2. Core Concepts\n\nTo fully grasp the transformer architecture, it's essential to understand its foundational components. Below are the core concepts that constitute the building blocks of transformers:\n\n### 2.1 GELU Activation Function\n\nThe Gaussian Error Linear Unit (GELU) is an advanced activation function that enhances the performance of deep neural networks.\n\n**Mathematical Expression**:  \n$$\n\\text{GELU}(x) = 0.5 \\cdot x \\cdot (1 + \\tanh(\\sqrt{\\frac{2}{\\pi}} \\cdot (x + 0.044715 \\cdot x^3)))\n$$\n\n**Purpose**:  \nGELU introduces non-linearity in the network while maintaining smooth gradient flow. Unlike the Rectified Linear Unit (ReLU) or Sigmoid functions, GELU provides a probabilistic approach to activation, allowing for better handling of uncertainty and improving model performance in deep architectures.\n\n**Benefits**:\n- **Smooth Activation**: Reduces the likelihood of \"dead neurons\" that can occur with ReLU.\n- **Improved Gradient Flow**: Facilitates more stable and efficient training by preventing gradient vanishing or exploding.\n\n### 2.2 Softmax for Attention\n\nSoftmax is a fundamental function used to convert raw attention scores into a probability distribution, ensuring that the weights sum to one.\n\n**Mathematical Expression**:  \n$$\n\\text{Softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_{j=1}^n \\exp(x_j)}\n$$\n\n**Purpose**:  \nIn the context of attention mechanisms, Softmax normalizes the attention scores, enabling the model to focus on relevant parts of the input sequence by assigning higher weights to more important tokens.\n\n**Example**:  \nIf the attention scores for a sentence are `[2, 1, 0.1]`, applying Softmax will convert these to probabilities like `[0.659, 0.242, 0.099]`, indicating the relative importance of each token.\n\n### 2.3 Layer Normalization\n\nLayer normalization stabilizes and accelerates the training process by standardizing the inputs across the features.\n\n**Mathematical Expression**:  \n$$\n\\text{LayerNorm}(x) = g \\cdot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + b\n$$\n\nWhere:\n- \\( \\mu \\): Mean of input \\( x \\) along the last axis.\n- \\( \\sigma^2 \\): Variance of \\( x \\).\n- \\( g, b \\): Learnable scaling and bias parameters.\n- \\( \\epsilon \\): A small constant to prevent division by zero.\n\n**Purpose**:  \nBy normalizing the inputs, layer normalization ensures that each layer receives inputs with a consistent distribution, which enhances training stability and convergence speed.\n\n---\n\n### 2.4 Multi-Head Attention\n\nMulti-head attention is an extension of the attention mechanism that allows the model to focus on different representation subspaces simultaneously.\n\n**Components**:\n- **Query (Q), Key (K), Value (V) Matrices**: Each attention head computes its own set of Q, K, and V matrices by projecting the input embeddings into different subspaces.\n- **Scaled Dot-Product Attention**:\n  $$\n  \\text{Attention}(Q, K, V) = \\text{Softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V\n  $$\n\n**Benefits**:\n- **Diversity of Attention**: Allows the model to focus on different parts of the input simultaneously.\n- **Enhanced Representation**: Captures richer features by aggregating multiple attention heads.\n\n---\n\n### 2.5 Feedforward Network (FFN)\n\nThe Feedforward Network is a simple yet powerful component applied to each position independently within the transformer.\n\n**Mathematical Expression**:  \n$$\n\\text{FFN}(x) = \\text{Linear}_2(\\text{GELU}(\\text{Linear}_1(x)))\n$$\n\n**Structure**:\n1. First Linear Layer: Projects the input to a higher-dimensional space.\n2. GELU Activation: Introduces non-linearity to the model.\n3. Second Linear Layer: Projects the data back to the original dimensionality.\n\n**Purpose**:  \nThe FFN enhances the model's capacity to learn intricate patterns.\n\n---\n\n### 2.6 Transformer Block\n\nA transformer block is the fundamental building unit of the transformer architecture, combining multi-head attention and the feedforward network with residual connections and layer normalization.\n\n**Structure**:\n- **Multi-Head Attention Layer**:  \n  $$ x_1 = \\text{LayerNorm}(x + \\text{MHA}(x)) $$\n- **Feedforward Network**:  \n  $$ x_2 = \\text{LayerNorm}(x_1 + \\text{FFN}(x_1)) $$\n\n**Advantages**:\n- **Deep Architecture Support**: Facilitates the construction of deep networks without significant performance degradation.\n- **Modularity**: Each transformer block can be stacked multiple times, allowing for scalable model depth.\n\n---\n\n### 2.7 GPT-2 Text Generation\n\nGPT-2 (Generative Pre-trained Transformer 2) leverages the transformer architecture for generating human-like text. Developed by OpenAI, GPT-2 has demonstrated remarkable capabilities in various NLP tasks.\n\n**Key Components**:\n- **Word and Positional Embeddings**: Captures semantic meaning and token position in a sequence.\n- **Causal Attention**: Ensures left-to-right text generation by masking future tokens.\n- **Stacked Transformer Blocks**: Refines input representations iteratively.\n\n**Text Generation Process**:\n1. Provide a prompt to initiate the process.\n2. Tokenize the input into embeddings.\n3. Process embeddings through transformer blocks.\n4. Generate the next token based on probabilities.\n5. Repeat steps 3-4 to produce coherent text.\n\n---\n\n### Conclusion\n\nTransformers have fundamentally transformed NLP by introducing efficient and scalable architectures capable of handling complex language tasks. Understanding their core components such as GELU activation, Softmax attention, layer normalization, multi-head attention, feedforward networks, and the transformer block provides a foundation for leveraging these models in various applications. GPT-2 exemplifies the transformative power of these architectures while highlighting ethical considerations for their use.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "Deep in the Crystal Cave, the enigmatic Pattern Weaver creates stunning sequences by uncovering the intricate relationships between crystals. Each crystal is marked by a unique numeric value, and the Weaver emphasizes that the true power of any crystal depends on how it interacts with all others. You have discovered N crystals, each with a specific value, and your task is to reveal their enhanced patterns by analyzing these relationships using self-attention. Given a sequence of crystals and their values, your task is to implement a simplified self-attention mechanism. For each crystal, calculate its relationship with every other crystal, compute the attention scores using the softmax function, and derive the final weighted pattern for each crystal. This Problem was made with the help of GroundZero AI",
        "id": "89",
        "test_cases": [
            {
                "test": "print(pattern_weaver(5, [4, 2, 7, 1, 9], 1))",
                "expected_output": "[8.9993, 8.9638, 9.0, 8.7259, 9.0]"
            },
            {
                "test": "print(pattern_weaver(3, [1, 3, 5], 1))",
                "expected_output": "[4.7019, 4.995, 4.9999]"
            },
            {
                "test": "print(pattern_weaver(4, [2, 8, 6, 4], 1))",
                "expected_output": "[7.9627, 8.0, 8.0, 7.9993]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\n\ndef softmax(values):\n    exps = np.exp(values - np.max(values))\n    return exps / np.sum(exps)\n\ndef pattern_weaver(n, crystal_values, dimension):\n    dimension_sqrt = np.sqrt(dimension)\n    final_patterns = []\n\n    for i in range(n):\n        attention_scores = []\n        for j in range(n):\n            score = crystal_values[i] * crystal_values[j] / dimension_sqrt\n            attention_scores.append(score)\n\n        softmax_scores = softmax(attention_scores)\n        weighted_sum = sum(softmax_scores[k] * crystal_values[k] for k in range(n))\n        final_patterns.append(round(weighted_sum, 4))\n\n    return final_patterns",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "number of crystals: 5\nvalues: 4 2 7 1 9\n dimension: 1",
            "output": "[8.9993, 8.9638, 9.0, 8.7259, 9.0]",
            "reasoning": "The self-attention mechanism calculates relationships (attention scores) for each crystal using the given formula. These scores are converted to probabilities using the softmax function, and the final weighted pattern for each crystal is derived by summing the weighted values."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef softmax(values):\n\t# Implement the softmax function\n\tpass\n\ndef pattern_weaver(n, crystal_values, dimension):\n\t# Your code here\n\treturn np.round(x,3)",
        "title": "The Pattern Weaver's Code",
        "learn_section": "## Understanding Self-Attention\n\nSelf-attention is a core concept in modern deep learning architectures, particularly transformers. It helps a model understand relationships between elements in a sequence by comparing each element with every other element.\n\n### Key Formula\n\nThe attention score between two elements $i$ and $j$ is calculated as:\n\n$$\n\\text{Attention Score}_{i,j} = \\frac{\\text{Value}_i \\times \\text{Value}_j}{\\sqrt{\\text{Dimension}}}\n$$\n\n### Softmax Function\n\nThe softmax function converts raw attention scores into probabilities:\n\n$$\n\\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j} e^{x_j}}\n$$\n\n### Weighted Sum\n\nUsing the softmax scores, the final value for each element is calculated as a weighted sum:\n\n$$\n\\text{Final Value}_i = \\sum_{j} \\text{Softmax Score}_{i,j} \\times \\text{Value}_j\n$$\n\n### Example Calculation\n\nConsider the following values:\n\n- Crystal values: $[4, 2, 7, 1, 9]$\n- Dimension: $1$\n\n#### Step 1: Calculate Attention Scores\n\nFor crystal $i = 1$ ($4$):\n\n$$\n\\text{Score}_{1,1} = \\frac{4 \\times 4}{\\sqrt{1}} = 16,\n\\quad \\text{Score}_{1,2} = \\frac{4 \\times 2}{\\sqrt{1}} = 8,\n\\ldots\n$$\n\n#### Step 2: Apply Softmax\n\nConvert scores to probabilities using softmax.\n\n#### Step 3: Compute Weighted Sum\n\nMultiply probabilities by crystal values and sum them to get the final value.\n\n### Applications\n\nSelf-attention is widely used in:\n\n- Natural Language Processing (e.g., transformers)\n- Computer Vision (e.g., Vision Transformers)\n- Sequence Analysis\n\nMastering self-attention provides a foundation for understanding advanced AI architectures.",
        "contributor": [
            {
                "profile_link": "https://discord.gg/27N5vXdPW4",
                "name": "GroundZero AI"
            }
        ]
    },
    {
        "description": "multiply two matrices together (return -1 if shapes of matrix dont aline), i.e. $C = A \\cdot B$",
        "mdx_file": "d11e8a70-6938-476f-86cc-b89f6849bfc4.mdx",
        "tinygrad_difficulty": "easy",
        "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIG1hdHJpeG11bF90ZyhhLCBiKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIE11bHRpcGx5IHR3byBtYXRyaWNlcyB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRpbnlncmFkIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMkQgVGVuc29yIG9mIHNoYXBlIChtLCBuKSBvciBhIHNjYWxhciBUZW5zb3IgLTEuMCBpZiBkaW1lbnNpb25zIG1pc21hdGNoLgogICAgIiIiCiAgICAjIGRpbWVuc2lvbiBtaXNtYXRjaAogICAgaWYgbGVuKGFbMF0pICE9IGxlbihiKToKICAgICAgICByZXR1cm4gVGVuc29yKC0xLjApCiAgICAjIGNvbnZlcnQgYW5kIG11bHRpcGx5CiAgICBhX3QgPSBUZW5zb3IoYSkKICAgIGJfdCA9IFRlbnNvcihiKQogICAgcmV0dXJuIGFfdC5tYXRtdWwoYl90KQo=",
        "test_cases": [
            {
                "test": "print(matrixmul([[1,2,3],[2,3,4],[5,6,7]],[[3,2,1],[4,3,2],[5,4,3]]))",
                "expected_output": "[[26, 20, 14], [38, 29, 20], [74, 56, 38]]"
            },
            {
                "test": "print(matrixmul([[0,0],[2,4],[1,2]],[[0,0],[2,4]]))",
                "expected_output": "[[0, 0], [8, 16], [4, 8]]"
            },
            {
                "test": "print(matrixmul([[0,0],[2,4],[1,2]],[[0,0,1],[2,4,1],[1,2,3]]))",
                "expected_output": "-1"
            }
        ],
        "solution": "\ndef matrixmul(a:list[list[int|float]],\n              b:list[list[int|float]])-> list[list[int|float]]:\n    if len(a[0]) != len(b):\n        return -1\n    \n    vals = []\n    for i in range(len(a)):\n        hold = []\n        for j in range(len(b[0])):\n            val = 0\n            for k in range(len(b)):\n                val += a[i][k] * b[k][j]\n                           \n            hold.append(val)\n        vals.append(hold)\n\n    return vals",
        "tinygrad_solution": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIG1hdHJpeG11bF90ZyhhLCBiKSAtPiBUZW5zb3I6CiAgICAiIiIKICAgIE11bHRpcGx5IHR3byBtYXRyaWNlcyB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRpbnlncmFkIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMkQgVGVuc29yIG9mIHNoYXBlIChtLCBuKSBvciBhIHNjYWxhciBUZW5zb3IgLTEuMCBpZiBkaW1lbnNpb25zIG1pc21hdGNoLgogICAgIiIiCiAgICBpZiBsZW4oYVswXSkgIT0gbGVuKGIpOgogICAgICAgIHJldHVybiBUZW5zb3IoLTEuMCkKICAgIGFfdCA9IFRlbnNvcihhKQogICAgYl90ID0gVGVuc29yKGIpCiAgICByZXR1cm4gYV90Lm1hdG11bChiX3QpCg==",
        "pytorch_difficulty": "easy",
        "video": "https://youtu.be/N2j0fA2E9k4",
        "likes": "0",
        "difficulty": "medium",
        "dislikes": "0",
        "example": {
            "input": "A = [[1,2],[2,4]], B = [[2,1],[3,4]]",
            "reasoning": "1\\*2 + 2\\*3 = 8;                   2\\*2 + 3\\*4 = 16;                   1\\*1 + 2\\*4 = 9;                   2\\*1 + 4\\*4 = 18                    Example 2:        input: A = [[1,2],                    [2,4]],                B = [[2,1],                    [3,4],                    [4,5]]        output: -1        reasoning: the length of the rows of A does not equal          the column length of B",
            "output": "[[ 8,  9],[16, 18]]"
        },
        "category": "Linear Algebra",
        "starter_code": "def matrixmul(a:list[list[int|float]],\n              b:list[list[int|float]])-> list[list[int|float]]:\n\treturn c",
        "title": "Matrix times Matrix ",
        "learn_section": "\n## Matrix Multiplication\n\nConsider two matrices \\( A \\) and \\( B \\) to demonstrate their multiplication, defined as follows:\n\n**Matrix \\( A \\):**\n$$\nA = \\begin{pmatrix} \na_{11} & a_{12} \\\\ \na_{21} & a_{22} \n\\end{pmatrix}\n$$\n\n**Matrix \\( B \\):**\n$$\nB = \\begin{pmatrix} \nb_{11} & b_{12} \\\\ \nb_{21} & b_{22} \n\\end{pmatrix}\n$$\n\nThe multiplication of matrix \\( A \\) by matrix \\( B \\) is calculated as:\n$$\nA \\times B = \\begin{pmatrix} \na_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\\\ \na_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22} \n\\end{pmatrix}\n$$\n\nThis operation results in a new matrix where each element is the result of the dot product between the rows of matrix \\( A \\) and the columns of matrix \\( B \\).\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ],
        "pytorch_test_cases": [
            {
                "test": "import torch\nres = matrixmul(\n    torch.tensor([[1,2],[3,4]]),\n    torch.tensor([[1,0],[0,1]])\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[1, 2], [3, 4]]"
            },
            {
                "test": "import torch\nres = matrixmul(\n    torch.tensor([[1,2,3],[2,4,5],[6,8,9]]),\n    torch.tensor([[1,2],[3,4],[5,6]])\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[22, 28], [39, 50], [75, 98]]"
            },
            {
                "test": "import torch\nres = matrixmul(\n    torch.tensor([[1,2,3],[2,4,5]]),\n    torch.tensor([[1,2],[3,4]])\n)\nprint(res.numpy().tolist())",
                "expected_output": "-1"
            }
        ],
        "tinygrad_test_cases": [
            {
                "test": "from tinygrad.tensor import Tensor\nres = matrixmul_tg(\n    [[1,2],[3,4]],\n    [[1,0],[0,1]]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[1.0, 2.0], [3.0, 4.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = matrixmul_tg(\n    [[1,2,3],[2,4,5],[6,8,9]],\n    [[1,2],[3,4],[5,6]]\n)\nprint(res.numpy().tolist())",
                "expected_output": "[[22.0, 28.0], [39.0, 50.0], [75.0, 98.0]]"
            },
            {
                "test": "from tinygrad.tensor import Tensor\nres = matrixmul_tg(\n    [[1,2,3],[2,4,5]],\n    [[1,2],[3,4]]\n)\nprint(res.numpy().tolist())",
                "expected_output": "-1.0"
            }
        ],
        "pytorch_solution": "aW1wb3J0IHRvcmNoCgpkZWYgbWF0cml4bXVsKGEsIGIpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgTXVsdGlwbHkgdHdvIG1hdHJpY2VzIHVzaW5nIFB5VG9yY2guCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0b3JjaCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDJEIHRlbnNvciBvZiBzaGFwZSAobSwgbikgb3IgYSBzY2FsYXIgdGVuc29yIC0xIGlmIGRpbWVuc2lvbnMgbWlzbWF0Y2guCiAgICAiIiIKICAgIGFfdCA9IHRvcmNoLmFzX3RlbnNvcihhKQogICAgYl90ID0gdG9yY2guYXNfdGVuc29yKGIpCiAgICBpZiBhX3Quc2l6ZSgxKSAhPSBiX3Quc2l6ZSgwKToKICAgICAgICByZXR1cm4gdG9yY2gudGVuc29yKC0xKQogICAgcmV0dXJuIGFfdC5tYXRtdWwoYl90KQo=",
        "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgbWF0cml4bXVsKGEsIGIpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgTXVsdGlwbHkgdHdvIG1hdHJpY2VzIHVzaW5nIFB5VG9yY2guCiAgICBJbnB1dHMgY2FuIGJlIFB5dGhvbiBsaXN0cywgTnVtUHkgYXJyYXlzLCBvciB0b3JjaCBUZW5zb3JzLgogICAgUmV0dXJucyBhIDJEIHRlbnNvciBvZiBzaGFwZSAobSwgbikgb3IgYSBzY2FsYXIgdGVuc29yIC0xIGlmIGRpbWVuc2lvbnMgbWlzbWF0Y2guCiAgICAiIiIKICAgIGFfdCA9IHRvcmNoLmFzX3RlbnNvcihhKQogICAgYl90ID0gdG9yY2guYXNfdGVuc29yKGIpCiAgICAjIGRpbWVuc2lvbiBtaXNtYXRjaAogICAgaWYgYV90LnNpemUoMSkgIT0gYl90LnNpemUoMCk6CiAgICAgICAgcmV0dXJuIHRvcmNoLnRlbnNvcigtMSkKICAgICMgbWF0cml4IG11bHRpcGxpY2F0aW9uCiAgICByZXR1cm4gYV90Lm1hdG11bChiX3QpCg==",
        "id": "9"
    },
    {
        "description": "Implement the BM25 ranking function to calculate document scores for a query in an information retrieval context. BM25 is an advanced variation of TF-IDF that incorporates term frequency saturation, document length normalization, and a configurable penalty for document length effects.",
        "id": "90",
        "test_cases": [
            {
                "test": "print(calculate_bm25_scores([['the', 'cat', 'sat'], ['the', 'dog', 'ran'], ['the', 'bird', 'flew']], ['the', 'cat']))",
                "expected_output": "[0.693, 0., 0. ]"
            },
            {
                "test": "print(calculate_bm25_scores([['the'] * 10, ['the']], ['the']))",
                "expected_output": "[0,0]"
            },
            {
                "test": "print(calculate_bm25_scores([['term'] * 10, ['the'] * 2], ['term'], k1=1.0))",
                "expected_output": "[.705, 0]"
            }
        ],
        "difficulty": "medium",
        "solution": "import numpy as np\nfrom collections import Counter\n\ndef calculate_bm25_scores(corpus, query, k1=1.5, b=0.75):\n    if not corpus or not query:\n        raise ValueError(\"Corpus and query cannot be empty\")\n\n    doc_lengths = [len(doc) for doc in corpus]\n    avg_doc_length = np.mean(doc_lengths)\n    doc_term_counts = [Counter(doc) for doc in corpus]\n    doc_freqs = Counter()\n    for doc in corpus:\n        doc_freqs.update(set(doc))\n\n    scores = np.zeros(len(corpus))\n    N = len(corpus)\n\n    for term in query:\n        df = doc_freqs.get(term, 0) + 1\n        idf = np.log((N + 1) / df)\n\n        for idx, term_counts in enumerate(doc_term_counts):\n            if term not in term_counts:\n                continue\n\n            tf = term_counts[term]\n            doc_len_norm = 1 - b + b * (doc_lengths[idx] / avg_doc_length)\n            term_score = (tf * (k1 + 1)) / (tf + k1 * doc_len_norm)\n            scores[idx] += idf * term_score\n\n    return np.round(scores, 3)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "corpus = [['the', 'cat', 'sat'], ['the', 'dog', 'ran'], ['the', 'bird', 'flew']], query = ['the', 'cat']",
            "output": "[0.693, 0., 0. ]",
            "reasoning": "BM25 calculates scores for each document in the corpus by evaluating how well the query terms match each document while considering term frequency saturation and document length normalization."
        },
        "category": "NLP",
        "starter_code": "import numpy as np\nfrom collections import Counter\n\ndef calculate_bm25_scores(corpus, query, k1=1.5, b=0.75):\n\t# Your code here\n\tpass\n\treturn np.round(scores,3)",
        "title": "BM25 Ranking ",
        "learn_section": "## **BM25**\n\nBM25 (Best Match 25) is used in information retrieval for search relevance. Similar to TF-IDF, it reflects the importance of a word in a document within a collection or corpus. However, BM25 improves upon TF-IDF by addressing key limitations.\n\n### Limitations of TF-IDF Addressed by BM25\n\n1. **Saturation**: In TF-IDF, having a term multiple times in a document skews the term frequency, making the document overly relevant. BM25 mitigates this by using:  \n   $$ \\text{TF-adjusted} = \\frac{\\text{TF}}{\\text{TF} + k_1} $$  \n\n2. **Document Length Normalization**: BM25 accounts for document length by normalizing term frequencies using:  \n   $$ \\text{Normalized Length} = 1 - b + b \\times \\frac{\\text{Doc Len}}{\\text{Average Doc Len}} $$  \n\n3. **Amplifying Parameter**: The $b$ parameter controls the influence of document length normalization. Higher $b$ values amplify the effect.\n\n### Final BM25 Formula\n\nThe BM25 score for a term is given by:  \n$$ \\text{BM25} = \\text{IDF} \\times \\frac{\\text{TF} \\times (k_1 + 1)} {\\text{TF} + k_1 \\times (1 - b + b \\times \\frac{\\text{dl}}{\\text{adl}})} $$  \n\nWhere:  \n- $ \\text{TF} $: Term frequency in the document.  \n- $ \\text{IDF} $: Inverse document frequency, calculated as $ \\log(\\frac{N + 1}{\\text{df} + 1}) $.  \n- $ N $: Total number of documents.  \n- $ \\text{df} $: Number of documents containing the term.  \n- $ \\text{dl} $: Document length.  \n- $ \\text{adl} $: Average document length.  \n- $ k_1 $: Saturation parameter.  \n- $ b $: Normalization parameter.\n\n### Implementation Steps\n\n1. Compute document length ($ dl $) and average document length ($ adl $).  \n2. Calculate term frequencies ($ TF $) using the BM25 formula.  \n3. Compute inverse document frequencies ($ IDF $) for each term.  \n4. Calculate BM25 scores for each document.\n\n### Applications\n\nBM25 is widely used in:  \n- Search Engines  \n- Recommendation Systems  \n- Natural Language Processing (NLP)  \n\nUnderstanding BM25 enables the creation of robust systems for search and ranking tasks.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/saitiger",
                "name": "Sai Tiger Raina"
            }
        ]
    },
    {
        "description": "Implement a function to calculate the F1 score given predicted and true labels. The F1 score is a widely used metric in machine learning, combining precision and recall into a single measure. round your solution to the 3rd decimal place",
        "id": "91",
        "test_cases": [
            {
                "test": "print(calculate_f1_score([1, 0, 1, 1, 0], [1, 0, 0, 1, 1]))",
                "expected_output": "0.667"
            },
            {
                "test": "print(calculate_f1_score([1, 1, 0, 0], [1, 0, 0, 1]))",
                "expected_output": "0.5"
            },
            {
                "test": "print(calculate_f1_score([0, 0, 0, 0], [1, 1, 1, 1]))",
                "expected_output": "0.0"
            }
        ],
        "difficulty": "easy",
        "solution": "def calculate_f1_score(y_true, y_pred):\n    \"\"\"\n    Calculate the F1 score based on true and predicted labels.\n\n    Args:\n        y_true (list): True labels (ground truth).\n        y_pred (list): Predicted labels.\n\n    Returns:\n        float: The F1 score rounded to three decimal places.\n    \"\"\"\n    if len(y_true) != len(y_pred):\n        raise ValueError(\"Lengths of y_true and y_pred must be the same\")\n\n    tp = sum(1 for yt, yp in zip(y_true, y_pred) if yt == yp == 1)\n    fp = sum(1 for yt, yp in zip(y_true, y_pred) if yt == 0 and yp == 1)\n    fn = sum(1 for yt, yp in zip(y_true, y_pred) if yt == 1 and yp == 0)\n\n    if tp + fp == 0 or tp + fn == 0:\n        return 0.0\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    if precision + recall == 0:\n        return 0.0\n\n    f1_score = 2 * (precision * recall) / (precision + recall)\n    return round(f1_score, 3)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "y_true = [1, 0, 1, 1, 0], y_pred = [1, 0, 0, 1, 1]",
            "output": "0.667",
            "reasoning": "The true positives, false positives, and false negatives are calculated from the given labels. Precision and recall are derived, and the F1 score is computed as their harmonic mean."
        },
        "category": "Machine Learning",
        "starter_code": "def calculate_f1_score(y_true, y_pred):\n\t\"\"\"\n\tCalculate the F1 score based on true and predicted labels.\n\n\tArgs:\n\t\ty_true (list): True labels (ground truth).\n\t\ty_pred (list): Predicted labels.\n\n\tReturns:\n\t\tfloat: The F1 score rounded to three decimal places.\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(f1,3)",
        "title": "Calculate F1 Score from Predicted and True Labels",
        "learn_section": "## **F1 Score**\n\nThe F1 score is a widely used metric in machine learning and statistics, particularly for evaluating classification models. It is the harmonic mean of **precision** and **recall**, providing a single measure that balances the trade-off between these two metrics.\n\n### **Key Concepts**\n\n1. **Precision**: Precision is the fraction of true positive predictions out of all positive predictions made by the model. It measures how many of the predicted positive instances are actually correct.\n\n    $$\n    \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Positives (FP)}}\n    $$\n\n2. **Recall**: Recall is the fraction of true positive predictions out of all actual positive instances in the dataset. It measures how many of the actual positive instances were correctly predicted.\n\n    $$\n    \\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}\n    $$\n\n3. **F1 Score**: The F1 score is the harmonic mean of precision and recall, providing a balanced measure that takes both metrics into account:\n\n    $$\n    \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n    $$\n\n### **Why Use the F1 Score?**\n\nThe F1 score is particularly useful when the dataset is imbalanced, meaning the classes are not equally represented. It provides a single metric that balances the trade-off between precision and recall, especially in scenarios where maximizing one metric might lead to a significant drop in the other.\n\n### **Example Calculation**\n\nGiven:\ny_true = [1, 0, 1, 1, 0] \n\n\ny_pred = [1, 0, 0, 1, 1] \n\n1. **Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)**:\n\n    $$\n    \\text{TP} = 2, \\quad \\text{FP} = 1, \\quad \\text{FN} = 1\n    $$\n\n2. **Calculate Precision**:\n\n    $$\n    \\text{Precision} = \\frac{2}{2 + 1} = \\frac{2}{3} \\approx 0.667\n    $$\n\n3. **Calculate Recall**:\n\n    $$\n    \\text{Recall} = \\frac{2}{2 + 1} = \\frac{2}{3} \\approx 0.667\n    $$\n\n4. **Calculate F1 Score**:\n\n    $$\n    \\text{F1 Score} = 2 \\times \\frac{0.667 \\times 0.667}{0.667 + 0.667} = 0.667\n    $$\n\n### **Applications**\n\nThe F1 score is widely used in:\n- Binary classification problems (e.g., spam detection, fraud detection).\n- Multi-class classification problems (evaluated per class and averaged).\n- Information retrieval tasks (e.g., search engines, recommendation systems).\n\nMastering the F1 score is essential for evaluating and comparing the performance of classification models.\n",
        "contributor": [
            {
                "profile_link": "https://github.com/moe18",
                "name": "Moe Chabot"
            }
        ]
    },
    {
        "description": "It is the year 2157. Mars has its first thriving colony, and energy consumption is steadily on the rise. As the lead data scientist, you have daily power usage measurements (10 days) affected by both a growing linear trend and a daily fluctuation. The fluctuation follows the formula fᵢ = 10 x sin(2π x i / 10), where i is the day number (1 through 10). Your challenge is to remove this known fluctuation from each data point, fit a linear regression model to the detrended data, predict day 15's base consumption, add back the fluctuation for day 15, and finally include a 5% safety margin. The final answer must be an integer, ensuring you meet the colony's future needs.",
        "id": "92",
        "test_cases": [
            {
                "test": "print(power_grid_forecast([150, 165, 185, 195, 210, 225, 240, 260, 275, 290]))",
                "expected_output": "404"
            },
            {
                "test": "print(power_grid_forecast([160, 170, 190, 200, 215, 230, 245, 265, 280, 295]))",
                "expected_output": "407"
            },
            {
                "test": "print(power_grid_forecast([140, 158, 180, 193, 205, 220, 237, 255, 270, 288]))",
                "expected_output": "404"
            }
        ],
        "difficulty": "medium",
        "solution": "import math\n\nPI = 3.14159\n\ndef power_grid_forecast(consumption_data):\n    # consumption_data: list of 10 daily consumption values\n    # days: 1 through 10\n    days = list(range(1, 11))\n    n = len(days)\n\n    # 1) Remove daily fluctuation f_i = 10 * sin(2π * i / 10)\n    detrended = []\n    for i, cons in zip(days, consumption_data):\n        fluctuation_i = 10 * math.sin((2 * PI * i) / 10)\n        detrended_value = cons - fluctuation_i\n        detrended.append(detrended_value)\n\n    # 2) Perform linear regression on the detrended data\n    sum_x = sum(days)\n    sum_y = sum(detrended)\n    sum_xy = sum(x * y for x, y in zip(days, detrended))\n    sum_x2 = sum(x**2 for x in days)\n\n    # slope (m) and intercept (b) for y = m*x + b\n    m = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)\n    b = (sum_y - m * sum_x) / n\n\n    # 3) Predict day 15's base usage\n    day_15_base = m * 15 + b\n\n    # 4) Add back daily fluctuation for day 15\n    day_15_fluctuation = 10 * math.sin((2 * PI * 15) / 10)\n    day_15_prediction = day_15_base + day_15_fluctuation\n\n    # 5) Round and add 5% safety margin\n    day_15_rounded = round(day_15_prediction)\n    final_15 = math.ceil(day_15_rounded * 1.05)\n\n    return final_15",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "Daily consumption data for 10 days: [150, 165, 185, 195, 210, 225, 240, 260, 275, 290]",
            "output": "404",
            "reasoning": "For each of the 10 days, we subtract the daily fluctuation given by 10xsin(2πxi/10). We then perform linear regression on the resulting values, predict day 15’s base usage, and add back the day 15 fluctuation. Finally, we apply a 5% margin. Running the provided solution code yields 404 for this dataset."
        },
        "category": "Machine Learning",
        "starter_code": "import math\n\nPI = 3.14159\n\ndef power_grid_forecast(consumption_data):\n\t# 1) Subtract the daily fluctuation (10 * sin(2π * i / 10)) from each data point.\n\t# 2) Perform linear regression on the detrended data.\n\t# 3) Predict day 15's base consumption.\n\t# 4) Add the day 15 fluctuation back.\n\t# 5) Round, then add a 5% safety margin (rounded up).\n\t# 6) Return the final integer.\n\tpass",
        "title": "Linear Regression - Power Grid Optimization",
        "learn_section": "## Balancing Trend and Fluctuation with Math\n\nWhen dealing with time-series data, it's common to see both a long-term trend and periodic fluctuations. In this challenge, the daily fluctuation for day $i$ is given by:\n\n$$\nf_i = 10 \\times \\sin\\left(\\frac{2\\pi \\times i}{10}\\right).\n$$\n\n### Steps to Solve\n\n1. **Fluctuation Removal**: Subtract $f_i$ from each day's consumption to isolate the colony's base usage.\n\n2. **Linear Regression**: Fit a linear model $y = mx + b$ using the detrended values. The slope $m$ and intercept $b$ are calculated using the least squares method:\n\n$$\nm = \\frac{n \\sum(x_i y_i) - (\\sum x_i)(\\sum y_i)}{n \\sum(x_i^2) - (\\sum x_i)^2}, \\quad b = \\frac{\\sum y_i - m \\sum x_i}{n}.\n$$\n\nHere, $n$ is the number of data points (10 in this case).\n\n3. **Forecast**: Use the regression line to predict the base consumption for day 15, $x = 15$:\n\n$$\n\\text{base}_{15} = m \\times 15 + b.\n$$\n\n4. **Add Back Fluctuation**: Compute $f_{15} = 10 \\times \\sin\\left(\\frac{2\\pi \\times 15}{10}\\right)$ and add it to the base prediction:\n\n$$\n\\text{pred}_{15} = \\text{base}_{15} + f_{15}.\n$$\n\n5. **Round and Add Safety Margin**: Round $\\text{pred}_{15}$ to the nearest integer and then apply a 5% upward safety margin to ensure sufficient capacity:\n\n$$\n\\text{final}_{15} = \\lceil 1.05 \\times \\text{round}(\\text{pred}_{15}) \\rceil.\n$$\n\n### Summary\n\nBy following these steps **removing the fluctuation**, **fitting the linear model**, **predicting day 15**'s base consumption, **restoring the fluctuation**, and **applying a safety margin** you'll arrive at a robust energy requirement forecast for the colony's future needs.\n",
        "contributor": [
            {
                "profile_link": "https://groundzeroai.netlify.app/",
                "name": "GroundZero AI"
            }
        ]
    },
    {
        "description": "Implement a function to calculate the Mean Absolute Error (MAE) between two arrays of actual and predicted values. The MAE is a metric used to measure the average magnitude of errors in a set of predictions without considering their direction.",
        "id": "93",
        "test_cases": [
            {
                "test": "print(mae(np.array([3, -0.5, 2, 7]), np.array([2.5, 0.0, 2, 8])))",
                "expected_output": "0.500"
            },
            {
                "test": "print(mae(np.array([[0.5, 1], [-1, 1], [7, -6]]), np.array([[0, 2], [-1, 2], [8, -5]])))",
                "expected_output": "0.750"
            },
            {
                "test": "print(mae(np.array([-1, -2, -3]), np.array([-1.5, -2.2, -2.8])))",
                "expected_output": "0.300"
            },
            {
                "test": "print(mae(np.array([1, -1, 0]), np.array([-1, 1, 0])))",
                "expected_output": "1.333"
            }
        ],
        "difficulty": "easy",
        "solution": "import numpy as np\n\ndef mae(y_true, y_pred):\n    \"\"\"\n    Calculate Mean Absolute Error between two arrays.\n\n    Parameters:\n    y_true (numpy.ndarray): Array of true values\n    y_pred (numpy.ndarray): Array of predicted values\n\n    Returns:\n    float: Mean Absolute Error rounded to 3 decimal places\n    \"\"\"\n    if y_true.shape != y_pred.shape:\n        raise ValueError(\"Arrays must have the same shape\")\n    if y_true.size == 0:\n        raise ValueError(\"Arrays cannot be empty\")\n\n    return round(np.mean(np.abs(y_true - y_pred)), 3)",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "y_true = np.array([3, -0.5, 2, 7]), y_pred = np.array([2.5, 0.0, 2, 8])",
            "output": "0.500",
            "reasoning": "The MAE is calculated by taking the mean of the absolute differences between the predicted and true values. Using the formula, the result is 0.500."
        },
        "category": "Machine Learning",
        "starter_code": "import numpy as np\n\ndef mae(y_true, y_pred):\n\t\"\"\"\n\tCalculate Mean Absolute Error between two arrays.\n\n\tParameters:\n\ty_true (numpy.ndarray): Array of true values\n    y_pred (numpy.ndarray): Array of predicted values\n\n\tReturns:\n\tfloat: Mean Absolute Error rounded to 3 decimal places\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,3)",
        "title": "Calculate Mean Absolute Error (MAE)",
        "learn_section": "## Mean Absolute Error (MAE)\n\nThe Mean Absolute Error (MAE) is a measure of the average magnitude of errors between predicted and actual values. Here's how to express it mathematically:\n\n1. **Basic Formula**:\n   - The MAE formula can be written as: $MAE = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i|$\n\n   Where:\n   - $n$ is the number of observations\n   - $y_i$ is the true value\n   - $\\hat{y}_i$ is the predicted value\n   - $|...|$ represents the absolute value\n\n2. **Example Calculation**:\n   For the values:\n   ```\n   y_true = [3, -0.5, 2, 7]\n   y_pred = [2.5, 0.0, 2, 8]\n   ```\n\n   The calculation would be:\n   $$\n   \\begin{align*}\n   MAE &= \\frac{1}{4}(|3-2.5| + |-0.5-0.0| + |2-2| + |7-8|) \\\\\n   &= \\frac{1}{4}(0.5 + 0.5 + 0 + 1) \\\\\n   &= \\frac{2}{4} \\\\\n   &= 0.5\n   \\end{align*}\n   $$\n\n3. **Properties**:\n   - MAE is always non-negative: $MAE \\geq 0$\n   - Perfect predictions result in $MAE = 0$\n   - MAE is measured in the same units as the original data\n   - MAE treats all errors with equal weight (unlike Mean Squared Error)\n\n4. **Comparison with Other Metrics**:\n   The formula for Mean Squared Error (MSE) is:\n   $$MSE = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2$$\n\n   While MAE uses absolute values, MSE squares the differences, which:\n   - Makes MSE more sensitive to outliers\n   - Results in MSE values that are not in the original unit of measurement",
        "contributor": [
            {
                "profile_link": "https://github.com/rittik9",
                "name": "rittik9"
            }
        ]
    },
    {
        "description": "Implement the multi-head attention mechanism, a critical component of transformer models. Given Query (Q), Key (K), and Value (V) matrices, compute the attention outputs for multiple heads and concatenate the results.",
        "id": "94",
        "test_cases": [
            {
                "test": "m, n = 4, 4\nn_heads = 2\nnp.random.seed(42)\nX = np.arange(m*n).reshape(m,n)\nX = np.random.permutation(X.flatten()).reshape(m, n)\nW_q = np.random.randint(0,4,size=(n,n))\nW_k = np.random.randint(0,5,size=(n,n))\nW_v = np.random.randint(0,6,size=(n,n))\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\nprint(multi_head_attention(Q, K, V, n_heads))",
                "expected_output": "np.array([[103, 109, 46, 99],\n                                [103, 109, 46, 99],\n                                [103, 109, 46, 99],\n                                [103, 109, 46, 99]])"
            },
            {
                "test": "m, n = 6, 8\nn_heads = 4\nnp.random.seed(42)\nX = np.arange(m*n).reshape(m,n)\nX = np.random.permutation(X.flatten()).reshape(m, n)\nW_q = np.random.randint(0,4,size=(n,n))\nW_k = np.random.randint(0,5,size=(n,n))\nW_v = np.random.randint(0,6,size=(n,n))\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\nprint(multi_head_attention(Q, K, V, n_heads))",
                "expected_output": "[[500, 463, 399, 495, 377, 450, 531, 362],\n                                [500, 463, 399, 495, 377, 450, 531, 362],\n                                [500, 463, 399, 495, 377, 450, 531, 362],\n                                [500, 463, 399, 495, 377, 450, 531, 362],\n                                [500, 463, 399, 495, 377, 450, 531, 362],\n                                [500, 463, 399, 495, 377, 450, 531, 362]]"
            },
            {
                "test": "m, n = 6, 8\nn_heads = 2\nnp.random.seed(42)\nX = np.arange(m*n).reshape(m,n)\nX = np.random.permutation(X.flatten()).reshape(m, n)\nW_q = np.random.randint(0,4,size=(n,n))\nW_k = np.random.randint(0,5,size=(n,n))\nW_v = np.random.randint(0,6,size=(n,n))\nQ, K, V = compute_qkv(X, W_q, W_k, W_v)\n\n# test multi-head attention\nactual_output = multi_head_attention(Q, K, V, n_heads)\nprint(actual_output)",
                "expected_output": "[[547, 490, 399, 495, 377, 450, 531, 362],\n                                [547, 490, 399, 495, 377, 450, 531, 362],\n                                [547, 490, 399, 495, 377, 450, 531, 362],\n                                [547, 490, 399, 495, 377, 450, 531, 362],\n                                [547, 490, 399, 495, 377, 450, 531, 362],\n                                [547, 490, 399, 495, 377, 450, 531, 362]]"
            }
        ],
        "difficulty": "hard",
        "solution": "import numpy as np\nfrom typing import Tuple, List\n\ndef compute_qkv(X: np.ndarray, W_q: np.ndarray, W_k: np.ndarray, W_v: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    Compute the Query (Q), Key (K), and Value (V) matrices.\n    \n    Args:\n    X: numpy array of shape (seq_len, d_model), input sequence\n    W_q, W_k, W_v: numpy arrays of shape (d_model, d_model), weight matrices for Q, K, and V\n    \n    Returns:\n    Q, K, V: numpy arrays of shape (seq_len, d_model)\n    \"\"\"\n    Q = np.dot(X, W_q)  # Compute the Query matrix Q\n    K = np.dot(X, W_k)  # Compute the Key matrix K\n    V = np.dot(X, W_v)  # Compute the Value matrix V\n    return Q, K, V\n\ndef self_attention(Q: np.ndarray, K: np.ndarray, V: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute self-attention for a single head.\n    \n    Args:\n    Q: numpy array of shape (seq_len, d_k), Query matrix\n    K: numpy array of shape (seq_len, d_k), Key matrix\n    V: numpy array of shape (seq_len, d_k), Value matrix\n    \n    Returns:\n    attention_output: numpy array of shape (seq_len, d_k), output of the self-attention mechanism\n    \"\"\"\n    d_k = Q.shape[1]  # Get the dimension of the keys\n    scores = np.matmul(Q, K.T) / np.sqrt(d_k)  # Compute scaled dot-product attention scores\n    score_max = np.max(scores, axis=1, keepdims=True)  # Find the maximum score for numerical stability\n    attention_weights = np.exp(scores - score_max) / np.sum(np.exp(scores - score_max), axis=1, keepdims=True)  # Compute softmax to get attention weights\n    attention_output = np.matmul(attention_weights, V)  # Compute the final attention output\n    return attention_output\n\ndef multi_head_attention(Q: np.ndarray, K: np.ndarray, V: np.ndarray, n_heads: int) -> np.ndarray:\n    \"\"\"\n    Compute multi-head attention.\n    \n    Args:\n    Q, K, V: numpy arrays of shape (seq_len, d_model), Query, Key, and Value matrices\n    n_heads: int, number of attention heads\n    \n    Returns:\n    attention_output: numpy array of shape (seq_len, d_model), final attention output\n    \"\"\"\n    d_model = Q.shape[1]  # Get the model dimension\n    assert d_model % n_heads == 0  # Ensure d_model is divisible by n_heads\n    d_k = d_model // n_heads  # Dimension for each head\n\n    # Reshape Q, K, V to separate heads\n    Q_reshaped = Q.reshape(Q.shape[0], n_heads, d_k).transpose(1, 0, 2)  # Reshape and transpose to (n_heads, seq_len, d_k)\n    K_reshaped = K.reshape(K.shape[0], n_heads, d_k).transpose(1, 0, 2)  # Reshape and transpose to (n_heads, seq_len, d_k)\n    V_reshaped = V.reshape(V.shape[0], n_heads, d_k).transpose(1, 0, 2)  # Reshape and transpose to (n_heads, seq_len, d_k)\n\n    # Compute attention scores for each head\n    attentions = []  # Store attention outputs for each head\n\n    for i in range(n_heads):\n        attn = self_attention(Q_reshaped[i], K_reshaped[i], V_reshaped[i])  # Compute attention for the i-th head\n        attentions.append(attn)  # Collect attention output\n\n    # Concatenate all head outputs\n    attention_output = np.concatenate(attentions, axis=-1)  # Concatenate along the last axis (columns)\n    return attention_output  # Return the final attention output",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "Q = np.array([[1, 0], [0, 1]]), K = np.array([[1, 0], [0, 1]]), V = np.array([[1, 0], [0, 1]]), n_heads = 2",
            "output": "[[1., 0.], [0., 1.]]",
            "reasoning": "Multi-head attention is computed for 2 heads using the input Q, K, and V matrices. The resulting outputs for each head are concatenated to form the final attention output."
        },
        "category": "Deep Learning",
        "starter_code": "import numpy as np\n\ndef compute_qkv(X, W_q, W_k, W_v):\n\tpass\n\ndef self_attention(Q, K, V):\n\tpass\n\ndef multi_head_attention(Q, K, V, n_heads):\n\tpass",
        "title": "Implement Multi-Head Attention",
        "learn_section": "## Understanding Multi-Head Attention\n\nMulti-head attention is a fundamental mechanism in transformer models, allowing the model to focus on different parts of the input sequence simultaneously. This enables the model to capture a wider variety of relationships and dependencies, which is crucial for handling complex data, such as natural language. By using multiple attention heads, the model learns to attend to various aspects of the input at different levels of abstraction, enhancing its ability to capture complex relationships.\n\n### Concepts\n\nThe attention mechanism allows the model to weigh the importance of different input elements based on their relevance to a specific task. In tasks like machine translation, for example, attention helps the model focus on relevant words in a sentence to understand the overall meaning. Multi-head attention extends this concept by using multiple attention heads, each learning different representations of the input data, which improves the model's ability to capture richer relationships and dependencies.\n\nThe process of multi-head attention involves several key steps:\n\n1. **Computing Attention Scores:** This involves calculating how much focus each element in the input should receive based on its relationship with other elements.\n2. **Applying Softmax:** The attention scores are transformed into probabilities using the softmax function, which normalizes the scores so that they sum to one.\n3. **Aggregating Results:** The final output is computed by taking a weighted sum of the input values, where the weights are determined by the attention scores.\n\n### Structure of Multi-Head Attention\n\nThe attention mechanism can be described with Query (Q), Key (K), and Value (V) matrices. The process of multi-head attention works by repeating the standard attention mechanism multiple times in parallel, with different sets of learned weight matrices for each attention head.\n\n#### 1. Splitting Q, K, and V\n\nAssume that the input Query (Q), Key (K), and Value (V) matrices have dimensions $(\\text{seqLen}, d_{model})$, where $d_{\\text{model}}$ is the model dimension. In multi-head attention, these matrices are divided into n smaller matrices, each corresponding to a different attention head. Each smaller matrix has dimensions $(\\text{seqLen}, d_k)$, where $d_k = \\frac{d_{\\text{model}}}{n}$ is the dimensionality of each head.\n\nFor each attention $\\text{head}_i$, we get its subset of Query $\\text{Q}_i$, Key $\\text{K}_i$, and Value $\\text{V}_i$. These subsets are computed independently for each head.\n\n#### 2. Computing Attention for Each Head\n\nEach head independently computes its attention output. The calculation is similar to the single-head attention mechanism:\n\n$$\n\\text{score}_i = \\frac{Q_i K_i^T}{\\sqrt{d_k}}\n$$\n\nWhere $$d_k$$ is the dimensionality of the key space for each head. The scaling factor $$\\frac{1}{\\sqrt{d_k}}$$ ensures the dot product doesn't grow too large, preventing instability in the softmax function.\n\nThe softmax function is applied to the scores to normalize them, transforming them into attention weights for each head:\n\n$$\n\\text{SoftmaxScore}_i = \\text{softmax}(\\text{score}_i)\n$$\n\n#### 3. Softmax Calculation and Numerical Stability\n\nWhen computing the softmax function, especially in the context of attention mechanisms, there's a risk of numerical overflow or underflow, which can occur when the attention scores become very large or very small. This issue arises because the exponential function $$\\exp$$ grows very quickly, and when dealing with large numbers, it can result in values that are too large for the computer to handle, leading to overflow errors.\n\nTo prevent this, we apply a common technique: subtracting the maximum score from each attention score before applying the exponential function. This helps to ensure that the largest value in the attention scores becomes zero, reducing the likelihood of overflow. Here's how it's done:\n\n$$\n\\text{SoftmaxScore} = \\frac{\\exp(\\text{score} - \\text{score}_{\\text{max}})}{\\sum\\exp(\\text{score} - \\text{score}_{\\text{max}})}\n$$\n\nWhere $$\\text{score}_{i,\\text{max}}$$ is the maximum value of the attention scores for the \\(i\\)-th head. Subtracting the maximum score from each individual score ensures that the largest value becomes 0, which prevents the exponentials from becoming too large.\n\nThis subtraction does not affect the final result of the softmax calculation because the softmax is a relative function it's the ratios of the exponentials that matter. Therefore, this adjustment ensures numerical stability while maintaining the correctness of the computation.\n\nTo summarize, when computing softmax in multi-head attention:\n\n- Subtract the maximum score from each attention score before applying the exponential function.\n- This technique prevents overflow by ensuring that the largest value becomes 0, which keeps the exponential values within a manageable range.\n- The relative relationships between the scores remain unchanged, so the softmax output remains correct.\n\nBy applying this numerical stability trick, the softmax function becomes more robust and prevents computational issues that could arise during training or inference, especially when dealing with large models or sequences.\n\nFinally, the attention output for each $$\\text{head}_i$$ is computed as:\n\n$$\n\\text{head}_i = \\text{SoftmaxScore}_i \\cdot V_i\n$$\n\n#### 4. Concatenation and Linear Transformation\n\nAfter computing the attention output for each head, the outputs are concatenated along the feature dimension. This results in a matrix of dimensions $$(\\text{seqLen}, d_{\\text{model}})$$, where the concatenated attention outputs are passed through a final linear transformation to obtain the final multi-head attention output.\n\n$$\n\\text{MultiHeadOutput} = \\text{concat}(\\text{head}_1, \\text{head}_2, \\dots, \\text{head}_n)\n$$\n\nThe concatenated result is then linearly transformed using a weight matrix $W_{\\text{o}}$ to obtain the final output. However, in our case, obtaining the multi-head attention output without this final transformation is sufficient:\n\n$$\n\\text{MultiHeadOutput} = W_o \\cdot \\text{MultiHeadOutput}\n$$\n\n### Key Points\n\n- Each attention head processes the input independently using its own set of learned weights. This allows each head to focus on different relationships in the data.\n- Each head calculates its attention scores based on its corresponding Query, Key, and Value matrices, producing different attention outputs.\n- The outputs of all attention heads are concatenated to form a unified representation. This concatenated result is then linearly transformed to generate the final output.\n\nMulti-head attention allows the model to attend to different aspects of the input sequence in parallel, making it more capable of learning complex and diverse relationships. This parallelization of attention heads enhances the model's ability to understand the data from multiple angles simultaneously, contributing to improved performance in tasks like machine translation, text generation, and more.",
        "contributor": [
            {
                "profile_link": "https://github.com/nzomi",
                "name": "nzomi"
            }
        ]
    },
    {
        "description": "Implement a function to calculate the Phi coefficient, a measure of the correlation between two binary variables. The function should take two lists of integers (0s and 1s) as input and return the Phi coefficient rounded to 4 decimal places.",
        "id": "95",
        "test_cases": [
            {
                "test": "print(phi_corr([1, 1, 0, 0], [0, 0, 1, 1]))",
                "expected_output": "-1.0"
            },
            {
                "test": "print(phi_corr([1, 1, 0, 0], [1, 0, 1, 1]))",
                "expected_output": "-0.5774"
            },
            {
                "test": "print(phi_corr([0, 0, 1, 1], [0, 1, 0, 1]))",
                "expected_output": "0.0"
            },
            {
                "test": "print(phi_corr([1, 0, 1, 0,1,1,0], [1, 1, 0, 0,1,1,1]))",
                "expected_output": "0.0913"
            }
        ],
        "difficulty": "easy",
        "solution": "def phi_corr(x: list[int], y: list[int]) -> float:\n    \"\"\"\n    Calculate the Phi coefficient between two binary variables.\n\n    Args:\n    x (list[int]): A list of binary values (0 or 1).\n    y (list[int]): A list of binary values (0 or 1).\n\n    Returns:\n    float: The Phi coefficient rounded to 4 decimal places.\n    \"\"\"\n    x1y1 = x1y0 = x0y1 = x0y0 = 0\n\n    # Count occurrences\n    for i in range(len(x)):\n        if x[i] == 1:\n            if y[i] == 1:\n                x1y1 += 1\n            else:\n                x1y0 += 1\n        elif x[i] == 0:\n            if y[i] == 1:\n                x0y1 += 1\n            else:\n                x0y0 += 1\n\n    # Calculate numerator and denominator\n    numerator = (x0y0 * x1y1) - (x0y1 * x1y0)\n    denominator = ((x0y0 + x0y1) * (x1y0 + x1y1) * (x0y0 + x1y0) * (x0y1 + x1y1)) ** 0.5\n\n    if denominator == 0:\n        return 0.0\n\n    phi = numerator / denominator\n    return round(phi, 4)",
        "likes": "0",
        "video": "https://youtu.be/z0A4peJnJOs",
        "dislikes": "0",
        "example": {
            "input": "phi_corr([1, 1, 0, 0], [0, 0, 1, 1])",
            "output": "-1.0",
            "reasoning": "The Phi coefficient measures the correlation between two binary variables. In this example, the variables have a perfect negative correlation, resulting in a Phi coefficient of -1.0."
        },
        "category": "Statistics",
        "starter_code": "def phi_corr(x: list[int], y: list[int]) -> float:\n\t\"\"\"\n\tCalculate the Phi coefficient between two binary variables.\n\n\tArgs:\n\tx (list[int]): A list of binary values (0 or 1).\n\ty (list[int]): A list of binary values (0 or 1).\n\n\tReturns:\n\tfloat: The Phi coefficient rounded to 4 decimal places.\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,4)",
        "title": "Calculate the Phi Coefficient",
        "learn_section": "# The Phi coefficient\n\nThe Phi coefficient is a type of correlation coefficient , which is used when we need to find the correlation between two binary variables.\nFor example when we have two variables x and y , x being gender and y signifying the presence of heart disease. \nBoth variables are binary and if we need to find a correlation between x and y then we can use the formula below :\n\n\n$\\phi = \\frac{(x_{00} \\cdot x_{11}) - (x_{01} \\cdot x_{10})}{\\sqrt{(x_{00} + x_{01})(x_{10} + x_{11})(x_{00} + x_{10})(x_{01} + x_{11})}}$\n\n\n\n\n### Explanation of Terms:\n- \\(x_00\\): The number of cases where \\(x = 0\\) and \\(y = 0\\).\n- \\(x_01\\): The number of cases where \\(x = 0\\) and \\(y = 1\\).\n- \\(x_10\\): The number of cases where \\(x = 1\\) and \\(y = 0\\).\n- \\(x_11\\): The number of cases where \\(x = 1\\) and \\(y = 1\\).",
        "contributor": [
            {
                "profile_link": "https://github.com/Noth2006",
                "name": "Noth2006"
            },
            {
                "profile_link": "https://github.com/Selbl",
                "name": "Selbl"
            }
        ]
    },
    {
        "description": "Implement the Hard Sigmoid activation function, a computationally efficient approximation of the standard sigmoid function. Your function should take a single input value and return the corresponding output based on the Hard Sigmoid definition.",
        "id": "96",
        "test_cases": [
            {
                "test": "print(hard_sigmoid(.56))",
                "expected_output": "0.612"
            },
            {
                "test": "print(hard_sigmoid(3.0))",
                "expected_output": "1.0"
            },
            {
                "test": "print(hard_sigmoid(0.0))",
                "expected_output": "0.5"
            },
            {
                "test": "print(hard_sigmoid(1.0))",
                "expected_output": "0.7"
            },
            {
                "test": "print(hard_sigmoid(-1.0))",
                "expected_output": "0.3"
            },
            {
                "test": "print(hard_sigmoid(2.5))",
                "expected_output": "1.0"
            },
            {
                "test": "print(hard_sigmoid(-2.5))",
                "expected_output": "0.0"
            }
        ],
        "difficulty": "easy",
        "solution": "def hard_sigmoid(x: float) -> float:\n    \"\"\"\n    Implements the Hard Sigmoid activation function.\n\n    Args:\n        x (float): Input value\n\n    Returns:\n        float: The Hard Sigmoid of the input\n    \"\"\"\n    if x <= -2.5:\n        return 0.0\n    elif x >= 2.5:\n        return 1.0\n    else:\n        return 0.2 * x + 0.5",
        "marimo_link": "https://open-deep-ml.github.io/deepml-notebooks/96/",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "hard_sigmoid(0.0)",
            "output": "0.5",
            "reasoning": "The input 0.0 falls in the linear region of the Hard Sigmoid function. Using the formula $HardSigmoid(x) = 0.2x + 0.5$, the output is $0.2 \\times 0.0 + 0.5 = 0.5$."
        },
        "category": "Deep Learning",
        "starter_code": "def hard_sigmoid(x: float) -> float:\n\t\"\"\"\n\tImplements the Hard Sigmoid activation function.\n\n\tArgs:\n\t\tx (float): Input value\n\n\tReturns:\n\t\tfloat: The Hard Sigmoid of the input\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Implement the Hard Sigmoid Activation Function",
        "learn_section": "## Understanding the Hard Sigmoid Activation Function\n\nThe Hard Sigmoid is a piecewise linear approximation of the sigmoid activation function. It's computationally more efficient than the standard sigmoid function while maintaining similar characteristics. This function is particularly useful in neural networks where computational efficiency is crucial.\n\n### Mathematical Definition\n\nThe Hard Sigmoid function is mathematically defined as:\n\n$$\nHardSigmoid(x) = \\begin{cases} \n0 & \\text{if } x \\leq -2.5 \\\\ \n0.2x + 0.5 & \\text{if } -2.5 < x < 2.5 \\\\ \n1 & \\text{if } x \\geq 2.5 \n\\end{cases}\n$$\n\nWhere $x$ is the input to the function.\n\n### Characteristics\n\n- **Output Range:** The output is always bounded in the range $[0, 1]$\n- **Shape:** The function consists of three parts:\n  - A constant value of 0 for inputs <= -2.5\n  - A linear segment with slope 0.2 for inputs between -2.5 and 2.5\n  - A constant value of 1 for inputs >= 2.5\n- **Gradient:** The gradient is 0.2 in the linear region and 0 in the saturated regions\n\n### Advantages in Neural Networks\n\nThis function is particularly useful in neural networks as it provides:\n- Computational efficiency compared to standard sigmoid\n- Bounded output range similar to sigmoid\n- Simple gradient computation",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    },
    {
        "description": "Implement the ELU (Exponential Linear Unit) activation function, which helps mitigate the limitations of ReLU by providing negative outputs for negative inputs. The function should compute the ELU activation value for a given input.",
        "id": "97",
        "test_cases": [
            {
                "test": "print(elu(0))",
                "expected_output": "0.0"
            },
            {
                "test": "print(elu(1))",
                "expected_output": "1.0"
            },
            {
                "test": "print(elu(-1))",
                "expected_output": "-0.6321"
            },
            {
                "test": "print(elu(-1, alpha=2.0))",
                "expected_output": "-1.2642"
            },
            {
                "test": "print(elu(5))",
                "expected_output": "5.0"
            },
            {
                "test": "print(elu(-5))",
                "expected_output": "-0.9933"
            }
        ],
        "difficulty": "easy",
        "solution": "import math\n\ndef elu(x: float, alpha: float = 1.0) -> float:\n    \"\"\"\n    Compute the ELU activation function.\n\n    Args:\n        x (float): Input value\n        alpha (float): ELU parameter for negative values (default: 1.0)\n\n    Returns:\n        float: ELU activation value\n    \"\"\"\n    return round(x if x > 0 else alpha * (math.exp(x) - 1),4)",
        "marimo_link": "https://open-deep-ml.github.io/deepml-notebooks/97/",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "elu(-1)",
            "output": "-0.6321",
            "reasoning": "For x = -1 and alpha = 1.0, the ELU activation is computed as $\\alpha(e^x - 1)$."
        },
        "category": "Deep Learning",
        "starter_code": "def elu(x: float, alpha: float = 1.0) -> float:\n\t\"\"\"\n\tCompute the ELU activation function.\n\n\tArgs:\n\t\tx (float): Input value\n\t\talpha (float): ELU parameter for negative values (default: 1.0)\n\n\tReturns:\n\t\tfloat: ELU activation value\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,4)",
        "title": "Implement the ELU Activation Function",
        "learn_section": "## Understanding the ELU Activation Function\n\nThe ELU (Exponential Linear Unit) activation function is an advanced activation function that addresses some limitations of ReLU by providing negative values for negative inputs, which can help prevent the \"dying ReLU\" problem and speed up learning.\n\n### Mathematical Definition\n\nThe ELU function is mathematically defined as:\n\n$$\nELU(x) = \\begin{cases} \nx & \\text{if } x > 0 \\\\\n\\alpha(e^x - 1) & \\text{otherwise}\n\\end{cases}\n$$\n\nWhere:\n- $x$ is the input to the function\n- $\\alpha$ is a hyperparameter (typically set to 1.0) that controls the value to which an ELU saturates for negative inputs\n- $e$ is the base of natural logarithms (Euler's number)\n\n### Characteristics\n\n- **Output Range:** The output is in the range $[-\\alpha, \\infty)$. For positive inputs, it behaves like the identity function, while for negative inputs, it has a smooth exponential curve that approaches -alpha.\n- **Smoothness:** Unlike ReLU, ELU is smooth everywhere, including at x = 0, which can lead to faster learning.\n- **Gradient:** The gradient is 1 for positive values and $\\alpha e^x$ for negative values, providing non-zero gradients for negative inputs.\n\n### Advantages\n\n1. Reduces the vanishing gradient problem\n2. Can produce negative outputs, allowing the function to push mean unit activations closer to zero\n3. Smoother gradient flow compared to ReLU\n4. Better handling of noise in the data due to the bounded negative part\n\n### Visual Comparison with ReLU\n\nWhile ReLU simply outputs zero for all negative inputs, ELU provides a smooth negative response:\n\n- For x > 0: Both ReLU and ELU output x\n- For x <= 0: \n  - ReLU outputs 0\n  - ELU outputs $\\alpha(e^x - 1)$, which smoothly approaches -alpha\n\nELU is particularly useful in deep neural networks where you want to maintain some of the benefits of ReLU while addressing its limitations regarding negative inputs.",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    },
    {
        "description": "Implement the PReLU (Parametric ReLU) activation function, a variant of the ReLU activation function that introduces a learnable parameter for negative inputs. Your task is to compute the PReLU activation value for a given input.",
        "id": "98",
        "test_cases": [
            {
                "test": "print(prelu(2.0))",
                "expected_output": "2.0"
            },
            {
                "test": "print(prelu(0.0))",
                "expected_output": "0.0"
            },
            {
                "test": "print(prelu(-2.0))",
                "expected_output": "-0.5"
            },
            {
                "test": "print(prelu(-2.0, alpha=0.1))",
                "expected_output": "-0.2"
            },
            {
                "test": "print(prelu(-2.0, alpha=1.0))",
                "expected_output": "-2.0"
            }
        ],
        "difficulty": "easy",
        "solution": "def prelu(x: float, alpha: float = 0.25) -> float:\n    \"\"\"\n    Implements the PReLU (Parametric ReLU) activation function.\n\n    Args:\n        x: Input value\n        alpha: Slope parameter for negative values (default: 0.25)\n\n    Returns:\n        float: PReLU activation value\n    \"\"\"\n    return x if x > 0 else alpha * x",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-98",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "prelu(-2.0, alpha=0.25)",
            "output": "-0.5",
            "reasoning": "For x = -2.0 and alpha = 0.25, the PReLU activation is calculated as $PReLU(x) = \\alpha x = 0.25 \\times -2.0 = -0.5$."
        },
        "category": "Deep Learning",
        "starter_code": "def prelu(x: float, alpha: float = 0.25) -> float:\n\t\"\"\"\n\tImplements the PReLU (Parametric ReLU) activation function.\n\n\tArgs:\n\t\tx: Input value\n\t\talpha: Slope parameter for negative values (default: 0.25)\n\n\tReturns:\n\t\tfloat: PReLU activation value\n\t\"\"\"\n\t# Your code here\n\tpass",
        "title": "Implement the PReLU Activation Function",
        "learn_section": "### Understanding the PReLU (Parametric ReLU) Activation Function\n\nThe PReLU (Parametric Rectified Linear Unit) is an advanced variant of the ReLU activation function that introduces a learnable parameter for negative inputs. This makes it more flexible than standard ReLU and helps prevent the \"dying ReLU\" problem.\n\n#### Mathematical Definition\n\nThe PReLU function is defined as:\n\n$$\nPReLU(x) = \\begin{cases}\nx & \\text{if } x > 0 \\\\\n\\alpha x & \\text{otherwise}\n\\end{cases}\n$$\n\nWhere:\n- $x$ is the input value\n- $\\alpha$ is a learnable parameter (typically initialized to a small value like 0.25)\n\n#### Key Characteristics\n\n1. **Adaptive Slope**: Unlike ReLU which has a zero slope for negative inputs, PReLU learns the optimal negative slope parameter ($\\alpha$) during training.\n\n2. **Output Range**: \n   - For $x > 0$: Output equals input ($y = x$)\n   - For $x \\leq 0$: Output is scaled by $\\alpha$ ($y = \\alpha x$)\n\n3. **Advantages**:\n   - Helps prevent the \"dying ReLU\" problem\n   - More flexible than standard ReLU\n   - Can improve model performance through learned parameter\n   - Maintains the computational efficiency of ReLU\n\n4. **Special Cases**:\n   - When $\\alpha = 0$, PReLU becomes ReLU\n   - When $\\alpha = 1$, PReLU becomes a linear function\n   - When $\\alpha$ is small (e.g., 0.01), PReLU behaves similarly to Leaky ReLU\n\nPReLU is particularly useful in deep neural networks where the optimal negative slope might vary across different layers or channels.",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    },
    {
        "description": "Implement the Softplus activation function, a smooth approximation of the ReLU function. Your task is to compute the Softplus value for a given input, handling edge cases to prevent numerical overflow or underflow.",
        "id": "99",
        "test_cases": [
            {
                "test": "print(softplus(0))",
                "expected_output": "0.6931"
            },
            {
                "test": "print(softplus(100))",
                "expected_output": "100.0"
            },
            {
                "test": "print(softplus(-100))",
                "expected_output": "0.0"
            },
            {
                "test": "print(softplus(2))",
                "expected_output": "2.1269"
            },
            {
                "test": "print(softplus(-2))",
                "expected_output": "0.1269"
            }
        ],
        "difficulty": "easy",
        "solution": "import math\n\ndef softplus(x: float) -> float:\n    \"\"\"\n    Compute the softplus activation function.\n\n    Args:\n        x: Input value\n\n    Returns:\n        The softplus value: log(1 + e^x)\n    \"\"\"\n    # To prevent overflow for large positive values\n    if x > 100:\n        return x\n    # To prevent underflow for large negative values\n    if x < -100:\n        return 0.0\n\n    return round (math.log(1.0 + math.exp(x)),4)",
        "marimo_link": "https://open-deep-ml.github.io/DML-OpenProblem/problem-99",
        "video": "",
        "likes": "0",
        "dislikes": "0",
        "example": {
            "input": "softplus(2)",
            "output": "2.1269",
            "reasoning": "For x = 2, the Softplus activation is calculated as $\\log(1 + e^x)$."
        },
        "category": "Deep Learning",
        "starter_code": "def softplus(x: float) -> float:\n\t\"\"\"\n\tCompute the softplus activation function.\n\n\tArgs:\n\t\tx: Input value\n\n\tReturns:\n\t\tThe softplus value: log(1 + e^x)\n\t\"\"\"\n\t# Your code here\n\tpass\n\t return round(val,4)",
        "title": "Implement the Softplus Activation Function",
        "learn_section": "### Understanding the Softplus Activation Function\n\nThe Softplus activation function is a smooth approximation of the ReLU function. It's used in neural networks where a smoother transition around zero is desired. Unlike ReLU which has a sharp transition at x=0, Softplus provides a more gradual change.\n\n### Mathematical Definition\n\nThe Softplus function is mathematically defined as:\n\n$$\nSoftplus(x) = \\log(1 + e^x)\n$$\n\nWhere:\n- $x$ is the input to the function\n- $e$ is Euler's number (approximately 2.71828)\n- $\\log$ is the natural logarithm\n\n### Characteristics\n\n1. **Output Range**: \n   - The output is always positive: $(0, \\infty)$\n   - Unlike ReLU, Softplus never outputs exactly zero\n\n2. **Smoothness**:\n   - Softplus is continuously differentiable\n   - The transition around x=0 is smooth, unlike ReLU's sharp \"elbow\"\n\n3. **Relationship to ReLU**:\n   - Softplus can be seen as a smooth approximation of ReLU\n   - As x becomes very negative, Softplus approaches 0\n   - As x becomes very positive, Softplus approaches x\n\n4. **Derivative**:\n   - The derivative of Softplus is the logistic sigmoid function:\n   $$\n   \\frac{d}{dx}Softplus(x) = \\frac{1}{1 + e^{-x}}\n   $$\n\n### Use Cases\n- When smooth gradients are important for optimization\n- In neural networks where a continuous approximation of ReLU is needed\n- Situations where strictly positive outputs are required with smooth transitions",
        "contributor": [
            {
                "profile_link": "https://github.com/Haleshot",
                "name": "Haleshot"
            }
        ]
    }
]